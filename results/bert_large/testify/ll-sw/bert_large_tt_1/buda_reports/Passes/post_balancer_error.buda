{
    "graph": {},
    "nodes": {
        "_fused_op_0": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_0.1 (port_0) ublock_order(c)",
                "Data: layernorm_0.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: pybuda_6_i0 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "dc.input_tensor.layernorm_0.1": "Data",
                "layernorm_0.dc.reduce_sum.0.lc1": "Data",
                "pybuda_6_i0": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_0.1",
                "layernorm_0.dc.reduce_sum.0.lc1",
                "pybuda_6_i0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_0",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_0.dc.multiply.4 (port_0)",
                "Data: buffer_1_29655_29656 (port_0)",
                "Data: layernorm_0.dc.multiply.4 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_0.dc.multiply.4",
                "buffer_1_29655_29656",
                "layernorm_0.dc.multiply.4"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_0.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_0.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29655
        },
        "_fused_op_1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_0.6 (port_0) ublock_order(r)",
                "Data: layernorm_0.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_0.8 (port_2) ublock_order(r)",
                "Data: buffer_0_29655_29656 (port_3) ublock_order(r)",
                "Data: bert.embeddings.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.embeddings.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.embeddings.LayerNorm.bias": "Data",
                "bert.embeddings.LayerNorm.weight": "Data",
                "buffer_0_29655_29656": "Data",
                "dc.input_tensor.layernorm_0.6": "Data",
                "dc.input_tensor.layernorm_0.8": "Data",
                "layernorm_0.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_0.6",
                "layernorm_0.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_0.8",
                "buffer_0_29655_29656",
                "bert.embeddings.LayerNorm.weight",
                "bert.embeddings.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_1",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_4 (port_0)",
                "Data: matmul_10 (port_0)",
                "Data: matmul_28 (port_0)",
                "Data: add_43 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_4",
                "matmul_10",
                "matmul_28",
                "add_43"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_0.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_0.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_0.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_0.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_0.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_0.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_0.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29656
        },
        "_fused_op_10": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_9 (port_0) ublock_order(c)",
                "Data: softmax_77.dc.reduce_max.0 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_9": "Data",
                "softmax_77.dc.reduce_max.0": "Data"
            },
            "input_nodes": [
                "_fused_op_9",
                "softmax_77.dc.reduce_max.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_10",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_77.dc.reduce_sum.3.lc1 (port_0)",
                "Data: _fused_op_11 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_77.dc.reduce_sum.3.lc1",
                "_fused_op_11"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_77.dc.subtract.1: subtract (1,16,12,12), out: 0",
                    "softmax_77.dc.exp.2: exp (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 29665
        },
        "_fused_op_100": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_762 (port_0) ublock_order(r)",
                "Data: input_1_multiply_764 (port_1) ublock_order(r)",
                "Data: multiply_22_attempt_1_input_op_fork_nop1 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "input_1_multiply_764": "Data",
                "matmul_762": "Data",
                "multiply_22_attempt_1_input_op_fork_nop1": "Data"
            },
            "input_nodes": [
                "matmul_762",
                "input_1_multiply_764",
                "multiply_22_attempt_1_input_op_fork_nop1"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_100",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_766.dc.reduce_max.0 (port_0)",
                "Data: _fused_op_101 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_766.dc.reduce_max.0",
                "_fused_op_101"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "multiply_764: multiply (1,16,12,12), out: 0",
                    "add_765: add (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "add"
            },
            "type": "fused_op",
            "unique_id": 29755
        },
        "_fused_op_101": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_100 (port_0) ublock_order(c)",
                "Data: softmax_766.dc.reduce_max.0 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_100": "Data",
                "softmax_766.dc.reduce_max.0": "Data"
            },
            "input_nodes": [
                "_fused_op_100",
                "softmax_766.dc.reduce_max.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_101",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_766.dc.reduce_sum.3.lc1 (port_0)",
                "Data: buffer_0_29756_29757 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_766.dc.reduce_sum.3.lc1",
                "buffer_0_29756_29757"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_766.dc.subtract.1: subtract (1,16,12,12), out: 0",
                    "softmax_766.dc.exp.2: exp (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 29756
        },
        "_fused_op_102": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: softmax_766.dc.reduce_sum.3.lc1 (port_0) ublock_order(r)",
                "Data: dc.input_tensor.softmax_766.4 (port_1) ublock_order(r)",
                "Data: buffer_0_29756_29757 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_29756_29757": "Data",
                "dc.input_tensor.softmax_766.4": "Data",
                "softmax_766.dc.reduce_sum.3.lc1": "Data"
            },
            "input_nodes": [
                "softmax_766.dc.reduce_sum.3.lc1",
                "dc.input_tensor.softmax_766.4",
                "buffer_0_29756_29757"
            ],
            "input_tms": [
                [],
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_102",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_777 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_777"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_766.dc.add.5: add (1,16,12,1), out: 0",
                    "softmax_766.dc.reciprocal.6: reciprocal (1,16,12,1), out: 0",
                    "softmax_766.dc.multiply.7: multiply (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 29757
        },
        "_fused_op_103": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_786.1 (port_0) ublock_order(c)",
                "Data: layernorm_786.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: buffer_0_28656_29758 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_28656_29758": "Data",
                "dc.input_tensor.layernorm_786.1": "Data",
                "layernorm_786.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_786.1",
                "layernorm_786.dc.reduce_sum.0.lc1",
                "buffer_0_28656_29758"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_103",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_786.dc.multiply.4 (port_0)",
                "Data: buffer_2_29758_29759 (port_0)",
                "Data: layernorm_786.dc.multiply.4 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_786.dc.multiply.4",
                "buffer_2_29758_29759",
                "layernorm_786.dc.multiply.4"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_786.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_786.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29758
        },
        "_fused_op_104": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_786.6 (port_0) ublock_order(r)",
                "Data: layernorm_786.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_786.8 (port_2) ublock_order(r)",
                "Data: buffer_0_29758_29759 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.14.attention.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.14.attention.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.14.attention.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.14.attention.output.LayerNorm.weight": "Data",
                "buffer_0_29758_29759": "Data",
                "dc.input_tensor.layernorm_786.6": "Data",
                "dc.input_tensor.layernorm_786.8": "Data",
                "layernorm_786.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_786.6",
                "layernorm_786.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_786.8",
                "buffer_0_29758_29759",
                "bert.encoder.layer.14.attention.output.LayerNorm.weight",
                "bert.encoder.layer.14.attention.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_104",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_789 (port_0)",
                "Data: add_799 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_789",
                "add_799"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_786.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_786.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_786.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_786.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_786.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_786.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_786.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29759
        },
        "_fused_op_105": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_800.1 (port_0) ublock_order(c)",
                "Data: layernorm_800.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: buffer_0_28688_29760 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_28688_29760": "Data",
                "dc.input_tensor.layernorm_800.1": "Data",
                "layernorm_800.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_800.1",
                "layernorm_800.dc.reduce_sum.0.lc1",
                "buffer_0_28688_29760"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_105",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_800.dc.multiply.4 (port_0)",
                "Data: buffer_1_29760_29761 (port_0)",
                "Data: layernorm_800.dc.multiply.4 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_800.dc.multiply.4",
                "buffer_1_29760_29761",
                "layernorm_800.dc.multiply.4"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_800.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_800.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29760
        },
        "_fused_op_106": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_800.6 (port_0) ublock_order(r)",
                "Data: layernorm_800.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_800.8 (port_2) ublock_order(r)",
                "Data: buffer_0_29760_29761 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.14.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.14.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.14.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.14.output.LayerNorm.weight": "Data",
                "buffer_0_29760_29761": "Data",
                "dc.input_tensor.layernorm_800.6": "Data",
                "dc.input_tensor.layernorm_800.8": "Data",
                "layernorm_800.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_800.6",
                "layernorm_800.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_800.8",
                "buffer_0_29760_29761",
                "bert.encoder.layer.14.output.LayerNorm.weight",
                "bert.encoder.layer.14.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_106",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_803 (port_0)",
                "Data: matmul_809 (port_0)",
                "Data: matmul_823 (port_0)",
                "Data: add_838 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_803",
                "matmul_809",
                "matmul_823",
                "add_838"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_800.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_800.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_800.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_800.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_800.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_800.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_800.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29761
        },
        "_fused_op_107": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_815 (port_0) ublock_order(r)",
                "Data: input_1_multiply_817 (port_1) ublock_order(r)",
                "Data: multiply_22_attempt_1_input_op_fork_nop1 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "input_1_multiply_817": "Data",
                "matmul_815": "Data",
                "multiply_22_attempt_1_input_op_fork_nop1": "Data"
            },
            "input_nodes": [
                "matmul_815",
                "input_1_multiply_817",
                "multiply_22_attempt_1_input_op_fork_nop1"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_107",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_819.dc.reduce_max.0 (port_0)",
                "Data: _fused_op_108 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_819.dc.reduce_max.0",
                "_fused_op_108"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "multiply_817: multiply (1,16,12,12), out: 0",
                    "add_818: add (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "add"
            },
            "type": "fused_op",
            "unique_id": 29762
        },
        "_fused_op_108": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_107 (port_0) ublock_order(c)",
                "Data: softmax_819.dc.reduce_max.0 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_107": "Data",
                "softmax_819.dc.reduce_max.0": "Data"
            },
            "input_nodes": [
                "_fused_op_107",
                "softmax_819.dc.reduce_max.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_108",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_819.dc.reduce_sum.3.lc1 (port_0)",
                "Data: _fused_op_109 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_819.dc.reduce_sum.3.lc1",
                "_fused_op_109"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_819.dc.subtract.1: subtract (1,16,12,12), out: 0",
                    "softmax_819.dc.exp.2: exp (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 29763
        },
        "_fused_op_109": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: softmax_819.dc.reduce_sum.3.lc1 (port_0) ublock_order(r)",
                "Data: dc.input_tensor.softmax_819.4 (port_1) ublock_order(r)",
                "Data: _fused_op_108 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_108": "Data",
                "dc.input_tensor.softmax_819.4": "Data",
                "softmax_819.dc.reduce_sum.3.lc1": "Data"
            },
            "input_nodes": [
                "softmax_819.dc.reduce_sum.3.lc1",
                "dc.input_tensor.softmax_819.4",
                "_fused_op_108"
            ],
            "input_tms": [
                [],
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_109",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_830 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_830"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_819.dc.add.5: add (1,16,12,1), out: 0",
                    "softmax_819.dc.reciprocal.6: reciprocal (1,16,12,1), out: 0",
                    "softmax_819.dc.multiply.7: multiply (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 29764
        },
        "_fused_op_11": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: softmax_77.dc.reduce_sum.3.lc1 (port_0) ublock_order(r)",
                "Data: dc.input_tensor.softmax_77.4 (port_1) ublock_order(r)",
                "Data: _fused_op_10 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_10": "Data",
                "dc.input_tensor.softmax_77.4": "Data",
                "softmax_77.dc.reduce_sum.3.lc1": "Data"
            },
            "input_nodes": [
                "softmax_77.dc.reduce_sum.3.lc1",
                "dc.input_tensor.softmax_77.4",
                "_fused_op_10"
            ],
            "input_tms": [
                [],
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_11",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_88 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_88"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_77.dc.add.5: add (1,16,12,1), out: 0",
                    "softmax_77.dc.reciprocal.6: reciprocal (1,16,12,1), out: 0",
                    "softmax_77.dc.multiply.7: multiply (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 29666
        },
        "_fused_op_110": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_839.1 (port_0) ublock_order(c)",
                "Data: layernorm_839.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: buffer_0_28760_29765 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_28760_29765": "Data",
                "dc.input_tensor.layernorm_839.1": "Data",
                "layernorm_839.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_839.1",
                "layernorm_839.dc.reduce_sum.0.lc1",
                "buffer_0_28760_29765"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_110",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_839.dc.multiply.4 (port_0)",
                "Data: buffer_4_29765_29766 (port_0)",
                "Data: layernorm_839.dc.multiply.4 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_839.dc.multiply.4",
                "buffer_4_29765_29766",
                "layernorm_839.dc.multiply.4"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_839.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_839.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29765
        },
        "_fused_op_111": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_839.6 (port_0) ublock_order(r)",
                "Data: layernorm_839.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_839.8 (port_2) ublock_order(r)",
                "Data: buffer_0_29765_29766 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.15.attention.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.15.attention.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.15.attention.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.15.attention.output.LayerNorm.weight": "Data",
                "buffer_0_29765_29766": "Data",
                "dc.input_tensor.layernorm_839.6": "Data",
                "dc.input_tensor.layernorm_839.8": "Data",
                "layernorm_839.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_839.6",
                "layernorm_839.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_839.8",
                "buffer_0_29765_29766",
                "bert.encoder.layer.15.attention.output.LayerNorm.weight",
                "bert.encoder.layer.15.attention.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_111",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_842 (port_0)",
                "Data: buffer_7_29766_28792 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_842",
                "buffer_7_29766_28792"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_839.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_839.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_839.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_839.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_839.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_839.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_839.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29766
        },
        "_fused_op_112": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_853.1 (port_0) ublock_order(c)",
                "Data: layernorm_853.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: buffer_0_28792_29767 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_28792_29767": "Data",
                "dc.input_tensor.layernorm_853.1": "Data",
                "layernorm_853.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_853.1",
                "layernorm_853.dc.reduce_sum.0.lc1",
                "buffer_0_28792_29767"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_112",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_853.dc.multiply.4 (port_0)",
                "Data: layernorm_853.dc.multiply.4 (port_0)",
                "Data: _fused_op_113 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_853.dc.multiply.4",
                "layernorm_853.dc.multiply.4",
                "_fused_op_113"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_853.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_853.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29767
        },
        "_fused_op_113": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_853.6 (port_0) ublock_order(r)",
                "Data: layernorm_853.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_853.8 (port_2) ublock_order(r)",
                "Data: _fused_op_112 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.15.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.15.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_112": "Data",
                "bert.encoder.layer.15.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.15.output.LayerNorm.weight": "Data",
                "dc.input_tensor.layernorm_853.6": "Data",
                "dc.input_tensor.layernorm_853.8": "Data",
                "layernorm_853.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_853.6",
                "layernorm_853.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_853.8",
                "_fused_op_112",
                "bert.encoder.layer.15.output.LayerNorm.weight",
                "bert.encoder.layer.15.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_113",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_856 (port_0)",
                "Data: matmul_862 (port_0)",
                "Data: matmul_876 (port_0)",
                "Data: add_891 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_856",
                "matmul_862",
                "matmul_876",
                "add_891"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_853.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_853.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_853.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_853.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_853.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_853.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_853.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29768
        },
        "_fused_op_114": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_868 (port_0) ublock_order(r)",
                "Data: input_1_multiply_870 (port_1) ublock_order(r)",
                "Data: multiply_22_attempt_1_input_op_fork_nop2 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "input_1_multiply_870": "Data",
                "matmul_868": "Data",
                "multiply_22_attempt_1_input_op_fork_nop2": "Data"
            },
            "input_nodes": [
                "matmul_868",
                "input_1_multiply_870",
                "multiply_22_attempt_1_input_op_fork_nop2"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_114",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_872.dc.reduce_max.0 (port_0)",
                "Data: _fused_op_115 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_872.dc.reduce_max.0",
                "_fused_op_115"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "multiply_870: multiply (1,16,12,12), out: 0",
                    "add_871: add (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "add"
            },
            "type": "fused_op",
            "unique_id": 29769
        },
        "_fused_op_115": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_114 (port_0) ublock_order(c)",
                "Data: softmax_872.dc.reduce_max.0 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_114": "Data",
                "softmax_872.dc.reduce_max.0": "Data"
            },
            "input_nodes": [
                "_fused_op_114",
                "softmax_872.dc.reduce_max.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_115",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_872.dc.reduce_sum.3.lc1 (port_0)",
                "Data: buffer_0_29770_29771 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_872.dc.reduce_sum.3.lc1",
                "buffer_0_29770_29771"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_872.dc.subtract.1: subtract (1,16,12,12), out: 0",
                    "softmax_872.dc.exp.2: exp (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 29770
        },
        "_fused_op_116": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: softmax_872.dc.reduce_sum.3.lc1 (port_0) ublock_order(r)",
                "Data: dc.input_tensor.softmax_872.4 (port_1) ublock_order(r)",
                "Data: buffer_0_29770_29771 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_29770_29771": "Data",
                "dc.input_tensor.softmax_872.4": "Data",
                "softmax_872.dc.reduce_sum.3.lc1": "Data"
            },
            "input_nodes": [
                "softmax_872.dc.reduce_sum.3.lc1",
                "dc.input_tensor.softmax_872.4",
                "buffer_0_29770_29771"
            ],
            "input_tms": [
                [],
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_116",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_883 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_883"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_872.dc.add.5: add (1,16,12,1), out: 0",
                    "softmax_872.dc.reciprocal.6: reciprocal (1,16,12,1), out: 0",
                    "softmax_872.dc.multiply.7: multiply (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 29771
        },
        "_fused_op_117": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_892.1 (port_0) ublock_order(c)",
                "Data: layernorm_892.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: buffer_0_28864_29772 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_28864_29772": "Data",
                "dc.input_tensor.layernorm_892.1": "Data",
                "layernorm_892.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_892.1",
                "layernorm_892.dc.reduce_sum.0.lc1",
                "buffer_0_28864_29772"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_117",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_892.dc.multiply.4 (port_0)",
                "Data: buffer_2_29772_29773 (port_0)",
                "Data: layernorm_892.dc.multiply.4 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_892.dc.multiply.4",
                "buffer_2_29772_29773",
                "layernorm_892.dc.multiply.4"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_892.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_892.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29772
        },
        "_fused_op_118": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_892.6 (port_0) ublock_order(r)",
                "Data: layernorm_892.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_892.8 (port_2) ublock_order(r)",
                "Data: buffer_0_29772_29773 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.16.attention.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.16.attention.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.16.attention.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.16.attention.output.LayerNorm.weight": "Data",
                "buffer_0_29772_29773": "Data",
                "dc.input_tensor.layernorm_892.6": "Data",
                "dc.input_tensor.layernorm_892.8": "Data",
                "layernorm_892.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_892.6",
                "layernorm_892.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_892.8",
                "buffer_0_29772_29773",
                "bert.encoder.layer.16.attention.output.LayerNorm.weight",
                "bert.encoder.layer.16.attention.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_118",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_895 (port_0)",
                "Data: add_905 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_895",
                "add_905"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_892.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_892.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_892.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_892.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_892.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_892.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_892.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29773
        },
        "_fused_op_119": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_906.1 (port_0) ublock_order(c)",
                "Data: layernorm_906.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: buffer_0_28896_29774 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_28896_29774": "Data",
                "dc.input_tensor.layernorm_906.1": "Data",
                "layernorm_906.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_906.1",
                "layernorm_906.dc.reduce_sum.0.lc1",
                "buffer_0_28896_29774"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_119",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_906.dc.multiply.4 (port_0)",
                "Data: buffer_1_29774_29775 (port_0)",
                "Data: layernorm_906.dc.multiply.4 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_906.dc.multiply.4",
                "buffer_1_29774_29775",
                "layernorm_906.dc.multiply.4"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_906.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_906.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29774
        },
        "_fused_op_12": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_97.1 (port_0) ublock_order(c)",
                "Data: layernorm_97.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: buffer_0_27304_29667 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_27304_29667": "Data",
                "dc.input_tensor.layernorm_97.1": "Data",
                "layernorm_97.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_97.1",
                "layernorm_97.dc.reduce_sum.0.lc1",
                "buffer_0_27304_29667"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_12",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_97.dc.multiply.4 (port_0)",
                "Data: buffer_4_29667_29668 (port_0)",
                "Data: layernorm_97.dc.multiply.4 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_97.dc.multiply.4",
                "buffer_4_29667_29668",
                "layernorm_97.dc.multiply.4"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_97.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_97.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29667
        },
        "_fused_op_120": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_906.6 (port_0) ublock_order(r)",
                "Data: layernorm_906.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_906.8 (port_2) ublock_order(r)",
                "Data: buffer_0_29774_29775 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.16.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.16.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.16.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.16.output.LayerNorm.weight": "Data",
                "buffer_0_29774_29775": "Data",
                "dc.input_tensor.layernorm_906.6": "Data",
                "dc.input_tensor.layernorm_906.8": "Data",
                "layernorm_906.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_906.6",
                "layernorm_906.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_906.8",
                "buffer_0_29774_29775",
                "bert.encoder.layer.16.output.LayerNorm.weight",
                "bert.encoder.layer.16.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_120",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_909 (port_0)",
                "Data: matmul_915 (port_0)",
                "Data: matmul_929 (port_0)",
                "Data: add_944 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_909",
                "matmul_915",
                "matmul_929",
                "add_944"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_906.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_906.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_906.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_906.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_906.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_906.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_906.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29775
        },
        "_fused_op_121": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_921 (port_0) ublock_order(r)",
                "Data: input_1_multiply_923 (port_1) ublock_order(r)",
                "Data: multiply_22_attempt_1_input_op_fork_nop2 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "input_1_multiply_923": "Data",
                "matmul_921": "Data",
                "multiply_22_attempt_1_input_op_fork_nop2": "Data"
            },
            "input_nodes": [
                "matmul_921",
                "input_1_multiply_923",
                "multiply_22_attempt_1_input_op_fork_nop2"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_121",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_925.dc.reduce_max.0 (port_0)",
                "Data: _fused_op_122 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_925.dc.reduce_max.0",
                "_fused_op_122"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "multiply_923: multiply (1,16,12,12), out: 0",
                    "add_924: add (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "add"
            },
            "type": "fused_op",
            "unique_id": 29776
        },
        "_fused_op_122": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_121 (port_0) ublock_order(c)",
                "Data: softmax_925.dc.reduce_max.0 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_121": "Data",
                "softmax_925.dc.reduce_max.0": "Data"
            },
            "input_nodes": [
                "_fused_op_121",
                "softmax_925.dc.reduce_max.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_122",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_925.dc.reduce_sum.3.lc1 (port_0)",
                "Data: _fused_op_123 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_925.dc.reduce_sum.3.lc1",
                "_fused_op_123"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_925.dc.subtract.1: subtract (1,16,12,12), out: 0",
                    "softmax_925.dc.exp.2: exp (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 29777
        },
        "_fused_op_123": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: softmax_925.dc.reduce_sum.3.lc1 (port_0) ublock_order(r)",
                "Data: dc.input_tensor.softmax_925.4 (port_1) ublock_order(r)",
                "Data: _fused_op_122 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_122": "Data",
                "dc.input_tensor.softmax_925.4": "Data",
                "softmax_925.dc.reduce_sum.3.lc1": "Data"
            },
            "input_nodes": [
                "softmax_925.dc.reduce_sum.3.lc1",
                "dc.input_tensor.softmax_925.4",
                "_fused_op_122"
            ],
            "input_tms": [
                [],
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_123",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_936 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_936"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_925.dc.add.5: add (1,16,12,1), out: 0",
                    "softmax_925.dc.reciprocal.6: reciprocal (1,16,12,1), out: 0",
                    "softmax_925.dc.multiply.7: multiply (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 29778
        },
        "_fused_op_124": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_945.1 (port_0) ublock_order(c)",
                "Data: layernorm_945.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: buffer_0_28968_29779 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_28968_29779": "Data",
                "dc.input_tensor.layernorm_945.1": "Data",
                "layernorm_945.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_945.1",
                "layernorm_945.dc.reduce_sum.0.lc1",
                "buffer_0_28968_29779"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_124",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_945.dc.multiply.4 (port_0)",
                "Data: buffer_4_29779_29780 (port_0)",
                "Data: layernorm_945.dc.multiply.4 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_945.dc.multiply.4",
                "buffer_4_29779_29780",
                "layernorm_945.dc.multiply.4"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_945.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_945.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29779
        },
        "_fused_op_125": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_945.6 (port_0) ublock_order(r)",
                "Data: layernorm_945.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_945.8 (port_2) ublock_order(r)",
                "Data: buffer_0_29779_29780 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.17.attention.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.17.attention.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.17.attention.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.17.attention.output.LayerNorm.weight": "Data",
                "buffer_0_29779_29780": "Data",
                "dc.input_tensor.layernorm_945.6": "Data",
                "dc.input_tensor.layernorm_945.8": "Data",
                "layernorm_945.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_945.6",
                "layernorm_945.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_945.8",
                "buffer_0_29779_29780",
                "bert.encoder.layer.17.attention.output.LayerNorm.weight",
                "bert.encoder.layer.17.attention.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_125",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_948 (port_0)",
                "Data: buffer_7_29780_29000 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_948",
                "buffer_7_29780_29000"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_945.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_945.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_945.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_945.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_945.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_945.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_945.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29780
        },
        "_fused_op_126": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_959.1 (port_0) ublock_order(c)",
                "Data: layernorm_959.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: buffer_0_29000_29781 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_29000_29781": "Data",
                "dc.input_tensor.layernorm_959.1": "Data",
                "layernorm_959.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_959.1",
                "layernorm_959.dc.reduce_sum.0.lc1",
                "buffer_0_29000_29781"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_126",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_959.dc.multiply.4 (port_0)",
                "Data: layernorm_959.dc.multiply.4 (port_0)",
                "Data: _fused_op_127 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_959.dc.multiply.4",
                "layernorm_959.dc.multiply.4",
                "_fused_op_127"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_959.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_959.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29781
        },
        "_fused_op_127": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_959.6 (port_0) ublock_order(r)",
                "Data: layernorm_959.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_959.8 (port_2) ublock_order(r)",
                "Data: _fused_op_126 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.17.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.17.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_126": "Data",
                "bert.encoder.layer.17.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.17.output.LayerNorm.weight": "Data",
                "dc.input_tensor.layernorm_959.6": "Data",
                "dc.input_tensor.layernorm_959.8": "Data",
                "layernorm_959.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_959.6",
                "layernorm_959.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_959.8",
                "_fused_op_126",
                "bert.encoder.layer.17.output.LayerNorm.weight",
                "bert.encoder.layer.17.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_127",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_962 (port_0)",
                "Data: matmul_968 (port_0)",
                "Data: matmul_982 (port_0)",
                "Data: add_997 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_962",
                "matmul_968",
                "matmul_982",
                "add_997"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_959.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_959.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_959.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_959.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_959.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_959.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_959.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29782
        },
        "_fused_op_128": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_974 (port_0) ublock_order(r)",
                "Data: input_1_multiply_976 (port_1) ublock_order(r)",
                "Data: multiply_22_attempt_1_input_op_fork_nop2 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "input_1_multiply_976": "Data",
                "matmul_974": "Data",
                "multiply_22_attempt_1_input_op_fork_nop2": "Data"
            },
            "input_nodes": [
                "matmul_974",
                "input_1_multiply_976",
                "multiply_22_attempt_1_input_op_fork_nop2"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_128",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_978.dc.reduce_max.0 (port_0)",
                "Data: _fused_op_129 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_978.dc.reduce_max.0",
                "_fused_op_129"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "multiply_976: multiply (1,16,12,12), out: 0",
                    "add_977: add (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "add"
            },
            "type": "fused_op",
            "unique_id": 29783
        },
        "_fused_op_129": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_128 (port_0) ublock_order(c)",
                "Data: softmax_978.dc.reduce_max.0 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_128": "Data",
                "softmax_978.dc.reduce_max.0": "Data"
            },
            "input_nodes": [
                "_fused_op_128",
                "softmax_978.dc.reduce_max.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_129",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_978.dc.reduce_sum.3.lc1 (port_0)",
                "Data: buffer_0_29784_29785 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_978.dc.reduce_sum.3.lc1",
                "buffer_0_29784_29785"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_978.dc.subtract.1: subtract (1,16,12,12), out: 0",
                    "softmax_978.dc.exp.2: exp (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 29784
        },
        "_fused_op_13": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_97.6 (port_0) ublock_order(r)",
                "Data: layernorm_97.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_97.8 (port_2) ublock_order(r)",
                "Data: buffer_0_29667_29668 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.1.attention.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.1.attention.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.1.attention.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.1.attention.output.LayerNorm.weight": "Data",
                "buffer_0_29667_29668": "Data",
                "dc.input_tensor.layernorm_97.6": "Data",
                "dc.input_tensor.layernorm_97.8": "Data",
                "layernorm_97.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_97.6",
                "layernorm_97.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_97.8",
                "buffer_0_29667_29668",
                "bert.encoder.layer.1.attention.output.LayerNorm.weight",
                "bert.encoder.layer.1.attention.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_13",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_100 (port_0)",
                "Data: buffer_7_29668_27336 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_100",
                "buffer_7_29668_27336"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_97.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_97.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_97.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_97.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_97.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_97.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_97.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29668
        },
        "_fused_op_130": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: softmax_978.dc.reduce_sum.3.lc1 (port_0) ublock_order(r)",
                "Data: dc.input_tensor.softmax_978.4 (port_1) ublock_order(r)",
                "Data: buffer_0_29784_29785 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_29784_29785": "Data",
                "dc.input_tensor.softmax_978.4": "Data",
                "softmax_978.dc.reduce_sum.3.lc1": "Data"
            },
            "input_nodes": [
                "softmax_978.dc.reduce_sum.3.lc1",
                "dc.input_tensor.softmax_978.4",
                "buffer_0_29784_29785"
            ],
            "input_tms": [
                [],
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_130",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_989 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_989"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_978.dc.add.5: add (1,16,12,1), out: 0",
                    "softmax_978.dc.reciprocal.6: reciprocal (1,16,12,1), out: 0",
                    "softmax_978.dc.multiply.7: multiply (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 29785
        },
        "_fused_op_131": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_998.1 (port_0) ublock_order(c)",
                "Data: layernorm_998.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: buffer_0_29072_29786 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_29072_29786": "Data",
                "dc.input_tensor.layernorm_998.1": "Data",
                "layernorm_998.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_998.1",
                "layernorm_998.dc.reduce_sum.0.lc1",
                "buffer_0_29072_29786"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_131",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_998.dc.multiply.4 (port_0)",
                "Data: buffer_2_29786_29787 (port_0)",
                "Data: layernorm_998.dc.multiply.4 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_998.dc.multiply.4",
                "buffer_2_29786_29787",
                "layernorm_998.dc.multiply.4"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_998.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_998.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29786
        },
        "_fused_op_132": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_998.6 (port_0) ublock_order(r)",
                "Data: layernorm_998.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_998.8 (port_2) ublock_order(r)",
                "Data: buffer_0_29786_29787 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.18.attention.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.18.attention.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.18.attention.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.18.attention.output.LayerNorm.weight": "Data",
                "buffer_0_29786_29787": "Data",
                "dc.input_tensor.layernorm_998.6": "Data",
                "dc.input_tensor.layernorm_998.8": "Data",
                "layernorm_998.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_998.6",
                "layernorm_998.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_998.8",
                "buffer_0_29786_29787",
                "bert.encoder.layer.18.attention.output.LayerNorm.weight",
                "bert.encoder.layer.18.attention.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_132",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1001 (port_0)",
                "Data: add_1011 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1001",
                "add_1011"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_998.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_998.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_998.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_998.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_998.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_998.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_998.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29787
        },
        "_fused_op_133": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_1012.1 (port_0) ublock_order(c)",
                "Data: layernorm_1012.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: buffer_0_29104_29788 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_29104_29788": "Data",
                "dc.input_tensor.layernorm_1012.1": "Data",
                "layernorm_1012.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_1012.1",
                "layernorm_1012.dc.reduce_sum.0.lc1",
                "buffer_0_29104_29788"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_133",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1012.dc.multiply.4 (port_0)",
                "Data: buffer_1_29788_29789 (port_0)",
                "Data: layernorm_1012.dc.multiply.4 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1012.dc.multiply.4",
                "buffer_1_29788_29789",
                "layernorm_1012.dc.multiply.4"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_1012.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_1012.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29788
        },
        "_fused_op_134": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_1012.6 (port_0) ublock_order(r)",
                "Data: layernorm_1012.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_1012.8 (port_2) ublock_order(r)",
                "Data: buffer_0_29788_29789 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.18.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.18.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.18.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.18.output.LayerNorm.weight": "Data",
                "buffer_0_29788_29789": "Data",
                "dc.input_tensor.layernorm_1012.6": "Data",
                "dc.input_tensor.layernorm_1012.8": "Data",
                "layernorm_1012.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_1012.6",
                "layernorm_1012.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_1012.8",
                "buffer_0_29788_29789",
                "bert.encoder.layer.18.output.LayerNorm.weight",
                "bert.encoder.layer.18.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_134",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1015 (port_0)",
                "Data: matmul_1021 (port_0)",
                "Data: matmul_1035 (port_0)",
                "Data: add_1050 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1015",
                "matmul_1021",
                "matmul_1035",
                "add_1050"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_1012.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_1012.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_1012.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_1012.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_1012.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_1012.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_1012.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29789
        },
        "_fused_op_135": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1027 (port_0) ublock_order(r)",
                "Data: input_1_multiply_1029 (port_1) ublock_order(r)",
                "Data: multiply_22_attempt_1_input_op_fork_nop2 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "input_1_multiply_1029": "Data",
                "matmul_1027": "Data",
                "multiply_22_attempt_1_input_op_fork_nop2": "Data"
            },
            "input_nodes": [
                "matmul_1027",
                "input_1_multiply_1029",
                "multiply_22_attempt_1_input_op_fork_nop2"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_135",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_1031.dc.reduce_max.0 (port_0)",
                "Data: _fused_op_136 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_1031.dc.reduce_max.0",
                "_fused_op_136"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "multiply_1029: multiply (1,16,12,12), out: 0",
                    "add_1030: add (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "add"
            },
            "type": "fused_op",
            "unique_id": 29790
        },
        "_fused_op_136": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_135 (port_0) ublock_order(c)",
                "Data: softmax_1031.dc.reduce_max.0 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_135": "Data",
                "softmax_1031.dc.reduce_max.0": "Data"
            },
            "input_nodes": [
                "_fused_op_135",
                "softmax_1031.dc.reduce_max.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_136",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_1031.dc.reduce_sum.3.lc1 (port_0)",
                "Data: _fused_op_137 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_1031.dc.reduce_sum.3.lc1",
                "_fused_op_137"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_1031.dc.subtract.1: subtract (1,16,12,12), out: 0",
                    "softmax_1031.dc.exp.2: exp (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 29791
        },
        "_fused_op_137": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: softmax_1031.dc.reduce_sum.3.lc1 (port_0) ublock_order(r)",
                "Data: dc.input_tensor.softmax_1031.4 (port_1) ublock_order(r)",
                "Data: _fused_op_136 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_136": "Data",
                "dc.input_tensor.softmax_1031.4": "Data",
                "softmax_1031.dc.reduce_sum.3.lc1": "Data"
            },
            "input_nodes": [
                "softmax_1031.dc.reduce_sum.3.lc1",
                "dc.input_tensor.softmax_1031.4",
                "_fused_op_136"
            ],
            "input_tms": [
                [],
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_137",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1042 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1042"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_1031.dc.add.5: add (1,16,12,1), out: 0",
                    "softmax_1031.dc.reciprocal.6: reciprocal (1,16,12,1), out: 0",
                    "softmax_1031.dc.multiply.7: multiply (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 29792
        },
        "_fused_op_138": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_1051.1 (port_0) ublock_order(c)",
                "Data: layernorm_1051.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: buffer_0_29176_29793 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_29176_29793": "Data",
                "dc.input_tensor.layernorm_1051.1": "Data",
                "layernorm_1051.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_1051.1",
                "layernorm_1051.dc.reduce_sum.0.lc1",
                "buffer_0_29176_29793"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_138",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1051.dc.multiply.4 (port_0)",
                "Data: buffer_4_29793_29794 (port_0)",
                "Data: layernorm_1051.dc.multiply.4 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1051.dc.multiply.4",
                "buffer_4_29793_29794",
                "layernorm_1051.dc.multiply.4"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_1051.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_1051.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29793
        },
        "_fused_op_139": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_1051.6 (port_0) ublock_order(r)",
                "Data: layernorm_1051.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_1051.8 (port_2) ublock_order(r)",
                "Data: buffer_0_29793_29794 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.19.attention.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.19.attention.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.19.attention.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.19.attention.output.LayerNorm.weight": "Data",
                "buffer_0_29793_29794": "Data",
                "dc.input_tensor.layernorm_1051.6": "Data",
                "dc.input_tensor.layernorm_1051.8": "Data",
                "layernorm_1051.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_1051.6",
                "layernorm_1051.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_1051.8",
                "buffer_0_29793_29794",
                "bert.encoder.layer.19.attention.output.LayerNorm.weight",
                "bert.encoder.layer.19.attention.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_139",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1054 (port_0)",
                "Data: buffer_7_29794_29208 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1054",
                "buffer_7_29794_29208"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_1051.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_1051.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_1051.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_1051.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_1051.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_1051.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_1051.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29794
        },
        "_fused_op_14": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_111.1 (port_0) ublock_order(c)",
                "Data: layernorm_111.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: buffer_0_27336_29669 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_27336_29669": "Data",
                "dc.input_tensor.layernorm_111.1": "Data",
                "layernorm_111.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_111.1",
                "layernorm_111.dc.reduce_sum.0.lc1",
                "buffer_0_27336_29669"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_14",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_111.dc.multiply.4 (port_0)",
                "Data: layernorm_111.dc.multiply.4 (port_0)",
                "Data: _fused_op_15 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_111.dc.multiply.4",
                "layernorm_111.dc.multiply.4",
                "_fused_op_15"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_111.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_111.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29669
        },
        "_fused_op_140": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_1065.1 (port_0) ublock_order(c)",
                "Data: layernorm_1065.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: buffer_0_29208_29795 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_29208_29795": "Data",
                "dc.input_tensor.layernorm_1065.1": "Data",
                "layernorm_1065.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_1065.1",
                "layernorm_1065.dc.reduce_sum.0.lc1",
                "buffer_0_29208_29795"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_140",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1065.dc.multiply.4 (port_0)",
                "Data: layernorm_1065.dc.multiply.4 (port_0)",
                "Data: _fused_op_141 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1065.dc.multiply.4",
                "layernorm_1065.dc.multiply.4",
                "_fused_op_141"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_1065.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_1065.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29795
        },
        "_fused_op_141": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_1065.6 (port_0) ublock_order(r)",
                "Data: layernorm_1065.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_1065.8 (port_2) ublock_order(r)",
                "Data: _fused_op_140 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.19.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.19.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_140": "Data",
                "bert.encoder.layer.19.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.19.output.LayerNorm.weight": "Data",
                "dc.input_tensor.layernorm_1065.6": "Data",
                "dc.input_tensor.layernorm_1065.8": "Data",
                "layernorm_1065.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_1065.6",
                "layernorm_1065.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_1065.8",
                "_fused_op_140",
                "bert.encoder.layer.19.output.LayerNorm.weight",
                "bert.encoder.layer.19.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_141",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1068 (port_0)",
                "Data: matmul_1074 (port_0)",
                "Data: matmul_1088 (port_0)",
                "Data: add_1103 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1068",
                "matmul_1074",
                "matmul_1088",
                "add_1103"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_1065.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_1065.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_1065.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_1065.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_1065.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_1065.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_1065.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29796
        },
        "_fused_op_142": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1080 (port_0) ublock_order(r)",
                "Data: input_1_multiply_1082 (port_1) ublock_order(r)",
                "Data: multiply_22_attempt_1_input_op_fork_nop2 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "input_1_multiply_1082": "Data",
                "matmul_1080": "Data",
                "multiply_22_attempt_1_input_op_fork_nop2": "Data"
            },
            "input_nodes": [
                "matmul_1080",
                "input_1_multiply_1082",
                "multiply_22_attempt_1_input_op_fork_nop2"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_142",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_1084.dc.reduce_max.0 (port_0)",
                "Data: _fused_op_143 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_1084.dc.reduce_max.0",
                "_fused_op_143"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "multiply_1082: multiply (1,16,12,12), out: 0",
                    "add_1083: add (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "add"
            },
            "type": "fused_op",
            "unique_id": 29797
        },
        "_fused_op_143": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_142 (port_0) ublock_order(c)",
                "Data: softmax_1084.dc.reduce_max.0 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_142": "Data",
                "softmax_1084.dc.reduce_max.0": "Data"
            },
            "input_nodes": [
                "_fused_op_142",
                "softmax_1084.dc.reduce_max.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_143",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_1084.dc.reduce_sum.3.lc1 (port_0)",
                "Data: buffer_0_29798_29799 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_1084.dc.reduce_sum.3.lc1",
                "buffer_0_29798_29799"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_1084.dc.subtract.1: subtract (1,16,12,12), out: 0",
                    "softmax_1084.dc.exp.2: exp (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 29798
        },
        "_fused_op_144": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: softmax_1084.dc.reduce_sum.3.lc1 (port_0) ublock_order(r)",
                "Data: dc.input_tensor.softmax_1084.4 (port_1) ublock_order(r)",
                "Data: buffer_0_29798_29799 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_29798_29799": "Data",
                "dc.input_tensor.softmax_1084.4": "Data",
                "softmax_1084.dc.reduce_sum.3.lc1": "Data"
            },
            "input_nodes": [
                "softmax_1084.dc.reduce_sum.3.lc1",
                "dc.input_tensor.softmax_1084.4",
                "buffer_0_29798_29799"
            ],
            "input_tms": [
                [],
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_144",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1095 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1095"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_1084.dc.add.5: add (1,16,12,1), out: 0",
                    "softmax_1084.dc.reciprocal.6: reciprocal (1,16,12,1), out: 0",
                    "softmax_1084.dc.multiply.7: multiply (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 29799
        },
        "_fused_op_145": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_1104.1 (port_0) ublock_order(c)",
                "Data: layernorm_1104.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: buffer_0_29280_29800 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_29280_29800": "Data",
                "dc.input_tensor.layernorm_1104.1": "Data",
                "layernorm_1104.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_1104.1",
                "layernorm_1104.dc.reduce_sum.0.lc1",
                "buffer_0_29280_29800"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_145",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1104.dc.multiply.4 (port_0)",
                "Data: buffer_2_29800_29801 (port_0)",
                "Data: layernorm_1104.dc.multiply.4 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1104.dc.multiply.4",
                "buffer_2_29800_29801",
                "layernorm_1104.dc.multiply.4"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_1104.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_1104.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29800
        },
        "_fused_op_146": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_1104.6 (port_0) ublock_order(r)",
                "Data: layernorm_1104.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_1104.8 (port_2) ublock_order(r)",
                "Data: buffer_0_29800_29801 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.20.attention.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.20.attention.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.20.attention.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.20.attention.output.LayerNorm.weight": "Data",
                "buffer_0_29800_29801": "Data",
                "dc.input_tensor.layernorm_1104.6": "Data",
                "dc.input_tensor.layernorm_1104.8": "Data",
                "layernorm_1104.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_1104.6",
                "layernorm_1104.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_1104.8",
                "buffer_0_29800_29801",
                "bert.encoder.layer.20.attention.output.LayerNorm.weight",
                "bert.encoder.layer.20.attention.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_146",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1107 (port_0)",
                "Data: add_1117 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1107",
                "add_1117"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_1104.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_1104.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_1104.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_1104.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_1104.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_1104.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_1104.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29801
        },
        "_fused_op_147": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_1118.1 (port_0) ublock_order(c)",
                "Data: layernorm_1118.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: buffer_0_29312_29802 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_29312_29802": "Data",
                "dc.input_tensor.layernorm_1118.1": "Data",
                "layernorm_1118.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_1118.1",
                "layernorm_1118.dc.reduce_sum.0.lc1",
                "buffer_0_29312_29802"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_147",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1118.dc.multiply.4 (port_0)",
                "Data: buffer_1_29802_29803 (port_0)",
                "Data: layernorm_1118.dc.multiply.4 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1118.dc.multiply.4",
                "buffer_1_29802_29803",
                "layernorm_1118.dc.multiply.4"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_1118.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_1118.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29802
        },
        "_fused_op_148": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_1118.6 (port_0) ublock_order(r)",
                "Data: layernorm_1118.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_1118.8 (port_2) ublock_order(r)",
                "Data: buffer_0_29802_29803 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.20.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.20.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.20.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.20.output.LayerNorm.weight": "Data",
                "buffer_0_29802_29803": "Data",
                "dc.input_tensor.layernorm_1118.6": "Data",
                "dc.input_tensor.layernorm_1118.8": "Data",
                "layernorm_1118.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_1118.6",
                "layernorm_1118.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_1118.8",
                "buffer_0_29802_29803",
                "bert.encoder.layer.20.output.LayerNorm.weight",
                "bert.encoder.layer.20.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_148",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1121 (port_0)",
                "Data: matmul_1127 (port_0)",
                "Data: matmul_1141 (port_0)",
                "Data: add_1156 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1121",
                "matmul_1127",
                "matmul_1141",
                "add_1156"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_1118.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_1118.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_1118.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_1118.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_1118.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_1118.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_1118.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29803
        },
        "_fused_op_149": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1133 (port_0) ublock_order(r)",
                "Data: input_1_multiply_1135 (port_1) ublock_order(r)",
                "Data: multiply_22_attempt_1_input_op_fork_nop2 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "input_1_multiply_1135": "Data",
                "matmul_1133": "Data",
                "multiply_22_attempt_1_input_op_fork_nop2": "Data"
            },
            "input_nodes": [
                "matmul_1133",
                "input_1_multiply_1135",
                "multiply_22_attempt_1_input_op_fork_nop2"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_149",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_1137.dc.reduce_max.0 (port_0)",
                "Data: _fused_op_150 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_1137.dc.reduce_max.0",
                "_fused_op_150"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "multiply_1135: multiply (1,16,12,12), out: 0",
                    "add_1136: add (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "add"
            },
            "type": "fused_op",
            "unique_id": 29804
        },
        "_fused_op_15": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_111.6 (port_0) ublock_order(r)",
                "Data: layernorm_111.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_111.8 (port_2) ublock_order(r)",
                "Data: _fused_op_14 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.1.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.1.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_14": "Data",
                "bert.encoder.layer.1.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.1.output.LayerNorm.weight": "Data",
                "dc.input_tensor.layernorm_111.6": "Data",
                "dc.input_tensor.layernorm_111.8": "Data",
                "layernorm_111.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_111.6",
                "layernorm_111.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_111.8",
                "_fused_op_14",
                "bert.encoder.layer.1.output.LayerNorm.weight",
                "bert.encoder.layer.1.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_15",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_114 (port_0)",
                "Data: matmul_120 (port_0)",
                "Data: matmul_134 (port_0)",
                "Data: add_149 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_114",
                "matmul_120",
                "matmul_134",
                "add_149"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_111.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_111.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_111.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_111.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_111.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_111.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_111.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29670
        },
        "_fused_op_150": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_149 (port_0) ublock_order(c)",
                "Data: softmax_1137.dc.reduce_max.0 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_149": "Data",
                "softmax_1137.dc.reduce_max.0": "Data"
            },
            "input_nodes": [
                "_fused_op_149",
                "softmax_1137.dc.reduce_max.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_150",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_1137.dc.reduce_sum.3.lc1 (port_0)",
                "Data: _fused_op_151 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_1137.dc.reduce_sum.3.lc1",
                "_fused_op_151"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_1137.dc.subtract.1: subtract (1,16,12,12), out: 0",
                    "softmax_1137.dc.exp.2: exp (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 29805
        },
        "_fused_op_151": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: softmax_1137.dc.reduce_sum.3.lc1 (port_0) ublock_order(r)",
                "Data: dc.input_tensor.softmax_1137.4 (port_1) ublock_order(r)",
                "Data: _fused_op_150 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_150": "Data",
                "dc.input_tensor.softmax_1137.4": "Data",
                "softmax_1137.dc.reduce_sum.3.lc1": "Data"
            },
            "input_nodes": [
                "softmax_1137.dc.reduce_sum.3.lc1",
                "dc.input_tensor.softmax_1137.4",
                "_fused_op_150"
            ],
            "input_tms": [
                [],
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_151",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1148 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1148"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_1137.dc.add.5: add (1,16,12,1), out: 0",
                    "softmax_1137.dc.reciprocal.6: reciprocal (1,16,12,1), out: 0",
                    "softmax_1137.dc.multiply.7: multiply (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 29806
        },
        "_fused_op_152": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_1157.1 (port_0) ublock_order(c)",
                "Data: layernorm_1157.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: buffer_0_29384_29807 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_29384_29807": "Data",
                "dc.input_tensor.layernorm_1157.1": "Data",
                "layernorm_1157.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_1157.1",
                "layernorm_1157.dc.reduce_sum.0.lc1",
                "buffer_0_29384_29807"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_152",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1157.dc.multiply.4 (port_0)",
                "Data: buffer_4_29807_29808 (port_0)",
                "Data: layernorm_1157.dc.multiply.4 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1157.dc.multiply.4",
                "buffer_4_29807_29808",
                "layernorm_1157.dc.multiply.4"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_1157.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_1157.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29807
        },
        "_fused_op_153": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_1157.6 (port_0) ublock_order(r)",
                "Data: layernorm_1157.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_1157.8 (port_2) ublock_order(r)",
                "Data: buffer_0_29807_29808 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.21.attention.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.21.attention.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.21.attention.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.21.attention.output.LayerNorm.weight": "Data",
                "buffer_0_29807_29808": "Data",
                "dc.input_tensor.layernorm_1157.6": "Data",
                "dc.input_tensor.layernorm_1157.8": "Data",
                "layernorm_1157.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_1157.6",
                "layernorm_1157.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_1157.8",
                "buffer_0_29807_29808",
                "bert.encoder.layer.21.attention.output.LayerNorm.weight",
                "bert.encoder.layer.21.attention.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_153",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1160 (port_0)",
                "Data: buffer_7_29808_29416 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1160",
                "buffer_7_29808_29416"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_1157.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_1157.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_1157.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_1157.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_1157.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_1157.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_1157.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29808
        },
        "_fused_op_154": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_1171.1 (port_0) ublock_order(c)",
                "Data: layernorm_1171.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: buffer_0_29416_29809 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_29416_29809": "Data",
                "dc.input_tensor.layernorm_1171.1": "Data",
                "layernorm_1171.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_1171.1",
                "layernorm_1171.dc.reduce_sum.0.lc1",
                "buffer_0_29416_29809"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_154",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1171.dc.multiply.4 (port_0)",
                "Data: layernorm_1171.dc.multiply.4 (port_0)",
                "Data: _fused_op_155 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1171.dc.multiply.4",
                "layernorm_1171.dc.multiply.4",
                "_fused_op_155"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_1171.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_1171.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29809
        },
        "_fused_op_155": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_1171.6 (port_0) ublock_order(r)",
                "Data: layernorm_1171.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_1171.8 (port_2) ublock_order(r)",
                "Data: _fused_op_154 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.21.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.21.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_154": "Data",
                "bert.encoder.layer.21.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.21.output.LayerNorm.weight": "Data",
                "dc.input_tensor.layernorm_1171.6": "Data",
                "dc.input_tensor.layernorm_1171.8": "Data",
                "layernorm_1171.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_1171.6",
                "layernorm_1171.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_1171.8",
                "_fused_op_154",
                "bert.encoder.layer.21.output.LayerNorm.weight",
                "bert.encoder.layer.21.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_155",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1174 (port_0)",
                "Data: matmul_1180 (port_0)",
                "Data: matmul_1194 (port_0)",
                "Data: add_1209 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1174",
                "matmul_1180",
                "matmul_1194",
                "add_1209"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_1171.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_1171.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_1171.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_1171.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_1171.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_1171.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_1171.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29810
        },
        "_fused_op_156": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1186 (port_0) ublock_order(r)",
                "Data: input_1_multiply_1188 (port_1) ublock_order(r)",
                "Data: multiply_22_attempt_1_input_op_fork_nop2 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "input_1_multiply_1188": "Data",
                "matmul_1186": "Data",
                "multiply_22_attempt_1_input_op_fork_nop2": "Data"
            },
            "input_nodes": [
                "matmul_1186",
                "input_1_multiply_1188",
                "multiply_22_attempt_1_input_op_fork_nop2"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_156",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_1190.dc.reduce_max.0 (port_0)",
                "Data: _fused_op_157 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_1190.dc.reduce_max.0",
                "_fused_op_157"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "multiply_1188: multiply (1,16,12,12), out: 0",
                    "add_1189: add (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "add"
            },
            "type": "fused_op",
            "unique_id": 29811
        },
        "_fused_op_157": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_156 (port_0) ublock_order(c)",
                "Data: softmax_1190.dc.reduce_max.0 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_156": "Data",
                "softmax_1190.dc.reduce_max.0": "Data"
            },
            "input_nodes": [
                "_fused_op_156",
                "softmax_1190.dc.reduce_max.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_157",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_1190.dc.reduce_sum.3.lc1 (port_0)",
                "Data: buffer_0_29812_29813 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_1190.dc.reduce_sum.3.lc1",
                "buffer_0_29812_29813"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_1190.dc.subtract.1: subtract (1,16,12,12), out: 0",
                    "softmax_1190.dc.exp.2: exp (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 29812
        },
        "_fused_op_158": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: softmax_1190.dc.reduce_sum.3.lc1 (port_0) ublock_order(r)",
                "Data: dc.input_tensor.softmax_1190.4 (port_1) ublock_order(r)",
                "Data: buffer_0_29812_29813 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_29812_29813": "Data",
                "dc.input_tensor.softmax_1190.4": "Data",
                "softmax_1190.dc.reduce_sum.3.lc1": "Data"
            },
            "input_nodes": [
                "softmax_1190.dc.reduce_sum.3.lc1",
                "dc.input_tensor.softmax_1190.4",
                "buffer_0_29812_29813"
            ],
            "input_tms": [
                [],
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_158",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1201 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1201"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_1190.dc.add.5: add (1,16,12,1), out: 0",
                    "softmax_1190.dc.reciprocal.6: reciprocal (1,16,12,1), out: 0",
                    "softmax_1190.dc.multiply.7: multiply (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 29813
        },
        "_fused_op_159": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_1210.1 (port_0) ublock_order(c)",
                "Data: layernorm_1210.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: buffer_0_29488_29814 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_29488_29814": "Data",
                "dc.input_tensor.layernorm_1210.1": "Data",
                "layernorm_1210.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_1210.1",
                "layernorm_1210.dc.reduce_sum.0.lc1",
                "buffer_0_29488_29814"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_159",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1210.dc.multiply.4 (port_0)",
                "Data: buffer_2_29814_29815 (port_0)",
                "Data: layernorm_1210.dc.multiply.4 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1210.dc.multiply.4",
                "buffer_2_29814_29815",
                "layernorm_1210.dc.multiply.4"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_1210.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_1210.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29814
        },
        "_fused_op_16": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_126 (port_0) ublock_order(r)",
                "Data: input_1_multiply_128 (port_1) ublock_order(r)",
                "Data: multiply_22_attempt_1_input_op_fork_nop0 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "input_1_multiply_128": "Data",
                "matmul_126": "Data",
                "multiply_22_attempt_1_input_op_fork_nop0": "Data"
            },
            "input_nodes": [
                "matmul_126",
                "input_1_multiply_128",
                "multiply_22_attempt_1_input_op_fork_nop0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_16",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_130.dc.reduce_max.0 (port_0)",
                "Data: _fused_op_17 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_130.dc.reduce_max.0",
                "_fused_op_17"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "multiply_128: multiply (1,16,12,12), out: 0",
                    "add_129: add (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "add"
            },
            "type": "fused_op",
            "unique_id": 29671
        },
        "_fused_op_160": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_1210.6 (port_0) ublock_order(r)",
                "Data: layernorm_1210.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_1210.8 (port_2) ublock_order(r)",
                "Data: buffer_0_29814_29815 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.22.attention.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.22.attention.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.22.attention.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.22.attention.output.LayerNorm.weight": "Data",
                "buffer_0_29814_29815": "Data",
                "dc.input_tensor.layernorm_1210.6": "Data",
                "dc.input_tensor.layernorm_1210.8": "Data",
                "layernorm_1210.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_1210.6",
                "layernorm_1210.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_1210.8",
                "buffer_0_29814_29815",
                "bert.encoder.layer.22.attention.output.LayerNorm.weight",
                "bert.encoder.layer.22.attention.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_160",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1213 (port_0)",
                "Data: add_1223 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1213",
                "add_1223"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_1210.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_1210.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_1210.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_1210.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_1210.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_1210.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_1210.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29815
        },
        "_fused_op_161": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_1224.1 (port_0) ublock_order(c)",
                "Data: layernorm_1224.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: buffer_0_29520_29816 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_29520_29816": "Data",
                "dc.input_tensor.layernorm_1224.1": "Data",
                "layernorm_1224.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_1224.1",
                "layernorm_1224.dc.reduce_sum.0.lc1",
                "buffer_0_29520_29816"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_161",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1224.dc.multiply.4 (port_0)",
                "Data: buffer_1_29816_29817 (port_0)",
                "Data: layernorm_1224.dc.multiply.4 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1224.dc.multiply.4",
                "buffer_1_29816_29817",
                "layernorm_1224.dc.multiply.4"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_1224.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_1224.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29816
        },
        "_fused_op_162": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_1224.6 (port_0) ublock_order(r)",
                "Data: layernorm_1224.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_1224.8 (port_2) ublock_order(r)",
                "Data: buffer_0_29816_29817 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.22.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.22.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.22.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.22.output.LayerNorm.weight": "Data",
                "buffer_0_29816_29817": "Data",
                "dc.input_tensor.layernorm_1224.6": "Data",
                "dc.input_tensor.layernorm_1224.8": "Data",
                "layernorm_1224.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_1224.6",
                "layernorm_1224.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_1224.8",
                "buffer_0_29816_29817",
                "bert.encoder.layer.22.output.LayerNorm.weight",
                "bert.encoder.layer.22.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_162",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1227 (port_0)",
                "Data: matmul_1233 (port_0)",
                "Data: matmul_1247 (port_0)",
                "Data: add_1262 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1227",
                "matmul_1233",
                "matmul_1247",
                "add_1262"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_1224.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_1224.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_1224.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_1224.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_1224.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_1224.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_1224.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29817
        },
        "_fused_op_163": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1239 (port_0) ublock_order(r)",
                "Data: input_1_multiply_1241 (port_1) ublock_order(r)",
                "Data: multiply_22_attempt_1_input_op_fork_nop2 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "input_1_multiply_1241": "Data",
                "matmul_1239": "Data",
                "multiply_22_attempt_1_input_op_fork_nop2": "Data"
            },
            "input_nodes": [
                "matmul_1239",
                "input_1_multiply_1241",
                "multiply_22_attempt_1_input_op_fork_nop2"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_163",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_1243.dc.reduce_max.0 (port_0)",
                "Data: _fused_op_164 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_1243.dc.reduce_max.0",
                "_fused_op_164"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "multiply_1241: multiply (1,16,12,12), out: 0",
                    "add_1242: add (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "add"
            },
            "type": "fused_op",
            "unique_id": 29818
        },
        "_fused_op_164": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_163 (port_0) ublock_order(c)",
                "Data: softmax_1243.dc.reduce_max.0 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_163": "Data",
                "softmax_1243.dc.reduce_max.0": "Data"
            },
            "input_nodes": [
                "_fused_op_163",
                "softmax_1243.dc.reduce_max.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_164",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_1243.dc.reduce_sum.3.lc1 (port_0)",
                "Data: _fused_op_165 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_1243.dc.reduce_sum.3.lc1",
                "_fused_op_165"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_1243.dc.subtract.1: subtract (1,16,12,12), out: 0",
                    "softmax_1243.dc.exp.2: exp (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 29819
        },
        "_fused_op_165": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: softmax_1243.dc.reduce_sum.3.lc1 (port_0) ublock_order(r)",
                "Data: dc.input_tensor.softmax_1243.4 (port_1) ublock_order(r)",
                "Data: _fused_op_164 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_164": "Data",
                "dc.input_tensor.softmax_1243.4": "Data",
                "softmax_1243.dc.reduce_sum.3.lc1": "Data"
            },
            "input_nodes": [
                "softmax_1243.dc.reduce_sum.3.lc1",
                "dc.input_tensor.softmax_1243.4",
                "_fused_op_164"
            ],
            "input_tms": [
                [],
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_165",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1254 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1254"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_1243.dc.add.5: add (1,16,12,1), out: 0",
                    "softmax_1243.dc.reciprocal.6: reciprocal (1,16,12,1), out: 0",
                    "softmax_1243.dc.multiply.7: multiply (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 29820
        },
        "_fused_op_166": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_1263.1 (port_0) ublock_order(c)",
                "Data: layernorm_1263.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: buffer_0_29592_29821 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_29592_29821": "Data",
                "dc.input_tensor.layernorm_1263.1": "Data",
                "layernorm_1263.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_1263.1",
                "layernorm_1263.dc.reduce_sum.0.lc1",
                "buffer_0_29592_29821"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_166",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1263.dc.multiply.4 (port_0)",
                "Data: buffer_4_29821_29822 (port_0)",
                "Data: layernorm_1263.dc.multiply.4 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1263.dc.multiply.4",
                "buffer_4_29821_29822",
                "layernorm_1263.dc.multiply.4"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_1263.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_1263.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29821
        },
        "_fused_op_167": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_1263.6 (port_0) ublock_order(r)",
                "Data: layernorm_1263.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_1263.8 (port_2) ublock_order(r)",
                "Data: buffer_0_29821_29822 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.23.attention.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.23.attention.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.23.attention.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.23.attention.output.LayerNorm.weight": "Data",
                "buffer_0_29821_29822": "Data",
                "dc.input_tensor.layernorm_1263.6": "Data",
                "dc.input_tensor.layernorm_1263.8": "Data",
                "layernorm_1263.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_1263.6",
                "layernorm_1263.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_1263.8",
                "buffer_0_29821_29822",
                "bert.encoder.layer.23.attention.output.LayerNorm.weight",
                "bert.encoder.layer.23.attention.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_167",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1266 (port_0)",
                "Data: buffer_7_29822_29624 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1266",
                "buffer_7_29822_29624"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_1263.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_1263.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_1263.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_1263.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_1263.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_1263.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_1263.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29822
        },
        "_fused_op_168": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_1277.1 (port_0) ublock_order(c)",
                "Data: layernorm_1277.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: buffer_0_29624_29823 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_29624_29823": "Data",
                "dc.input_tensor.layernorm_1277.1": "Data",
                "layernorm_1277.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_1277.1",
                "layernorm_1277.dc.reduce_sum.0.lc1",
                "buffer_0_29624_29823"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_168",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1277.dc.multiply.4 (port_0)",
                "Data: buffer_2_29823_29824 (port_0)",
                "Data: layernorm_1277.dc.multiply.4 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1277.dc.multiply.4",
                "buffer_2_29823_29824",
                "layernorm_1277.dc.multiply.4"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_1277.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_1277.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29823
        },
        "_fused_op_169": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_1277.6 (port_0) ublock_order(r)",
                "Data: layernorm_1277.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_1277.8 (port_2) ublock_order(r)",
                "Data: buffer_0_29823_29824 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.23.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.23.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.23.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.23.output.LayerNorm.weight": "Data",
                "buffer_0_29823_29824": "Data",
                "dc.input_tensor.layernorm_1277.6": "Data",
                "dc.input_tensor.layernorm_1277.8": "Data",
                "layernorm_1277.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_1277.6",
                "layernorm_1277.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_1277.8",
                "buffer_0_29823_29824",
                "bert.encoder.layer.23.output.LayerNorm.weight",
                "bert.encoder.layer.23.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_169",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1281 (port_0)",
                "Data: matmul_1288 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1281",
                "matmul_1288"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_1277.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_1277.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_1277.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_1277.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_1277.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_1277.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_1277.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29824
        },
        "_fused_op_17": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_16 (port_0) ublock_order(c)",
                "Data: softmax_130.dc.reduce_max.0 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_16": "Data",
                "softmax_130.dc.reduce_max.0": "Data"
            },
            "input_nodes": [
                "_fused_op_16",
                "softmax_130.dc.reduce_max.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_17",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_130.dc.reduce_sum.3.lc1 (port_0)",
                "Data: buffer_0_29672_29673 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_130.dc.reduce_sum.3.lc1",
                "buffer_0_29672_29673"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_130.dc.subtract.1: subtract (1,16,12,12), out: 0",
                    "softmax_130.dc.exp.2: exp (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 29672
        },
        "_fused_op_18": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: softmax_130.dc.reduce_sum.3.lc1 (port_0) ublock_order(r)",
                "Data: dc.input_tensor.softmax_130.4 (port_1) ublock_order(r)",
                "Data: buffer_0_29672_29673 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_29672_29673": "Data",
                "dc.input_tensor.softmax_130.4": "Data",
                "softmax_130.dc.reduce_sum.3.lc1": "Data"
            },
            "input_nodes": [
                "softmax_130.dc.reduce_sum.3.lc1",
                "dc.input_tensor.softmax_130.4",
                "buffer_0_29672_29673"
            ],
            "input_tms": [
                [],
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_18",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_141 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_141"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_130.dc.add.5: add (1,16,12,1), out: 0",
                    "softmax_130.dc.reciprocal.6: reciprocal (1,16,12,1), out: 0",
                    "softmax_130.dc.multiply.7: multiply (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 29673
        },
        "_fused_op_19": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_150.1 (port_0) ublock_order(c)",
                "Data: layernorm_150.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: buffer_0_27408_29674 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_27408_29674": "Data",
                "dc.input_tensor.layernorm_150.1": "Data",
                "layernorm_150.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_150.1",
                "layernorm_150.dc.reduce_sum.0.lc1",
                "buffer_0_27408_29674"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_19",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_150.dc.multiply.4 (port_0)",
                "Data: buffer_2_29674_29675 (port_0)",
                "Data: layernorm_150.dc.multiply.4 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_150.dc.multiply.4",
                "buffer_2_29674_29675",
                "layernorm_150.dc.multiply.4"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_150.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_150.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29674
        },
        "_fused_op_2": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_16 (port_0) ublock_order(r)",
                "Data: input_1_multiply_18 (port_1) ublock_order(r)",
                "Data: multiply_22_attempt_1_input_op_fork_nop0 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "input_1_multiply_18": "Data",
                "matmul_16": "Data",
                "multiply_22_attempt_1_input_op_fork_nop0": "Data"
            },
            "input_nodes": [
                "matmul_16",
                "input_1_multiply_18",
                "multiply_22_attempt_1_input_op_fork_nop0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_2",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_24.dc.reduce_max.0 (port_0)",
                "Data: _fused_op_3 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_24.dc.reduce_max.0",
                "_fused_op_3"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "multiply_18: multiply (1,16,12,12), out: 0",
                    "add_23: add (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "add"
            },
            "type": "fused_op",
            "unique_id": 29657
        },
        "_fused_op_20": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_150.6 (port_0) ublock_order(r)",
                "Data: layernorm_150.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_150.8 (port_2) ublock_order(r)",
                "Data: buffer_0_29674_29675 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.2.attention.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.2.attention.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.2.attention.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.2.attention.output.LayerNorm.weight": "Data",
                "buffer_0_29674_29675": "Data",
                "dc.input_tensor.layernorm_150.6": "Data",
                "dc.input_tensor.layernorm_150.8": "Data",
                "layernorm_150.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_150.6",
                "layernorm_150.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_150.8",
                "buffer_0_29674_29675",
                "bert.encoder.layer.2.attention.output.LayerNorm.weight",
                "bert.encoder.layer.2.attention.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_20",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_153 (port_0)",
                "Data: add_163 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_153",
                "add_163"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_150.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_150.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_150.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_150.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_150.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_150.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_150.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29675
        },
        "_fused_op_21": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_164.1 (port_0) ublock_order(c)",
                "Data: layernorm_164.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: buffer_0_27440_29676 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_27440_29676": "Data",
                "dc.input_tensor.layernorm_164.1": "Data",
                "layernorm_164.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_164.1",
                "layernorm_164.dc.reduce_sum.0.lc1",
                "buffer_0_27440_29676"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_21",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_164.dc.multiply.4 (port_0)",
                "Data: buffer_1_29676_29677 (port_0)",
                "Data: layernorm_164.dc.multiply.4 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_164.dc.multiply.4",
                "buffer_1_29676_29677",
                "layernorm_164.dc.multiply.4"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_164.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_164.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29676
        },
        "_fused_op_22": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_164.6 (port_0) ublock_order(r)",
                "Data: layernorm_164.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_164.8 (port_2) ublock_order(r)",
                "Data: buffer_0_29676_29677 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.2.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.2.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.2.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.2.output.LayerNorm.weight": "Data",
                "buffer_0_29676_29677": "Data",
                "dc.input_tensor.layernorm_164.6": "Data",
                "dc.input_tensor.layernorm_164.8": "Data",
                "layernorm_164.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_164.6",
                "layernorm_164.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_164.8",
                "buffer_0_29676_29677",
                "bert.encoder.layer.2.output.LayerNorm.weight",
                "bert.encoder.layer.2.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_22",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_167 (port_0)",
                "Data: matmul_173 (port_0)",
                "Data: matmul_187 (port_0)",
                "Data: add_202 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_167",
                "matmul_173",
                "matmul_187",
                "add_202"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_164.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_164.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_164.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_164.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_164.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_164.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_164.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29677
        },
        "_fused_op_23": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_179 (port_0) ublock_order(r)",
                "Data: input_1_multiply_181 (port_1) ublock_order(r)",
                "Data: multiply_22_attempt_1_input_op_fork_nop0 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "input_1_multiply_181": "Data",
                "matmul_179": "Data",
                "multiply_22_attempt_1_input_op_fork_nop0": "Data"
            },
            "input_nodes": [
                "matmul_179",
                "input_1_multiply_181",
                "multiply_22_attempt_1_input_op_fork_nop0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_23",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_183.dc.reduce_max.0 (port_0)",
                "Data: _fused_op_24 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_183.dc.reduce_max.0",
                "_fused_op_24"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "multiply_181: multiply (1,16,12,12), out: 0",
                    "add_182: add (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "add"
            },
            "type": "fused_op",
            "unique_id": 29678
        },
        "_fused_op_24": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_23 (port_0) ublock_order(c)",
                "Data: softmax_183.dc.reduce_max.0 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_23": "Data",
                "softmax_183.dc.reduce_max.0": "Data"
            },
            "input_nodes": [
                "_fused_op_23",
                "softmax_183.dc.reduce_max.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_24",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_183.dc.reduce_sum.3.lc1 (port_0)",
                "Data: _fused_op_25 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_183.dc.reduce_sum.3.lc1",
                "_fused_op_25"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_183.dc.subtract.1: subtract (1,16,12,12), out: 0",
                    "softmax_183.dc.exp.2: exp (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 29679
        },
        "_fused_op_25": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: softmax_183.dc.reduce_sum.3.lc1 (port_0) ublock_order(r)",
                "Data: dc.input_tensor.softmax_183.4 (port_1) ublock_order(r)",
                "Data: _fused_op_24 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_24": "Data",
                "dc.input_tensor.softmax_183.4": "Data",
                "softmax_183.dc.reduce_sum.3.lc1": "Data"
            },
            "input_nodes": [
                "softmax_183.dc.reduce_sum.3.lc1",
                "dc.input_tensor.softmax_183.4",
                "_fused_op_24"
            ],
            "input_tms": [
                [],
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_25",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_194 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_194"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_183.dc.add.5: add (1,16,12,1), out: 0",
                    "softmax_183.dc.reciprocal.6: reciprocal (1,16,12,1), out: 0",
                    "softmax_183.dc.multiply.7: multiply (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 29680
        },
        "_fused_op_26": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_203.1 (port_0) ublock_order(c)",
                "Data: layernorm_203.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: buffer_0_27512_29681 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_27512_29681": "Data",
                "dc.input_tensor.layernorm_203.1": "Data",
                "layernorm_203.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_203.1",
                "layernorm_203.dc.reduce_sum.0.lc1",
                "buffer_0_27512_29681"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_26",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_203.dc.multiply.4 (port_0)",
                "Data: buffer_4_29681_29682 (port_0)",
                "Data: layernorm_203.dc.multiply.4 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_203.dc.multiply.4",
                "buffer_4_29681_29682",
                "layernorm_203.dc.multiply.4"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_203.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_203.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29681
        },
        "_fused_op_27": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_203.6 (port_0) ublock_order(r)",
                "Data: layernorm_203.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_203.8 (port_2) ublock_order(r)",
                "Data: buffer_0_29681_29682 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.3.attention.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.3.attention.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.3.attention.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.3.attention.output.LayerNorm.weight": "Data",
                "buffer_0_29681_29682": "Data",
                "dc.input_tensor.layernorm_203.6": "Data",
                "dc.input_tensor.layernorm_203.8": "Data",
                "layernorm_203.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_203.6",
                "layernorm_203.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_203.8",
                "buffer_0_29681_29682",
                "bert.encoder.layer.3.attention.output.LayerNorm.weight",
                "bert.encoder.layer.3.attention.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_27",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_206 (port_0)",
                "Data: buffer_7_29682_27544 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_206",
                "buffer_7_29682_27544"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_203.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_203.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_203.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_203.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_203.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_203.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_203.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29682
        },
        "_fused_op_28": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_217.1 (port_0) ublock_order(c)",
                "Data: layernorm_217.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: buffer_0_27544_29683 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_27544_29683": "Data",
                "dc.input_tensor.layernorm_217.1": "Data",
                "layernorm_217.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_217.1",
                "layernorm_217.dc.reduce_sum.0.lc1",
                "buffer_0_27544_29683"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_28",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_217.dc.multiply.4 (port_0)",
                "Data: layernorm_217.dc.multiply.4 (port_0)",
                "Data: _fused_op_29 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_217.dc.multiply.4",
                "layernorm_217.dc.multiply.4",
                "_fused_op_29"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_217.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_217.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29683
        },
        "_fused_op_29": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_217.6 (port_0) ublock_order(r)",
                "Data: layernorm_217.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_217.8 (port_2) ublock_order(r)",
                "Data: _fused_op_28 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.3.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.3.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_28": "Data",
                "bert.encoder.layer.3.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.3.output.LayerNorm.weight": "Data",
                "dc.input_tensor.layernorm_217.6": "Data",
                "dc.input_tensor.layernorm_217.8": "Data",
                "layernorm_217.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_217.6",
                "layernorm_217.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_217.8",
                "_fused_op_28",
                "bert.encoder.layer.3.output.LayerNorm.weight",
                "bert.encoder.layer.3.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_29",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_220 (port_0)",
                "Data: matmul_226 (port_0)",
                "Data: matmul_240 (port_0)",
                "Data: add_255 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_220",
                "matmul_226",
                "matmul_240",
                "add_255"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_217.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_217.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_217.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_217.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_217.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_217.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_217.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29684
        },
        "_fused_op_3": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_2 (port_0) ublock_order(c)",
                "Data: softmax_24.dc.reduce_max.0 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_2": "Data",
                "softmax_24.dc.reduce_max.0": "Data"
            },
            "input_nodes": [
                "_fused_op_2",
                "softmax_24.dc.reduce_max.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_3",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_24.dc.reduce_sum.3.lc1 (port_0)",
                "Data: buffer_0_29658_29659 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_24.dc.reduce_sum.3.lc1",
                "buffer_0_29658_29659"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_24.dc.subtract.1: subtract (1,16,12,12), out: 0",
                    "softmax_24.dc.exp.2: exp (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 29658
        },
        "_fused_op_30": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_232 (port_0) ublock_order(r)",
                "Data: input_1_multiply_234 (port_1) ublock_order(r)",
                "Data: multiply_22_attempt_1_input_op_fork_nop0 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "input_1_multiply_234": "Data",
                "matmul_232": "Data",
                "multiply_22_attempt_1_input_op_fork_nop0": "Data"
            },
            "input_nodes": [
                "matmul_232",
                "input_1_multiply_234",
                "multiply_22_attempt_1_input_op_fork_nop0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_30",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_236.dc.reduce_max.0 (port_0)",
                "Data: _fused_op_31 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_236.dc.reduce_max.0",
                "_fused_op_31"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "multiply_234: multiply (1,16,12,12), out: 0",
                    "add_235: add (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "add"
            },
            "type": "fused_op",
            "unique_id": 29685
        },
        "_fused_op_31": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_30 (port_0) ublock_order(c)",
                "Data: softmax_236.dc.reduce_max.0 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_30": "Data",
                "softmax_236.dc.reduce_max.0": "Data"
            },
            "input_nodes": [
                "_fused_op_30",
                "softmax_236.dc.reduce_max.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_31",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_236.dc.reduce_sum.3.lc1 (port_0)",
                "Data: buffer_0_29686_29687 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_236.dc.reduce_sum.3.lc1",
                "buffer_0_29686_29687"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_236.dc.subtract.1: subtract (1,16,12,12), out: 0",
                    "softmax_236.dc.exp.2: exp (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 29686
        },
        "_fused_op_32": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: softmax_236.dc.reduce_sum.3.lc1 (port_0) ublock_order(r)",
                "Data: dc.input_tensor.softmax_236.4 (port_1) ublock_order(r)",
                "Data: buffer_0_29686_29687 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_29686_29687": "Data",
                "dc.input_tensor.softmax_236.4": "Data",
                "softmax_236.dc.reduce_sum.3.lc1": "Data"
            },
            "input_nodes": [
                "softmax_236.dc.reduce_sum.3.lc1",
                "dc.input_tensor.softmax_236.4",
                "buffer_0_29686_29687"
            ],
            "input_tms": [
                [],
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_32",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_247 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_247"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_236.dc.add.5: add (1,16,12,1), out: 0",
                    "softmax_236.dc.reciprocal.6: reciprocal (1,16,12,1), out: 0",
                    "softmax_236.dc.multiply.7: multiply (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 29687
        },
        "_fused_op_33": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_256.1 (port_0) ublock_order(c)",
                "Data: layernorm_256.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: buffer_0_27616_29688 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_27616_29688": "Data",
                "dc.input_tensor.layernorm_256.1": "Data",
                "layernorm_256.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_256.1",
                "layernorm_256.dc.reduce_sum.0.lc1",
                "buffer_0_27616_29688"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_33",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_256.dc.multiply.4 (port_0)",
                "Data: buffer_2_29688_29689 (port_0)",
                "Data: layernorm_256.dc.multiply.4 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_256.dc.multiply.4",
                "buffer_2_29688_29689",
                "layernorm_256.dc.multiply.4"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_256.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_256.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29688
        },
        "_fused_op_34": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_256.6 (port_0) ublock_order(r)",
                "Data: layernorm_256.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_256.8 (port_2) ublock_order(r)",
                "Data: buffer_0_29688_29689 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.4.attention.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.4.attention.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.4.attention.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.4.attention.output.LayerNorm.weight": "Data",
                "buffer_0_29688_29689": "Data",
                "dc.input_tensor.layernorm_256.6": "Data",
                "dc.input_tensor.layernorm_256.8": "Data",
                "layernorm_256.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_256.6",
                "layernorm_256.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_256.8",
                "buffer_0_29688_29689",
                "bert.encoder.layer.4.attention.output.LayerNorm.weight",
                "bert.encoder.layer.4.attention.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_34",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_259 (port_0)",
                "Data: add_269 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_259",
                "add_269"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_256.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_256.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_256.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_256.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_256.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_256.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_256.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29689
        },
        "_fused_op_35": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_270.1 (port_0) ublock_order(c)",
                "Data: layernorm_270.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: buffer_0_27648_29690 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_27648_29690": "Data",
                "dc.input_tensor.layernorm_270.1": "Data",
                "layernorm_270.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_270.1",
                "layernorm_270.dc.reduce_sum.0.lc1",
                "buffer_0_27648_29690"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_35",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_270.dc.multiply.4 (port_0)",
                "Data: buffer_1_29690_29691 (port_0)",
                "Data: layernorm_270.dc.multiply.4 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_270.dc.multiply.4",
                "buffer_1_29690_29691",
                "layernorm_270.dc.multiply.4"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_270.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_270.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29690
        },
        "_fused_op_36": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_270.6 (port_0) ublock_order(r)",
                "Data: layernorm_270.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_270.8 (port_2) ublock_order(r)",
                "Data: buffer_0_29690_29691 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.4.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.4.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.4.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.4.output.LayerNorm.weight": "Data",
                "buffer_0_29690_29691": "Data",
                "dc.input_tensor.layernorm_270.6": "Data",
                "dc.input_tensor.layernorm_270.8": "Data",
                "layernorm_270.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_270.6",
                "layernorm_270.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_270.8",
                "buffer_0_29690_29691",
                "bert.encoder.layer.4.output.LayerNorm.weight",
                "bert.encoder.layer.4.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_36",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_273 (port_0)",
                "Data: matmul_279 (port_0)",
                "Data: matmul_293 (port_0)",
                "Data: add_308 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_273",
                "matmul_279",
                "matmul_293",
                "add_308"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_270.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_270.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_270.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_270.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_270.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_270.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_270.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29691
        },
        "_fused_op_37": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_285 (port_0) ublock_order(r)",
                "Data: input_1_multiply_287 (port_1) ublock_order(r)",
                "Data: multiply_22_attempt_1_input_op_fork_nop0 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "input_1_multiply_287": "Data",
                "matmul_285": "Data",
                "multiply_22_attempt_1_input_op_fork_nop0": "Data"
            },
            "input_nodes": [
                "matmul_285",
                "input_1_multiply_287",
                "multiply_22_attempt_1_input_op_fork_nop0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_37",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_289.dc.reduce_max.0 (port_0)",
                "Data: _fused_op_38 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_289.dc.reduce_max.0",
                "_fused_op_38"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "multiply_287: multiply (1,16,12,12), out: 0",
                    "add_288: add (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "add"
            },
            "type": "fused_op",
            "unique_id": 29692
        },
        "_fused_op_38": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_37 (port_0) ublock_order(c)",
                "Data: softmax_289.dc.reduce_max.0 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_37": "Data",
                "softmax_289.dc.reduce_max.0": "Data"
            },
            "input_nodes": [
                "_fused_op_37",
                "softmax_289.dc.reduce_max.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_38",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_289.dc.reduce_sum.3.lc1 (port_0)",
                "Data: _fused_op_39 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_289.dc.reduce_sum.3.lc1",
                "_fused_op_39"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_289.dc.subtract.1: subtract (1,16,12,12), out: 0",
                    "softmax_289.dc.exp.2: exp (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 29693
        },
        "_fused_op_39": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: softmax_289.dc.reduce_sum.3.lc1 (port_0) ublock_order(r)",
                "Data: dc.input_tensor.softmax_289.4 (port_1) ublock_order(r)",
                "Data: _fused_op_38 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_38": "Data",
                "dc.input_tensor.softmax_289.4": "Data",
                "softmax_289.dc.reduce_sum.3.lc1": "Data"
            },
            "input_nodes": [
                "softmax_289.dc.reduce_sum.3.lc1",
                "dc.input_tensor.softmax_289.4",
                "_fused_op_38"
            ],
            "input_tms": [
                [],
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_39",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_300 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_300"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_289.dc.add.5: add (1,16,12,1), out: 0",
                    "softmax_289.dc.reciprocal.6: reciprocal (1,16,12,1), out: 0",
                    "softmax_289.dc.multiply.7: multiply (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 29694
        },
        "_fused_op_4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: softmax_24.dc.reduce_sum.3.lc1 (port_0) ublock_order(r)",
                "Data: dc.input_tensor.softmax_24.4 (port_1) ublock_order(r)",
                "Data: buffer_0_29658_29659 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_29658_29659": "Data",
                "dc.input_tensor.softmax_24.4": "Data",
                "softmax_24.dc.reduce_sum.3.lc1": "Data"
            },
            "input_nodes": [
                "softmax_24.dc.reduce_sum.3.lc1",
                "dc.input_tensor.softmax_24.4",
                "buffer_0_29658_29659"
            ],
            "input_tms": [
                [],
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_4",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_35 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_35"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_24.dc.add.5: add (1,16,12,1), out: 0",
                    "softmax_24.dc.reciprocal.6: reciprocal (1,16,12,1), out: 0",
                    "softmax_24.dc.multiply.7: multiply (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 29659
        },
        "_fused_op_40": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_309.1 (port_0) ublock_order(c)",
                "Data: layernorm_309.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: buffer_0_27720_29695 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_27720_29695": "Data",
                "dc.input_tensor.layernorm_309.1": "Data",
                "layernorm_309.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_309.1",
                "layernorm_309.dc.reduce_sum.0.lc1",
                "buffer_0_27720_29695"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_40",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_309.dc.multiply.4 (port_0)",
                "Data: buffer_4_29695_29696 (port_0)",
                "Data: layernorm_309.dc.multiply.4 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_309.dc.multiply.4",
                "buffer_4_29695_29696",
                "layernorm_309.dc.multiply.4"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_309.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_309.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29695
        },
        "_fused_op_41": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_309.6 (port_0) ublock_order(r)",
                "Data: layernorm_309.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_309.8 (port_2) ublock_order(r)",
                "Data: buffer_0_29695_29696 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.5.attention.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.5.attention.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.5.attention.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.5.attention.output.LayerNorm.weight": "Data",
                "buffer_0_29695_29696": "Data",
                "dc.input_tensor.layernorm_309.6": "Data",
                "dc.input_tensor.layernorm_309.8": "Data",
                "layernorm_309.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_309.6",
                "layernorm_309.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_309.8",
                "buffer_0_29695_29696",
                "bert.encoder.layer.5.attention.output.LayerNorm.weight",
                "bert.encoder.layer.5.attention.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_41",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_312 (port_0)",
                "Data: buffer_7_29696_27752 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_312",
                "buffer_7_29696_27752"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_309.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_309.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_309.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_309.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_309.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_309.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_309.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29696
        },
        "_fused_op_42": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_323.1 (port_0) ublock_order(c)",
                "Data: layernorm_323.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: buffer_0_27752_29697 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_27752_29697": "Data",
                "dc.input_tensor.layernorm_323.1": "Data",
                "layernorm_323.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_323.1",
                "layernorm_323.dc.reduce_sum.0.lc1",
                "buffer_0_27752_29697"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_42",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_323.dc.multiply.4 (port_0)",
                "Data: layernorm_323.dc.multiply.4 (port_0)",
                "Data: _fused_op_43 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_323.dc.multiply.4",
                "layernorm_323.dc.multiply.4",
                "_fused_op_43"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_323.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_323.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29697
        },
        "_fused_op_43": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_323.6 (port_0) ublock_order(r)",
                "Data: layernorm_323.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_323.8 (port_2) ublock_order(r)",
                "Data: _fused_op_42 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.5.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.5.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_42": "Data",
                "bert.encoder.layer.5.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.5.output.LayerNorm.weight": "Data",
                "dc.input_tensor.layernorm_323.6": "Data",
                "dc.input_tensor.layernorm_323.8": "Data",
                "layernorm_323.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_323.6",
                "layernorm_323.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_323.8",
                "_fused_op_42",
                "bert.encoder.layer.5.output.LayerNorm.weight",
                "bert.encoder.layer.5.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_43",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_326 (port_0)",
                "Data: matmul_332 (port_0)",
                "Data: matmul_346 (port_0)",
                "Data: add_361 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_326",
                "matmul_332",
                "matmul_346",
                "add_361"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_323.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_323.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_323.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_323.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_323.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_323.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_323.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29698
        },
        "_fused_op_44": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_338 (port_0) ublock_order(r)",
                "Data: input_1_multiply_340 (port_1) ublock_order(r)",
                "Data: multiply_22_attempt_1_input_op_fork_nop0 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "input_1_multiply_340": "Data",
                "matmul_338": "Data",
                "multiply_22_attempt_1_input_op_fork_nop0": "Data"
            },
            "input_nodes": [
                "matmul_338",
                "input_1_multiply_340",
                "multiply_22_attempt_1_input_op_fork_nop0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_44",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_342.dc.reduce_max.0 (port_0)",
                "Data: _fused_op_45 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_342.dc.reduce_max.0",
                "_fused_op_45"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "multiply_340: multiply (1,16,12,12), out: 0",
                    "add_341: add (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "add"
            },
            "type": "fused_op",
            "unique_id": 29699
        },
        "_fused_op_45": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_44 (port_0) ublock_order(c)",
                "Data: softmax_342.dc.reduce_max.0 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_44": "Data",
                "softmax_342.dc.reduce_max.0": "Data"
            },
            "input_nodes": [
                "_fused_op_44",
                "softmax_342.dc.reduce_max.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_45",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_342.dc.reduce_sum.3.lc1 (port_0)",
                "Data: buffer_0_29700_29701 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_342.dc.reduce_sum.3.lc1",
                "buffer_0_29700_29701"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_342.dc.subtract.1: subtract (1,16,12,12), out: 0",
                    "softmax_342.dc.exp.2: exp (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 29700
        },
        "_fused_op_46": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: softmax_342.dc.reduce_sum.3.lc1 (port_0) ublock_order(r)",
                "Data: dc.input_tensor.softmax_342.4 (port_1) ublock_order(r)",
                "Data: buffer_0_29700_29701 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_29700_29701": "Data",
                "dc.input_tensor.softmax_342.4": "Data",
                "softmax_342.dc.reduce_sum.3.lc1": "Data"
            },
            "input_nodes": [
                "softmax_342.dc.reduce_sum.3.lc1",
                "dc.input_tensor.softmax_342.4",
                "buffer_0_29700_29701"
            ],
            "input_tms": [
                [],
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_46",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_353 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_353"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_342.dc.add.5: add (1,16,12,1), out: 0",
                    "softmax_342.dc.reciprocal.6: reciprocal (1,16,12,1), out: 0",
                    "softmax_342.dc.multiply.7: multiply (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 29701
        },
        "_fused_op_47": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_362.1 (port_0) ublock_order(c)",
                "Data: layernorm_362.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: buffer_0_27824_29702 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_27824_29702": "Data",
                "dc.input_tensor.layernorm_362.1": "Data",
                "layernorm_362.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_362.1",
                "layernorm_362.dc.reduce_sum.0.lc1",
                "buffer_0_27824_29702"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_47",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_362.dc.multiply.4 (port_0)",
                "Data: buffer_2_29702_29703 (port_0)",
                "Data: layernorm_362.dc.multiply.4 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_362.dc.multiply.4",
                "buffer_2_29702_29703",
                "layernorm_362.dc.multiply.4"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_362.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_362.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29702
        },
        "_fused_op_48": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_362.6 (port_0) ublock_order(r)",
                "Data: layernorm_362.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_362.8 (port_2) ublock_order(r)",
                "Data: buffer_0_29702_29703 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.6.attention.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.6.attention.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.6.attention.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.6.attention.output.LayerNorm.weight": "Data",
                "buffer_0_29702_29703": "Data",
                "dc.input_tensor.layernorm_362.6": "Data",
                "dc.input_tensor.layernorm_362.8": "Data",
                "layernorm_362.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_362.6",
                "layernorm_362.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_362.8",
                "buffer_0_29702_29703",
                "bert.encoder.layer.6.attention.output.LayerNorm.weight",
                "bert.encoder.layer.6.attention.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_48",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_365 (port_0)",
                "Data: add_375 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_365",
                "add_375"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_362.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_362.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_362.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_362.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_362.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_362.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_362.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29703
        },
        "_fused_op_49": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_376.1 (port_0) ublock_order(c)",
                "Data: layernorm_376.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: buffer_0_27856_29704 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_27856_29704": "Data",
                "dc.input_tensor.layernorm_376.1": "Data",
                "layernorm_376.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_376.1",
                "layernorm_376.dc.reduce_sum.0.lc1",
                "buffer_0_27856_29704"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_49",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_376.dc.multiply.4 (port_0)",
                "Data: buffer_1_29704_29705 (port_0)",
                "Data: layernorm_376.dc.multiply.4 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_376.dc.multiply.4",
                "buffer_1_29704_29705",
                "layernorm_376.dc.multiply.4"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_376.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_376.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29704
        },
        "_fused_op_5": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_44.1 (port_0) ublock_order(c)",
                "Data: layernorm_44.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: buffer_0_27200_29660 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_27200_29660": "Data",
                "dc.input_tensor.layernorm_44.1": "Data",
                "layernorm_44.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_44.1",
                "layernorm_44.dc.reduce_sum.0.lc1",
                "buffer_0_27200_29660"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_5",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_44.dc.multiply.4 (port_0)",
                "Data: buffer_2_29660_29661 (port_0)",
                "Data: layernorm_44.dc.multiply.4 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_44.dc.multiply.4",
                "buffer_2_29660_29661",
                "layernorm_44.dc.multiply.4"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_44.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_44.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29660
        },
        "_fused_op_50": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_376.6 (port_0) ublock_order(r)",
                "Data: layernorm_376.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_376.8 (port_2) ublock_order(r)",
                "Data: buffer_0_29704_29705 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.6.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.6.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.6.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.6.output.LayerNorm.weight": "Data",
                "buffer_0_29704_29705": "Data",
                "dc.input_tensor.layernorm_376.6": "Data",
                "dc.input_tensor.layernorm_376.8": "Data",
                "layernorm_376.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_376.6",
                "layernorm_376.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_376.8",
                "buffer_0_29704_29705",
                "bert.encoder.layer.6.output.LayerNorm.weight",
                "bert.encoder.layer.6.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_50",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_379 (port_0)",
                "Data: matmul_385 (port_0)",
                "Data: matmul_399 (port_0)",
                "Data: add_414 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_379",
                "matmul_385",
                "matmul_399",
                "add_414"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_376.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_376.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_376.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_376.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_376.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_376.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_376.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29705
        },
        "_fused_op_51": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_391 (port_0) ublock_order(r)",
                "Data: input_1_multiply_393 (port_1) ublock_order(r)",
                "Data: multiply_22_attempt_1_input_op_fork_nop0 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "input_1_multiply_393": "Data",
                "matmul_391": "Data",
                "multiply_22_attempt_1_input_op_fork_nop0": "Data"
            },
            "input_nodes": [
                "matmul_391",
                "input_1_multiply_393",
                "multiply_22_attempt_1_input_op_fork_nop0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_51",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_395.dc.reduce_max.0 (port_0)",
                "Data: _fused_op_52 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_395.dc.reduce_max.0",
                "_fused_op_52"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "multiply_393: multiply (1,16,12,12), out: 0",
                    "add_394: add (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "add"
            },
            "type": "fused_op",
            "unique_id": 29706
        },
        "_fused_op_52": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_51 (port_0) ublock_order(c)",
                "Data: softmax_395.dc.reduce_max.0 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_51": "Data",
                "softmax_395.dc.reduce_max.0": "Data"
            },
            "input_nodes": [
                "_fused_op_51",
                "softmax_395.dc.reduce_max.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_52",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_395.dc.reduce_sum.3.lc1 (port_0)",
                "Data: _fused_op_53 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_395.dc.reduce_sum.3.lc1",
                "_fused_op_53"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_395.dc.subtract.1: subtract (1,16,12,12), out: 0",
                    "softmax_395.dc.exp.2: exp (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 29707
        },
        "_fused_op_53": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: softmax_395.dc.reduce_sum.3.lc1 (port_0) ublock_order(r)",
                "Data: dc.input_tensor.softmax_395.4 (port_1) ublock_order(r)",
                "Data: _fused_op_52 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_52": "Data",
                "dc.input_tensor.softmax_395.4": "Data",
                "softmax_395.dc.reduce_sum.3.lc1": "Data"
            },
            "input_nodes": [
                "softmax_395.dc.reduce_sum.3.lc1",
                "dc.input_tensor.softmax_395.4",
                "_fused_op_52"
            ],
            "input_tms": [
                [],
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_53",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_406 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_406"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_395.dc.add.5: add (1,16,12,1), out: 0",
                    "softmax_395.dc.reciprocal.6: reciprocal (1,16,12,1), out: 0",
                    "softmax_395.dc.multiply.7: multiply (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 29708
        },
        "_fused_op_54": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_415.1 (port_0) ublock_order(c)",
                "Data: layernorm_415.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: buffer_0_27928_29709 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_27928_29709": "Data",
                "dc.input_tensor.layernorm_415.1": "Data",
                "layernorm_415.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_415.1",
                "layernorm_415.dc.reduce_sum.0.lc1",
                "buffer_0_27928_29709"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_54",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_415.dc.multiply.4 (port_0)",
                "Data: buffer_4_29709_29710 (port_0)",
                "Data: layernorm_415.dc.multiply.4 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_415.dc.multiply.4",
                "buffer_4_29709_29710",
                "layernorm_415.dc.multiply.4"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_415.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_415.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29709
        },
        "_fused_op_55": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_415.6 (port_0) ublock_order(r)",
                "Data: layernorm_415.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_415.8 (port_2) ublock_order(r)",
                "Data: buffer_0_29709_29710 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.7.attention.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.7.attention.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.7.attention.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.7.attention.output.LayerNorm.weight": "Data",
                "buffer_0_29709_29710": "Data",
                "dc.input_tensor.layernorm_415.6": "Data",
                "dc.input_tensor.layernorm_415.8": "Data",
                "layernorm_415.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_415.6",
                "layernorm_415.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_415.8",
                "buffer_0_29709_29710",
                "bert.encoder.layer.7.attention.output.LayerNorm.weight",
                "bert.encoder.layer.7.attention.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_55",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_418 (port_0)",
                "Data: buffer_7_29710_27960 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_418",
                "buffer_7_29710_27960"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_415.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_415.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_415.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_415.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_415.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_415.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_415.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29710
        },
        "_fused_op_56": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_429.1 (port_0) ublock_order(c)",
                "Data: layernorm_429.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: buffer_0_27960_29711 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_27960_29711": "Data",
                "dc.input_tensor.layernorm_429.1": "Data",
                "layernorm_429.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_429.1",
                "layernorm_429.dc.reduce_sum.0.lc1",
                "buffer_0_27960_29711"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_56",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_429.dc.multiply.4 (port_0)",
                "Data: layernorm_429.dc.multiply.4 (port_0)",
                "Data: _fused_op_57 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_429.dc.multiply.4",
                "layernorm_429.dc.multiply.4",
                "_fused_op_57"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_429.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_429.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29711
        },
        "_fused_op_57": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_429.6 (port_0) ublock_order(r)",
                "Data: layernorm_429.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_429.8 (port_2) ublock_order(r)",
                "Data: _fused_op_56 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.7.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.7.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_56": "Data",
                "bert.encoder.layer.7.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.7.output.LayerNorm.weight": "Data",
                "dc.input_tensor.layernorm_429.6": "Data",
                "dc.input_tensor.layernorm_429.8": "Data",
                "layernorm_429.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_429.6",
                "layernorm_429.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_429.8",
                "_fused_op_56",
                "bert.encoder.layer.7.output.LayerNorm.weight",
                "bert.encoder.layer.7.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_57",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_432 (port_0)",
                "Data: matmul_438 (port_0)",
                "Data: matmul_452 (port_0)",
                "Data: add_467 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_432",
                "matmul_438",
                "matmul_452",
                "add_467"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_429.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_429.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_429.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_429.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_429.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_429.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_429.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29712
        },
        "_fused_op_58": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_444 (port_0) ublock_order(r)",
                "Data: input_1_multiply_446 (port_1) ublock_order(r)",
                "Data: multiply_22_attempt_1_input_op_fork_nop1 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "input_1_multiply_446": "Data",
                "matmul_444": "Data",
                "multiply_22_attempt_1_input_op_fork_nop1": "Data"
            },
            "input_nodes": [
                "matmul_444",
                "input_1_multiply_446",
                "multiply_22_attempt_1_input_op_fork_nop1"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_58",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_448.dc.reduce_max.0 (port_0)",
                "Data: _fused_op_59 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_448.dc.reduce_max.0",
                "_fused_op_59"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "multiply_446: multiply (1,16,12,12), out: 0",
                    "add_447: add (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "add"
            },
            "type": "fused_op",
            "unique_id": 29713
        },
        "_fused_op_59": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_58 (port_0) ublock_order(c)",
                "Data: softmax_448.dc.reduce_max.0 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_58": "Data",
                "softmax_448.dc.reduce_max.0": "Data"
            },
            "input_nodes": [
                "_fused_op_58",
                "softmax_448.dc.reduce_max.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_59",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_448.dc.reduce_sum.3.lc1 (port_0)",
                "Data: buffer_0_29714_29715 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_448.dc.reduce_sum.3.lc1",
                "buffer_0_29714_29715"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_448.dc.subtract.1: subtract (1,16,12,12), out: 0",
                    "softmax_448.dc.exp.2: exp (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 29714
        },
        "_fused_op_6": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_44.6 (port_0) ublock_order(r)",
                "Data: layernorm_44.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_44.8 (port_2) ublock_order(r)",
                "Data: buffer_0_29660_29661 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.0.attention.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.0.attention.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.0.attention.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.0.attention.output.LayerNorm.weight": "Data",
                "buffer_0_29660_29661": "Data",
                "dc.input_tensor.layernorm_44.6": "Data",
                "dc.input_tensor.layernorm_44.8": "Data",
                "layernorm_44.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_44.6",
                "layernorm_44.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_44.8",
                "buffer_0_29660_29661",
                "bert.encoder.layer.0.attention.output.LayerNorm.weight",
                "bert.encoder.layer.0.attention.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_6",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_47 (port_0)",
                "Data: add_57 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_47",
                "add_57"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_44.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_44.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_44.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_44.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_44.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_44.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_44.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29661
        },
        "_fused_op_60": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: softmax_448.dc.reduce_sum.3.lc1 (port_0) ublock_order(r)",
                "Data: dc.input_tensor.softmax_448.4 (port_1) ublock_order(r)",
                "Data: buffer_0_29714_29715 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_29714_29715": "Data",
                "dc.input_tensor.softmax_448.4": "Data",
                "softmax_448.dc.reduce_sum.3.lc1": "Data"
            },
            "input_nodes": [
                "softmax_448.dc.reduce_sum.3.lc1",
                "dc.input_tensor.softmax_448.4",
                "buffer_0_29714_29715"
            ],
            "input_tms": [
                [],
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_60",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_459 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_459"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_448.dc.add.5: add (1,16,12,1), out: 0",
                    "softmax_448.dc.reciprocal.6: reciprocal (1,16,12,1), out: 0",
                    "softmax_448.dc.multiply.7: multiply (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 29715
        },
        "_fused_op_61": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_468.1 (port_0) ublock_order(c)",
                "Data: layernorm_468.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: buffer_0_28032_29716 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_28032_29716": "Data",
                "dc.input_tensor.layernorm_468.1": "Data",
                "layernorm_468.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_468.1",
                "layernorm_468.dc.reduce_sum.0.lc1",
                "buffer_0_28032_29716"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_61",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_468.dc.multiply.4 (port_0)",
                "Data: buffer_2_29716_29717 (port_0)",
                "Data: layernorm_468.dc.multiply.4 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_468.dc.multiply.4",
                "buffer_2_29716_29717",
                "layernorm_468.dc.multiply.4"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_468.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_468.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29716
        },
        "_fused_op_62": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_468.6 (port_0) ublock_order(r)",
                "Data: layernorm_468.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_468.8 (port_2) ublock_order(r)",
                "Data: buffer_0_29716_29717 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.8.attention.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.8.attention.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.8.attention.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.8.attention.output.LayerNorm.weight": "Data",
                "buffer_0_29716_29717": "Data",
                "dc.input_tensor.layernorm_468.6": "Data",
                "dc.input_tensor.layernorm_468.8": "Data",
                "layernorm_468.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_468.6",
                "layernorm_468.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_468.8",
                "buffer_0_29716_29717",
                "bert.encoder.layer.8.attention.output.LayerNorm.weight",
                "bert.encoder.layer.8.attention.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_62",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_471 (port_0)",
                "Data: add_481 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_471",
                "add_481"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_468.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_468.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_468.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_468.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_468.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_468.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_468.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29717
        },
        "_fused_op_63": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_482.1 (port_0) ublock_order(c)",
                "Data: layernorm_482.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: buffer_0_28064_29718 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_28064_29718": "Data",
                "dc.input_tensor.layernorm_482.1": "Data",
                "layernorm_482.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_482.1",
                "layernorm_482.dc.reduce_sum.0.lc1",
                "buffer_0_28064_29718"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_63",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_482.dc.multiply.4 (port_0)",
                "Data: buffer_1_29718_29719 (port_0)",
                "Data: layernorm_482.dc.multiply.4 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_482.dc.multiply.4",
                "buffer_1_29718_29719",
                "layernorm_482.dc.multiply.4"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_482.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_482.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29718
        },
        "_fused_op_64": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_482.6 (port_0) ublock_order(r)",
                "Data: layernorm_482.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_482.8 (port_2) ublock_order(r)",
                "Data: buffer_0_29718_29719 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.8.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.8.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.8.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.8.output.LayerNorm.weight": "Data",
                "buffer_0_29718_29719": "Data",
                "dc.input_tensor.layernorm_482.6": "Data",
                "dc.input_tensor.layernorm_482.8": "Data",
                "layernorm_482.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_482.6",
                "layernorm_482.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_482.8",
                "buffer_0_29718_29719",
                "bert.encoder.layer.8.output.LayerNorm.weight",
                "bert.encoder.layer.8.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_64",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_485 (port_0)",
                "Data: matmul_491 (port_0)",
                "Data: matmul_505 (port_0)",
                "Data: add_520 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_485",
                "matmul_491",
                "matmul_505",
                "add_520"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_482.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_482.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_482.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_482.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_482.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_482.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_482.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29719
        },
        "_fused_op_65": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_497 (port_0) ublock_order(r)",
                "Data: input_1_multiply_499 (port_1) ublock_order(r)",
                "Data: multiply_22_attempt_1_input_op_fork_nop1 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "input_1_multiply_499": "Data",
                "matmul_497": "Data",
                "multiply_22_attempt_1_input_op_fork_nop1": "Data"
            },
            "input_nodes": [
                "matmul_497",
                "input_1_multiply_499",
                "multiply_22_attempt_1_input_op_fork_nop1"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_65",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_501.dc.reduce_max.0 (port_0)",
                "Data: _fused_op_66 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_501.dc.reduce_max.0",
                "_fused_op_66"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "multiply_499: multiply (1,16,12,12), out: 0",
                    "add_500: add (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "add"
            },
            "type": "fused_op",
            "unique_id": 29720
        },
        "_fused_op_66": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_65 (port_0) ublock_order(c)",
                "Data: softmax_501.dc.reduce_max.0 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_65": "Data",
                "softmax_501.dc.reduce_max.0": "Data"
            },
            "input_nodes": [
                "_fused_op_65",
                "softmax_501.dc.reduce_max.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_66",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_501.dc.reduce_sum.3.lc1 (port_0)",
                "Data: _fused_op_67 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_501.dc.reduce_sum.3.lc1",
                "_fused_op_67"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_501.dc.subtract.1: subtract (1,16,12,12), out: 0",
                    "softmax_501.dc.exp.2: exp (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 29721
        },
        "_fused_op_67": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: softmax_501.dc.reduce_sum.3.lc1 (port_0) ublock_order(r)",
                "Data: dc.input_tensor.softmax_501.4 (port_1) ublock_order(r)",
                "Data: _fused_op_66 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_66": "Data",
                "dc.input_tensor.softmax_501.4": "Data",
                "softmax_501.dc.reduce_sum.3.lc1": "Data"
            },
            "input_nodes": [
                "softmax_501.dc.reduce_sum.3.lc1",
                "dc.input_tensor.softmax_501.4",
                "_fused_op_66"
            ],
            "input_tms": [
                [],
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_67",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_512 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_512"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_501.dc.add.5: add (1,16,12,1), out: 0",
                    "softmax_501.dc.reciprocal.6: reciprocal (1,16,12,1), out: 0",
                    "softmax_501.dc.multiply.7: multiply (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 29722
        },
        "_fused_op_68": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_521.1 (port_0) ublock_order(c)",
                "Data: layernorm_521.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: buffer_0_28136_29723 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_28136_29723": "Data",
                "dc.input_tensor.layernorm_521.1": "Data",
                "layernorm_521.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_521.1",
                "layernorm_521.dc.reduce_sum.0.lc1",
                "buffer_0_28136_29723"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_68",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_521.dc.multiply.4 (port_0)",
                "Data: buffer_4_29723_29724 (port_0)",
                "Data: layernorm_521.dc.multiply.4 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_521.dc.multiply.4",
                "buffer_4_29723_29724",
                "layernorm_521.dc.multiply.4"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_521.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_521.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29723
        },
        "_fused_op_69": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_521.6 (port_0) ublock_order(r)",
                "Data: layernorm_521.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_521.8 (port_2) ublock_order(r)",
                "Data: buffer_0_29723_29724 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.9.attention.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.9.attention.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.9.attention.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.9.attention.output.LayerNorm.weight": "Data",
                "buffer_0_29723_29724": "Data",
                "dc.input_tensor.layernorm_521.6": "Data",
                "dc.input_tensor.layernorm_521.8": "Data",
                "layernorm_521.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_521.6",
                "layernorm_521.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_521.8",
                "buffer_0_29723_29724",
                "bert.encoder.layer.9.attention.output.LayerNorm.weight",
                "bert.encoder.layer.9.attention.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_69",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_524 (port_0)",
                "Data: buffer_7_29724_28168 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_524",
                "buffer_7_29724_28168"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_521.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_521.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_521.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_521.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_521.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_521.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_521.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29724
        },
        "_fused_op_7": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_58.1 (port_0) ublock_order(c)",
                "Data: layernorm_58.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: buffer_0_27232_29662 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_27232_29662": "Data",
                "dc.input_tensor.layernorm_58.1": "Data",
                "layernorm_58.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_58.1",
                "layernorm_58.dc.reduce_sum.0.lc1",
                "buffer_0_27232_29662"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_7",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_58.dc.multiply.4 (port_0)",
                "Data: buffer_1_29662_29663 (port_0)",
                "Data: layernorm_58.dc.multiply.4 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_58.dc.multiply.4",
                "buffer_1_29662_29663",
                "layernorm_58.dc.multiply.4"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_58.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_58.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29662
        },
        "_fused_op_70": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_535.1 (port_0) ublock_order(c)",
                "Data: layernorm_535.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: buffer_0_28168_29725 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_28168_29725": "Data",
                "dc.input_tensor.layernorm_535.1": "Data",
                "layernorm_535.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_535.1",
                "layernorm_535.dc.reduce_sum.0.lc1",
                "buffer_0_28168_29725"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_70",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_535.dc.multiply.4 (port_0)",
                "Data: layernorm_535.dc.multiply.4 (port_0)",
                "Data: _fused_op_71 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_535.dc.multiply.4",
                "layernorm_535.dc.multiply.4",
                "_fused_op_71"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_535.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_535.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29725
        },
        "_fused_op_71": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_535.6 (port_0) ublock_order(r)",
                "Data: layernorm_535.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_535.8 (port_2) ublock_order(r)",
                "Data: _fused_op_70 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.9.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.9.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_70": "Data",
                "bert.encoder.layer.9.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.9.output.LayerNorm.weight": "Data",
                "dc.input_tensor.layernorm_535.6": "Data",
                "dc.input_tensor.layernorm_535.8": "Data",
                "layernorm_535.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_535.6",
                "layernorm_535.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_535.8",
                "_fused_op_70",
                "bert.encoder.layer.9.output.LayerNorm.weight",
                "bert.encoder.layer.9.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_71",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_538 (port_0)",
                "Data: matmul_544 (port_0)",
                "Data: matmul_558 (port_0)",
                "Data: add_573 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_538",
                "matmul_544",
                "matmul_558",
                "add_573"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_535.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_535.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_535.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_535.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_535.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_535.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_535.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29726
        },
        "_fused_op_72": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_550 (port_0) ublock_order(r)",
                "Data: input_1_multiply_552 (port_1) ublock_order(r)",
                "Data: multiply_22_attempt_1_input_op_fork_nop1 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "input_1_multiply_552": "Data",
                "matmul_550": "Data",
                "multiply_22_attempt_1_input_op_fork_nop1": "Data"
            },
            "input_nodes": [
                "matmul_550",
                "input_1_multiply_552",
                "multiply_22_attempt_1_input_op_fork_nop1"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_72",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_554.dc.reduce_max.0 (port_0)",
                "Data: _fused_op_73 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_554.dc.reduce_max.0",
                "_fused_op_73"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "multiply_552: multiply (1,16,12,12), out: 0",
                    "add_553: add (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "add"
            },
            "type": "fused_op",
            "unique_id": 29727
        },
        "_fused_op_73": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_72 (port_0) ublock_order(c)",
                "Data: softmax_554.dc.reduce_max.0 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_72": "Data",
                "softmax_554.dc.reduce_max.0": "Data"
            },
            "input_nodes": [
                "_fused_op_72",
                "softmax_554.dc.reduce_max.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_73",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_554.dc.reduce_sum.3.lc1 (port_0)",
                "Data: buffer_0_29728_29729 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_554.dc.reduce_sum.3.lc1",
                "buffer_0_29728_29729"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_554.dc.subtract.1: subtract (1,16,12,12), out: 0",
                    "softmax_554.dc.exp.2: exp (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 29728
        },
        "_fused_op_74": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: softmax_554.dc.reduce_sum.3.lc1 (port_0) ublock_order(r)",
                "Data: dc.input_tensor.softmax_554.4 (port_1) ublock_order(r)",
                "Data: buffer_0_29728_29729 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_29728_29729": "Data",
                "dc.input_tensor.softmax_554.4": "Data",
                "softmax_554.dc.reduce_sum.3.lc1": "Data"
            },
            "input_nodes": [
                "softmax_554.dc.reduce_sum.3.lc1",
                "dc.input_tensor.softmax_554.4",
                "buffer_0_29728_29729"
            ],
            "input_tms": [
                [],
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_74",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_565 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_565"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_554.dc.add.5: add (1,16,12,1), out: 0",
                    "softmax_554.dc.reciprocal.6: reciprocal (1,16,12,1), out: 0",
                    "softmax_554.dc.multiply.7: multiply (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 29729
        },
        "_fused_op_75": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_574.1 (port_0) ublock_order(c)",
                "Data: layernorm_574.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: buffer_0_28240_29730 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_28240_29730": "Data",
                "dc.input_tensor.layernorm_574.1": "Data",
                "layernorm_574.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_574.1",
                "layernorm_574.dc.reduce_sum.0.lc1",
                "buffer_0_28240_29730"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_75",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_574.dc.multiply.4 (port_0)",
                "Data: buffer_2_29730_29731 (port_0)",
                "Data: layernorm_574.dc.multiply.4 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_574.dc.multiply.4",
                "buffer_2_29730_29731",
                "layernorm_574.dc.multiply.4"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_574.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_574.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29730
        },
        "_fused_op_76": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_574.6 (port_0) ublock_order(r)",
                "Data: layernorm_574.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_574.8 (port_2) ublock_order(r)",
                "Data: buffer_0_29730_29731 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.10.attention.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.10.attention.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.10.attention.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.10.attention.output.LayerNorm.weight": "Data",
                "buffer_0_29730_29731": "Data",
                "dc.input_tensor.layernorm_574.6": "Data",
                "dc.input_tensor.layernorm_574.8": "Data",
                "layernorm_574.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_574.6",
                "layernorm_574.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_574.8",
                "buffer_0_29730_29731",
                "bert.encoder.layer.10.attention.output.LayerNorm.weight",
                "bert.encoder.layer.10.attention.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_76",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_577 (port_0)",
                "Data: add_587 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_577",
                "add_587"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_574.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_574.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_574.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_574.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_574.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_574.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_574.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29731
        },
        "_fused_op_77": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_588.1 (port_0) ublock_order(c)",
                "Data: layernorm_588.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: buffer_0_28272_29732 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_28272_29732": "Data",
                "dc.input_tensor.layernorm_588.1": "Data",
                "layernorm_588.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_588.1",
                "layernorm_588.dc.reduce_sum.0.lc1",
                "buffer_0_28272_29732"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_77",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_588.dc.multiply.4 (port_0)",
                "Data: buffer_1_29732_29733 (port_0)",
                "Data: layernorm_588.dc.multiply.4 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_588.dc.multiply.4",
                "buffer_1_29732_29733",
                "layernorm_588.dc.multiply.4"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_588.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_588.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29732
        },
        "_fused_op_78": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_588.6 (port_0) ublock_order(r)",
                "Data: layernorm_588.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_588.8 (port_2) ublock_order(r)",
                "Data: buffer_0_29732_29733 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.10.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.10.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.10.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.10.output.LayerNorm.weight": "Data",
                "buffer_0_29732_29733": "Data",
                "dc.input_tensor.layernorm_588.6": "Data",
                "dc.input_tensor.layernorm_588.8": "Data",
                "layernorm_588.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_588.6",
                "layernorm_588.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_588.8",
                "buffer_0_29732_29733",
                "bert.encoder.layer.10.output.LayerNorm.weight",
                "bert.encoder.layer.10.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_78",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_591 (port_0)",
                "Data: matmul_597 (port_0)",
                "Data: matmul_611 (port_0)",
                "Data: add_626 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_591",
                "matmul_597",
                "matmul_611",
                "add_626"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_588.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_588.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_588.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_588.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_588.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_588.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_588.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29733
        },
        "_fused_op_79": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_603 (port_0) ublock_order(r)",
                "Data: input_1_multiply_605 (port_1) ublock_order(r)",
                "Data: multiply_22_attempt_1_input_op_fork_nop1 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "input_1_multiply_605": "Data",
                "matmul_603": "Data",
                "multiply_22_attempt_1_input_op_fork_nop1": "Data"
            },
            "input_nodes": [
                "matmul_603",
                "input_1_multiply_605",
                "multiply_22_attempt_1_input_op_fork_nop1"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_79",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_607.dc.reduce_max.0 (port_0)",
                "Data: _fused_op_80 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_607.dc.reduce_max.0",
                "_fused_op_80"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "multiply_605: multiply (1,16,12,12), out: 0",
                    "add_606: add (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "add"
            },
            "type": "fused_op",
            "unique_id": 29734
        },
        "_fused_op_8": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_58.6 (port_0) ublock_order(r)",
                "Data: layernorm_58.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_58.8 (port_2) ublock_order(r)",
                "Data: buffer_0_29662_29663 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.0.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.0.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.0.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.0.output.LayerNorm.weight": "Data",
                "buffer_0_29662_29663": "Data",
                "dc.input_tensor.layernorm_58.6": "Data",
                "dc.input_tensor.layernorm_58.8": "Data",
                "layernorm_58.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_58.6",
                "layernorm_58.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_58.8",
                "buffer_0_29662_29663",
                "bert.encoder.layer.0.output.LayerNorm.weight",
                "bert.encoder.layer.0.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_8",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_61 (port_0)",
                "Data: matmul_67 (port_0)",
                "Data: matmul_81 (port_0)",
                "Data: add_96 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_61",
                "matmul_67",
                "matmul_81",
                "add_96"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_58.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_58.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_58.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_58.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_58.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_58.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_58.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29663
        },
        "_fused_op_80": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_79 (port_0) ublock_order(c)",
                "Data: softmax_607.dc.reduce_max.0 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_79": "Data",
                "softmax_607.dc.reduce_max.0": "Data"
            },
            "input_nodes": [
                "_fused_op_79",
                "softmax_607.dc.reduce_max.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_80",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_607.dc.reduce_sum.3.lc1 (port_0)",
                "Data: _fused_op_81 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_607.dc.reduce_sum.3.lc1",
                "_fused_op_81"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_607.dc.subtract.1: subtract (1,16,12,12), out: 0",
                    "softmax_607.dc.exp.2: exp (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 29735
        },
        "_fused_op_81": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: softmax_607.dc.reduce_sum.3.lc1 (port_0) ublock_order(r)",
                "Data: dc.input_tensor.softmax_607.4 (port_1) ublock_order(r)",
                "Data: _fused_op_80 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_80": "Data",
                "dc.input_tensor.softmax_607.4": "Data",
                "softmax_607.dc.reduce_sum.3.lc1": "Data"
            },
            "input_nodes": [
                "softmax_607.dc.reduce_sum.3.lc1",
                "dc.input_tensor.softmax_607.4",
                "_fused_op_80"
            ],
            "input_tms": [
                [],
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_81",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_618 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_618"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_607.dc.add.5: add (1,16,12,1), out: 0",
                    "softmax_607.dc.reciprocal.6: reciprocal (1,16,12,1), out: 0",
                    "softmax_607.dc.multiply.7: multiply (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 29736
        },
        "_fused_op_82": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_627.1 (port_0) ublock_order(c)",
                "Data: layernorm_627.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: buffer_0_28344_29737 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_28344_29737": "Data",
                "dc.input_tensor.layernorm_627.1": "Data",
                "layernorm_627.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_627.1",
                "layernorm_627.dc.reduce_sum.0.lc1",
                "buffer_0_28344_29737"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_82",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_627.dc.multiply.4 (port_0)",
                "Data: buffer_4_29737_29738 (port_0)",
                "Data: layernorm_627.dc.multiply.4 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_627.dc.multiply.4",
                "buffer_4_29737_29738",
                "layernorm_627.dc.multiply.4"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_627.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_627.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29737
        },
        "_fused_op_83": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_627.6 (port_0) ublock_order(r)",
                "Data: layernorm_627.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_627.8 (port_2) ublock_order(r)",
                "Data: buffer_0_29737_29738 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.11.attention.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.11.attention.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.11.attention.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.11.attention.output.LayerNorm.weight": "Data",
                "buffer_0_29737_29738": "Data",
                "dc.input_tensor.layernorm_627.6": "Data",
                "dc.input_tensor.layernorm_627.8": "Data",
                "layernorm_627.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_627.6",
                "layernorm_627.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_627.8",
                "buffer_0_29737_29738",
                "bert.encoder.layer.11.attention.output.LayerNorm.weight",
                "bert.encoder.layer.11.attention.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_83",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_630 (port_0)",
                "Data: buffer_7_29738_28376 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_630",
                "buffer_7_29738_28376"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_627.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_627.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_627.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_627.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_627.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_627.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_627.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29738
        },
        "_fused_op_84": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_641.1 (port_0) ublock_order(c)",
                "Data: layernorm_641.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: buffer_0_28376_29739 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_28376_29739": "Data",
                "dc.input_tensor.layernorm_641.1": "Data",
                "layernorm_641.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_641.1",
                "layernorm_641.dc.reduce_sum.0.lc1",
                "buffer_0_28376_29739"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_84",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_641.dc.multiply.4 (port_0)",
                "Data: layernorm_641.dc.multiply.4 (port_0)",
                "Data: _fused_op_85 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_641.dc.multiply.4",
                "layernorm_641.dc.multiply.4",
                "_fused_op_85"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_641.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_641.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29739
        },
        "_fused_op_85": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_641.6 (port_0) ublock_order(r)",
                "Data: layernorm_641.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_641.8 (port_2) ublock_order(r)",
                "Data: _fused_op_84 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.11.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.11.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_84": "Data",
                "bert.encoder.layer.11.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.11.output.LayerNorm.weight": "Data",
                "dc.input_tensor.layernorm_641.6": "Data",
                "dc.input_tensor.layernorm_641.8": "Data",
                "layernorm_641.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_641.6",
                "layernorm_641.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_641.8",
                "_fused_op_84",
                "bert.encoder.layer.11.output.LayerNorm.weight",
                "bert.encoder.layer.11.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_85",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_644 (port_0)",
                "Data: matmul_650 (port_0)",
                "Data: matmul_664 (port_0)",
                "Data: add_679 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_644",
                "matmul_650",
                "matmul_664",
                "add_679"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_641.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_641.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_641.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_641.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_641.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_641.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_641.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29740
        },
        "_fused_op_86": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_656 (port_0) ublock_order(r)",
                "Data: input_1_multiply_658 (port_1) ublock_order(r)",
                "Data: multiply_22_attempt_1_input_op_fork_nop1 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "input_1_multiply_658": "Data",
                "matmul_656": "Data",
                "multiply_22_attempt_1_input_op_fork_nop1": "Data"
            },
            "input_nodes": [
                "matmul_656",
                "input_1_multiply_658",
                "multiply_22_attempt_1_input_op_fork_nop1"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_86",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_660.dc.reduce_max.0 (port_0)",
                "Data: _fused_op_87 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_660.dc.reduce_max.0",
                "_fused_op_87"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "multiply_658: multiply (1,16,12,12), out: 0",
                    "add_659: add (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "add"
            },
            "type": "fused_op",
            "unique_id": 29741
        },
        "_fused_op_87": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_86 (port_0) ublock_order(c)",
                "Data: softmax_660.dc.reduce_max.0 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_86": "Data",
                "softmax_660.dc.reduce_max.0": "Data"
            },
            "input_nodes": [
                "_fused_op_86",
                "softmax_660.dc.reduce_max.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_87",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_660.dc.reduce_sum.3.lc1 (port_0)",
                "Data: buffer_0_29742_29743 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_660.dc.reduce_sum.3.lc1",
                "buffer_0_29742_29743"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_660.dc.subtract.1: subtract (1,16,12,12), out: 0",
                    "softmax_660.dc.exp.2: exp (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 29742
        },
        "_fused_op_88": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: softmax_660.dc.reduce_sum.3.lc1 (port_0) ublock_order(r)",
                "Data: dc.input_tensor.softmax_660.4 (port_1) ublock_order(r)",
                "Data: buffer_0_29742_29743 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_29742_29743": "Data",
                "dc.input_tensor.softmax_660.4": "Data",
                "softmax_660.dc.reduce_sum.3.lc1": "Data"
            },
            "input_nodes": [
                "softmax_660.dc.reduce_sum.3.lc1",
                "dc.input_tensor.softmax_660.4",
                "buffer_0_29742_29743"
            ],
            "input_tms": [
                [],
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_88",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_671 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_671"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_660.dc.add.5: add (1,16,12,1), out: 0",
                    "softmax_660.dc.reciprocal.6: reciprocal (1,16,12,1), out: 0",
                    "softmax_660.dc.multiply.7: multiply (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 29743
        },
        "_fused_op_89": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_680.1 (port_0) ublock_order(c)",
                "Data: layernorm_680.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: buffer_0_28448_29744 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_28448_29744": "Data",
                "dc.input_tensor.layernorm_680.1": "Data",
                "layernorm_680.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_680.1",
                "layernorm_680.dc.reduce_sum.0.lc1",
                "buffer_0_28448_29744"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_89",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_680.dc.multiply.4 (port_0)",
                "Data: buffer_2_29744_29745 (port_0)",
                "Data: layernorm_680.dc.multiply.4 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_680.dc.multiply.4",
                "buffer_2_29744_29745",
                "layernorm_680.dc.multiply.4"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_680.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_680.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29744
        },
        "_fused_op_9": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_73 (port_0) ublock_order(r)",
                "Data: input_1_multiply_75 (port_1) ublock_order(r)",
                "Data: multiply_22_attempt_1_input_op_fork_nop0 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "input_1_multiply_75": "Data",
                "matmul_73": "Data",
                "multiply_22_attempt_1_input_op_fork_nop0": "Data"
            },
            "input_nodes": [
                "matmul_73",
                "input_1_multiply_75",
                "multiply_22_attempt_1_input_op_fork_nop0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_9",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_77.dc.reduce_max.0 (port_0)",
                "Data: _fused_op_10 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_77.dc.reduce_max.0",
                "_fused_op_10"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "multiply_75: multiply (1,16,12,12), out: 0",
                    "add_76: add (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "add"
            },
            "type": "fused_op",
            "unique_id": 29664
        },
        "_fused_op_90": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_680.6 (port_0) ublock_order(r)",
                "Data: layernorm_680.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_680.8 (port_2) ublock_order(r)",
                "Data: buffer_0_29744_29745 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.12.attention.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.12.attention.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.12.attention.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.12.attention.output.LayerNorm.weight": "Data",
                "buffer_0_29744_29745": "Data",
                "dc.input_tensor.layernorm_680.6": "Data",
                "dc.input_tensor.layernorm_680.8": "Data",
                "layernorm_680.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_680.6",
                "layernorm_680.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_680.8",
                "buffer_0_29744_29745",
                "bert.encoder.layer.12.attention.output.LayerNorm.weight",
                "bert.encoder.layer.12.attention.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_90",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_683 (port_0)",
                "Data: add_693 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_683",
                "add_693"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_680.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_680.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_680.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_680.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_680.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_680.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_680.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29745
        },
        "_fused_op_91": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_694.1 (port_0) ublock_order(c)",
                "Data: layernorm_694.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: buffer_0_28480_29746 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_28480_29746": "Data",
                "dc.input_tensor.layernorm_694.1": "Data",
                "layernorm_694.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_694.1",
                "layernorm_694.dc.reduce_sum.0.lc1",
                "buffer_0_28480_29746"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_91",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_694.dc.multiply.4 (port_0)",
                "Data: buffer_1_29746_29747 (port_0)",
                "Data: layernorm_694.dc.multiply.4 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_694.dc.multiply.4",
                "buffer_1_29746_29747",
                "layernorm_694.dc.multiply.4"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_694.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_694.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29746
        },
        "_fused_op_92": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_694.6 (port_0) ublock_order(r)",
                "Data: layernorm_694.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_694.8 (port_2) ublock_order(r)",
                "Data: buffer_0_29746_29747 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.12.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.12.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.12.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.12.output.LayerNorm.weight": "Data",
                "buffer_0_29746_29747": "Data",
                "dc.input_tensor.layernorm_694.6": "Data",
                "dc.input_tensor.layernorm_694.8": "Data",
                "layernorm_694.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_694.6",
                "layernorm_694.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_694.8",
                "buffer_0_29746_29747",
                "bert.encoder.layer.12.output.LayerNorm.weight",
                "bert.encoder.layer.12.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_92",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_697 (port_0)",
                "Data: matmul_703 (port_0)",
                "Data: matmul_717 (port_0)",
                "Data: add_732 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_697",
                "matmul_703",
                "matmul_717",
                "add_732"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_694.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_694.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_694.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_694.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_694.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_694.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_694.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29747
        },
        "_fused_op_93": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_709 (port_0) ublock_order(r)",
                "Data: input_1_multiply_711 (port_1) ublock_order(r)",
                "Data: multiply_22_attempt_1_input_op_fork_nop1 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "input_1_multiply_711": "Data",
                "matmul_709": "Data",
                "multiply_22_attempt_1_input_op_fork_nop1": "Data"
            },
            "input_nodes": [
                "matmul_709",
                "input_1_multiply_711",
                "multiply_22_attempt_1_input_op_fork_nop1"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_93",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_713.dc.reduce_max.0 (port_0)",
                "Data: _fused_op_94 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_713.dc.reduce_max.0",
                "_fused_op_94"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "multiply_711: multiply (1,16,12,12), out: 0",
                    "add_712: add (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "add"
            },
            "type": "fused_op",
            "unique_id": 29748
        },
        "_fused_op_94": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_93 (port_0) ublock_order(c)",
                "Data: softmax_713.dc.reduce_max.0 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_93": "Data",
                "softmax_713.dc.reduce_max.0": "Data"
            },
            "input_nodes": [
                "_fused_op_93",
                "softmax_713.dc.reduce_max.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_94",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_713.dc.reduce_sum.3.lc1 (port_0)",
                "Data: _fused_op_95 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_713.dc.reduce_sum.3.lc1",
                "_fused_op_95"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_713.dc.subtract.1: subtract (1,16,12,12), out: 0",
                    "softmax_713.dc.exp.2: exp (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 29749
        },
        "_fused_op_95": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: softmax_713.dc.reduce_sum.3.lc1 (port_0) ublock_order(r)",
                "Data: dc.input_tensor.softmax_713.4 (port_1) ublock_order(r)",
                "Data: _fused_op_94 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_94": "Data",
                "dc.input_tensor.softmax_713.4": "Data",
                "softmax_713.dc.reduce_sum.3.lc1": "Data"
            },
            "input_nodes": [
                "softmax_713.dc.reduce_sum.3.lc1",
                "dc.input_tensor.softmax_713.4",
                "_fused_op_94"
            ],
            "input_tms": [
                [],
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_95",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_724 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_724"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_713.dc.add.5: add (1,16,12,1), out: 0",
                    "softmax_713.dc.reciprocal.6: reciprocal (1,16,12,1), out: 0",
                    "softmax_713.dc.multiply.7: multiply (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 29750
        },
        "_fused_op_96": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_733.1 (port_0) ublock_order(c)",
                "Data: layernorm_733.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: buffer_0_28552_29751 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_28552_29751": "Data",
                "dc.input_tensor.layernorm_733.1": "Data",
                "layernorm_733.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_733.1",
                "layernorm_733.dc.reduce_sum.0.lc1",
                "buffer_0_28552_29751"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_96",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_733.dc.multiply.4 (port_0)",
                "Data: buffer_4_29751_29752 (port_0)",
                "Data: layernorm_733.dc.multiply.4 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_733.dc.multiply.4",
                "buffer_4_29751_29752",
                "layernorm_733.dc.multiply.4"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_733.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_733.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29751
        },
        "_fused_op_97": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_733.6 (port_0) ublock_order(r)",
                "Data: layernorm_733.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_733.8 (port_2) ublock_order(r)",
                "Data: buffer_0_29751_29752 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.13.attention.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.13.attention.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.13.attention.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.13.attention.output.LayerNorm.weight": "Data",
                "buffer_0_29751_29752": "Data",
                "dc.input_tensor.layernorm_733.6": "Data",
                "dc.input_tensor.layernorm_733.8": "Data",
                "layernorm_733.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_733.6",
                "layernorm_733.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_733.8",
                "buffer_0_29751_29752",
                "bert.encoder.layer.13.attention.output.LayerNorm.weight",
                "bert.encoder.layer.13.attention.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_97",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_736 (port_0)",
                "Data: buffer_7_29752_28584 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_736",
                "buffer_7_29752_28584"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_733.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_733.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_733.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_733.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_733.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_733.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_733.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29752
        },
        "_fused_op_98": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_747.1 (port_0) ublock_order(c)",
                "Data: layernorm_747.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: buffer_0_28584_29753 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_28584_29753": "Data",
                "dc.input_tensor.layernorm_747.1": "Data",
                "layernorm_747.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_747.1",
                "layernorm_747.dc.reduce_sum.0.lc1",
                "buffer_0_28584_29753"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_98",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_747.dc.multiply.4 (port_0)",
                "Data: layernorm_747.dc.multiply.4 (port_0)",
                "Data: _fused_op_99 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_747.dc.multiply.4",
                "layernorm_747.dc.multiply.4",
                "_fused_op_99"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_747.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_747.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29753
        },
        "_fused_op_99": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_747.6 (port_0) ublock_order(r)",
                "Data: layernorm_747.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_747.8 (port_2) ublock_order(r)",
                "Data: _fused_op_98 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.13.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.13.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_98": "Data",
                "bert.encoder.layer.13.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.13.output.LayerNorm.weight": "Data",
                "dc.input_tensor.layernorm_747.6": "Data",
                "dc.input_tensor.layernorm_747.8": "Data",
                "layernorm_747.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_747.6",
                "layernorm_747.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_747.8",
                "_fused_op_98",
                "bert.encoder.layer.13.output.LayerNorm.weight",
                "bert.encoder.layer.13.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_99",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_750 (port_0)",
                "Data: matmul_756 (port_0)",
                "Data: matmul_770 (port_0)",
                "Data: add_785 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_750",
                "matmul_756",
                "matmul_770",
                "add_785"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_747.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_747.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_747.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_747.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_747.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_747.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_747.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29754
        },
        "add_1011": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1007 (port_0) ublock_order(c)",
                "Data: _fused_op_132 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_132": "Data",
                "matmul_1007": "Data"
            },
            "input_nodes": [
                "matmul_1007",
                "_fused_op_132"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_1011",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1012.dc.reduce_sum.0.lc1 (port_0)",
                "Data: buffer_1_29104_29788 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1012.dc.reduce_sum.0.lc1",
                "buffer_1_29104_29788"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertOutput::output",
                "original_op_name": "add_1011",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 29104
        },
        "add_1050": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1046 (port_0) ublock_order(c)",
                "Data: _fused_op_134 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_134": "Data",
                "matmul_1046": "Data"
            },
            "input_nodes": [
                "matmul_1046",
                "_fused_op_134"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_1050",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1051.dc.reduce_sum.0.lc1 (port_0)",
                "Data: buffer_3_29176_29793 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1051.dc.reduce_sum.0.lc1",
                "buffer_3_29176_29793"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output",
                "original_op_name": "add_1050",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 29176
        },
        "add_1064": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1060 (port_0) ublock_order(c)",
                "Data: buffer_0_29794_29208 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_29794_29208": "Data",
                "matmul_1060": "Data"
            },
            "input_nodes": [
                "matmul_1060",
                "buffer_0_29794_29208"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_1064",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1065.dc.reduce_sum.0.lc1 (port_0)",
                "Data: buffer_3_29208_29795 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1065.dc.reduce_sum.0.lc1",
                "buffer_3_29208_29795"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertOutput::output",
                "original_op_name": "add_1064",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 29208
        },
        "add_110": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_106 (port_0) ublock_order(c)",
                "Data: buffer_0_29668_27336 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_29668_27336": "Data",
                "matmul_106": "Data"
            },
            "input_nodes": [
                "matmul_106",
                "buffer_0_29668_27336"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_110",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_111.dc.reduce_sum.0.lc1 (port_0)",
                "Data: buffer_3_27336_29669 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_111.dc.reduce_sum.0.lc1",
                "buffer_3_27336_29669"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertOutput::output",
                "original_op_name": "add_110",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 27336
        },
        "add_1103": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1099 (port_0) ublock_order(c)",
                "Data: _fused_op_141 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_141": "Data",
                "matmul_1099": "Data"
            },
            "input_nodes": [
                "matmul_1099",
                "_fused_op_141"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_1103",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1104.dc.reduce_sum.0.lc1 (port_0)",
                "Data: buffer_1_29280_29800 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1104.dc.reduce_sum.0.lc1",
                "buffer_1_29280_29800"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output",
                "original_op_name": "add_1103",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 29280
        },
        "add_1117": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1113 (port_0) ublock_order(c)",
                "Data: _fused_op_146 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_146": "Data",
                "matmul_1113": "Data"
            },
            "input_nodes": [
                "matmul_1113",
                "_fused_op_146"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_1117",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1118.dc.reduce_sum.0.lc1 (port_0)",
                "Data: buffer_1_29312_29802 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1118.dc.reduce_sum.0.lc1",
                "buffer_1_29312_29802"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertOutput::output",
                "original_op_name": "add_1117",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 29312
        },
        "add_1156": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1152 (port_0) ublock_order(c)",
                "Data: _fused_op_148 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_148": "Data",
                "matmul_1152": "Data"
            },
            "input_nodes": [
                "matmul_1152",
                "_fused_op_148"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_1156",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1157.dc.reduce_sum.0.lc1 (port_0)",
                "Data: buffer_3_29384_29807 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1157.dc.reduce_sum.0.lc1",
                "buffer_3_29384_29807"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output",
                "original_op_name": "add_1156",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 29384
        },
        "add_1170": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1166 (port_0) ublock_order(c)",
                "Data: buffer_0_29808_29416 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_29808_29416": "Data",
                "matmul_1166": "Data"
            },
            "input_nodes": [
                "matmul_1166",
                "buffer_0_29808_29416"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_1170",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1171.dc.reduce_sum.0.lc1 (port_0)",
                "Data: buffer_3_29416_29809 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1171.dc.reduce_sum.0.lc1",
                "buffer_3_29416_29809"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertOutput::output",
                "original_op_name": "add_1170",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 29416
        },
        "add_1209": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1205 (port_0) ublock_order(c)",
                "Data: _fused_op_155 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_155": "Data",
                "matmul_1205": "Data"
            },
            "input_nodes": [
                "matmul_1205",
                "_fused_op_155"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_1209",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1210.dc.reduce_sum.0.lc1 (port_0)",
                "Data: buffer_1_29488_29814 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1210.dc.reduce_sum.0.lc1",
                "buffer_1_29488_29814"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output",
                "original_op_name": "add_1209",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 29488
        },
        "add_1223": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1219 (port_0) ublock_order(c)",
                "Data: _fused_op_160 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_160": "Data",
                "matmul_1219": "Data"
            },
            "input_nodes": [
                "matmul_1219",
                "_fused_op_160"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_1223",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1224.dc.reduce_sum.0.lc1 (port_0)",
                "Data: buffer_1_29520_29816 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1224.dc.reduce_sum.0.lc1",
                "buffer_1_29520_29816"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertOutput::output",
                "original_op_name": "add_1223",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 29520
        },
        "add_1262": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1258 (port_0) ublock_order(c)",
                "Data: _fused_op_162 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_162": "Data",
                "matmul_1258": "Data"
            },
            "input_nodes": [
                "matmul_1258",
                "_fused_op_162"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_1262",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1263.dc.reduce_sum.0.lc1 (port_0)",
                "Data: buffer_3_29592_29821 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1263.dc.reduce_sum.0.lc1",
                "buffer_3_29592_29821"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output",
                "original_op_name": "add_1262",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 29592
        },
        "add_1276": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1272 (port_0) ublock_order(c)",
                "Data: buffer_0_29822_29624 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_29822_29624": "Data",
                "matmul_1272": "Data"
            },
            "input_nodes": [
                "matmul_1272",
                "buffer_0_29822_29624"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_1276",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1277.dc.reduce_sum.0.lc1 (port_0)",
                "Data: buffer_3_29624_29823 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1277.dc.reduce_sum.0.lc1",
                "buffer_3_29624_29823"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertOutput::output",
                "original_op_name": "add_1276",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 29624
        },
        "add_149": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_145 (port_0) ublock_order(c)",
                "Data: _fused_op_15 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_15": "Data",
                "matmul_145": "Data"
            },
            "input_nodes": [
                "matmul_145",
                "_fused_op_15"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_149",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_150.dc.reduce_sum.0.lc1 (port_0)",
                "Data: buffer_1_27408_29674 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_150.dc.reduce_sum.0.lc1",
                "buffer_1_27408_29674"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output",
                "original_op_name": "add_149",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 27408
        },
        "add_163": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_159 (port_0) ublock_order(c)",
                "Data: _fused_op_20 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_20": "Data",
                "matmul_159": "Data"
            },
            "input_nodes": [
                "matmul_159",
                "_fused_op_20"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_163",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_164.dc.reduce_sum.0.lc1 (port_0)",
                "Data: buffer_1_27440_29676 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_164.dc.reduce_sum.0.lc1",
                "buffer_1_27440_29676"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertOutput::output",
                "original_op_name": "add_163",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 27440
        },
        "add_202": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_198 (port_0) ublock_order(c)",
                "Data: _fused_op_22 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_22": "Data",
                "matmul_198": "Data"
            },
            "input_nodes": [
                "matmul_198",
                "_fused_op_22"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_202",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_203.dc.reduce_sum.0.lc1 (port_0)",
                "Data: buffer_3_27512_29681 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_203.dc.reduce_sum.0.lc1",
                "buffer_3_27512_29681"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output",
                "original_op_name": "add_202",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 27512
        },
        "add_216": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_212 (port_0) ublock_order(c)",
                "Data: buffer_0_29682_27544 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_29682_27544": "Data",
                "matmul_212": "Data"
            },
            "input_nodes": [
                "matmul_212",
                "buffer_0_29682_27544"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_216",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_217.dc.reduce_sum.0.lc1 (port_0)",
                "Data: buffer_3_27544_29683 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_217.dc.reduce_sum.0.lc1",
                "buffer_3_27544_29683"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertOutput::output",
                "original_op_name": "add_216",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 27544
        },
        "add_255": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_251 (port_0) ublock_order(c)",
                "Data: _fused_op_29 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_29": "Data",
                "matmul_251": "Data"
            },
            "input_nodes": [
                "matmul_251",
                "_fused_op_29"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_255",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_256.dc.reduce_sum.0.lc1 (port_0)",
                "Data: buffer_1_27616_29688 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_256.dc.reduce_sum.0.lc1",
                "buffer_1_27616_29688"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output",
                "original_op_name": "add_255",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 27616
        },
        "add_269": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_265 (port_0) ublock_order(c)",
                "Data: _fused_op_34 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_34": "Data",
                "matmul_265": "Data"
            },
            "input_nodes": [
                "matmul_265",
                "_fused_op_34"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_269",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_270.dc.reduce_sum.0.lc1 (port_0)",
                "Data: buffer_1_27648_29690 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_270.dc.reduce_sum.0.lc1",
                "buffer_1_27648_29690"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertOutput::output",
                "original_op_name": "add_269",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 27648
        },
        "add_308": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_304 (port_0) ublock_order(c)",
                "Data: _fused_op_36 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_36": "Data",
                "matmul_304": "Data"
            },
            "input_nodes": [
                "matmul_304",
                "_fused_op_36"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_308",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_309.dc.reduce_sum.0.lc1 (port_0)",
                "Data: buffer_3_27720_29695 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_309.dc.reduce_sum.0.lc1",
                "buffer_3_27720_29695"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output",
                "original_op_name": "add_308",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 27720
        },
        "add_322": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_318 (port_0) ublock_order(c)",
                "Data: buffer_0_29696_27752 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_29696_27752": "Data",
                "matmul_318": "Data"
            },
            "input_nodes": [
                "matmul_318",
                "buffer_0_29696_27752"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_322",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_323.dc.reduce_sum.0.lc1 (port_0)",
                "Data: buffer_3_27752_29697 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_323.dc.reduce_sum.0.lc1",
                "buffer_3_27752_29697"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertOutput::output",
                "original_op_name": "add_322",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 27752
        },
        "add_361": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_357 (port_0) ublock_order(c)",
                "Data: _fused_op_43 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_43": "Data",
                "matmul_357": "Data"
            },
            "input_nodes": [
                "matmul_357",
                "_fused_op_43"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_361",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_362.dc.reduce_sum.0.lc1 (port_0)",
                "Data: buffer_1_27824_29702 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_362.dc.reduce_sum.0.lc1",
                "buffer_1_27824_29702"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output",
                "original_op_name": "add_361",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 27824
        },
        "add_375": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_371 (port_0) ublock_order(c)",
                "Data: _fused_op_48 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_48": "Data",
                "matmul_371": "Data"
            },
            "input_nodes": [
                "matmul_371",
                "_fused_op_48"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_375",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_376.dc.reduce_sum.0.lc1 (port_0)",
                "Data: buffer_1_27856_29704 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_376.dc.reduce_sum.0.lc1",
                "buffer_1_27856_29704"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertOutput::output",
                "original_op_name": "add_375",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 27856
        },
        "add_414": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_410 (port_0) ublock_order(c)",
                "Data: _fused_op_50 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_50": "Data",
                "matmul_410": "Data"
            },
            "input_nodes": [
                "matmul_410",
                "_fused_op_50"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_414",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_415.dc.reduce_sum.0.lc1 (port_0)",
                "Data: buffer_3_27928_29709 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_415.dc.reduce_sum.0.lc1",
                "buffer_3_27928_29709"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output",
                "original_op_name": "add_414",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 27928
        },
        "add_428": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_424 (port_0) ublock_order(c)",
                "Data: buffer_0_29710_27960 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_29710_27960": "Data",
                "matmul_424": "Data"
            },
            "input_nodes": [
                "matmul_424",
                "buffer_0_29710_27960"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_428",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_429.dc.reduce_sum.0.lc1 (port_0)",
                "Data: buffer_3_27960_29711 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_429.dc.reduce_sum.0.lc1",
                "buffer_3_27960_29711"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertOutput::output",
                "original_op_name": "add_428",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 27960
        },
        "add_43": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_39 (port_0) ublock_order(c)",
                "Data: _fused_op_1 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_1": "Data",
                "matmul_39": "Data"
            },
            "input_nodes": [
                "matmul_39",
                "_fused_op_1"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_43",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_44.dc.reduce_sum.0.lc1 (port_0)",
                "Data: buffer_1_27200_29660 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_44.dc.reduce_sum.0.lc1",
                "buffer_1_27200_29660"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output",
                "original_op_name": "add_43",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 27200
        },
        "add_467": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_463 (port_0) ublock_order(c)",
                "Data: _fused_op_57 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_57": "Data",
                "matmul_463": "Data"
            },
            "input_nodes": [
                "matmul_463",
                "_fused_op_57"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_467",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_468.dc.reduce_sum.0.lc1 (port_0)",
                "Data: buffer_1_28032_29716 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_468.dc.reduce_sum.0.lc1",
                "buffer_1_28032_29716"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output",
                "original_op_name": "add_467",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 28032
        },
        "add_481": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_477 (port_0) ublock_order(c)",
                "Data: _fused_op_62 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_62": "Data",
                "matmul_477": "Data"
            },
            "input_nodes": [
                "matmul_477",
                "_fused_op_62"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_481",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_482.dc.reduce_sum.0.lc1 (port_0)",
                "Data: buffer_1_28064_29718 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_482.dc.reduce_sum.0.lc1",
                "buffer_1_28064_29718"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertOutput::output",
                "original_op_name": "add_481",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 28064
        },
        "add_520": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_516 (port_0) ublock_order(c)",
                "Data: _fused_op_64 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_64": "Data",
                "matmul_516": "Data"
            },
            "input_nodes": [
                "matmul_516",
                "_fused_op_64"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_520",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_521.dc.reduce_sum.0.lc1 (port_0)",
                "Data: buffer_3_28136_29723 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_521.dc.reduce_sum.0.lc1",
                "buffer_3_28136_29723"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output",
                "original_op_name": "add_520",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 28136
        },
        "add_534": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_530 (port_0) ublock_order(c)",
                "Data: buffer_0_29724_28168 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_29724_28168": "Data",
                "matmul_530": "Data"
            },
            "input_nodes": [
                "matmul_530",
                "buffer_0_29724_28168"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_534",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_535.dc.reduce_sum.0.lc1 (port_0)",
                "Data: buffer_3_28168_29725 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_535.dc.reduce_sum.0.lc1",
                "buffer_3_28168_29725"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertOutput::output",
                "original_op_name": "add_534",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 28168
        },
        "add_57": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_53 (port_0) ublock_order(c)",
                "Data: _fused_op_6 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_6": "Data",
                "matmul_53": "Data"
            },
            "input_nodes": [
                "matmul_53",
                "_fused_op_6"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_57",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_58.dc.reduce_sum.0.lc1 (port_0)",
                "Data: buffer_1_27232_29662 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_58.dc.reduce_sum.0.lc1",
                "buffer_1_27232_29662"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertOutput::output",
                "original_op_name": "add_57",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 27232
        },
        "add_573": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_569 (port_0) ublock_order(c)",
                "Data: _fused_op_71 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_71": "Data",
                "matmul_569": "Data"
            },
            "input_nodes": [
                "matmul_569",
                "_fused_op_71"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_573",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_574.dc.reduce_sum.0.lc1 (port_0)",
                "Data: buffer_1_28240_29730 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_574.dc.reduce_sum.0.lc1",
                "buffer_1_28240_29730"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output",
                "original_op_name": "add_573",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 28240
        },
        "add_587": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_583 (port_0) ublock_order(c)",
                "Data: _fused_op_76 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_76": "Data",
                "matmul_583": "Data"
            },
            "input_nodes": [
                "matmul_583",
                "_fused_op_76"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_587",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_588.dc.reduce_sum.0.lc1 (port_0)",
                "Data: buffer_1_28272_29732 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_588.dc.reduce_sum.0.lc1",
                "buffer_1_28272_29732"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertOutput::output",
                "original_op_name": "add_587",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 28272
        },
        "add_626": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_622 (port_0) ublock_order(c)",
                "Data: _fused_op_78 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_78": "Data",
                "matmul_622": "Data"
            },
            "input_nodes": [
                "matmul_622",
                "_fused_op_78"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_626",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_627.dc.reduce_sum.0.lc1 (port_0)",
                "Data: buffer_3_28344_29737 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_627.dc.reduce_sum.0.lc1",
                "buffer_3_28344_29737"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output",
                "original_op_name": "add_626",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 28344
        },
        "add_640": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_636 (port_0) ublock_order(c)",
                "Data: buffer_0_29738_28376 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_29738_28376": "Data",
                "matmul_636": "Data"
            },
            "input_nodes": [
                "matmul_636",
                "buffer_0_29738_28376"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_640",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_641.dc.reduce_sum.0.lc1 (port_0)",
                "Data: buffer_3_28376_29739 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_641.dc.reduce_sum.0.lc1",
                "buffer_3_28376_29739"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertOutput::output",
                "original_op_name": "add_640",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 28376
        },
        "add_679": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_675 (port_0) ublock_order(c)",
                "Data: _fused_op_85 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_85": "Data",
                "matmul_675": "Data"
            },
            "input_nodes": [
                "matmul_675",
                "_fused_op_85"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_679",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_680.dc.reduce_sum.0.lc1 (port_0)",
                "Data: buffer_1_28448_29744 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_680.dc.reduce_sum.0.lc1",
                "buffer_1_28448_29744"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output",
                "original_op_name": "add_679",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 28448
        },
        "add_693": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_689 (port_0) ublock_order(c)",
                "Data: _fused_op_90 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_90": "Data",
                "matmul_689": "Data"
            },
            "input_nodes": [
                "matmul_689",
                "_fused_op_90"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_693",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_694.dc.reduce_sum.0.lc1 (port_0)",
                "Data: buffer_1_28480_29746 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_694.dc.reduce_sum.0.lc1",
                "buffer_1_28480_29746"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertOutput::output",
                "original_op_name": "add_693",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 28480
        },
        "add_732": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_728 (port_0) ublock_order(c)",
                "Data: _fused_op_92 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_92": "Data",
                "matmul_728": "Data"
            },
            "input_nodes": [
                "matmul_728",
                "_fused_op_92"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_732",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_733.dc.reduce_sum.0.lc1 (port_0)",
                "Data: buffer_3_28552_29751 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_733.dc.reduce_sum.0.lc1",
                "buffer_3_28552_29751"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output",
                "original_op_name": "add_732",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 28552
        },
        "add_746": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_742 (port_0) ublock_order(c)",
                "Data: buffer_0_29752_28584 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_29752_28584": "Data",
                "matmul_742": "Data"
            },
            "input_nodes": [
                "matmul_742",
                "buffer_0_29752_28584"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_746",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_747.dc.reduce_sum.0.lc1 (port_0)",
                "Data: buffer_3_28584_29753 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_747.dc.reduce_sum.0.lc1",
                "buffer_3_28584_29753"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertOutput::output",
                "original_op_name": "add_746",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 28584
        },
        "add_785": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_781 (port_0) ublock_order(c)",
                "Data: _fused_op_99 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_99": "Data",
                "matmul_781": "Data"
            },
            "input_nodes": [
                "matmul_781",
                "_fused_op_99"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_785",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_786.dc.reduce_sum.0.lc1 (port_0)",
                "Data: buffer_1_28656_29758 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_786.dc.reduce_sum.0.lc1",
                "buffer_1_28656_29758"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output",
                "original_op_name": "add_785",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 28656
        },
        "add_799": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_795 (port_0) ublock_order(c)",
                "Data: _fused_op_104 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_104": "Data",
                "matmul_795": "Data"
            },
            "input_nodes": [
                "matmul_795",
                "_fused_op_104"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_799",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_800.dc.reduce_sum.0.lc1 (port_0)",
                "Data: buffer_1_28688_29760 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_800.dc.reduce_sum.0.lc1",
                "buffer_1_28688_29760"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertOutput::output",
                "original_op_name": "add_799",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 28688
        },
        "add_838": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_834 (port_0) ublock_order(c)",
                "Data: _fused_op_106 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_106": "Data",
                "matmul_834": "Data"
            },
            "input_nodes": [
                "matmul_834",
                "_fused_op_106"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_838",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_839.dc.reduce_sum.0.lc1 (port_0)",
                "Data: buffer_3_28760_29765 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_839.dc.reduce_sum.0.lc1",
                "buffer_3_28760_29765"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output",
                "original_op_name": "add_838",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 28760
        },
        "add_852": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_848 (port_0) ublock_order(c)",
                "Data: buffer_0_29766_28792 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_29766_28792": "Data",
                "matmul_848": "Data"
            },
            "input_nodes": [
                "matmul_848",
                "buffer_0_29766_28792"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_852",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_853.dc.reduce_sum.0.lc1 (port_0)",
                "Data: buffer_3_28792_29767 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_853.dc.reduce_sum.0.lc1",
                "buffer_3_28792_29767"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertOutput::output",
                "original_op_name": "add_852",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 28792
        },
        "add_891": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_887 (port_0) ublock_order(c)",
                "Data: _fused_op_113 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_113": "Data",
                "matmul_887": "Data"
            },
            "input_nodes": [
                "matmul_887",
                "_fused_op_113"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_891",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_892.dc.reduce_sum.0.lc1 (port_0)",
                "Data: buffer_1_28864_29772 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_892.dc.reduce_sum.0.lc1",
                "buffer_1_28864_29772"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output",
                "original_op_name": "add_891",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 28864
        },
        "add_905": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_901 (port_0) ublock_order(c)",
                "Data: _fused_op_118 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_118": "Data",
                "matmul_901": "Data"
            },
            "input_nodes": [
                "matmul_901",
                "_fused_op_118"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_905",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_906.dc.reduce_sum.0.lc1 (port_0)",
                "Data: buffer_1_28896_29774 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_906.dc.reduce_sum.0.lc1",
                "buffer_1_28896_29774"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertOutput::output",
                "original_op_name": "add_905",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 28896
        },
        "add_944": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_940 (port_0) ublock_order(c)",
                "Data: _fused_op_120 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_120": "Data",
                "matmul_940": "Data"
            },
            "input_nodes": [
                "matmul_940",
                "_fused_op_120"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_944",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_945.dc.reduce_sum.0.lc1 (port_0)",
                "Data: buffer_3_28968_29779 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_945.dc.reduce_sum.0.lc1",
                "buffer_3_28968_29779"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output",
                "original_op_name": "add_944",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 28968
        },
        "add_958": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_954 (port_0) ublock_order(c)",
                "Data: buffer_0_29780_29000 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_29780_29000": "Data",
                "matmul_954": "Data"
            },
            "input_nodes": [
                "matmul_954",
                "buffer_0_29780_29000"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_958",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_959.dc.reduce_sum.0.lc1 (port_0)",
                "Data: buffer_3_29000_29781 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_959.dc.reduce_sum.0.lc1",
                "buffer_3_29000_29781"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertOutput::output",
                "original_op_name": "add_958",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 29000
        },
        "add_96": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_92 (port_0) ublock_order(c)",
                "Data: _fused_op_8 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_8": "Data",
                "matmul_92": "Data"
            },
            "input_nodes": [
                "matmul_92",
                "_fused_op_8"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_96",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_97.dc.reduce_sum.0.lc1 (port_0)",
                "Data: buffer_3_27304_29667 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_97.dc.reduce_sum.0.lc1",
                "buffer_3_27304_29667"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output",
                "original_op_name": "add_96",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 27304
        },
        "add_997": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_993 (port_0) ublock_order(c)",
                "Data: _fused_op_127 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_127": "Data",
                "matmul_993": "Data"
            },
            "input_nodes": [
                "matmul_993",
                "_fused_op_127"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_997",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_998.dc.reduce_sum.0.lc1 (port_0)",
                "Data: buffer_1_29072_29786 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_998.dc.reduce_sum.0.lc1",
                "buffer_1_29072_29786"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output",
                "original_op_name": "add_997",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 29072
        },
        "attention_mask_1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    384
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "attention_mask_1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: subtract_21 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "subtract_21"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_name": "attention_mask_1"
            },
            "tile_broadcast": [],
            "type": "Input::input",
            "unique_id": 27161
        },
        "bert.embeddings.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.embeddings.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.embeddings.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27140
        },
        "bert.embeddings.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.embeddings.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.embeddings.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27138
        },
        "bert.encoder.layer.0.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.0.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_6 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_6"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.0.attention.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27221
        },
        "bert.encoder.layer.0.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.0.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_6 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_6"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.0.attention.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27219
        },
        "bert.encoder.layer.0.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.0.attention.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_39 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_39"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.0.attention.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27197
        },
        "bert.encoder.layer.0.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.0.attention.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_39 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_39"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.0.attention.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27196
        },
        "bert.encoder.layer.0.attention.self.key.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.0.attention.self.key.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_10 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_10"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.0.attention.self.key.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27151
        },
        "bert.encoder.layer.0.attention.self.key.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.0.attention.self.key.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_10 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_10"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.0.attention.self.key.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27150
        },
        "bert.encoder.layer.0.attention.self.query.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.0.attention.self.query.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_4 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_4"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.0.attention.self.query.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27145
        },
        "bert.encoder.layer.0.attention.self.query.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.0.attention.self.query.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_4 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_4"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.0.attention.self.query.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27144
        },
        "bert.encoder.layer.0.attention.self.value.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.0.attention.self.value.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_28 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_28"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.0.attention.self.value.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27188
        },
        "bert.encoder.layer.0.attention.self.value.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.0.attention.self.value.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_28 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_28"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.0.attention.self.value.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27187
        },
        "bert.encoder.layer.0.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.0.intermediate.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_47 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_47"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.0.intermediate.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27225
        },
        "bert.encoder.layer.0.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.0.intermediate.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_47 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_47"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.0.intermediate.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27224
        },
        "bert.encoder.layer.0.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.0.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_8 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_8"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.0.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27253
        },
        "bert.encoder.layer.0.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.0.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_8 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_8"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.0.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27251
        },
        "bert.encoder.layer.0.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.0.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_53 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_53"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.0.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27229
        },
        "bert.encoder.layer.0.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    4096,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.0.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_53 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_53"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.0.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27228
        },
        "bert.encoder.layer.1.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.1.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_13 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_13"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.1.attention.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27325
        },
        "bert.encoder.layer.1.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.1.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_13 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_13"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.1.attention.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27323
        },
        "bert.encoder.layer.1.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.1.attention.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_92 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_92"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.1.attention.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27301
        },
        "bert.encoder.layer.1.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.1.attention.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_92 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_92"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.1.attention.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27300
        },
        "bert.encoder.layer.1.attention.self.key.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.1.attention.self.key.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_67 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_67"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.1.attention.self.key.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27263
        },
        "bert.encoder.layer.1.attention.self.key.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.1.attention.self.key.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_67 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_67"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.1.attention.self.key.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27262
        },
        "bert.encoder.layer.1.attention.self.query.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.1.attention.self.query.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_61 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_61"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.1.attention.self.query.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27257
        },
        "bert.encoder.layer.1.attention.self.query.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.1.attention.self.query.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_61 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_61"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.1.attention.self.query.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27256
        },
        "bert.encoder.layer.1.attention.self.value.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.1.attention.self.value.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_81 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_81"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.1.attention.self.value.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27292
        },
        "bert.encoder.layer.1.attention.self.value.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.1.attention.self.value.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_81 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_81"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.1.attention.self.value.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27291
        },
        "bert.encoder.layer.1.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.1.intermediate.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_100 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_100"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.1.intermediate.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27329
        },
        "bert.encoder.layer.1.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.1.intermediate.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_100 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_100"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.1.intermediate.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27328
        },
        "bert.encoder.layer.1.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.1.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_15 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_15"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.1.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27357
        },
        "bert.encoder.layer.1.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.1.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_15 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_15"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.1.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27355
        },
        "bert.encoder.layer.1.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.1.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_106 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_106"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.1.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27333
        },
        "bert.encoder.layer.1.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    4096,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.1.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_106 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_106"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.1.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27332
        },
        "bert.encoder.layer.10.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.10.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_76 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_76"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.10.attention.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28261
        },
        "bert.encoder.layer.10.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.10.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_76 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_76"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.10.attention.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28259
        },
        "bert.encoder.layer.10.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.10.attention.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_569 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_569"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.10.attention.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28237
        },
        "bert.encoder.layer.10.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.10.attention.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_569 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_569"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.10.attention.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28236
        },
        "bert.encoder.layer.10.attention.self.key.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.10.attention.self.key.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_544 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_544"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.10.attention.self.key.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28199
        },
        "bert.encoder.layer.10.attention.self.key.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.10.attention.self.key.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_544 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_544"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.10.attention.self.key.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28198
        },
        "bert.encoder.layer.10.attention.self.query.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.10.attention.self.query.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_538 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_538"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.10.attention.self.query.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28193
        },
        "bert.encoder.layer.10.attention.self.query.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.10.attention.self.query.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_538 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_538"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.10.attention.self.query.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28192
        },
        "bert.encoder.layer.10.attention.self.value.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.10.attention.self.value.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_558 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_558"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.10.attention.self.value.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28228
        },
        "bert.encoder.layer.10.attention.self.value.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.10.attention.self.value.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_558 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_558"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.10.attention.self.value.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28227
        },
        "bert.encoder.layer.10.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.10.intermediate.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_577 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_577"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.10.intermediate.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28265
        },
        "bert.encoder.layer.10.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.10.intermediate.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_577 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_577"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.10.intermediate.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28264
        },
        "bert.encoder.layer.10.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.10.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_78 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_78"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.10.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28293
        },
        "bert.encoder.layer.10.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.10.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_78 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_78"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.10.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28291
        },
        "bert.encoder.layer.10.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.10.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_583 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_583"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.10.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28269
        },
        "bert.encoder.layer.10.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    4096,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.10.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_583 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_583"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.10.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28268
        },
        "bert.encoder.layer.11.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.11.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_83 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_83"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.11.attention.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28365
        },
        "bert.encoder.layer.11.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.11.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_83 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_83"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.11.attention.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28363
        },
        "bert.encoder.layer.11.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.11.attention.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_622 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_622"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.11.attention.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28341
        },
        "bert.encoder.layer.11.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.11.attention.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_622 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_622"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.11.attention.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28340
        },
        "bert.encoder.layer.11.attention.self.key.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.11.attention.self.key.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_597 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_597"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.11.attention.self.key.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28303
        },
        "bert.encoder.layer.11.attention.self.key.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.11.attention.self.key.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_597 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_597"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.11.attention.self.key.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28302
        },
        "bert.encoder.layer.11.attention.self.query.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.11.attention.self.query.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_591 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_591"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.11.attention.self.query.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28297
        },
        "bert.encoder.layer.11.attention.self.query.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.11.attention.self.query.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_591 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_591"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.11.attention.self.query.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28296
        },
        "bert.encoder.layer.11.attention.self.value.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.11.attention.self.value.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_611 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_611"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.11.attention.self.value.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28332
        },
        "bert.encoder.layer.11.attention.self.value.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.11.attention.self.value.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_611 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_611"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.11.attention.self.value.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28331
        },
        "bert.encoder.layer.11.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.11.intermediate.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_630 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_630"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.11.intermediate.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28369
        },
        "bert.encoder.layer.11.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.11.intermediate.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_630 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_630"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.11.intermediate.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28368
        },
        "bert.encoder.layer.11.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.11.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_85 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_85"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.11.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28397
        },
        "bert.encoder.layer.11.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.11.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_85 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_85"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.11.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28395
        },
        "bert.encoder.layer.11.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.11.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_636 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_636"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.11.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28373
        },
        "bert.encoder.layer.11.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    4096,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.11.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_636 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_636"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.11.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28372
        },
        "bert.encoder.layer.12.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.12.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_90 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_90"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.12.attention.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28469
        },
        "bert.encoder.layer.12.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.12.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_90 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_90"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.12.attention.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28467
        },
        "bert.encoder.layer.12.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.12.attention.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_675 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_675"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.12.attention.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28445
        },
        "bert.encoder.layer.12.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.12.attention.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_675 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_675"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.12.attention.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28444
        },
        "bert.encoder.layer.12.attention.self.key.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.12.attention.self.key.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_650 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_650"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.12.attention.self.key.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28407
        },
        "bert.encoder.layer.12.attention.self.key.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.12.attention.self.key.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_650 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_650"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.12.attention.self.key.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28406
        },
        "bert.encoder.layer.12.attention.self.query.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.12.attention.self.query.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_644 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_644"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.12.attention.self.query.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28401
        },
        "bert.encoder.layer.12.attention.self.query.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.12.attention.self.query.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_644 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_644"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.12.attention.self.query.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28400
        },
        "bert.encoder.layer.12.attention.self.value.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.12.attention.self.value.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_664 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_664"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.12.attention.self.value.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28436
        },
        "bert.encoder.layer.12.attention.self.value.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.12.attention.self.value.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_664 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_664"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.12.attention.self.value.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28435
        },
        "bert.encoder.layer.12.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.12.intermediate.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_683 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_683"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.12.intermediate.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28473
        },
        "bert.encoder.layer.12.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.12.intermediate.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_683 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_683"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.12.intermediate.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28472
        },
        "bert.encoder.layer.12.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.12.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_92 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_92"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.12.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28501
        },
        "bert.encoder.layer.12.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.12.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_92 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_92"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.12.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28499
        },
        "bert.encoder.layer.12.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.12.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_689 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_689"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.12.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28477
        },
        "bert.encoder.layer.12.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    4096,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.12.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_689 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_689"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.12.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28476
        },
        "bert.encoder.layer.13.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.13.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_97 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_97"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.13.attention.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28573
        },
        "bert.encoder.layer.13.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.13.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_97 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_97"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.13.attention.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28571
        },
        "bert.encoder.layer.13.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.13.attention.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_728 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_728"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.13.attention.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28549
        },
        "bert.encoder.layer.13.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.13.attention.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_728 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_728"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.13.attention.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28548
        },
        "bert.encoder.layer.13.attention.self.key.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.13.attention.self.key.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_703 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_703"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.13.attention.self.key.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28511
        },
        "bert.encoder.layer.13.attention.self.key.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.13.attention.self.key.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_703 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_703"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.13.attention.self.key.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28510
        },
        "bert.encoder.layer.13.attention.self.query.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.13.attention.self.query.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_697 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_697"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.13.attention.self.query.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28505
        },
        "bert.encoder.layer.13.attention.self.query.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.13.attention.self.query.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_697 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_697"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.13.attention.self.query.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28504
        },
        "bert.encoder.layer.13.attention.self.value.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.13.attention.self.value.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_717 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_717"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.13.attention.self.value.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28540
        },
        "bert.encoder.layer.13.attention.self.value.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.13.attention.self.value.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_717 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_717"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.13.attention.self.value.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28539
        },
        "bert.encoder.layer.13.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.13.intermediate.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_736 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_736"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.13.intermediate.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28577
        },
        "bert.encoder.layer.13.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.13.intermediate.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_736 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_736"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.13.intermediate.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28576
        },
        "bert.encoder.layer.13.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.13.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_99 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_99"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.13.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28605
        },
        "bert.encoder.layer.13.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.13.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_99 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_99"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.13.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28603
        },
        "bert.encoder.layer.13.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.13.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_742 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_742"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.13.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28581
        },
        "bert.encoder.layer.13.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    4096,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.13.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_742 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_742"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.13.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28580
        },
        "bert.encoder.layer.14.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.14.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_104 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_104"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.14.attention.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28677
        },
        "bert.encoder.layer.14.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.14.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_104 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_104"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.14.attention.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28675
        },
        "bert.encoder.layer.14.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.14.attention.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_781 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_781"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.14.attention.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28653
        },
        "bert.encoder.layer.14.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.14.attention.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_781 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_781"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.14.attention.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28652
        },
        "bert.encoder.layer.14.attention.self.key.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.14.attention.self.key.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_756 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_756"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.14.attention.self.key.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28615
        },
        "bert.encoder.layer.14.attention.self.key.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.14.attention.self.key.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_756 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_756"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.14.attention.self.key.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28614
        },
        "bert.encoder.layer.14.attention.self.query.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.14.attention.self.query.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_750 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_750"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.14.attention.self.query.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28609
        },
        "bert.encoder.layer.14.attention.self.query.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.14.attention.self.query.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_750 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_750"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.14.attention.self.query.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28608
        },
        "bert.encoder.layer.14.attention.self.value.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.14.attention.self.value.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_770 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_770"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.14.attention.self.value.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28644
        },
        "bert.encoder.layer.14.attention.self.value.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.14.attention.self.value.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_770 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_770"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.14.attention.self.value.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28643
        },
        "bert.encoder.layer.14.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.14.intermediate.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_789 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_789"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.14.intermediate.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28681
        },
        "bert.encoder.layer.14.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.14.intermediate.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_789 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_789"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.14.intermediate.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28680
        },
        "bert.encoder.layer.14.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.14.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_106 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_106"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.14.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28709
        },
        "bert.encoder.layer.14.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.14.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_106 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_106"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.14.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28707
        },
        "bert.encoder.layer.14.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.14.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_795 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_795"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.14.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28685
        },
        "bert.encoder.layer.14.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    4096,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.14.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_795 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_795"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.14.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28684
        },
        "bert.encoder.layer.15.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.15.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_111 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_111"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.15.attention.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28781
        },
        "bert.encoder.layer.15.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.15.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_111 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_111"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.15.attention.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28779
        },
        "bert.encoder.layer.15.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.15.attention.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_834 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_834"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.15.attention.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28757
        },
        "bert.encoder.layer.15.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.15.attention.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_834 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_834"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.15.attention.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28756
        },
        "bert.encoder.layer.15.attention.self.key.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.15.attention.self.key.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_809 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_809"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.15.attention.self.key.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28719
        },
        "bert.encoder.layer.15.attention.self.key.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.15.attention.self.key.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_809 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_809"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.15.attention.self.key.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28718
        },
        "bert.encoder.layer.15.attention.self.query.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.15.attention.self.query.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_803 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_803"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.15.attention.self.query.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28713
        },
        "bert.encoder.layer.15.attention.self.query.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.15.attention.self.query.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_803 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_803"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.15.attention.self.query.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28712
        },
        "bert.encoder.layer.15.attention.self.value.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.15.attention.self.value.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_823 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_823"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.15.attention.self.value.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28748
        },
        "bert.encoder.layer.15.attention.self.value.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.15.attention.self.value.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_823 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_823"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.15.attention.self.value.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28747
        },
        "bert.encoder.layer.15.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.15.intermediate.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_842 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_842"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.15.intermediate.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28785
        },
        "bert.encoder.layer.15.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.15.intermediate.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_842 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_842"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.15.intermediate.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28784
        },
        "bert.encoder.layer.15.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.15.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_113 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_113"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.15.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28813
        },
        "bert.encoder.layer.15.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.15.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_113 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_113"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.15.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28811
        },
        "bert.encoder.layer.15.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.15.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_848 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_848"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.15.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28789
        },
        "bert.encoder.layer.15.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    4096,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.15.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_848 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_848"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.15.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28788
        },
        "bert.encoder.layer.16.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.16.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_118 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_118"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.16.attention.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28885
        },
        "bert.encoder.layer.16.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.16.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_118 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_118"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.16.attention.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28883
        },
        "bert.encoder.layer.16.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.16.attention.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_887 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_887"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.16.attention.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28861
        },
        "bert.encoder.layer.16.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.16.attention.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_887 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_887"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.16.attention.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28860
        },
        "bert.encoder.layer.16.attention.self.key.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.16.attention.self.key.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_862 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_862"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.16.attention.self.key.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28823
        },
        "bert.encoder.layer.16.attention.self.key.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.16.attention.self.key.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_862 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_862"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.16.attention.self.key.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28822
        },
        "bert.encoder.layer.16.attention.self.query.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.16.attention.self.query.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_856 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_856"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.16.attention.self.query.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28817
        },
        "bert.encoder.layer.16.attention.self.query.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.16.attention.self.query.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_856 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_856"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.16.attention.self.query.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28816
        },
        "bert.encoder.layer.16.attention.self.value.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.16.attention.self.value.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_876 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_876"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.16.attention.self.value.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28852
        },
        "bert.encoder.layer.16.attention.self.value.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.16.attention.self.value.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_876 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_876"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.16.attention.self.value.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28851
        },
        "bert.encoder.layer.16.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.16.intermediate.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_895 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_895"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.16.intermediate.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28889
        },
        "bert.encoder.layer.16.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.16.intermediate.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_895 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_895"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.16.intermediate.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28888
        },
        "bert.encoder.layer.16.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.16.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_120 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_120"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.16.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28917
        },
        "bert.encoder.layer.16.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.16.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_120 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_120"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.16.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28915
        },
        "bert.encoder.layer.16.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.16.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_901 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_901"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.16.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28893
        },
        "bert.encoder.layer.16.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    4096,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.16.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_901 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_901"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.16.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28892
        },
        "bert.encoder.layer.17.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.17.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_125 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_125"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.17.attention.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28989
        },
        "bert.encoder.layer.17.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.17.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_125 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_125"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.17.attention.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28987
        },
        "bert.encoder.layer.17.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.17.attention.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_940 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_940"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.17.attention.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28965
        },
        "bert.encoder.layer.17.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.17.attention.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_940 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_940"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.17.attention.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28964
        },
        "bert.encoder.layer.17.attention.self.key.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.17.attention.self.key.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_915 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_915"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.17.attention.self.key.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28927
        },
        "bert.encoder.layer.17.attention.self.key.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.17.attention.self.key.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_915 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_915"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.17.attention.self.key.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28926
        },
        "bert.encoder.layer.17.attention.self.query.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.17.attention.self.query.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_909 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_909"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.17.attention.self.query.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28921
        },
        "bert.encoder.layer.17.attention.self.query.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.17.attention.self.query.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_909 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_909"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.17.attention.self.query.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28920
        },
        "bert.encoder.layer.17.attention.self.value.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.17.attention.self.value.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_929 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_929"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.17.attention.self.value.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28956
        },
        "bert.encoder.layer.17.attention.self.value.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.17.attention.self.value.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_929 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_929"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.17.attention.self.value.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28955
        },
        "bert.encoder.layer.17.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.17.intermediate.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_948 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_948"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.17.intermediate.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28993
        },
        "bert.encoder.layer.17.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.17.intermediate.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_948 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_948"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.17.intermediate.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28992
        },
        "bert.encoder.layer.17.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.17.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_127 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_127"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.17.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29021
        },
        "bert.encoder.layer.17.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.17.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_127 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_127"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.17.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29019
        },
        "bert.encoder.layer.17.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.17.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_954 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_954"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.17.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28997
        },
        "bert.encoder.layer.17.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    4096,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.17.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_954 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_954"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.17.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28996
        },
        "bert.encoder.layer.18.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.18.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_132 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_132"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.18.attention.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29093
        },
        "bert.encoder.layer.18.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.18.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_132 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_132"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.18.attention.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29091
        },
        "bert.encoder.layer.18.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.18.attention.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_993 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_993"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.18.attention.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29069
        },
        "bert.encoder.layer.18.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.18.attention.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_993 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_993"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.18.attention.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29068
        },
        "bert.encoder.layer.18.attention.self.key.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.18.attention.self.key.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_968 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_968"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.18.attention.self.key.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29031
        },
        "bert.encoder.layer.18.attention.self.key.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.18.attention.self.key.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_968 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_968"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.18.attention.self.key.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29030
        },
        "bert.encoder.layer.18.attention.self.query.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.18.attention.self.query.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_962 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_962"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.18.attention.self.query.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29025
        },
        "bert.encoder.layer.18.attention.self.query.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.18.attention.self.query.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_962 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_962"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.18.attention.self.query.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29024
        },
        "bert.encoder.layer.18.attention.self.value.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.18.attention.self.value.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_982 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_982"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.18.attention.self.value.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29060
        },
        "bert.encoder.layer.18.attention.self.value.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.18.attention.self.value.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_982 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_982"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.18.attention.self.value.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29059
        },
        "bert.encoder.layer.18.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.18.intermediate.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1001 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1001"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.18.intermediate.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29097
        },
        "bert.encoder.layer.18.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.18.intermediate.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1001 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1001"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.18.intermediate.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29096
        },
        "bert.encoder.layer.18.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.18.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_134 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_134"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.18.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29125
        },
        "bert.encoder.layer.18.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.18.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_134 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_134"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.18.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29123
        },
        "bert.encoder.layer.18.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.18.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1007 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1007"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.18.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29101
        },
        "bert.encoder.layer.18.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    4096,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.18.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1007 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1007"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.18.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29100
        },
        "bert.encoder.layer.19.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.19.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_139 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_139"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.19.attention.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29197
        },
        "bert.encoder.layer.19.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.19.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_139 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_139"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.19.attention.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29195
        },
        "bert.encoder.layer.19.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.19.attention.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1046 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1046"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.19.attention.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29173
        },
        "bert.encoder.layer.19.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.19.attention.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1046 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1046"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.19.attention.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29172
        },
        "bert.encoder.layer.19.attention.self.key.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.19.attention.self.key.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1021 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1021"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.19.attention.self.key.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29135
        },
        "bert.encoder.layer.19.attention.self.key.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.19.attention.self.key.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1021 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1021"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.19.attention.self.key.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29134
        },
        "bert.encoder.layer.19.attention.self.query.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.19.attention.self.query.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1015 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1015"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.19.attention.self.query.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29129
        },
        "bert.encoder.layer.19.attention.self.query.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.19.attention.self.query.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1015 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1015"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.19.attention.self.query.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29128
        },
        "bert.encoder.layer.19.attention.self.value.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.19.attention.self.value.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1035 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1035"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.19.attention.self.value.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29164
        },
        "bert.encoder.layer.19.attention.self.value.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.19.attention.self.value.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1035 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1035"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.19.attention.self.value.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29163
        },
        "bert.encoder.layer.19.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.19.intermediate.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1054 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1054"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.19.intermediate.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29201
        },
        "bert.encoder.layer.19.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.19.intermediate.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1054 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1054"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.19.intermediate.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29200
        },
        "bert.encoder.layer.19.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.19.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_141 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_141"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.19.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29229
        },
        "bert.encoder.layer.19.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.19.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_141 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_141"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.19.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29227
        },
        "bert.encoder.layer.19.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.19.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1060 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1060"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.19.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29205
        },
        "bert.encoder.layer.19.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    4096,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.19.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1060 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1060"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.19.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29204
        },
        "bert.encoder.layer.2.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.2.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_20 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_20"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.2.attention.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27429
        },
        "bert.encoder.layer.2.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.2.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_20 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_20"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.2.attention.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27427
        },
        "bert.encoder.layer.2.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.2.attention.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_145 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_145"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.2.attention.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27405
        },
        "bert.encoder.layer.2.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.2.attention.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_145 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_145"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.2.attention.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27404
        },
        "bert.encoder.layer.2.attention.self.key.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.2.attention.self.key.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_120 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_120"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.2.attention.self.key.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27367
        },
        "bert.encoder.layer.2.attention.self.key.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.2.attention.self.key.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_120 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_120"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.2.attention.self.key.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27366
        },
        "bert.encoder.layer.2.attention.self.query.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.2.attention.self.query.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_114 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_114"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.2.attention.self.query.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27361
        },
        "bert.encoder.layer.2.attention.self.query.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.2.attention.self.query.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_114 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_114"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.2.attention.self.query.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27360
        },
        "bert.encoder.layer.2.attention.self.value.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.2.attention.self.value.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_134 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_134"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.2.attention.self.value.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27396
        },
        "bert.encoder.layer.2.attention.self.value.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.2.attention.self.value.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_134 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_134"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.2.attention.self.value.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27395
        },
        "bert.encoder.layer.2.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.2.intermediate.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_153 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_153"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.2.intermediate.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27433
        },
        "bert.encoder.layer.2.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.2.intermediate.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_153 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_153"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.2.intermediate.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27432
        },
        "bert.encoder.layer.2.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.2.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_22 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_22"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.2.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27461
        },
        "bert.encoder.layer.2.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.2.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_22 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_22"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.2.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27459
        },
        "bert.encoder.layer.2.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.2.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_159 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_159"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.2.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27437
        },
        "bert.encoder.layer.2.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    4096,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.2.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_159 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_159"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.2.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27436
        },
        "bert.encoder.layer.20.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.20.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_146 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_146"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.20.attention.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29301
        },
        "bert.encoder.layer.20.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.20.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_146 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_146"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.20.attention.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29299
        },
        "bert.encoder.layer.20.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.20.attention.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1099 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1099"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.20.attention.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29277
        },
        "bert.encoder.layer.20.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.20.attention.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1099 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1099"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.20.attention.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29276
        },
        "bert.encoder.layer.20.attention.self.key.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.20.attention.self.key.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1074 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1074"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.20.attention.self.key.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29239
        },
        "bert.encoder.layer.20.attention.self.key.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.20.attention.self.key.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1074 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1074"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.20.attention.self.key.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29238
        },
        "bert.encoder.layer.20.attention.self.query.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.20.attention.self.query.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1068 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1068"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.20.attention.self.query.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29233
        },
        "bert.encoder.layer.20.attention.self.query.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.20.attention.self.query.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1068 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1068"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.20.attention.self.query.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29232
        },
        "bert.encoder.layer.20.attention.self.value.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.20.attention.self.value.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1088 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1088"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.20.attention.self.value.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29268
        },
        "bert.encoder.layer.20.attention.self.value.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.20.attention.self.value.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1088 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1088"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.20.attention.self.value.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29267
        },
        "bert.encoder.layer.20.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.20.intermediate.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1107 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1107"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.20.intermediate.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29305
        },
        "bert.encoder.layer.20.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.20.intermediate.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1107 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1107"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.20.intermediate.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29304
        },
        "bert.encoder.layer.20.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.20.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_148 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_148"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.20.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29333
        },
        "bert.encoder.layer.20.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.20.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_148 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_148"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.20.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29331
        },
        "bert.encoder.layer.20.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.20.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1113 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1113"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.20.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29309
        },
        "bert.encoder.layer.20.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    4096,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.20.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1113 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1113"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.20.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29308
        },
        "bert.encoder.layer.21.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.21.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_153 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_153"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.21.attention.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29405
        },
        "bert.encoder.layer.21.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.21.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_153 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_153"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.21.attention.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29403
        },
        "bert.encoder.layer.21.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.21.attention.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1152 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1152"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.21.attention.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29381
        },
        "bert.encoder.layer.21.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.21.attention.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1152 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1152"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.21.attention.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29380
        },
        "bert.encoder.layer.21.attention.self.key.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.21.attention.self.key.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1127 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1127"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.21.attention.self.key.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29343
        },
        "bert.encoder.layer.21.attention.self.key.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.21.attention.self.key.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1127 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1127"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.21.attention.self.key.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29342
        },
        "bert.encoder.layer.21.attention.self.query.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.21.attention.self.query.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1121 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1121"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.21.attention.self.query.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29337
        },
        "bert.encoder.layer.21.attention.self.query.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.21.attention.self.query.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1121 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1121"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.21.attention.self.query.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29336
        },
        "bert.encoder.layer.21.attention.self.value.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.21.attention.self.value.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1141 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1141"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.21.attention.self.value.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29372
        },
        "bert.encoder.layer.21.attention.self.value.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.21.attention.self.value.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1141 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1141"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.21.attention.self.value.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29371
        },
        "bert.encoder.layer.21.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.21.intermediate.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1160 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1160"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.21.intermediate.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29409
        },
        "bert.encoder.layer.21.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.21.intermediate.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1160 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1160"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.21.intermediate.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29408
        },
        "bert.encoder.layer.21.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.21.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_155 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_155"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.21.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29437
        },
        "bert.encoder.layer.21.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.21.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_155 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_155"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.21.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29435
        },
        "bert.encoder.layer.21.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.21.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1166 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1166"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.21.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29413
        },
        "bert.encoder.layer.21.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    4096,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.21.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1166 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1166"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.21.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29412
        },
        "bert.encoder.layer.22.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.22.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_160 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_160"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.22.attention.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29509
        },
        "bert.encoder.layer.22.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.22.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_160 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_160"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.22.attention.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29507
        },
        "bert.encoder.layer.22.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.22.attention.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1205 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1205"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.22.attention.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29485
        },
        "bert.encoder.layer.22.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.22.attention.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1205 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1205"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.22.attention.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29484
        },
        "bert.encoder.layer.22.attention.self.key.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.22.attention.self.key.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1180 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1180"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.22.attention.self.key.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29447
        },
        "bert.encoder.layer.22.attention.self.key.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.22.attention.self.key.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1180 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1180"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.22.attention.self.key.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29446
        },
        "bert.encoder.layer.22.attention.self.query.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.22.attention.self.query.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1174 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1174"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.22.attention.self.query.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29441
        },
        "bert.encoder.layer.22.attention.self.query.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.22.attention.self.query.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1174 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1174"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.22.attention.self.query.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29440
        },
        "bert.encoder.layer.22.attention.self.value.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.22.attention.self.value.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1194 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1194"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.22.attention.self.value.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29476
        },
        "bert.encoder.layer.22.attention.self.value.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.22.attention.self.value.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1194 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1194"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.22.attention.self.value.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29475
        },
        "bert.encoder.layer.22.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.22.intermediate.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1213 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1213"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.22.intermediate.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29513
        },
        "bert.encoder.layer.22.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.22.intermediate.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1213 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1213"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.22.intermediate.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29512
        },
        "bert.encoder.layer.22.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.22.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_162 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_162"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.22.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29541
        },
        "bert.encoder.layer.22.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.22.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_162 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_162"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.22.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29539
        },
        "bert.encoder.layer.22.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.22.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1219 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1219"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.22.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29517
        },
        "bert.encoder.layer.22.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    4096,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.22.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1219 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1219"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.22.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29516
        },
        "bert.encoder.layer.23.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.23.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_167 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_167"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.23.attention.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29613
        },
        "bert.encoder.layer.23.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.23.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_167 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_167"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.23.attention.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29611
        },
        "bert.encoder.layer.23.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.23.attention.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1258 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1258"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.23.attention.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29589
        },
        "bert.encoder.layer.23.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.23.attention.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1258 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1258"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.23.attention.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29588
        },
        "bert.encoder.layer.23.attention.self.key.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.23.attention.self.key.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1233 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1233"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.23.attention.self.key.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29551
        },
        "bert.encoder.layer.23.attention.self.key.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.23.attention.self.key.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1233 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1233"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.23.attention.self.key.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29550
        },
        "bert.encoder.layer.23.attention.self.query.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.23.attention.self.query.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1227 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1227"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.23.attention.self.query.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29545
        },
        "bert.encoder.layer.23.attention.self.query.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.23.attention.self.query.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1227 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1227"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.23.attention.self.query.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29544
        },
        "bert.encoder.layer.23.attention.self.value.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.23.attention.self.value.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1247 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1247"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.23.attention.self.value.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29580
        },
        "bert.encoder.layer.23.attention.self.value.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.23.attention.self.value.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1247 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1247"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.23.attention.self.value.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29579
        },
        "bert.encoder.layer.23.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.23.intermediate.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1266 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1266"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.23.intermediate.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29617
        },
        "bert.encoder.layer.23.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.23.intermediate.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1266 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1266"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.23.intermediate.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29616
        },
        "bert.encoder.layer.23.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.23.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_169 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_169"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.23.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29645
        },
        "bert.encoder.layer.23.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.23.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_169 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_169"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.23.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29643
        },
        "bert.encoder.layer.23.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.23.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1272 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1272"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.23.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29621
        },
        "bert.encoder.layer.23.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    4096,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.23.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1272 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1272"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.23.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29620
        },
        "bert.encoder.layer.3.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.3.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_27 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_27"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.3.attention.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27533
        },
        "bert.encoder.layer.3.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.3.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_27 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_27"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.3.attention.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27531
        },
        "bert.encoder.layer.3.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.3.attention.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_198 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_198"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.3.attention.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27509
        },
        "bert.encoder.layer.3.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.3.attention.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_198 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_198"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.3.attention.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27508
        },
        "bert.encoder.layer.3.attention.self.key.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.3.attention.self.key.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_173 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_173"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.3.attention.self.key.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27471
        },
        "bert.encoder.layer.3.attention.self.key.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.3.attention.self.key.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_173 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_173"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.3.attention.self.key.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27470
        },
        "bert.encoder.layer.3.attention.self.query.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.3.attention.self.query.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_167 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_167"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.3.attention.self.query.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27465
        },
        "bert.encoder.layer.3.attention.self.query.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.3.attention.self.query.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_167 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_167"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.3.attention.self.query.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27464
        },
        "bert.encoder.layer.3.attention.self.value.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.3.attention.self.value.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_187 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_187"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.3.attention.self.value.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27500
        },
        "bert.encoder.layer.3.attention.self.value.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.3.attention.self.value.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_187 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_187"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.3.attention.self.value.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27499
        },
        "bert.encoder.layer.3.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.3.intermediate.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_206 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_206"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.3.intermediate.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27537
        },
        "bert.encoder.layer.3.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.3.intermediate.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_206 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_206"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.3.intermediate.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27536
        },
        "bert.encoder.layer.3.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.3.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_29 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_29"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.3.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27565
        },
        "bert.encoder.layer.3.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.3.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_29 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_29"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.3.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27563
        },
        "bert.encoder.layer.3.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.3.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_212 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_212"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.3.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27541
        },
        "bert.encoder.layer.3.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    4096,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.3.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_212 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_212"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.3.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27540
        },
        "bert.encoder.layer.4.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.4.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_34 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_34"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.4.attention.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27637
        },
        "bert.encoder.layer.4.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.4.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_34 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_34"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.4.attention.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27635
        },
        "bert.encoder.layer.4.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.4.attention.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_251 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_251"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.4.attention.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27613
        },
        "bert.encoder.layer.4.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.4.attention.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_251 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_251"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.4.attention.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27612
        },
        "bert.encoder.layer.4.attention.self.key.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.4.attention.self.key.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_226 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_226"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.4.attention.self.key.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27575
        },
        "bert.encoder.layer.4.attention.self.key.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.4.attention.self.key.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_226 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_226"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.4.attention.self.key.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27574
        },
        "bert.encoder.layer.4.attention.self.query.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.4.attention.self.query.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_220 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_220"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.4.attention.self.query.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27569
        },
        "bert.encoder.layer.4.attention.self.query.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.4.attention.self.query.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_220 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_220"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.4.attention.self.query.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27568
        },
        "bert.encoder.layer.4.attention.self.value.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.4.attention.self.value.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_240 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_240"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.4.attention.self.value.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27604
        },
        "bert.encoder.layer.4.attention.self.value.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.4.attention.self.value.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_240 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_240"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.4.attention.self.value.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27603
        },
        "bert.encoder.layer.4.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.4.intermediate.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_259 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_259"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.4.intermediate.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27641
        },
        "bert.encoder.layer.4.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.4.intermediate.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_259 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_259"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.4.intermediate.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27640
        },
        "bert.encoder.layer.4.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.4.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_36 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_36"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.4.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27669
        },
        "bert.encoder.layer.4.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.4.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_36 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_36"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.4.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27667
        },
        "bert.encoder.layer.4.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.4.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_265 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_265"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.4.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27645
        },
        "bert.encoder.layer.4.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    4096,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.4.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_265 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_265"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.4.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27644
        },
        "bert.encoder.layer.5.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.5.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_41 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_41"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.5.attention.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27741
        },
        "bert.encoder.layer.5.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.5.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_41 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_41"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.5.attention.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27739
        },
        "bert.encoder.layer.5.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.5.attention.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_304 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_304"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.5.attention.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27717
        },
        "bert.encoder.layer.5.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.5.attention.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_304 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_304"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.5.attention.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27716
        },
        "bert.encoder.layer.5.attention.self.key.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.5.attention.self.key.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_279 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_279"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.5.attention.self.key.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27679
        },
        "bert.encoder.layer.5.attention.self.key.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.5.attention.self.key.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_279 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_279"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.5.attention.self.key.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27678
        },
        "bert.encoder.layer.5.attention.self.query.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.5.attention.self.query.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_273 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_273"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.5.attention.self.query.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27673
        },
        "bert.encoder.layer.5.attention.self.query.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.5.attention.self.query.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_273 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_273"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.5.attention.self.query.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27672
        },
        "bert.encoder.layer.5.attention.self.value.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.5.attention.self.value.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_293 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_293"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.5.attention.self.value.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27708
        },
        "bert.encoder.layer.5.attention.self.value.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.5.attention.self.value.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_293 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_293"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.5.attention.self.value.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27707
        },
        "bert.encoder.layer.5.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.5.intermediate.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_312 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_312"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.5.intermediate.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27745
        },
        "bert.encoder.layer.5.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.5.intermediate.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_312 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_312"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.5.intermediate.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27744
        },
        "bert.encoder.layer.5.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.5.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_43 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_43"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.5.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27773
        },
        "bert.encoder.layer.5.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.5.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_43 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_43"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.5.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27771
        },
        "bert.encoder.layer.5.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.5.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_318 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_318"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.5.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27749
        },
        "bert.encoder.layer.5.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    4096,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.5.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_318 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_318"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.5.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27748
        },
        "bert.encoder.layer.6.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.6.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_48 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_48"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.6.attention.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27845
        },
        "bert.encoder.layer.6.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.6.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_48 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_48"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.6.attention.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27843
        },
        "bert.encoder.layer.6.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.6.attention.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_357 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_357"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.6.attention.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27821
        },
        "bert.encoder.layer.6.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.6.attention.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_357 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_357"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.6.attention.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27820
        },
        "bert.encoder.layer.6.attention.self.key.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.6.attention.self.key.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_332 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_332"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.6.attention.self.key.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27783
        },
        "bert.encoder.layer.6.attention.self.key.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.6.attention.self.key.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_332 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_332"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.6.attention.self.key.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27782
        },
        "bert.encoder.layer.6.attention.self.query.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.6.attention.self.query.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_326 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_326"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.6.attention.self.query.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27777
        },
        "bert.encoder.layer.6.attention.self.query.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.6.attention.self.query.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_326 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_326"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.6.attention.self.query.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27776
        },
        "bert.encoder.layer.6.attention.self.value.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.6.attention.self.value.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_346 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_346"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.6.attention.self.value.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27812
        },
        "bert.encoder.layer.6.attention.self.value.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.6.attention.self.value.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_346 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_346"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.6.attention.self.value.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27811
        },
        "bert.encoder.layer.6.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.6.intermediate.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_365 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_365"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.6.intermediate.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27849
        },
        "bert.encoder.layer.6.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.6.intermediate.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_365 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_365"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.6.intermediate.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27848
        },
        "bert.encoder.layer.6.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.6.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_50 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_50"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.6.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27877
        },
        "bert.encoder.layer.6.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.6.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_50 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_50"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.6.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27875
        },
        "bert.encoder.layer.6.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.6.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_371 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_371"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.6.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27853
        },
        "bert.encoder.layer.6.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    4096,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.6.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_371 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_371"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.6.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27852
        },
        "bert.encoder.layer.7.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.7.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_55 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_55"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.7.attention.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27949
        },
        "bert.encoder.layer.7.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.7.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_55 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_55"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.7.attention.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27947
        },
        "bert.encoder.layer.7.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.7.attention.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_410 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_410"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.7.attention.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27925
        },
        "bert.encoder.layer.7.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.7.attention.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_410 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_410"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.7.attention.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27924
        },
        "bert.encoder.layer.7.attention.self.key.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.7.attention.self.key.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_385 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_385"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.7.attention.self.key.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27887
        },
        "bert.encoder.layer.7.attention.self.key.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.7.attention.self.key.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_385 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_385"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.7.attention.self.key.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27886
        },
        "bert.encoder.layer.7.attention.self.query.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.7.attention.self.query.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_379 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_379"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.7.attention.self.query.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27881
        },
        "bert.encoder.layer.7.attention.self.query.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.7.attention.self.query.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_379 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_379"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.7.attention.self.query.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27880
        },
        "bert.encoder.layer.7.attention.self.value.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.7.attention.self.value.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_399 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_399"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.7.attention.self.value.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27916
        },
        "bert.encoder.layer.7.attention.self.value.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.7.attention.self.value.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_399 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_399"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.7.attention.self.value.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27915
        },
        "bert.encoder.layer.7.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.7.intermediate.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_418 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_418"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.7.intermediate.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27953
        },
        "bert.encoder.layer.7.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.7.intermediate.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_418 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_418"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.7.intermediate.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27952
        },
        "bert.encoder.layer.7.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.7.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_57 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_57"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.7.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27981
        },
        "bert.encoder.layer.7.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.7.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_57 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_57"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.7.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27979
        },
        "bert.encoder.layer.7.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.7.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_424 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_424"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.7.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27957
        },
        "bert.encoder.layer.7.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    4096,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.7.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_424 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_424"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.7.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27956
        },
        "bert.encoder.layer.8.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.8.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_62 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_62"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.8.attention.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28053
        },
        "bert.encoder.layer.8.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.8.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_62 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_62"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.8.attention.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28051
        },
        "bert.encoder.layer.8.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.8.attention.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_463 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_463"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.8.attention.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28029
        },
        "bert.encoder.layer.8.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.8.attention.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_463 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_463"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.8.attention.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28028
        },
        "bert.encoder.layer.8.attention.self.key.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.8.attention.self.key.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_438 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_438"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.8.attention.self.key.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27991
        },
        "bert.encoder.layer.8.attention.self.key.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.8.attention.self.key.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_438 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_438"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.8.attention.self.key.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27990
        },
        "bert.encoder.layer.8.attention.self.query.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.8.attention.self.query.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_432 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_432"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.8.attention.self.query.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27985
        },
        "bert.encoder.layer.8.attention.self.query.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.8.attention.self.query.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_432 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_432"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.8.attention.self.query.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27984
        },
        "bert.encoder.layer.8.attention.self.value.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.8.attention.self.value.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_452 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_452"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.8.attention.self.value.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28020
        },
        "bert.encoder.layer.8.attention.self.value.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.8.attention.self.value.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_452 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_452"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.8.attention.self.value.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28019
        },
        "bert.encoder.layer.8.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.8.intermediate.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_471 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_471"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.8.intermediate.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28057
        },
        "bert.encoder.layer.8.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.8.intermediate.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_471 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_471"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.8.intermediate.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28056
        },
        "bert.encoder.layer.8.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.8.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_64 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_64"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.8.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28085
        },
        "bert.encoder.layer.8.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.8.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_64 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_64"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.8.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28083
        },
        "bert.encoder.layer.8.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.8.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_477 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_477"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.8.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28061
        },
        "bert.encoder.layer.8.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    4096,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.8.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_477 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_477"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.8.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28060
        },
        "bert.encoder.layer.9.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.9.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_69 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_69"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.9.attention.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28157
        },
        "bert.encoder.layer.9.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.9.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_69 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_69"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.9.attention.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28155
        },
        "bert.encoder.layer.9.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.9.attention.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_516 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_516"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.9.attention.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28133
        },
        "bert.encoder.layer.9.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.9.attention.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_516 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_516"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.9.attention.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28132
        },
        "bert.encoder.layer.9.attention.self.key.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.9.attention.self.key.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_491 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_491"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.9.attention.self.key.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28095
        },
        "bert.encoder.layer.9.attention.self.key.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.9.attention.self.key.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_491 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_491"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.9.attention.self.key.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28094
        },
        "bert.encoder.layer.9.attention.self.query.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.9.attention.self.query.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_485 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_485"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.9.attention.self.query.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28089
        },
        "bert.encoder.layer.9.attention.self.query.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.9.attention.self.query.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_485 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_485"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.9.attention.self.query.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28088
        },
        "bert.encoder.layer.9.attention.self.value.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.9.attention.self.value.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_505 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_505"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.9.attention.self.value.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28124
        },
        "bert.encoder.layer.9.attention.self.value.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.9.attention.self.value.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_505 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_505"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.9.attention.self.value.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28123
        },
        "bert.encoder.layer.9.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.9.intermediate.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_524 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_524"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.9.intermediate.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28161
        },
        "bert.encoder.layer.9.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.9.intermediate.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_524 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_524"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.9.intermediate.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28160
        },
        "bert.encoder.layer.9.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.9.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_71 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_71"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.9.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28189
        },
        "bert.encoder.layer.9.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.9.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_71 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_71"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.9.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28187
        },
        "bert.encoder.layer.9.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.9.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_530 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_530"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.9.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28165
        },
        "bert.encoder.layer.9.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    4096,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.9.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_530 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_530"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.9.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28164
        },
        "bert_large_tt_1.output_reshape_1285": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "Output",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [
                "Data: matmul_1281_output_nop_0 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "matmul_1281_output_nop_0": "Data"
            },
            "input_nodes": [
                "matmul_1281_output_nop_0"
            ],
            "input_tms": [
                []
            ],
            "is_cross_epoch_type": false,
            "is_saved_intermediate": false,
            "memory_access": "FIFO",
            "name": "bert_large_tt_1.output_reshape_1285",
            "opcode": "Output",
            "outgoing_edge_port_info": [],
            "output_df": "Float16_b",
            "output_nodes": [],
            "pybuda": 1,
            "queue_type": "output",
            "tags": {},
            "type": "Output",
            "unique_id": 29650
        },
        "bert_large_tt_1.output_reshape_1292": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "Output",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [
                "Data: matmul_1288_output_nop_0 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "matmul_1288_output_nop_0": "Data"
            },
            "input_nodes": [
                "matmul_1288_output_nop_0"
            ],
            "input_tms": [
                []
            ],
            "is_cross_epoch_type": false,
            "is_saved_intermediate": false,
            "memory_access": "FIFO",
            "name": "bert_large_tt_1.output_reshape_1292",
            "opcode": "Output",
            "outgoing_edge_port_info": [],
            "output_df": "Float16_b",
            "output_nodes": [],
            "pybuda": 1,
            "queue_type": "output",
            "tags": {},
            "type": "Output",
            "unique_id": 29654
        },
        "buffer_0_27200_29660": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_27200_29660 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_27200_29660": "Data"
            },
            "input_nodes": [
                "buffer_1_27200_29660"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_27200_29660",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_5 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_5"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 29860
        },
        "buffer_0_27232_29662": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_27232_29662 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_27232_29662": "Data"
            },
            "input_nodes": [
                "buffer_1_27232_29662"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_27232_29662",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_7 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_7"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 29867
        },
        "buffer_0_27304_29667": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_27304_29667 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_27304_29667": "Data"
            },
            "input_nodes": [
                "buffer_1_27304_29667"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_27304_29667",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_12 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_12"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 29968
        },
        "buffer_0_27336_29669": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_27336_29669 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_27336_29669": "Data"
            },
            "input_nodes": [
                "buffer_1_27336_29669"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_27336_29669",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_14 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_14"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 29985
        },
        "buffer_0_27408_29674": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_27408_29674 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_27408_29674": "Data"
            },
            "input_nodes": [
                "buffer_1_27408_29674"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_27408_29674",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_19 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_19"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 29996
        },
        "buffer_0_27440_29676": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_27440_29676 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_27440_29676": "Data"
            },
            "input_nodes": [
                "buffer_1_27440_29676"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_27440_29676",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_21 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_21"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30003
        },
        "buffer_0_27512_29681": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_27512_29681 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_27512_29681": "Data"
            },
            "input_nodes": [
                "buffer_1_27512_29681"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_27512_29681",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_26 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_26"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30104
        },
        "buffer_0_27544_29683": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_27544_29683 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_27544_29683": "Data"
            },
            "input_nodes": [
                "buffer_1_27544_29683"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_27544_29683",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_28 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_28"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30121
        },
        "buffer_0_27616_29688": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_27616_29688 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_27616_29688": "Data"
            },
            "input_nodes": [
                "buffer_1_27616_29688"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_27616_29688",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_33 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_33"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30132
        },
        "buffer_0_27648_29690": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_27648_29690 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_27648_29690": "Data"
            },
            "input_nodes": [
                "buffer_1_27648_29690"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_27648_29690",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_35 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_35"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30139
        },
        "buffer_0_27720_29695": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_27720_29695 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_27720_29695": "Data"
            },
            "input_nodes": [
                "buffer_1_27720_29695"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_27720_29695",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_40 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_40"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30240
        },
        "buffer_0_27752_29697": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_27752_29697 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_27752_29697": "Data"
            },
            "input_nodes": [
                "buffer_1_27752_29697"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_27752_29697",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_42 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_42"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30257
        },
        "buffer_0_27824_29702": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_27824_29702 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_27824_29702": "Data"
            },
            "input_nodes": [
                "buffer_1_27824_29702"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_27824_29702",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_47 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_47"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30268
        },
        "buffer_0_27856_29704": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_27856_29704 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_27856_29704": "Data"
            },
            "input_nodes": [
                "buffer_1_27856_29704"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_27856_29704",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_49 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_49"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30275
        },
        "buffer_0_27928_29709": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_27928_29709 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_27928_29709": "Data"
            },
            "input_nodes": [
                "buffer_1_27928_29709"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_27928_29709",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_54 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_54"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30376
        },
        "buffer_0_27960_29711": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_27960_29711 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_27960_29711": "Data"
            },
            "input_nodes": [
                "buffer_1_27960_29711"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_27960_29711",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_56 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_56"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30393
        },
        "buffer_0_28032_29716": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_28032_29716 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_28032_29716": "Data"
            },
            "input_nodes": [
                "buffer_1_28032_29716"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_28032_29716",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_61 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_61"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30404
        },
        "buffer_0_28064_29718": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_28064_29718 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_28064_29718": "Data"
            },
            "input_nodes": [
                "buffer_1_28064_29718"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_28064_29718",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_63 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_63"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30411
        },
        "buffer_0_28136_29723": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_28136_29723 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_28136_29723": "Data"
            },
            "input_nodes": [
                "buffer_1_28136_29723"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_28136_29723",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_68 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_68"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30512
        },
        "buffer_0_28168_29725": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_28168_29725 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_28168_29725": "Data"
            },
            "input_nodes": [
                "buffer_1_28168_29725"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_28168_29725",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_70 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_70"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30529
        },
        "buffer_0_28240_29730": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_28240_29730 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_28240_29730": "Data"
            },
            "input_nodes": [
                "buffer_1_28240_29730"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_28240_29730",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_75 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_75"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30540
        },
        "buffer_0_28272_29732": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_28272_29732 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_28272_29732": "Data"
            },
            "input_nodes": [
                "buffer_1_28272_29732"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_28272_29732",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_77 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_77"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30547
        },
        "buffer_0_28344_29737": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_28344_29737 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_28344_29737": "Data"
            },
            "input_nodes": [
                "buffer_1_28344_29737"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_28344_29737",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_82 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_82"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30648
        },
        "buffer_0_28376_29739": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_28376_29739 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_28376_29739": "Data"
            },
            "input_nodes": [
                "buffer_1_28376_29739"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_28376_29739",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_84 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_84"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30665
        },
        "buffer_0_28448_29744": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_28448_29744 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_28448_29744": "Data"
            },
            "input_nodes": [
                "buffer_1_28448_29744"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_28448_29744",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_89 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_89"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30676
        },
        "buffer_0_28480_29746": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_28480_29746 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_28480_29746": "Data"
            },
            "input_nodes": [
                "buffer_1_28480_29746"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_28480_29746",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_91 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_91"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30683
        },
        "buffer_0_28552_29751": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_28552_29751 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_28552_29751": "Data"
            },
            "input_nodes": [
                "buffer_1_28552_29751"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_28552_29751",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_96 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_96"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30784
        },
        "buffer_0_28584_29753": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_28584_29753 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_28584_29753": "Data"
            },
            "input_nodes": [
                "buffer_1_28584_29753"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_28584_29753",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_98 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_98"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30801
        },
        "buffer_0_28656_29758": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_28656_29758 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_28656_29758": "Data"
            },
            "input_nodes": [
                "buffer_1_28656_29758"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_28656_29758",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_103 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_103"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30812
        },
        "buffer_0_28688_29760": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_28688_29760 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_28688_29760": "Data"
            },
            "input_nodes": [
                "buffer_1_28688_29760"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_28688_29760",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_105 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_105"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30819
        },
        "buffer_0_28760_29765": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_28760_29765 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_28760_29765": "Data"
            },
            "input_nodes": [
                "buffer_1_28760_29765"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_28760_29765",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_110 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_110"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30920
        },
        "buffer_0_28792_29767": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_28792_29767 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_28792_29767": "Data"
            },
            "input_nodes": [
                "buffer_1_28792_29767"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_28792_29767",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_112 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_112"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30937
        },
        "buffer_0_28864_29772": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_28864_29772 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_28864_29772": "Data"
            },
            "input_nodes": [
                "buffer_1_28864_29772"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_28864_29772",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_117 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_117"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30948
        },
        "buffer_0_28896_29774": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_28896_29774 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_28896_29774": "Data"
            },
            "input_nodes": [
                "buffer_1_28896_29774"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_28896_29774",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_119 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_119"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30955
        },
        "buffer_0_28968_29779": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_28968_29779 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_28968_29779": "Data"
            },
            "input_nodes": [
                "buffer_1_28968_29779"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_28968_29779",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_124 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_124"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31056
        },
        "buffer_0_29000_29781": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29000_29781 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29000_29781": "Data"
            },
            "input_nodes": [
                "buffer_1_29000_29781"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29000_29781",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_126 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_126"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31073
        },
        "buffer_0_29072_29786": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29072_29786 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29072_29786": "Data"
            },
            "input_nodes": [
                "buffer_1_29072_29786"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29072_29786",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_131 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_131"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31084
        },
        "buffer_0_29104_29788": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29104_29788 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29104_29788": "Data"
            },
            "input_nodes": [
                "buffer_1_29104_29788"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29104_29788",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_133 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_133"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31091
        },
        "buffer_0_29176_29793": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29176_29793 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29176_29793": "Data"
            },
            "input_nodes": [
                "buffer_1_29176_29793"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29176_29793",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_138 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_138"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31192
        },
        "buffer_0_29208_29795": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29208_29795 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29208_29795": "Data"
            },
            "input_nodes": [
                "buffer_1_29208_29795"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29208_29795",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_140 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_140"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31209
        },
        "buffer_0_29280_29800": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29280_29800 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29280_29800": "Data"
            },
            "input_nodes": [
                "buffer_1_29280_29800"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29280_29800",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_145 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_145"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31220
        },
        "buffer_0_29312_29802": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29312_29802 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29312_29802": "Data"
            },
            "input_nodes": [
                "buffer_1_29312_29802"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29312_29802",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_147 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_147"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31227
        },
        "buffer_0_29384_29807": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29384_29807 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29384_29807": "Data"
            },
            "input_nodes": [
                "buffer_1_29384_29807"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29384_29807",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_152 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_152"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31328
        },
        "buffer_0_29416_29809": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29416_29809 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29416_29809": "Data"
            },
            "input_nodes": [
                "buffer_1_29416_29809"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29416_29809",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_154 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_154"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31345
        },
        "buffer_0_29488_29814": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29488_29814 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29488_29814": "Data"
            },
            "input_nodes": [
                "buffer_1_29488_29814"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29488_29814",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_159 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_159"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31356
        },
        "buffer_0_29520_29816": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29520_29816 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29520_29816": "Data"
            },
            "input_nodes": [
                "buffer_1_29520_29816"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29520_29816",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_161 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_161"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31363
        },
        "buffer_0_29592_29821": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29592_29821 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29592_29821": "Data"
            },
            "input_nodes": [
                "buffer_1_29592_29821"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29592_29821",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_166 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_166"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31447
        },
        "buffer_0_29624_29823": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29624_29823 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29624_29823": "Data"
            },
            "input_nodes": [
                "buffer_1_29624_29823"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29624_29823",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_168 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_168"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31464
        },
        "buffer_0_29655_29656": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29655_29656 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29655_29656": "Data"
            },
            "input_nodes": [
                "buffer_1_29655_29656"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29655_29656",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_1"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 29830
        },
        "buffer_0_29658_29659": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_3 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_3": "Data"
            },
            "input_nodes": [
                "_fused_op_3"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29658_29659",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_4 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_4"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 29859
        },
        "buffer_0_29660_29661": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29660_29661 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29660_29661": "Data"
            },
            "input_nodes": [
                "buffer_1_29660_29661"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29660_29661",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_6 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_6"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 29862
        },
        "buffer_0_29662_29663": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29662_29663 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29662_29663": "Data"
            },
            "input_nodes": [
                "buffer_1_29662_29663"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29662_29663",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_8 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_8"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 29869
        },
        "buffer_0_29667_29668": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29667_29668 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29667_29668": "Data"
            },
            "input_nodes": [
                "buffer_1_29667_29668"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29667_29668",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_13 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_13"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 29972
        },
        "buffer_0_29668_27336": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29668_27336 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29668_27336": "Data"
            },
            "input_nodes": [
                "buffer_1_29668_27336"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29668_27336",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_110 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_110"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 29977
        },
        "buffer_0_29672_29673": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_17 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_17": "Data"
            },
            "input_nodes": [
                "_fused_op_17"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29672_29673",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_18 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_18"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 29995
        },
        "buffer_0_29674_29675": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29674_29675 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29674_29675": "Data"
            },
            "input_nodes": [
                "buffer_1_29674_29675"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29674_29675",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_20 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_20"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 29998
        },
        "buffer_0_29676_29677": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29676_29677 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29676_29677": "Data"
            },
            "input_nodes": [
                "buffer_1_29676_29677"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29676_29677",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_22 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_22"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30005
        },
        "buffer_0_29681_29682": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29681_29682 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29681_29682": "Data"
            },
            "input_nodes": [
                "buffer_1_29681_29682"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29681_29682",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_27 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_27"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30108
        },
        "buffer_0_29682_27544": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29682_27544 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29682_27544": "Data"
            },
            "input_nodes": [
                "buffer_1_29682_27544"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29682_27544",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_216 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_216"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30113
        },
        "buffer_0_29686_29687": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_31 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_31": "Data"
            },
            "input_nodes": [
                "_fused_op_31"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29686_29687",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_32 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_32"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30131
        },
        "buffer_0_29688_29689": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29688_29689 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29688_29689": "Data"
            },
            "input_nodes": [
                "buffer_1_29688_29689"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29688_29689",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_34 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_34"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30134
        },
        "buffer_0_29690_29691": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29690_29691 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29690_29691": "Data"
            },
            "input_nodes": [
                "buffer_1_29690_29691"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29690_29691",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_36 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_36"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30141
        },
        "buffer_0_29695_29696": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29695_29696 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29695_29696": "Data"
            },
            "input_nodes": [
                "buffer_1_29695_29696"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29695_29696",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_41 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_41"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30244
        },
        "buffer_0_29696_27752": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29696_27752 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29696_27752": "Data"
            },
            "input_nodes": [
                "buffer_1_29696_27752"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29696_27752",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_322 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_322"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30249
        },
        "buffer_0_29700_29701": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_45 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_45": "Data"
            },
            "input_nodes": [
                "_fused_op_45"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29700_29701",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_46 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_46"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30267
        },
        "buffer_0_29702_29703": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29702_29703 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29702_29703": "Data"
            },
            "input_nodes": [
                "buffer_1_29702_29703"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29702_29703",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_48 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_48"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30270
        },
        "buffer_0_29704_29705": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29704_29705 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29704_29705": "Data"
            },
            "input_nodes": [
                "buffer_1_29704_29705"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29704_29705",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_50 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_50"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30277
        },
        "buffer_0_29709_29710": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29709_29710 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29709_29710": "Data"
            },
            "input_nodes": [
                "buffer_1_29709_29710"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29709_29710",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_55 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_55"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30380
        },
        "buffer_0_29710_27960": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29710_27960 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29710_27960": "Data"
            },
            "input_nodes": [
                "buffer_1_29710_27960"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29710_27960",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_428 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_428"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30385
        },
        "buffer_0_29714_29715": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_59 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_59": "Data"
            },
            "input_nodes": [
                "_fused_op_59"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29714_29715",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_60 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_60"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30403
        },
        "buffer_0_29716_29717": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29716_29717 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29716_29717": "Data"
            },
            "input_nodes": [
                "buffer_1_29716_29717"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29716_29717",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_62 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_62"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30406
        },
        "buffer_0_29718_29719": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29718_29719 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29718_29719": "Data"
            },
            "input_nodes": [
                "buffer_1_29718_29719"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29718_29719",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_64 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_64"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30413
        },
        "buffer_0_29723_29724": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29723_29724 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29723_29724": "Data"
            },
            "input_nodes": [
                "buffer_1_29723_29724"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29723_29724",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_69 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_69"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30516
        },
        "buffer_0_29724_28168": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29724_28168 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29724_28168": "Data"
            },
            "input_nodes": [
                "buffer_1_29724_28168"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29724_28168",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_534 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_534"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30521
        },
        "buffer_0_29728_29729": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_73 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_73": "Data"
            },
            "input_nodes": [
                "_fused_op_73"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29728_29729",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_74 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_74"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30539
        },
        "buffer_0_29730_29731": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29730_29731 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29730_29731": "Data"
            },
            "input_nodes": [
                "buffer_1_29730_29731"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29730_29731",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_76 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_76"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30542
        },
        "buffer_0_29732_29733": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29732_29733 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29732_29733": "Data"
            },
            "input_nodes": [
                "buffer_1_29732_29733"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29732_29733",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_78 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_78"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30549
        },
        "buffer_0_29737_29738": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29737_29738 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29737_29738": "Data"
            },
            "input_nodes": [
                "buffer_1_29737_29738"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29737_29738",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_83 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_83"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30652
        },
        "buffer_0_29738_28376": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29738_28376 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29738_28376": "Data"
            },
            "input_nodes": [
                "buffer_1_29738_28376"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29738_28376",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_640 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_640"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30657
        },
        "buffer_0_29742_29743": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_87 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_87": "Data"
            },
            "input_nodes": [
                "_fused_op_87"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29742_29743",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_88 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_88"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30675
        },
        "buffer_0_29744_29745": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29744_29745 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29744_29745": "Data"
            },
            "input_nodes": [
                "buffer_1_29744_29745"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29744_29745",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_90 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_90"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30678
        },
        "buffer_0_29746_29747": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29746_29747 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29746_29747": "Data"
            },
            "input_nodes": [
                "buffer_1_29746_29747"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29746_29747",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_92 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_92"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30685
        },
        "buffer_0_29751_29752": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29751_29752 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29751_29752": "Data"
            },
            "input_nodes": [
                "buffer_1_29751_29752"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29751_29752",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_97 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_97"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30788
        },
        "buffer_0_29752_28584": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29752_28584 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29752_28584": "Data"
            },
            "input_nodes": [
                "buffer_1_29752_28584"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29752_28584",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_746 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_746"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30793
        },
        "buffer_0_29756_29757": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_101 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_101": "Data"
            },
            "input_nodes": [
                "_fused_op_101"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29756_29757",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_102 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_102"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30811
        },
        "buffer_0_29758_29759": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29758_29759 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29758_29759": "Data"
            },
            "input_nodes": [
                "buffer_1_29758_29759"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29758_29759",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_104 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_104"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30814
        },
        "buffer_0_29760_29761": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29760_29761 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29760_29761": "Data"
            },
            "input_nodes": [
                "buffer_1_29760_29761"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29760_29761",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_106 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_106"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30821
        },
        "buffer_0_29765_29766": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29765_29766 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29765_29766": "Data"
            },
            "input_nodes": [
                "buffer_1_29765_29766"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29765_29766",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_111 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_111"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30924
        },
        "buffer_0_29766_28792": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29766_28792 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29766_28792": "Data"
            },
            "input_nodes": [
                "buffer_1_29766_28792"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29766_28792",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_852 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_852"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30929
        },
        "buffer_0_29770_29771": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_115 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_115": "Data"
            },
            "input_nodes": [
                "_fused_op_115"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29770_29771",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_116 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_116"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30947
        },
        "buffer_0_29772_29773": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29772_29773 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29772_29773": "Data"
            },
            "input_nodes": [
                "buffer_1_29772_29773"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29772_29773",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_118 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_118"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30950
        },
        "buffer_0_29774_29775": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29774_29775 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29774_29775": "Data"
            },
            "input_nodes": [
                "buffer_1_29774_29775"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29774_29775",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_120 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_120"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30957
        },
        "buffer_0_29779_29780": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29779_29780 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29779_29780": "Data"
            },
            "input_nodes": [
                "buffer_1_29779_29780"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29779_29780",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_125 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_125"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31060
        },
        "buffer_0_29780_29000": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29780_29000 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29780_29000": "Data"
            },
            "input_nodes": [
                "buffer_1_29780_29000"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29780_29000",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_958 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_958"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31065
        },
        "buffer_0_29784_29785": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_129 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_129": "Data"
            },
            "input_nodes": [
                "_fused_op_129"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29784_29785",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_130 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_130"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31083
        },
        "buffer_0_29786_29787": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29786_29787 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29786_29787": "Data"
            },
            "input_nodes": [
                "buffer_1_29786_29787"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29786_29787",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_132 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_132"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31086
        },
        "buffer_0_29788_29789": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29788_29789 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29788_29789": "Data"
            },
            "input_nodes": [
                "buffer_1_29788_29789"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29788_29789",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_134 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_134"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31093
        },
        "buffer_0_29793_29794": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29793_29794 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29793_29794": "Data"
            },
            "input_nodes": [
                "buffer_1_29793_29794"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29793_29794",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_139 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_139"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31196
        },
        "buffer_0_29794_29208": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29794_29208 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29794_29208": "Data"
            },
            "input_nodes": [
                "buffer_1_29794_29208"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29794_29208",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_1064 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_1064"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31201
        },
        "buffer_0_29798_29799": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_143 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_143": "Data"
            },
            "input_nodes": [
                "_fused_op_143"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29798_29799",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_144 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_144"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31219
        },
        "buffer_0_29800_29801": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29800_29801 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29800_29801": "Data"
            },
            "input_nodes": [
                "buffer_1_29800_29801"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29800_29801",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_146 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_146"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31222
        },
        "buffer_0_29802_29803": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29802_29803 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29802_29803": "Data"
            },
            "input_nodes": [
                "buffer_1_29802_29803"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29802_29803",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_148 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_148"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31229
        },
        "buffer_0_29807_29808": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29807_29808 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29807_29808": "Data"
            },
            "input_nodes": [
                "buffer_1_29807_29808"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29807_29808",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_153 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_153"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31332
        },
        "buffer_0_29808_29416": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29808_29416 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29808_29416": "Data"
            },
            "input_nodes": [
                "buffer_1_29808_29416"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29808_29416",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_1170 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_1170"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31337
        },
        "buffer_0_29812_29813": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_157 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_157": "Data"
            },
            "input_nodes": [
                "_fused_op_157"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29812_29813",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_158 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_158"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31355
        },
        "buffer_0_29814_29815": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29814_29815 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29814_29815": "Data"
            },
            "input_nodes": [
                "buffer_1_29814_29815"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29814_29815",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_160 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_160"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31358
        },
        "buffer_0_29816_29817": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29816_29817 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29816_29817": "Data"
            },
            "input_nodes": [
                "buffer_1_29816_29817"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29816_29817",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_162 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_162"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31365
        },
        "buffer_0_29821_29822": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29821_29822 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29821_29822": "Data"
            },
            "input_nodes": [
                "buffer_1_29821_29822"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29821_29822",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_167 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_167"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31451
        },
        "buffer_0_29822_29624": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29822_29624 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29822_29624": "Data"
            },
            "input_nodes": [
                "buffer_1_29822_29624"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29822_29624",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_1276 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_1276"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31456
        },
        "buffer_0_29823_29824": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_1_29823_29824 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29823_29824": "Data"
            },
            "input_nodes": [
                "buffer_1_29823_29824"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29823_29824",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_169 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_169"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31468
        },
        "buffer_1_27200_29660": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_43 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_43": "Data"
            },
            "input_nodes": [
                "add_43"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_27200_29660",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_27200_29660 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_27200_29660"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 29861
        },
        "buffer_1_27232_29662": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_57 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_57": "Data"
            },
            "input_nodes": [
                "add_57"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_27232_29662",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_27232_29662 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_27232_29662"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 29868
        },
        "buffer_1_27304_29667": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_2_27304_29667 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_27304_29667": "Data"
            },
            "input_nodes": [
                "buffer_2_27304_29667"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_27304_29667",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_27304_29667 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_27304_29667"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 29969
        },
        "buffer_1_27336_29669": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_2_27336_29669 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_27336_29669": "Data"
            },
            "input_nodes": [
                "buffer_2_27336_29669"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_27336_29669",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_27336_29669 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_27336_29669"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 29986
        },
        "buffer_1_27408_29674": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_149 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_149": "Data"
            },
            "input_nodes": [
                "add_149"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_27408_29674",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_27408_29674 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_27408_29674"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 29997
        },
        "buffer_1_27440_29676": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_163 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_163": "Data"
            },
            "input_nodes": [
                "add_163"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_27440_29676",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_27440_29676 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_27440_29676"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30004
        },
        "buffer_1_27512_29681": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_2_27512_29681 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_27512_29681": "Data"
            },
            "input_nodes": [
                "buffer_2_27512_29681"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_27512_29681",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_27512_29681 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_27512_29681"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30105
        },
        "buffer_1_27544_29683": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_2_27544_29683 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_27544_29683": "Data"
            },
            "input_nodes": [
                "buffer_2_27544_29683"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_27544_29683",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_27544_29683 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_27544_29683"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30122
        },
        "buffer_1_27616_29688": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_255 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_255": "Data"
            },
            "input_nodes": [
                "add_255"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_27616_29688",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_27616_29688 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_27616_29688"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30133
        },
        "buffer_1_27648_29690": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_269 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_269": "Data"
            },
            "input_nodes": [
                "add_269"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_27648_29690",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_27648_29690 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_27648_29690"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30140
        },
        "buffer_1_27720_29695": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_2_27720_29695 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_27720_29695": "Data"
            },
            "input_nodes": [
                "buffer_2_27720_29695"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_27720_29695",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_27720_29695 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_27720_29695"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30241
        },
        "buffer_1_27752_29697": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_2_27752_29697 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_27752_29697": "Data"
            },
            "input_nodes": [
                "buffer_2_27752_29697"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_27752_29697",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_27752_29697 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_27752_29697"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30258
        },
        "buffer_1_27824_29702": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_361 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_361": "Data"
            },
            "input_nodes": [
                "add_361"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_27824_29702",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_27824_29702 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_27824_29702"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30269
        },
        "buffer_1_27856_29704": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_375 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_375": "Data"
            },
            "input_nodes": [
                "add_375"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_27856_29704",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_27856_29704 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_27856_29704"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30276
        },
        "buffer_1_27928_29709": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_2_27928_29709 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_27928_29709": "Data"
            },
            "input_nodes": [
                "buffer_2_27928_29709"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_27928_29709",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_27928_29709 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_27928_29709"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30377
        },
        "buffer_1_27960_29711": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_2_27960_29711 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_27960_29711": "Data"
            },
            "input_nodes": [
                "buffer_2_27960_29711"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_27960_29711",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_27960_29711 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_27960_29711"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30394
        },
        "buffer_1_28032_29716": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_467 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_467": "Data"
            },
            "input_nodes": [
                "add_467"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_28032_29716",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_28032_29716 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_28032_29716"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30405
        },
        "buffer_1_28064_29718": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_481 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_481": "Data"
            },
            "input_nodes": [
                "add_481"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_28064_29718",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_28064_29718 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_28064_29718"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30412
        },
        "buffer_1_28136_29723": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_2_28136_29723 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_28136_29723": "Data"
            },
            "input_nodes": [
                "buffer_2_28136_29723"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_28136_29723",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_28136_29723 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_28136_29723"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30513
        },
        "buffer_1_28168_29725": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_2_28168_29725 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_28168_29725": "Data"
            },
            "input_nodes": [
                "buffer_2_28168_29725"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_28168_29725",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_28168_29725 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_28168_29725"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30530
        },
        "buffer_1_28240_29730": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_573 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_573": "Data"
            },
            "input_nodes": [
                "add_573"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_28240_29730",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_28240_29730 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_28240_29730"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30541
        },
        "buffer_1_28272_29732": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_587 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_587": "Data"
            },
            "input_nodes": [
                "add_587"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_28272_29732",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_28272_29732 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_28272_29732"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30548
        },
        "buffer_1_28344_29737": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_2_28344_29737 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_28344_29737": "Data"
            },
            "input_nodes": [
                "buffer_2_28344_29737"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_28344_29737",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_28344_29737 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_28344_29737"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30649
        },
        "buffer_1_28376_29739": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_2_28376_29739 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_28376_29739": "Data"
            },
            "input_nodes": [
                "buffer_2_28376_29739"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_28376_29739",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_28376_29739 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_28376_29739"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30666
        },
        "buffer_1_28448_29744": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_679 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_679": "Data"
            },
            "input_nodes": [
                "add_679"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_28448_29744",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_28448_29744 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_28448_29744"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30677
        },
        "buffer_1_28480_29746": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_693 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_693": "Data"
            },
            "input_nodes": [
                "add_693"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_28480_29746",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_28480_29746 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_28480_29746"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30684
        },
        "buffer_1_28552_29751": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_2_28552_29751 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_28552_29751": "Data"
            },
            "input_nodes": [
                "buffer_2_28552_29751"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_28552_29751",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_28552_29751 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_28552_29751"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30785
        },
        "buffer_1_28584_29753": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_2_28584_29753 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_28584_29753": "Data"
            },
            "input_nodes": [
                "buffer_2_28584_29753"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_28584_29753",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_28584_29753 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_28584_29753"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30802
        },
        "buffer_1_28656_29758": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_785 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_785": "Data"
            },
            "input_nodes": [
                "add_785"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_28656_29758",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_28656_29758 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_28656_29758"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30813
        },
        "buffer_1_28688_29760": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_799 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_799": "Data"
            },
            "input_nodes": [
                "add_799"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_28688_29760",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_28688_29760 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_28688_29760"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30820
        },
        "buffer_1_28760_29765": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_2_28760_29765 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_28760_29765": "Data"
            },
            "input_nodes": [
                "buffer_2_28760_29765"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_28760_29765",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_28760_29765 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_28760_29765"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30921
        },
        "buffer_1_28792_29767": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_2_28792_29767 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_28792_29767": "Data"
            },
            "input_nodes": [
                "buffer_2_28792_29767"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_28792_29767",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_28792_29767 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_28792_29767"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30938
        },
        "buffer_1_28864_29772": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_891 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_891": "Data"
            },
            "input_nodes": [
                "add_891"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_28864_29772",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_28864_29772 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_28864_29772"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30949
        },
        "buffer_1_28896_29774": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_905 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_905": "Data"
            },
            "input_nodes": [
                "add_905"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_28896_29774",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_28896_29774 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_28896_29774"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30956
        },
        "buffer_1_28968_29779": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_2_28968_29779 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_28968_29779": "Data"
            },
            "input_nodes": [
                "buffer_2_28968_29779"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_28968_29779",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_28968_29779 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_28968_29779"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31057
        },
        "buffer_1_29000_29781": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_2_29000_29781 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_29000_29781": "Data"
            },
            "input_nodes": [
                "buffer_2_29000_29781"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29000_29781",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29000_29781 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29000_29781"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31074
        },
        "buffer_1_29072_29786": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_997 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_997": "Data"
            },
            "input_nodes": [
                "add_997"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29072_29786",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29072_29786 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29072_29786"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31085
        },
        "buffer_1_29104_29788": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_1011 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_1011": "Data"
            },
            "input_nodes": [
                "add_1011"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29104_29788",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29104_29788 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29104_29788"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31092
        },
        "buffer_1_29176_29793": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_2_29176_29793 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_29176_29793": "Data"
            },
            "input_nodes": [
                "buffer_2_29176_29793"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29176_29793",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29176_29793 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29176_29793"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31193
        },
        "buffer_1_29208_29795": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_2_29208_29795 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_29208_29795": "Data"
            },
            "input_nodes": [
                "buffer_2_29208_29795"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29208_29795",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29208_29795 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29208_29795"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31210
        },
        "buffer_1_29280_29800": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_1103 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_1103": "Data"
            },
            "input_nodes": [
                "add_1103"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29280_29800",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29280_29800 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29280_29800"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31221
        },
        "buffer_1_29312_29802": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_1117 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_1117": "Data"
            },
            "input_nodes": [
                "add_1117"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29312_29802",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29312_29802 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29312_29802"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31228
        },
        "buffer_1_29384_29807": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_2_29384_29807 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_29384_29807": "Data"
            },
            "input_nodes": [
                "buffer_2_29384_29807"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29384_29807",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29384_29807 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29384_29807"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31329
        },
        "buffer_1_29416_29809": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_2_29416_29809 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_29416_29809": "Data"
            },
            "input_nodes": [
                "buffer_2_29416_29809"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29416_29809",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29416_29809 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29416_29809"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31346
        },
        "buffer_1_29488_29814": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_1209 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_1209": "Data"
            },
            "input_nodes": [
                "add_1209"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29488_29814",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29488_29814 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29488_29814"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31357
        },
        "buffer_1_29520_29816": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_1223 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_1223": "Data"
            },
            "input_nodes": [
                "add_1223"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29520_29816",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29520_29816 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29520_29816"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31364
        },
        "buffer_1_29592_29821": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_2_29592_29821 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_29592_29821": "Data"
            },
            "input_nodes": [
                "buffer_2_29592_29821"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29592_29821",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29592_29821 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29592_29821"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31448
        },
        "buffer_1_29624_29823": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_2_29624_29823 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_29624_29823": "Data"
            },
            "input_nodes": [
                "buffer_2_29624_29823"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29624_29823",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29624_29823 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29624_29823"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31465
        },
        "buffer_1_29655_29656": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_0 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_0": "Data"
            },
            "input_nodes": [
                "_fused_op_0"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29655_29656",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29655_29656 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29655_29656"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 29831
        },
        "buffer_1_29660_29661": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_2_29660_29661 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_29660_29661": "Data"
            },
            "input_nodes": [
                "buffer_2_29660_29661"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29660_29661",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29660_29661 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29660_29661"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 29863
        },
        "buffer_1_29662_29663": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_7 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_7": "Data"
            },
            "input_nodes": [
                "_fused_op_7"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29662_29663",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29662_29663 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29662_29663"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 29870
        },
        "buffer_1_29667_29668": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_2_29667_29668 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_29667_29668": "Data"
            },
            "input_nodes": [
                "buffer_2_29667_29668"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29667_29668",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29667_29668 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29667_29668"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 29973
        },
        "buffer_1_29668_27336": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_2_29668_27336 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_29668_27336": "Data"
            },
            "input_nodes": [
                "buffer_2_29668_27336"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29668_27336",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29668_27336 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29668_27336"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 29978
        },
        "buffer_1_29674_29675": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_2_29674_29675 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_29674_29675": "Data"
            },
            "input_nodes": [
                "buffer_2_29674_29675"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29674_29675",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29674_29675 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29674_29675"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 29999
        },
        "buffer_1_29676_29677": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_21 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_21": "Data"
            },
            "input_nodes": [
                "_fused_op_21"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29676_29677",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29676_29677 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29676_29677"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30006
        },
        "buffer_1_29681_29682": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_2_29681_29682 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_29681_29682": "Data"
            },
            "input_nodes": [
                "buffer_2_29681_29682"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29681_29682",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29681_29682 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29681_29682"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30109
        },
        "buffer_1_29682_27544": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_2_29682_27544 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_29682_27544": "Data"
            },
            "input_nodes": [
                "buffer_2_29682_27544"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29682_27544",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29682_27544 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29682_27544"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30114
        },
        "buffer_1_29688_29689": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_2_29688_29689 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_29688_29689": "Data"
            },
            "input_nodes": [
                "buffer_2_29688_29689"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29688_29689",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29688_29689 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29688_29689"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30135
        },
        "buffer_1_29690_29691": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_35 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_35": "Data"
            },
            "input_nodes": [
                "_fused_op_35"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29690_29691",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29690_29691 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29690_29691"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30142
        },
        "buffer_1_29695_29696": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_2_29695_29696 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_29695_29696": "Data"
            },
            "input_nodes": [
                "buffer_2_29695_29696"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29695_29696",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29695_29696 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29695_29696"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30245
        },
        "buffer_1_29696_27752": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_2_29696_27752 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_29696_27752": "Data"
            },
            "input_nodes": [
                "buffer_2_29696_27752"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29696_27752",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29696_27752 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29696_27752"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30250
        },
        "buffer_1_29702_29703": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_2_29702_29703 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_29702_29703": "Data"
            },
            "input_nodes": [
                "buffer_2_29702_29703"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29702_29703",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29702_29703 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29702_29703"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30271
        },
        "buffer_1_29704_29705": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_49 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_49": "Data"
            },
            "input_nodes": [
                "_fused_op_49"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29704_29705",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29704_29705 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29704_29705"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30278
        },
        "buffer_1_29709_29710": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_2_29709_29710 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_29709_29710": "Data"
            },
            "input_nodes": [
                "buffer_2_29709_29710"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29709_29710",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29709_29710 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29709_29710"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30381
        },
        "buffer_1_29710_27960": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_2_29710_27960 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_29710_27960": "Data"
            },
            "input_nodes": [
                "buffer_2_29710_27960"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29710_27960",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29710_27960 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29710_27960"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30386
        },
        "buffer_1_29716_29717": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_2_29716_29717 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_29716_29717": "Data"
            },
            "input_nodes": [
                "buffer_2_29716_29717"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29716_29717",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29716_29717 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29716_29717"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30407
        },
        "buffer_1_29718_29719": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_63 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_63": "Data"
            },
            "input_nodes": [
                "_fused_op_63"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29718_29719",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29718_29719 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29718_29719"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30414
        },
        "buffer_1_29723_29724": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_2_29723_29724 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_29723_29724": "Data"
            },
            "input_nodes": [
                "buffer_2_29723_29724"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29723_29724",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29723_29724 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29723_29724"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30517
        },
        "buffer_1_29724_28168": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_2_29724_28168 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_29724_28168": "Data"
            },
            "input_nodes": [
                "buffer_2_29724_28168"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29724_28168",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29724_28168 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29724_28168"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30522
        },
        "buffer_1_29730_29731": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_2_29730_29731 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_29730_29731": "Data"
            },
            "input_nodes": [
                "buffer_2_29730_29731"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29730_29731",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29730_29731 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29730_29731"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30543
        },
        "buffer_1_29732_29733": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_77 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_77": "Data"
            },
            "input_nodes": [
                "_fused_op_77"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29732_29733",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29732_29733 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29732_29733"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30550
        },
        "buffer_1_29737_29738": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_2_29737_29738 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_29737_29738": "Data"
            },
            "input_nodes": [
                "buffer_2_29737_29738"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29737_29738",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29737_29738 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29737_29738"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30653
        },
        "buffer_1_29738_28376": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_2_29738_28376 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_29738_28376": "Data"
            },
            "input_nodes": [
                "buffer_2_29738_28376"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29738_28376",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29738_28376 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29738_28376"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30658
        },
        "buffer_1_29744_29745": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_2_29744_29745 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_29744_29745": "Data"
            },
            "input_nodes": [
                "buffer_2_29744_29745"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29744_29745",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29744_29745 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29744_29745"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30679
        },
        "buffer_1_29746_29747": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_91 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_91": "Data"
            },
            "input_nodes": [
                "_fused_op_91"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29746_29747",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29746_29747 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29746_29747"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30686
        },
        "buffer_1_29751_29752": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_2_29751_29752 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_29751_29752": "Data"
            },
            "input_nodes": [
                "buffer_2_29751_29752"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29751_29752",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29751_29752 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29751_29752"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30789
        },
        "buffer_1_29752_28584": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_2_29752_28584 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_29752_28584": "Data"
            },
            "input_nodes": [
                "buffer_2_29752_28584"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29752_28584",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29752_28584 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29752_28584"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30794
        },
        "buffer_1_29758_29759": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_2_29758_29759 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_29758_29759": "Data"
            },
            "input_nodes": [
                "buffer_2_29758_29759"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29758_29759",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29758_29759 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29758_29759"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30815
        },
        "buffer_1_29760_29761": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_105 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_105": "Data"
            },
            "input_nodes": [
                "_fused_op_105"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29760_29761",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29760_29761 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29760_29761"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30822
        },
        "buffer_1_29765_29766": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_2_29765_29766 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_29765_29766": "Data"
            },
            "input_nodes": [
                "buffer_2_29765_29766"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29765_29766",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29765_29766 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29765_29766"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30925
        },
        "buffer_1_29766_28792": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_2_29766_28792 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_29766_28792": "Data"
            },
            "input_nodes": [
                "buffer_2_29766_28792"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29766_28792",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29766_28792 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29766_28792"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30930
        },
        "buffer_1_29772_29773": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_2_29772_29773 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_29772_29773": "Data"
            },
            "input_nodes": [
                "buffer_2_29772_29773"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29772_29773",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29772_29773 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29772_29773"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30951
        },
        "buffer_1_29774_29775": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_119 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_119": "Data"
            },
            "input_nodes": [
                "_fused_op_119"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29774_29775",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29774_29775 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29774_29775"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30958
        },
        "buffer_1_29779_29780": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_2_29779_29780 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_29779_29780": "Data"
            },
            "input_nodes": [
                "buffer_2_29779_29780"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29779_29780",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29779_29780 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29779_29780"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31061
        },
        "buffer_1_29780_29000": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_2_29780_29000 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_29780_29000": "Data"
            },
            "input_nodes": [
                "buffer_2_29780_29000"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29780_29000",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29780_29000 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29780_29000"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31066
        },
        "buffer_1_29786_29787": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_2_29786_29787 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_29786_29787": "Data"
            },
            "input_nodes": [
                "buffer_2_29786_29787"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29786_29787",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29786_29787 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29786_29787"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31087
        },
        "buffer_1_29788_29789": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_133 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_133": "Data"
            },
            "input_nodes": [
                "_fused_op_133"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29788_29789",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29788_29789 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29788_29789"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31094
        },
        "buffer_1_29793_29794": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_2_29793_29794 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_29793_29794": "Data"
            },
            "input_nodes": [
                "buffer_2_29793_29794"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29793_29794",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29793_29794 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29793_29794"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31197
        },
        "buffer_1_29794_29208": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_2_29794_29208 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_29794_29208": "Data"
            },
            "input_nodes": [
                "buffer_2_29794_29208"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29794_29208",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29794_29208 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29794_29208"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31202
        },
        "buffer_1_29800_29801": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_2_29800_29801 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_29800_29801": "Data"
            },
            "input_nodes": [
                "buffer_2_29800_29801"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29800_29801",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29800_29801 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29800_29801"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31223
        },
        "buffer_1_29802_29803": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_147 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_147": "Data"
            },
            "input_nodes": [
                "_fused_op_147"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29802_29803",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29802_29803 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29802_29803"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31230
        },
        "buffer_1_29807_29808": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_2_29807_29808 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_29807_29808": "Data"
            },
            "input_nodes": [
                "buffer_2_29807_29808"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29807_29808",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29807_29808 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29807_29808"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31333
        },
        "buffer_1_29808_29416": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_2_29808_29416 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_29808_29416": "Data"
            },
            "input_nodes": [
                "buffer_2_29808_29416"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29808_29416",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29808_29416 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29808_29416"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31338
        },
        "buffer_1_29814_29815": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_2_29814_29815 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_29814_29815": "Data"
            },
            "input_nodes": [
                "buffer_2_29814_29815"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29814_29815",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29814_29815 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29814_29815"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31359
        },
        "buffer_1_29816_29817": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_161 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_161": "Data"
            },
            "input_nodes": [
                "_fused_op_161"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29816_29817",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29816_29817 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29816_29817"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31366
        },
        "buffer_1_29821_29822": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_2_29821_29822 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_29821_29822": "Data"
            },
            "input_nodes": [
                "buffer_2_29821_29822"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29821_29822",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29821_29822 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29821_29822"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31452
        },
        "buffer_1_29822_29624": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_2_29822_29624 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_29822_29624": "Data"
            },
            "input_nodes": [
                "buffer_2_29822_29624"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29822_29624",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29822_29624 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29822_29624"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31457
        },
        "buffer_1_29823_29824": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_2_29823_29824 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_29823_29824": "Data"
            },
            "input_nodes": [
                "buffer_2_29823_29824"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29823_29824",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29823_29824 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29823_29824"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31469
        },
        "buffer_2_27304_29667": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_3_27304_29667 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_3_27304_29667": "Data"
            },
            "input_nodes": [
                "buffer_3_27304_29667"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_27304_29667",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_27304_29667 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_27304_29667"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 29970
        },
        "buffer_2_27336_29669": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_3_27336_29669 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_3_27336_29669": "Data"
            },
            "input_nodes": [
                "buffer_3_27336_29669"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_27336_29669",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_27336_29669 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_27336_29669"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 29987
        },
        "buffer_2_27512_29681": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_3_27512_29681 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_3_27512_29681": "Data"
            },
            "input_nodes": [
                "buffer_3_27512_29681"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_27512_29681",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_27512_29681 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_27512_29681"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30106
        },
        "buffer_2_27544_29683": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_3_27544_29683 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_3_27544_29683": "Data"
            },
            "input_nodes": [
                "buffer_3_27544_29683"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_27544_29683",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_27544_29683 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_27544_29683"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30123
        },
        "buffer_2_27720_29695": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_3_27720_29695 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_3_27720_29695": "Data"
            },
            "input_nodes": [
                "buffer_3_27720_29695"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_27720_29695",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_27720_29695 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_27720_29695"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30242
        },
        "buffer_2_27752_29697": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_3_27752_29697 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_3_27752_29697": "Data"
            },
            "input_nodes": [
                "buffer_3_27752_29697"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_27752_29697",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_27752_29697 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_27752_29697"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30259
        },
        "buffer_2_27928_29709": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_3_27928_29709 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_3_27928_29709": "Data"
            },
            "input_nodes": [
                "buffer_3_27928_29709"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_27928_29709",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_27928_29709 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_27928_29709"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30378
        },
        "buffer_2_27960_29711": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_3_27960_29711 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_3_27960_29711": "Data"
            },
            "input_nodes": [
                "buffer_3_27960_29711"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_27960_29711",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_27960_29711 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_27960_29711"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30395
        },
        "buffer_2_28136_29723": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_3_28136_29723 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_3_28136_29723": "Data"
            },
            "input_nodes": [
                "buffer_3_28136_29723"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_28136_29723",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_28136_29723 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_28136_29723"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30514
        },
        "buffer_2_28168_29725": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_3_28168_29725 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_3_28168_29725": "Data"
            },
            "input_nodes": [
                "buffer_3_28168_29725"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_28168_29725",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_28168_29725 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_28168_29725"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30531
        },
        "buffer_2_28344_29737": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_3_28344_29737 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_3_28344_29737": "Data"
            },
            "input_nodes": [
                "buffer_3_28344_29737"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_28344_29737",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_28344_29737 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_28344_29737"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30650
        },
        "buffer_2_28376_29739": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_3_28376_29739 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_3_28376_29739": "Data"
            },
            "input_nodes": [
                "buffer_3_28376_29739"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_28376_29739",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_28376_29739 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_28376_29739"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30667
        },
        "buffer_2_28552_29751": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_3_28552_29751 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_3_28552_29751": "Data"
            },
            "input_nodes": [
                "buffer_3_28552_29751"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_28552_29751",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_28552_29751 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_28552_29751"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30786
        },
        "buffer_2_28584_29753": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_3_28584_29753 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_3_28584_29753": "Data"
            },
            "input_nodes": [
                "buffer_3_28584_29753"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_28584_29753",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_28584_29753 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_28584_29753"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30803
        },
        "buffer_2_28760_29765": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_3_28760_29765 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_3_28760_29765": "Data"
            },
            "input_nodes": [
                "buffer_3_28760_29765"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_28760_29765",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_28760_29765 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_28760_29765"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30922
        },
        "buffer_2_28792_29767": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_3_28792_29767 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_3_28792_29767": "Data"
            },
            "input_nodes": [
                "buffer_3_28792_29767"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_28792_29767",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_28792_29767 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_28792_29767"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30939
        },
        "buffer_2_28968_29779": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_3_28968_29779 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_3_28968_29779": "Data"
            },
            "input_nodes": [
                "buffer_3_28968_29779"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_28968_29779",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_28968_29779 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_28968_29779"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31058
        },
        "buffer_2_29000_29781": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_3_29000_29781 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_3_29000_29781": "Data"
            },
            "input_nodes": [
                "buffer_3_29000_29781"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_29000_29781",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_29000_29781 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_29000_29781"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31075
        },
        "buffer_2_29176_29793": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_3_29176_29793 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_3_29176_29793": "Data"
            },
            "input_nodes": [
                "buffer_3_29176_29793"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_29176_29793",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_29176_29793 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_29176_29793"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31194
        },
        "buffer_2_29208_29795": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_3_29208_29795 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_3_29208_29795": "Data"
            },
            "input_nodes": [
                "buffer_3_29208_29795"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_29208_29795",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_29208_29795 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_29208_29795"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31211
        },
        "buffer_2_29384_29807": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_3_29384_29807 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_3_29384_29807": "Data"
            },
            "input_nodes": [
                "buffer_3_29384_29807"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_29384_29807",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_29384_29807 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_29384_29807"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31330
        },
        "buffer_2_29416_29809": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_3_29416_29809 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_3_29416_29809": "Data"
            },
            "input_nodes": [
                "buffer_3_29416_29809"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_29416_29809",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_29416_29809 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_29416_29809"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31347
        },
        "buffer_2_29592_29821": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_3_29592_29821 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_3_29592_29821": "Data"
            },
            "input_nodes": [
                "buffer_3_29592_29821"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_29592_29821",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_29592_29821 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_29592_29821"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31449
        },
        "buffer_2_29624_29823": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_3_29624_29823 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_3_29624_29823": "Data"
            },
            "input_nodes": [
                "buffer_3_29624_29823"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_29624_29823",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_29624_29823 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_29624_29823"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31466
        },
        "buffer_2_29660_29661": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_5 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_5": "Data"
            },
            "input_nodes": [
                "_fused_op_5"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_29660_29661",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_29660_29661 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_29660_29661"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 29864
        },
        "buffer_2_29667_29668": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_3_29667_29668 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_3_29667_29668": "Data"
            },
            "input_nodes": [
                "buffer_3_29667_29668"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_29667_29668",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_29667_29668 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_29667_29668"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 29974
        },
        "buffer_2_29668_27336": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_3_29668_27336 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_3_29668_27336": "Data"
            },
            "input_nodes": [
                "buffer_3_29668_27336"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_29668_27336",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_29668_27336 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_29668_27336"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 29979
        },
        "buffer_2_29674_29675": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_19 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_19": "Data"
            },
            "input_nodes": [
                "_fused_op_19"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_29674_29675",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_29674_29675 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_29674_29675"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30000
        },
        "buffer_2_29681_29682": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_3_29681_29682 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_3_29681_29682": "Data"
            },
            "input_nodes": [
                "buffer_3_29681_29682"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_29681_29682",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_29681_29682 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_29681_29682"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30110
        },
        "buffer_2_29682_27544": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_3_29682_27544 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_3_29682_27544": "Data"
            },
            "input_nodes": [
                "buffer_3_29682_27544"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_29682_27544",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_29682_27544 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_29682_27544"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30115
        },
        "buffer_2_29688_29689": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_33 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_33": "Data"
            },
            "input_nodes": [
                "_fused_op_33"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_29688_29689",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_29688_29689 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_29688_29689"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30136
        },
        "buffer_2_29695_29696": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_3_29695_29696 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_3_29695_29696": "Data"
            },
            "input_nodes": [
                "buffer_3_29695_29696"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_29695_29696",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_29695_29696 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_29695_29696"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30246
        },
        "buffer_2_29696_27752": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_3_29696_27752 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_3_29696_27752": "Data"
            },
            "input_nodes": [
                "buffer_3_29696_27752"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_29696_27752",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_29696_27752 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_29696_27752"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30251
        },
        "buffer_2_29702_29703": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_47 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_47": "Data"
            },
            "input_nodes": [
                "_fused_op_47"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_29702_29703",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_29702_29703 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_29702_29703"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30272
        },
        "buffer_2_29709_29710": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_3_29709_29710 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_3_29709_29710": "Data"
            },
            "input_nodes": [
                "buffer_3_29709_29710"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_29709_29710",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_29709_29710 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_29709_29710"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30382
        },
        "buffer_2_29710_27960": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_3_29710_27960 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_3_29710_27960": "Data"
            },
            "input_nodes": [
                "buffer_3_29710_27960"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_29710_27960",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_29710_27960 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_29710_27960"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30387
        },
        "buffer_2_29716_29717": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_61 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_61": "Data"
            },
            "input_nodes": [
                "_fused_op_61"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_29716_29717",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_29716_29717 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_29716_29717"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30408
        },
        "buffer_2_29723_29724": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_3_29723_29724 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_3_29723_29724": "Data"
            },
            "input_nodes": [
                "buffer_3_29723_29724"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_29723_29724",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_29723_29724 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_29723_29724"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30518
        },
        "buffer_2_29724_28168": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_3_29724_28168 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_3_29724_28168": "Data"
            },
            "input_nodes": [
                "buffer_3_29724_28168"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_29724_28168",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_29724_28168 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_29724_28168"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30523
        },
        "buffer_2_29730_29731": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_75 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_75": "Data"
            },
            "input_nodes": [
                "_fused_op_75"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_29730_29731",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_29730_29731 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_29730_29731"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30544
        },
        "buffer_2_29737_29738": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_3_29737_29738 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_3_29737_29738": "Data"
            },
            "input_nodes": [
                "buffer_3_29737_29738"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_29737_29738",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_29737_29738 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_29737_29738"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30654
        },
        "buffer_2_29738_28376": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_3_29738_28376 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_3_29738_28376": "Data"
            },
            "input_nodes": [
                "buffer_3_29738_28376"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_29738_28376",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_29738_28376 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_29738_28376"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30659
        },
        "buffer_2_29744_29745": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_89 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_89": "Data"
            },
            "input_nodes": [
                "_fused_op_89"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_29744_29745",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_29744_29745 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_29744_29745"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30680
        },
        "buffer_2_29751_29752": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_3_29751_29752 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_3_29751_29752": "Data"
            },
            "input_nodes": [
                "buffer_3_29751_29752"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_29751_29752",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_29751_29752 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_29751_29752"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30790
        },
        "buffer_2_29752_28584": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_3_29752_28584 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_3_29752_28584": "Data"
            },
            "input_nodes": [
                "buffer_3_29752_28584"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_29752_28584",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_29752_28584 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_29752_28584"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30795
        },
        "buffer_2_29758_29759": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_103 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_103": "Data"
            },
            "input_nodes": [
                "_fused_op_103"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_29758_29759",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_29758_29759 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_29758_29759"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30816
        },
        "buffer_2_29765_29766": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_3_29765_29766 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_3_29765_29766": "Data"
            },
            "input_nodes": [
                "buffer_3_29765_29766"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_29765_29766",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_29765_29766 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_29765_29766"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30926
        },
        "buffer_2_29766_28792": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_3_29766_28792 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_3_29766_28792": "Data"
            },
            "input_nodes": [
                "buffer_3_29766_28792"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_29766_28792",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_29766_28792 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_29766_28792"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30931
        },
        "buffer_2_29772_29773": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_117 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_117": "Data"
            },
            "input_nodes": [
                "_fused_op_117"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_29772_29773",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_29772_29773 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_29772_29773"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30952
        },
        "buffer_2_29779_29780": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_3_29779_29780 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_3_29779_29780": "Data"
            },
            "input_nodes": [
                "buffer_3_29779_29780"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_29779_29780",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_29779_29780 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_29779_29780"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31062
        },
        "buffer_2_29780_29000": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_3_29780_29000 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_3_29780_29000": "Data"
            },
            "input_nodes": [
                "buffer_3_29780_29000"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_29780_29000",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_29780_29000 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_29780_29000"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31067
        },
        "buffer_2_29786_29787": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_131 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_131": "Data"
            },
            "input_nodes": [
                "_fused_op_131"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_29786_29787",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_29786_29787 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_29786_29787"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31088
        },
        "buffer_2_29793_29794": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_3_29793_29794 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_3_29793_29794": "Data"
            },
            "input_nodes": [
                "buffer_3_29793_29794"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_29793_29794",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_29793_29794 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_29793_29794"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31198
        },
        "buffer_2_29794_29208": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_3_29794_29208 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_3_29794_29208": "Data"
            },
            "input_nodes": [
                "buffer_3_29794_29208"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_29794_29208",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_29794_29208 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_29794_29208"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31203
        },
        "buffer_2_29800_29801": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_145 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_145": "Data"
            },
            "input_nodes": [
                "_fused_op_145"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_29800_29801",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_29800_29801 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_29800_29801"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31224
        },
        "buffer_2_29807_29808": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_3_29807_29808 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_3_29807_29808": "Data"
            },
            "input_nodes": [
                "buffer_3_29807_29808"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_29807_29808",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_29807_29808 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_29807_29808"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31334
        },
        "buffer_2_29808_29416": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_3_29808_29416 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_3_29808_29416": "Data"
            },
            "input_nodes": [
                "buffer_3_29808_29416"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_29808_29416",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_29808_29416 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_29808_29416"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31339
        },
        "buffer_2_29814_29815": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_159 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_159": "Data"
            },
            "input_nodes": [
                "_fused_op_159"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_29814_29815",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_29814_29815 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_29814_29815"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31360
        },
        "buffer_2_29821_29822": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_3_29821_29822 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_3_29821_29822": "Data"
            },
            "input_nodes": [
                "buffer_3_29821_29822"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_29821_29822",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_29821_29822 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_29821_29822"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31453
        },
        "buffer_2_29822_29624": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_3_29822_29624 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_3_29822_29624": "Data"
            },
            "input_nodes": [
                "buffer_3_29822_29624"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_29822_29624",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_29822_29624 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_29822_29624"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31458
        },
        "buffer_2_29823_29824": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_168 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_168": "Data"
            },
            "input_nodes": [
                "_fused_op_168"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_29823_29824",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_29823_29824 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_29823_29824"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31470
        },
        "buffer_3_27304_29667": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_96 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_96": "Data"
            },
            "input_nodes": [
                "add_96"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_3_27304_29667",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_2_27304_29667 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_2_27304_29667"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 29971
        },
        "buffer_3_27336_29669": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_110 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_110": "Data"
            },
            "input_nodes": [
                "add_110"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_3_27336_29669",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_2_27336_29669 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_2_27336_29669"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 29988
        },
        "buffer_3_27512_29681": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_202 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_202": "Data"
            },
            "input_nodes": [
                "add_202"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_3_27512_29681",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_2_27512_29681 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_2_27512_29681"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30107
        },
        "buffer_3_27544_29683": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_216 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_216": "Data"
            },
            "input_nodes": [
                "add_216"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_3_27544_29683",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_2_27544_29683 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_2_27544_29683"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30124
        },
        "buffer_3_27720_29695": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_308 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_308": "Data"
            },
            "input_nodes": [
                "add_308"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_3_27720_29695",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_2_27720_29695 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_2_27720_29695"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30243
        },
        "buffer_3_27752_29697": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_322 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_322": "Data"
            },
            "input_nodes": [
                "add_322"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_3_27752_29697",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_2_27752_29697 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_2_27752_29697"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30260
        },
        "buffer_3_27928_29709": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_414 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_414": "Data"
            },
            "input_nodes": [
                "add_414"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_3_27928_29709",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_2_27928_29709 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_2_27928_29709"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30379
        },
        "buffer_3_27960_29711": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_428 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_428": "Data"
            },
            "input_nodes": [
                "add_428"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_3_27960_29711",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_2_27960_29711 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_2_27960_29711"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30396
        },
        "buffer_3_28136_29723": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_520 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_520": "Data"
            },
            "input_nodes": [
                "add_520"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_3_28136_29723",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_2_28136_29723 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_2_28136_29723"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30515
        },
        "buffer_3_28168_29725": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_534 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_534": "Data"
            },
            "input_nodes": [
                "add_534"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_3_28168_29725",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_2_28168_29725 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_2_28168_29725"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30532
        },
        "buffer_3_28344_29737": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_626 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_626": "Data"
            },
            "input_nodes": [
                "add_626"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_3_28344_29737",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_2_28344_29737 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_2_28344_29737"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30651
        },
        "buffer_3_28376_29739": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_640 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_640": "Data"
            },
            "input_nodes": [
                "add_640"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_3_28376_29739",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_2_28376_29739 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_2_28376_29739"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30668
        },
        "buffer_3_28552_29751": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_732 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_732": "Data"
            },
            "input_nodes": [
                "add_732"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_3_28552_29751",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_2_28552_29751 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_2_28552_29751"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30787
        },
        "buffer_3_28584_29753": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_746 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_746": "Data"
            },
            "input_nodes": [
                "add_746"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_3_28584_29753",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_2_28584_29753 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_2_28584_29753"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30804
        },
        "buffer_3_28760_29765": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_838 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_838": "Data"
            },
            "input_nodes": [
                "add_838"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_3_28760_29765",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_2_28760_29765 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_2_28760_29765"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30923
        },
        "buffer_3_28792_29767": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_852 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_852": "Data"
            },
            "input_nodes": [
                "add_852"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_3_28792_29767",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_2_28792_29767 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_2_28792_29767"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30940
        },
        "buffer_3_28968_29779": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_944 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_944": "Data"
            },
            "input_nodes": [
                "add_944"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_3_28968_29779",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_2_28968_29779 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_2_28968_29779"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31059
        },
        "buffer_3_29000_29781": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_958 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_958": "Data"
            },
            "input_nodes": [
                "add_958"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_3_29000_29781",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_2_29000_29781 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_2_29000_29781"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31076
        },
        "buffer_3_29176_29793": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_1050 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_1050": "Data"
            },
            "input_nodes": [
                "add_1050"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_3_29176_29793",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_2_29176_29793 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_2_29176_29793"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31195
        },
        "buffer_3_29208_29795": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_1064 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_1064": "Data"
            },
            "input_nodes": [
                "add_1064"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_3_29208_29795",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_2_29208_29795 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_2_29208_29795"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31212
        },
        "buffer_3_29384_29807": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_1156 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_1156": "Data"
            },
            "input_nodes": [
                "add_1156"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_3_29384_29807",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_2_29384_29807 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_2_29384_29807"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31331
        },
        "buffer_3_29416_29809": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_1170 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_1170": "Data"
            },
            "input_nodes": [
                "add_1170"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_3_29416_29809",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_2_29416_29809 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_2_29416_29809"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31348
        },
        "buffer_3_29592_29821": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_1262 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_1262": "Data"
            },
            "input_nodes": [
                "add_1262"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_3_29592_29821",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_2_29592_29821 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_2_29592_29821"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31450
        },
        "buffer_3_29624_29823": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_1276 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_1276": "Data"
            },
            "input_nodes": [
                "add_1276"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_3_29624_29823",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_2_29624_29823 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_2_29624_29823"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31467
        },
        "buffer_3_29667_29668": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_4_29667_29668 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_4_29667_29668": "Data"
            },
            "input_nodes": [
                "buffer_4_29667_29668"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_3_29667_29668",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_2_29667_29668 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_2_29667_29668"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 29975
        },
        "buffer_3_29668_27336": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_4_29668_27336 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_4_29668_27336": "Data"
            },
            "input_nodes": [
                "buffer_4_29668_27336"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_3_29668_27336",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_2_29668_27336 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_2_29668_27336"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 29980
        },
        "buffer_3_29681_29682": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_4_29681_29682 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_4_29681_29682": "Data"
            },
            "input_nodes": [
                "buffer_4_29681_29682"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_3_29681_29682",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_2_29681_29682 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_2_29681_29682"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30111
        },
        "buffer_3_29682_27544": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_4_29682_27544 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_4_29682_27544": "Data"
            },
            "input_nodes": [
                "buffer_4_29682_27544"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_3_29682_27544",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_2_29682_27544 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_2_29682_27544"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30116
        },
        "buffer_3_29695_29696": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_4_29695_29696 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_4_29695_29696": "Data"
            },
            "input_nodes": [
                "buffer_4_29695_29696"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_3_29695_29696",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_2_29695_29696 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_2_29695_29696"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30247
        },
        "buffer_3_29696_27752": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_4_29696_27752 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_4_29696_27752": "Data"
            },
            "input_nodes": [
                "buffer_4_29696_27752"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_3_29696_27752",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_2_29696_27752 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_2_29696_27752"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30252
        },
        "buffer_3_29709_29710": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_4_29709_29710 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_4_29709_29710": "Data"
            },
            "input_nodes": [
                "buffer_4_29709_29710"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_3_29709_29710",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_2_29709_29710 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_2_29709_29710"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30383
        },
        "buffer_3_29710_27960": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_4_29710_27960 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_4_29710_27960": "Data"
            },
            "input_nodes": [
                "buffer_4_29710_27960"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_3_29710_27960",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_2_29710_27960 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_2_29710_27960"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30388
        },
        "buffer_3_29723_29724": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_4_29723_29724 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_4_29723_29724": "Data"
            },
            "input_nodes": [
                "buffer_4_29723_29724"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_3_29723_29724",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_2_29723_29724 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_2_29723_29724"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30519
        },
        "buffer_3_29724_28168": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_4_29724_28168 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_4_29724_28168": "Data"
            },
            "input_nodes": [
                "buffer_4_29724_28168"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_3_29724_28168",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_2_29724_28168 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_2_29724_28168"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30524
        },
        "buffer_3_29737_29738": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_4_29737_29738 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_4_29737_29738": "Data"
            },
            "input_nodes": [
                "buffer_4_29737_29738"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_3_29737_29738",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_2_29737_29738 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_2_29737_29738"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30655
        },
        "buffer_3_29738_28376": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_4_29738_28376 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_4_29738_28376": "Data"
            },
            "input_nodes": [
                "buffer_4_29738_28376"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_3_29738_28376",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_2_29738_28376 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_2_29738_28376"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30660
        },
        "buffer_3_29751_29752": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_4_29751_29752 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_4_29751_29752": "Data"
            },
            "input_nodes": [
                "buffer_4_29751_29752"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_3_29751_29752",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_2_29751_29752 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_2_29751_29752"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30791
        },
        "buffer_3_29752_28584": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_4_29752_28584 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_4_29752_28584": "Data"
            },
            "input_nodes": [
                "buffer_4_29752_28584"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_3_29752_28584",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_2_29752_28584 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_2_29752_28584"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30796
        },
        "buffer_3_29765_29766": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_4_29765_29766 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_4_29765_29766": "Data"
            },
            "input_nodes": [
                "buffer_4_29765_29766"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_3_29765_29766",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_2_29765_29766 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_2_29765_29766"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30927
        },
        "buffer_3_29766_28792": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_4_29766_28792 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_4_29766_28792": "Data"
            },
            "input_nodes": [
                "buffer_4_29766_28792"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_3_29766_28792",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_2_29766_28792 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_2_29766_28792"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30932
        },
        "buffer_3_29779_29780": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_4_29779_29780 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_4_29779_29780": "Data"
            },
            "input_nodes": [
                "buffer_4_29779_29780"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_3_29779_29780",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_2_29779_29780 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_2_29779_29780"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31063
        },
        "buffer_3_29780_29000": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_4_29780_29000 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_4_29780_29000": "Data"
            },
            "input_nodes": [
                "buffer_4_29780_29000"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_3_29780_29000",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_2_29780_29000 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_2_29780_29000"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31068
        },
        "buffer_3_29793_29794": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_4_29793_29794 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_4_29793_29794": "Data"
            },
            "input_nodes": [
                "buffer_4_29793_29794"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_3_29793_29794",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_2_29793_29794 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_2_29793_29794"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31199
        },
        "buffer_3_29794_29208": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_4_29794_29208 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_4_29794_29208": "Data"
            },
            "input_nodes": [
                "buffer_4_29794_29208"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_3_29794_29208",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_2_29794_29208 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_2_29794_29208"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31204
        },
        "buffer_3_29807_29808": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_4_29807_29808 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_4_29807_29808": "Data"
            },
            "input_nodes": [
                "buffer_4_29807_29808"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_3_29807_29808",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_2_29807_29808 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_2_29807_29808"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31335
        },
        "buffer_3_29808_29416": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_4_29808_29416 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_4_29808_29416": "Data"
            },
            "input_nodes": [
                "buffer_4_29808_29416"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_3_29808_29416",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_2_29808_29416 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_2_29808_29416"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31340
        },
        "buffer_3_29821_29822": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_4_29821_29822 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_4_29821_29822": "Data"
            },
            "input_nodes": [
                "buffer_4_29821_29822"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_3_29821_29822",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_2_29821_29822 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_2_29821_29822"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31454
        },
        "buffer_3_29822_29624": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_4_29822_29624 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_4_29822_29624": "Data"
            },
            "input_nodes": [
                "buffer_4_29822_29624"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_3_29822_29624",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_2_29822_29624 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_2_29822_29624"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31459
        },
        "buffer_4_29667_29668": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_12 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_12": "Data"
            },
            "input_nodes": [
                "_fused_op_12"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_4_29667_29668",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_3_29667_29668 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_3_29667_29668"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 29976
        },
        "buffer_4_29668_27336": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_5_29668_27336 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_5_29668_27336": "Data"
            },
            "input_nodes": [
                "buffer_5_29668_27336"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_4_29668_27336",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_3_29668_27336 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_3_29668_27336"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 29981
        },
        "buffer_4_29681_29682": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_26 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_26": "Data"
            },
            "input_nodes": [
                "_fused_op_26"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_4_29681_29682",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_3_29681_29682 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_3_29681_29682"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30112
        },
        "buffer_4_29682_27544": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_5_29682_27544 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_5_29682_27544": "Data"
            },
            "input_nodes": [
                "buffer_5_29682_27544"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_4_29682_27544",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_3_29682_27544 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_3_29682_27544"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30117
        },
        "buffer_4_29695_29696": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_40 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_40": "Data"
            },
            "input_nodes": [
                "_fused_op_40"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_4_29695_29696",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_3_29695_29696 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_3_29695_29696"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30248
        },
        "buffer_4_29696_27752": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_5_29696_27752 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_5_29696_27752": "Data"
            },
            "input_nodes": [
                "buffer_5_29696_27752"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_4_29696_27752",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_3_29696_27752 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_3_29696_27752"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30253
        },
        "buffer_4_29709_29710": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_54 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_54": "Data"
            },
            "input_nodes": [
                "_fused_op_54"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_4_29709_29710",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_3_29709_29710 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_3_29709_29710"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30384
        },
        "buffer_4_29710_27960": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_5_29710_27960 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_5_29710_27960": "Data"
            },
            "input_nodes": [
                "buffer_5_29710_27960"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_4_29710_27960",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_3_29710_27960 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_3_29710_27960"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30389
        },
        "buffer_4_29723_29724": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_68 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_68": "Data"
            },
            "input_nodes": [
                "_fused_op_68"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_4_29723_29724",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_3_29723_29724 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_3_29723_29724"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30520
        },
        "buffer_4_29724_28168": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_5_29724_28168 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_5_29724_28168": "Data"
            },
            "input_nodes": [
                "buffer_5_29724_28168"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_4_29724_28168",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_3_29724_28168 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_3_29724_28168"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30525
        },
        "buffer_4_29737_29738": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_82 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_82": "Data"
            },
            "input_nodes": [
                "_fused_op_82"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_4_29737_29738",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_3_29737_29738 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_3_29737_29738"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30656
        },
        "buffer_4_29738_28376": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_5_29738_28376 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_5_29738_28376": "Data"
            },
            "input_nodes": [
                "buffer_5_29738_28376"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_4_29738_28376",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_3_29738_28376 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_3_29738_28376"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30661
        },
        "buffer_4_29751_29752": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_96 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_96": "Data"
            },
            "input_nodes": [
                "_fused_op_96"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_4_29751_29752",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_3_29751_29752 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_3_29751_29752"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30792
        },
        "buffer_4_29752_28584": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_5_29752_28584 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_5_29752_28584": "Data"
            },
            "input_nodes": [
                "buffer_5_29752_28584"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_4_29752_28584",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_3_29752_28584 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_3_29752_28584"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30797
        },
        "buffer_4_29765_29766": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_110 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_110": "Data"
            },
            "input_nodes": [
                "_fused_op_110"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_4_29765_29766",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_3_29765_29766 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_3_29765_29766"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30928
        },
        "buffer_4_29766_28792": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_5_29766_28792 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_5_29766_28792": "Data"
            },
            "input_nodes": [
                "buffer_5_29766_28792"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_4_29766_28792",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_3_29766_28792 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_3_29766_28792"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30933
        },
        "buffer_4_29779_29780": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_124 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_124": "Data"
            },
            "input_nodes": [
                "_fused_op_124"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_4_29779_29780",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_3_29779_29780 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_3_29779_29780"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31064
        },
        "buffer_4_29780_29000": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_5_29780_29000 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_5_29780_29000": "Data"
            },
            "input_nodes": [
                "buffer_5_29780_29000"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_4_29780_29000",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_3_29780_29000 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_3_29780_29000"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31069
        },
        "buffer_4_29793_29794": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_138 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_138": "Data"
            },
            "input_nodes": [
                "_fused_op_138"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_4_29793_29794",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_3_29793_29794 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_3_29793_29794"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31200
        },
        "buffer_4_29794_29208": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_5_29794_29208 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_5_29794_29208": "Data"
            },
            "input_nodes": [
                "buffer_5_29794_29208"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_4_29794_29208",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_3_29794_29208 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_3_29794_29208"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31205
        },
        "buffer_4_29807_29808": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_152 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_152": "Data"
            },
            "input_nodes": [
                "_fused_op_152"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_4_29807_29808",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_3_29807_29808 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_3_29807_29808"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31336
        },
        "buffer_4_29808_29416": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_5_29808_29416 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_5_29808_29416": "Data"
            },
            "input_nodes": [
                "buffer_5_29808_29416"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_4_29808_29416",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_3_29808_29416 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_3_29808_29416"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31341
        },
        "buffer_4_29821_29822": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_166 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_166": "Data"
            },
            "input_nodes": [
                "_fused_op_166"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_4_29821_29822",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_3_29821_29822 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_3_29821_29822"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31455
        },
        "buffer_4_29822_29624": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_5_29822_29624 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_5_29822_29624": "Data"
            },
            "input_nodes": [
                "buffer_5_29822_29624"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_4_29822_29624",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_3_29822_29624 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_3_29822_29624"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31460
        },
        "buffer_5_29668_27336": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_6_29668_27336 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_6_29668_27336": "Data"
            },
            "input_nodes": [
                "buffer_6_29668_27336"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_5_29668_27336",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_4_29668_27336 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_4_29668_27336"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 29982
        },
        "buffer_5_29682_27544": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_6_29682_27544 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_6_29682_27544": "Data"
            },
            "input_nodes": [
                "buffer_6_29682_27544"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_5_29682_27544",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_4_29682_27544 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_4_29682_27544"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30118
        },
        "buffer_5_29696_27752": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_6_29696_27752 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_6_29696_27752": "Data"
            },
            "input_nodes": [
                "buffer_6_29696_27752"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_5_29696_27752",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_4_29696_27752 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_4_29696_27752"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30254
        },
        "buffer_5_29710_27960": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_6_29710_27960 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_6_29710_27960": "Data"
            },
            "input_nodes": [
                "buffer_6_29710_27960"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_5_29710_27960",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_4_29710_27960 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_4_29710_27960"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30390
        },
        "buffer_5_29724_28168": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_6_29724_28168 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_6_29724_28168": "Data"
            },
            "input_nodes": [
                "buffer_6_29724_28168"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_5_29724_28168",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_4_29724_28168 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_4_29724_28168"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30526
        },
        "buffer_5_29738_28376": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_6_29738_28376 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_6_29738_28376": "Data"
            },
            "input_nodes": [
                "buffer_6_29738_28376"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_5_29738_28376",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_4_29738_28376 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_4_29738_28376"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30662
        },
        "buffer_5_29752_28584": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_6_29752_28584 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_6_29752_28584": "Data"
            },
            "input_nodes": [
                "buffer_6_29752_28584"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_5_29752_28584",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_4_29752_28584 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_4_29752_28584"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30798
        },
        "buffer_5_29766_28792": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_6_29766_28792 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_6_29766_28792": "Data"
            },
            "input_nodes": [
                "buffer_6_29766_28792"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_5_29766_28792",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_4_29766_28792 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_4_29766_28792"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30934
        },
        "buffer_5_29780_29000": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_6_29780_29000 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_6_29780_29000": "Data"
            },
            "input_nodes": [
                "buffer_6_29780_29000"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_5_29780_29000",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_4_29780_29000 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_4_29780_29000"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31070
        },
        "buffer_5_29794_29208": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_6_29794_29208 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_6_29794_29208": "Data"
            },
            "input_nodes": [
                "buffer_6_29794_29208"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_5_29794_29208",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_4_29794_29208 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_4_29794_29208"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31206
        },
        "buffer_5_29808_29416": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_6_29808_29416 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_6_29808_29416": "Data"
            },
            "input_nodes": [
                "buffer_6_29808_29416"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_5_29808_29416",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_4_29808_29416 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_4_29808_29416"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31342
        },
        "buffer_5_29822_29624": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_6_29822_29624 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_6_29822_29624": "Data"
            },
            "input_nodes": [
                "buffer_6_29822_29624"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_5_29822_29624",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_4_29822_29624 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_4_29822_29624"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31461
        },
        "buffer_6_29668_27336": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_7_29668_27336 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_7_29668_27336": "Data"
            },
            "input_nodes": [
                "buffer_7_29668_27336"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_6_29668_27336",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_5_29668_27336 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_5_29668_27336"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 29983
        },
        "buffer_6_29682_27544": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_7_29682_27544 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_7_29682_27544": "Data"
            },
            "input_nodes": [
                "buffer_7_29682_27544"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_6_29682_27544",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_5_29682_27544 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_5_29682_27544"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30119
        },
        "buffer_6_29696_27752": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_7_29696_27752 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_7_29696_27752": "Data"
            },
            "input_nodes": [
                "buffer_7_29696_27752"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_6_29696_27752",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_5_29696_27752 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_5_29696_27752"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30255
        },
        "buffer_6_29710_27960": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_7_29710_27960 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_7_29710_27960": "Data"
            },
            "input_nodes": [
                "buffer_7_29710_27960"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_6_29710_27960",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_5_29710_27960 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_5_29710_27960"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30391
        },
        "buffer_6_29724_28168": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_7_29724_28168 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_7_29724_28168": "Data"
            },
            "input_nodes": [
                "buffer_7_29724_28168"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_6_29724_28168",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_5_29724_28168 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_5_29724_28168"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30527
        },
        "buffer_6_29738_28376": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_7_29738_28376 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_7_29738_28376": "Data"
            },
            "input_nodes": [
                "buffer_7_29738_28376"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_6_29738_28376",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_5_29738_28376 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_5_29738_28376"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30663
        },
        "buffer_6_29752_28584": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_7_29752_28584 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_7_29752_28584": "Data"
            },
            "input_nodes": [
                "buffer_7_29752_28584"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_6_29752_28584",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_5_29752_28584 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_5_29752_28584"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30799
        },
        "buffer_6_29766_28792": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_7_29766_28792 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_7_29766_28792": "Data"
            },
            "input_nodes": [
                "buffer_7_29766_28792"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_6_29766_28792",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_5_29766_28792 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_5_29766_28792"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30935
        },
        "buffer_6_29780_29000": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_7_29780_29000 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_7_29780_29000": "Data"
            },
            "input_nodes": [
                "buffer_7_29780_29000"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_6_29780_29000",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_5_29780_29000 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_5_29780_29000"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31071
        },
        "buffer_6_29794_29208": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_7_29794_29208 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_7_29794_29208": "Data"
            },
            "input_nodes": [
                "buffer_7_29794_29208"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_6_29794_29208",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_5_29794_29208 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_5_29794_29208"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31207
        },
        "buffer_6_29808_29416": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_7_29808_29416 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_7_29808_29416": "Data"
            },
            "input_nodes": [
                "buffer_7_29808_29416"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_6_29808_29416",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_5_29808_29416 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_5_29808_29416"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31343
        },
        "buffer_6_29822_29624": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: buffer_7_29822_29624 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_7_29822_29624": "Data"
            },
            "input_nodes": [
                "buffer_7_29822_29624"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_6_29822_29624",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_5_29822_29624 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_5_29822_29624"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31462
        },
        "buffer_7_29668_27336": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_13 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_13": "Data"
            },
            "input_nodes": [
                "_fused_op_13"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_7_29668_27336",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_6_29668_27336 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_6_29668_27336"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 29984
        },
        "buffer_7_29682_27544": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_27 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_27": "Data"
            },
            "input_nodes": [
                "_fused_op_27"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_7_29682_27544",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_6_29682_27544 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_6_29682_27544"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30120
        },
        "buffer_7_29696_27752": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_41 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_41": "Data"
            },
            "input_nodes": [
                "_fused_op_41"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_7_29696_27752",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_6_29696_27752 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_6_29696_27752"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30256
        },
        "buffer_7_29710_27960": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_55 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_55": "Data"
            },
            "input_nodes": [
                "_fused_op_55"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_7_29710_27960",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_6_29710_27960 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_6_29710_27960"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30392
        },
        "buffer_7_29724_28168": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_69 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_69": "Data"
            },
            "input_nodes": [
                "_fused_op_69"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_7_29724_28168",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_6_29724_28168 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_6_29724_28168"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30528
        },
        "buffer_7_29738_28376": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_83 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_83": "Data"
            },
            "input_nodes": [
                "_fused_op_83"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_7_29738_28376",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_6_29738_28376 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_6_29738_28376"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30664
        },
        "buffer_7_29752_28584": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_97 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_97": "Data"
            },
            "input_nodes": [
                "_fused_op_97"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_7_29752_28584",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_6_29752_28584 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_6_29752_28584"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30800
        },
        "buffer_7_29766_28792": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_111 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_111": "Data"
            },
            "input_nodes": [
                "_fused_op_111"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_7_29766_28792",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_6_29766_28792 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_6_29766_28792"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30936
        },
        "buffer_7_29780_29000": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_125 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_125": "Data"
            },
            "input_nodes": [
                "_fused_op_125"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_7_29780_29000",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_6_29780_29000 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_6_29780_29000"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31072
        },
        "buffer_7_29794_29208": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_139 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_139": "Data"
            },
            "input_nodes": [
                "_fused_op_139"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_7_29794_29208",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_6_29794_29208 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_6_29794_29208"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31208
        },
        "buffer_7_29808_29416": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_153 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_153": "Data"
            },
            "input_nodes": [
                "_fused_op_153"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_7_29808_29416",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_6_29808_29416 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_6_29808_29416"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31344
        },
        "buffer_7_29822_29624": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_167 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_167": "Data"
            },
            "input_nodes": [
                "_fused_op_167"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_7_29822_29624",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_6_29822_29624 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_6_29822_29624"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 31463
        },
        "dc.input_tensor.layernorm_0.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_0.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_0 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_0"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27123
        },
        "dc.input_tensor.layernorm_0.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_0.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27129
        },
        "dc.input_tensor.layernorm_0.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_0.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27131
        },
        "dc.input_tensor.layernorm_1012.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1012.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_133 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_133"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29108
        },
        "dc.input_tensor.layernorm_1012.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1012.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_134 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_134"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29114
        },
        "dc.input_tensor.layernorm_1012.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1012.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_134 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_134"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29116
        },
        "dc.input_tensor.layernorm_1051.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1051.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_138 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_138"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29180
        },
        "dc.input_tensor.layernorm_1051.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1051.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_139 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_139"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29186
        },
        "dc.input_tensor.layernorm_1051.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1051.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_139 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_139"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29188
        },
        "dc.input_tensor.layernorm_1065.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1065.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_140 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_140"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29212
        },
        "dc.input_tensor.layernorm_1065.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1065.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_141 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_141"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29218
        },
        "dc.input_tensor.layernorm_1065.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1065.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_141 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_141"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29220
        },
        "dc.input_tensor.layernorm_1104.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1104.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_145 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_145"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29284
        },
        "dc.input_tensor.layernorm_1104.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1104.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_146 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_146"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29290
        },
        "dc.input_tensor.layernorm_1104.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1104.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_146 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_146"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29292
        },
        "dc.input_tensor.layernorm_111.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_111.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_14 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_14"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27340
        },
        "dc.input_tensor.layernorm_111.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_111.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_15 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_15"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27346
        },
        "dc.input_tensor.layernorm_111.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_111.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_15 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_15"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27348
        },
        "dc.input_tensor.layernorm_1118.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1118.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_147 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_147"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29316
        },
        "dc.input_tensor.layernorm_1118.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1118.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_148 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_148"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29322
        },
        "dc.input_tensor.layernorm_1118.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1118.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_148 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_148"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29324
        },
        "dc.input_tensor.layernorm_1157.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1157.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_152 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_152"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29388
        },
        "dc.input_tensor.layernorm_1157.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1157.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_153 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_153"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29394
        },
        "dc.input_tensor.layernorm_1157.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1157.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_153 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_153"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29396
        },
        "dc.input_tensor.layernorm_1171.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1171.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_154 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_154"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29420
        },
        "dc.input_tensor.layernorm_1171.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1171.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_155 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_155"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29426
        },
        "dc.input_tensor.layernorm_1171.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1171.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_155 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_155"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29428
        },
        "dc.input_tensor.layernorm_1210.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1210.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_159 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_159"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29492
        },
        "dc.input_tensor.layernorm_1210.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1210.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_160 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_160"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29498
        },
        "dc.input_tensor.layernorm_1210.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1210.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_160 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_160"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29500
        },
        "dc.input_tensor.layernorm_1224.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1224.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_161 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_161"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29524
        },
        "dc.input_tensor.layernorm_1224.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1224.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_162 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_162"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29530
        },
        "dc.input_tensor.layernorm_1224.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1224.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_162 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_162"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29532
        },
        "dc.input_tensor.layernorm_1263.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1263.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_166 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_166"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29596
        },
        "dc.input_tensor.layernorm_1263.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1263.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_167 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_167"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29602
        },
        "dc.input_tensor.layernorm_1263.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1263.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_167 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_167"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29604
        },
        "dc.input_tensor.layernorm_1277.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1277.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_168 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_168"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29628
        },
        "dc.input_tensor.layernorm_1277.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1277.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_169 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_169"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29634
        },
        "dc.input_tensor.layernorm_1277.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1277.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_169 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_169"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29636
        },
        "dc.input_tensor.layernorm_150.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_150.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_19 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_19"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27412
        },
        "dc.input_tensor.layernorm_150.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_150.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_20 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_20"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27418
        },
        "dc.input_tensor.layernorm_150.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_150.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_20 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_20"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27420
        },
        "dc.input_tensor.layernorm_164.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_164.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_21 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_21"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27444
        },
        "dc.input_tensor.layernorm_164.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_164.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_22 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_22"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27450
        },
        "dc.input_tensor.layernorm_164.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_164.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_22 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_22"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27452
        },
        "dc.input_tensor.layernorm_203.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_203.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_26 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_26"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27516
        },
        "dc.input_tensor.layernorm_203.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_203.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_27 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_27"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27522
        },
        "dc.input_tensor.layernorm_203.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_203.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_27 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_27"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27524
        },
        "dc.input_tensor.layernorm_217.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_217.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_28 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_28"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27548
        },
        "dc.input_tensor.layernorm_217.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_217.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_29 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_29"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27554
        },
        "dc.input_tensor.layernorm_217.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_217.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_29 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_29"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27556
        },
        "dc.input_tensor.layernorm_256.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_256.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_33 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_33"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27620
        },
        "dc.input_tensor.layernorm_256.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_256.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_34 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_34"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27626
        },
        "dc.input_tensor.layernorm_256.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_256.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_34 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_34"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27628
        },
        "dc.input_tensor.layernorm_270.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_270.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_35 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_35"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27652
        },
        "dc.input_tensor.layernorm_270.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_270.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_36 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_36"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27658
        },
        "dc.input_tensor.layernorm_270.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_270.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_36 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_36"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27660
        },
        "dc.input_tensor.layernorm_309.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_309.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_40 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_40"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27724
        },
        "dc.input_tensor.layernorm_309.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_309.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_41 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_41"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27730
        },
        "dc.input_tensor.layernorm_309.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_309.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_41 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_41"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27732
        },
        "dc.input_tensor.layernorm_323.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_323.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_42 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_42"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27756
        },
        "dc.input_tensor.layernorm_323.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_323.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_43 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_43"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27762
        },
        "dc.input_tensor.layernorm_323.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_323.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_43 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_43"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27764
        },
        "dc.input_tensor.layernorm_362.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_362.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_47 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_47"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27828
        },
        "dc.input_tensor.layernorm_362.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_362.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_48 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_48"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27834
        },
        "dc.input_tensor.layernorm_362.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_362.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_48 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_48"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27836
        },
        "dc.input_tensor.layernorm_376.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_376.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_49 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_49"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27860
        },
        "dc.input_tensor.layernorm_376.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_376.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_50 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_50"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27866
        },
        "dc.input_tensor.layernorm_376.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_376.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_50 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_50"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27868
        },
        "dc.input_tensor.layernorm_415.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_415.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_54 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_54"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27932
        },
        "dc.input_tensor.layernorm_415.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_415.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_55 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_55"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27938
        },
        "dc.input_tensor.layernorm_415.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_415.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_55 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_55"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27940
        },
        "dc.input_tensor.layernorm_429.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_429.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_56 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_56"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27964
        },
        "dc.input_tensor.layernorm_429.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_429.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_57 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_57"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27970
        },
        "dc.input_tensor.layernorm_429.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_429.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_57 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_57"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27972
        },
        "dc.input_tensor.layernorm_44.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_44.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_5 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_5"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27204
        },
        "dc.input_tensor.layernorm_44.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_44.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_6 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_6"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27210
        },
        "dc.input_tensor.layernorm_44.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_44.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_6 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_6"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27212
        },
        "dc.input_tensor.layernorm_468.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_468.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_61 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_61"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28036
        },
        "dc.input_tensor.layernorm_468.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_468.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_62 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_62"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28042
        },
        "dc.input_tensor.layernorm_468.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_468.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_62 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_62"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28044
        },
        "dc.input_tensor.layernorm_482.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_482.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_63 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_63"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28068
        },
        "dc.input_tensor.layernorm_482.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_482.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_64 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_64"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28074
        },
        "dc.input_tensor.layernorm_482.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_482.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_64 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_64"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28076
        },
        "dc.input_tensor.layernorm_521.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_521.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_68 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_68"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28140
        },
        "dc.input_tensor.layernorm_521.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_521.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_69 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_69"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28146
        },
        "dc.input_tensor.layernorm_521.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_521.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_69 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_69"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28148
        },
        "dc.input_tensor.layernorm_535.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_535.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_70 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_70"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28172
        },
        "dc.input_tensor.layernorm_535.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_535.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_71 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_71"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28178
        },
        "dc.input_tensor.layernorm_535.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_535.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_71 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_71"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28180
        },
        "dc.input_tensor.layernorm_574.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_574.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_75 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_75"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28244
        },
        "dc.input_tensor.layernorm_574.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_574.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_76 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_76"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28250
        },
        "dc.input_tensor.layernorm_574.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_574.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_76 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_76"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28252
        },
        "dc.input_tensor.layernorm_58.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_58.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_7 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_7"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27236
        },
        "dc.input_tensor.layernorm_58.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_58.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_8 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_8"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27242
        },
        "dc.input_tensor.layernorm_58.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_58.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_8 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_8"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27244
        },
        "dc.input_tensor.layernorm_588.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_588.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_77 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_77"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28276
        },
        "dc.input_tensor.layernorm_588.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_588.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_78 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_78"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28282
        },
        "dc.input_tensor.layernorm_588.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_588.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_78 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_78"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28284
        },
        "dc.input_tensor.layernorm_627.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_627.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_82 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_82"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28348
        },
        "dc.input_tensor.layernorm_627.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_627.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_83 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_83"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28354
        },
        "dc.input_tensor.layernorm_627.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_627.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_83 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_83"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28356
        },
        "dc.input_tensor.layernorm_641.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_641.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_84 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_84"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28380
        },
        "dc.input_tensor.layernorm_641.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_641.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_85 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_85"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28386
        },
        "dc.input_tensor.layernorm_641.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_641.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_85 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_85"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28388
        },
        "dc.input_tensor.layernorm_680.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_680.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_89 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_89"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28452
        },
        "dc.input_tensor.layernorm_680.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_680.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_90 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_90"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28458
        },
        "dc.input_tensor.layernorm_680.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_680.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_90 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_90"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28460
        },
        "dc.input_tensor.layernorm_694.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_694.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_91 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_91"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28484
        },
        "dc.input_tensor.layernorm_694.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_694.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_92 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_92"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28490
        },
        "dc.input_tensor.layernorm_694.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_694.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_92 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_92"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28492
        },
        "dc.input_tensor.layernorm_733.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_733.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_96 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_96"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28556
        },
        "dc.input_tensor.layernorm_733.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_733.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_97 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_97"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28562
        },
        "dc.input_tensor.layernorm_733.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_733.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_97 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_97"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28564
        },
        "dc.input_tensor.layernorm_747.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_747.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_98 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_98"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28588
        },
        "dc.input_tensor.layernorm_747.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_747.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_99 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_99"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28594
        },
        "dc.input_tensor.layernorm_747.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_747.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_99 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_99"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28596
        },
        "dc.input_tensor.layernorm_786.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_786.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_103 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_103"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28660
        },
        "dc.input_tensor.layernorm_786.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_786.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_104 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_104"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28666
        },
        "dc.input_tensor.layernorm_786.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_786.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_104 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_104"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28668
        },
        "dc.input_tensor.layernorm_800.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_800.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_105 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_105"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28692
        },
        "dc.input_tensor.layernorm_800.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_800.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_106 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_106"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28698
        },
        "dc.input_tensor.layernorm_800.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_800.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_106 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_106"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28700
        },
        "dc.input_tensor.layernorm_839.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_839.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_110 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_110"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28764
        },
        "dc.input_tensor.layernorm_839.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_839.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_111 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_111"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28770
        },
        "dc.input_tensor.layernorm_839.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_839.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_111 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_111"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28772
        },
        "dc.input_tensor.layernorm_853.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_853.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_112 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_112"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28796
        },
        "dc.input_tensor.layernorm_853.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_853.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_113 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_113"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28802
        },
        "dc.input_tensor.layernorm_853.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_853.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_113 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_113"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28804
        },
        "dc.input_tensor.layernorm_892.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_892.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_117 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_117"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28868
        },
        "dc.input_tensor.layernorm_892.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_892.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_118 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_118"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28874
        },
        "dc.input_tensor.layernorm_892.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_892.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_118 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_118"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28876
        },
        "dc.input_tensor.layernorm_906.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_906.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_119 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_119"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28900
        },
        "dc.input_tensor.layernorm_906.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_906.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_120 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_120"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28906
        },
        "dc.input_tensor.layernorm_906.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_906.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_120 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_120"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28908
        },
        "dc.input_tensor.layernorm_945.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_945.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_124 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_124"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28972
        },
        "dc.input_tensor.layernorm_945.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_945.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_125 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_125"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28978
        },
        "dc.input_tensor.layernorm_945.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_945.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_125 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_125"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28980
        },
        "dc.input_tensor.layernorm_959.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_959.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_126 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_126"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29004
        },
        "dc.input_tensor.layernorm_959.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_959.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_127 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_127"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29010
        },
        "dc.input_tensor.layernorm_959.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_959.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_127 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_127"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29012
        },
        "dc.input_tensor.layernorm_97.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_97.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_12 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_12"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27308
        },
        "dc.input_tensor.layernorm_97.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_97.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_13 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_13"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27314
        },
        "dc.input_tensor.layernorm_97.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_97.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_13 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_13"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27316
        },
        "dc.input_tensor.layernorm_998.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_998.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_131 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_131"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29076
        },
        "dc.input_tensor.layernorm_998.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_998.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_132 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_132"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29082
        },
        "dc.input_tensor.layernorm_998.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_998.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_132 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_132"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29084
        },
        "dc.input_tensor.softmax_1031.4": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                16,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.softmax_1031.4",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_137 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_137"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "softmax"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29155
        },
        "dc.input_tensor.softmax_1084.4": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                16,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.softmax_1084.4",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_144 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_144"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "softmax"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29259
        },
        "dc.input_tensor.softmax_1137.4": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                16,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.softmax_1137.4",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_151 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_151"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "softmax"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29363
        },
        "dc.input_tensor.softmax_1190.4": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                16,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.softmax_1190.4",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_158 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_158"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "softmax"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29467
        },
        "dc.input_tensor.softmax_1243.4": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                16,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.softmax_1243.4",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_165 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_165"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "softmax"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29571
        },
        "dc.input_tensor.softmax_130.4": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                16,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.softmax_130.4",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_18 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_18"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "softmax"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27387
        },
        "dc.input_tensor.softmax_183.4": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                16,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.softmax_183.4",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_25 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_25"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "softmax"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27491
        },
        "dc.input_tensor.softmax_236.4": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                16,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.softmax_236.4",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_32 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_32"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "softmax"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27595
        },
        "dc.input_tensor.softmax_24.4": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                16,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.softmax_24.4",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_4 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_4"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "softmax"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27179
        },
        "dc.input_tensor.softmax_289.4": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                16,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.softmax_289.4",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_39 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_39"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "softmax"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27699
        },
        "dc.input_tensor.softmax_342.4": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                16,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.softmax_342.4",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_46 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_46"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "softmax"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27803
        },
        "dc.input_tensor.softmax_395.4": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                16,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.softmax_395.4",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_53 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_53"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "softmax"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27907
        },
        "dc.input_tensor.softmax_448.4": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                16,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.softmax_448.4",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_60 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_60"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "softmax"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28011
        },
        "dc.input_tensor.softmax_501.4": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                16,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.softmax_501.4",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_67 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_67"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "softmax"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28115
        },
        "dc.input_tensor.softmax_554.4": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                16,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.softmax_554.4",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_74 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_74"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "softmax"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28219
        },
        "dc.input_tensor.softmax_607.4": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                16,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.softmax_607.4",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_81 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_81"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "softmax"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28323
        },
        "dc.input_tensor.softmax_660.4": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                16,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.softmax_660.4",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_88 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_88"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "softmax"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28427
        },
        "dc.input_tensor.softmax_713.4": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                16,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.softmax_713.4",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_95 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_95"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "softmax"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28531
        },
        "dc.input_tensor.softmax_766.4": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                16,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.softmax_766.4",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_102 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_102"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "softmax"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28635
        },
        "dc.input_tensor.softmax_77.4": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                16,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.softmax_77.4",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_11 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_11"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "softmax"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27283
        },
        "dc.input_tensor.softmax_819.4": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                16,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.softmax_819.4",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_109 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_109"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "softmax"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28739
        },
        "dc.input_tensor.softmax_872.4": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                16,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.softmax_872.4",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_116 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_116"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "softmax"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28843
        },
        "dc.input_tensor.softmax_925.4": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                16,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.softmax_925.4",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_123 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_123"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "softmax"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28947
        },
        "dc.input_tensor.softmax_978.4": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                16,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.softmax_978.4",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_130 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_130"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "softmax"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29051
        },
        "gelu_1004": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu(none,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1001 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "matmul_1001": "Data"
            },
            "input_nodes": [
                "matmul_1001"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "gelu_1004",
            "op_type": {
                "attrs": [
                    "none"
                ],
                "buda_attrs": {
                    "approximate_mode": "false"
                },
                "named_attrs": {},
                "type": "gelu"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1007 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1007"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn",
                "original_op_name": "gelu_1004",
                "original_op_type": "gelu"
            },
            "type": "gelu",
            "unique_id": 29098
        },
        "gelu_103": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu(none,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_100 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "matmul_100": "Data"
            },
            "input_nodes": [
                "matmul_100"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "gelu_103",
            "op_type": {
                "attrs": [
                    "none"
                ],
                "buda_attrs": {
                    "approximate_mode": "false"
                },
                "named_attrs": {},
                "type": "gelu"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_106 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_106"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn",
                "original_op_name": "gelu_103",
                "original_op_type": "gelu"
            },
            "type": "gelu",
            "unique_id": 27330
        },
        "gelu_1057": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu(none,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1054 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "matmul_1054": "Data"
            },
            "input_nodes": [
                "matmul_1054"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "gelu_1057",
            "op_type": {
                "attrs": [
                    "none"
                ],
                "buda_attrs": {
                    "approximate_mode": "false"
                },
                "named_attrs": {},
                "type": "gelu"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1060 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1060"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn",
                "original_op_name": "gelu_1057",
                "original_op_type": "gelu"
            },
            "type": "gelu",
            "unique_id": 29202
        },
        "gelu_1110": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu(none,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1107 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "matmul_1107": "Data"
            },
            "input_nodes": [
                "matmul_1107"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "gelu_1110",
            "op_type": {
                "attrs": [
                    "none"
                ],
                "buda_attrs": {
                    "approximate_mode": "false"
                },
                "named_attrs": {},
                "type": "gelu"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1113 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1113"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn",
                "original_op_name": "gelu_1110",
                "original_op_type": "gelu"
            },
            "type": "gelu",
            "unique_id": 29306
        },
        "gelu_1163": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu(none,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1160 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "matmul_1160": "Data"
            },
            "input_nodes": [
                "matmul_1160"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "gelu_1163",
            "op_type": {
                "attrs": [
                    "none"
                ],
                "buda_attrs": {
                    "approximate_mode": "false"
                },
                "named_attrs": {},
                "type": "gelu"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1166 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1166"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn",
                "original_op_name": "gelu_1163",
                "original_op_type": "gelu"
            },
            "type": "gelu",
            "unique_id": 29410
        },
        "gelu_1216": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu(none,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1213 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "matmul_1213": "Data"
            },
            "input_nodes": [
                "matmul_1213"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "gelu_1216",
            "op_type": {
                "attrs": [
                    "none"
                ],
                "buda_attrs": {
                    "approximate_mode": "false"
                },
                "named_attrs": {},
                "type": "gelu"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1219 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1219"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn",
                "original_op_name": "gelu_1216",
                "original_op_type": "gelu"
            },
            "type": "gelu",
            "unique_id": 29514
        },
        "gelu_1269": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu(none,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1266 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "matmul_1266": "Data"
            },
            "input_nodes": [
                "matmul_1266"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "gelu_1269",
            "op_type": {
                "attrs": [
                    "none"
                ],
                "buda_attrs": {
                    "approximate_mode": "false"
                },
                "named_attrs": {},
                "type": "gelu"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1272 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1272"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn",
                "original_op_name": "gelu_1269",
                "original_op_type": "gelu"
            },
            "type": "gelu",
            "unique_id": 29618
        },
        "gelu_156": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu(none,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_153 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "matmul_153": "Data"
            },
            "input_nodes": [
                "matmul_153"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "gelu_156",
            "op_type": {
                "attrs": [
                    "none"
                ],
                "buda_attrs": {
                    "approximate_mode": "false"
                },
                "named_attrs": {},
                "type": "gelu"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_159 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_159"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn",
                "original_op_name": "gelu_156",
                "original_op_type": "gelu"
            },
            "type": "gelu",
            "unique_id": 27434
        },
        "gelu_209": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu(none,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_206 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "matmul_206": "Data"
            },
            "input_nodes": [
                "matmul_206"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "gelu_209",
            "op_type": {
                "attrs": [
                    "none"
                ],
                "buda_attrs": {
                    "approximate_mode": "false"
                },
                "named_attrs": {},
                "type": "gelu"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_212 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_212"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn",
                "original_op_name": "gelu_209",
                "original_op_type": "gelu"
            },
            "type": "gelu",
            "unique_id": 27538
        },
        "gelu_262": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu(none,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_259 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "matmul_259": "Data"
            },
            "input_nodes": [
                "matmul_259"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "gelu_262",
            "op_type": {
                "attrs": [
                    "none"
                ],
                "buda_attrs": {
                    "approximate_mode": "false"
                },
                "named_attrs": {},
                "type": "gelu"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_265 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_265"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn",
                "original_op_name": "gelu_262",
                "original_op_type": "gelu"
            },
            "type": "gelu",
            "unique_id": 27642
        },
        "gelu_315": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu(none,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_312 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "matmul_312": "Data"
            },
            "input_nodes": [
                "matmul_312"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "gelu_315",
            "op_type": {
                "attrs": [
                    "none"
                ],
                "buda_attrs": {
                    "approximate_mode": "false"
                },
                "named_attrs": {},
                "type": "gelu"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_318 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_318"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn",
                "original_op_name": "gelu_315",
                "original_op_type": "gelu"
            },
            "type": "gelu",
            "unique_id": 27746
        },
        "gelu_368": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu(none,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_365 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "matmul_365": "Data"
            },
            "input_nodes": [
                "matmul_365"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "gelu_368",
            "op_type": {
                "attrs": [
                    "none"
                ],
                "buda_attrs": {
                    "approximate_mode": "false"
                },
                "named_attrs": {},
                "type": "gelu"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_371 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_371"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn",
                "original_op_name": "gelu_368",
                "original_op_type": "gelu"
            },
            "type": "gelu",
            "unique_id": 27850
        },
        "gelu_421": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu(none,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_418 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "matmul_418": "Data"
            },
            "input_nodes": [
                "matmul_418"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "gelu_421",
            "op_type": {
                "attrs": [
                    "none"
                ],
                "buda_attrs": {
                    "approximate_mode": "false"
                },
                "named_attrs": {},
                "type": "gelu"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_424 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_424"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn",
                "original_op_name": "gelu_421",
                "original_op_type": "gelu"
            },
            "type": "gelu",
            "unique_id": 27954
        },
        "gelu_474": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu(none,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_471 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "matmul_471": "Data"
            },
            "input_nodes": [
                "matmul_471"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "gelu_474",
            "op_type": {
                "attrs": [
                    "none"
                ],
                "buda_attrs": {
                    "approximate_mode": "false"
                },
                "named_attrs": {},
                "type": "gelu"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_477 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_477"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn",
                "original_op_name": "gelu_474",
                "original_op_type": "gelu"
            },
            "type": "gelu",
            "unique_id": 28058
        },
        "gelu_50": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu(none,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_47 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "matmul_47": "Data"
            },
            "input_nodes": [
                "matmul_47"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "gelu_50",
            "op_type": {
                "attrs": [
                    "none"
                ],
                "buda_attrs": {
                    "approximate_mode": "false"
                },
                "named_attrs": {},
                "type": "gelu"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_53 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_53"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn",
                "original_op_name": "gelu_50",
                "original_op_type": "gelu"
            },
            "type": "gelu",
            "unique_id": 27226
        },
        "gelu_527": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu(none,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_524 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "matmul_524": "Data"
            },
            "input_nodes": [
                "matmul_524"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "gelu_527",
            "op_type": {
                "attrs": [
                    "none"
                ],
                "buda_attrs": {
                    "approximate_mode": "false"
                },
                "named_attrs": {},
                "type": "gelu"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_530 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_530"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn",
                "original_op_name": "gelu_527",
                "original_op_type": "gelu"
            },
            "type": "gelu",
            "unique_id": 28162
        },
        "gelu_580": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu(none,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_577 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "matmul_577": "Data"
            },
            "input_nodes": [
                "matmul_577"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "gelu_580",
            "op_type": {
                "attrs": [
                    "none"
                ],
                "buda_attrs": {
                    "approximate_mode": "false"
                },
                "named_attrs": {},
                "type": "gelu"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_583 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_583"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn",
                "original_op_name": "gelu_580",
                "original_op_type": "gelu"
            },
            "type": "gelu",
            "unique_id": 28266
        },
        "gelu_633": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu(none,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_630 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "matmul_630": "Data"
            },
            "input_nodes": [
                "matmul_630"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "gelu_633",
            "op_type": {
                "attrs": [
                    "none"
                ],
                "buda_attrs": {
                    "approximate_mode": "false"
                },
                "named_attrs": {},
                "type": "gelu"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_636 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_636"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn",
                "original_op_name": "gelu_633",
                "original_op_type": "gelu"
            },
            "type": "gelu",
            "unique_id": 28370
        },
        "gelu_686": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu(none,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_683 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "matmul_683": "Data"
            },
            "input_nodes": [
                "matmul_683"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "gelu_686",
            "op_type": {
                "attrs": [
                    "none"
                ],
                "buda_attrs": {
                    "approximate_mode": "false"
                },
                "named_attrs": {},
                "type": "gelu"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_689 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_689"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn",
                "original_op_name": "gelu_686",
                "original_op_type": "gelu"
            },
            "type": "gelu",
            "unique_id": 28474
        },
        "gelu_739": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu(none,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_736 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "matmul_736": "Data"
            },
            "input_nodes": [
                "matmul_736"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "gelu_739",
            "op_type": {
                "attrs": [
                    "none"
                ],
                "buda_attrs": {
                    "approximate_mode": "false"
                },
                "named_attrs": {},
                "type": "gelu"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_742 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_742"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn",
                "original_op_name": "gelu_739",
                "original_op_type": "gelu"
            },
            "type": "gelu",
            "unique_id": 28578
        },
        "gelu_792": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu(none,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_789 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "matmul_789": "Data"
            },
            "input_nodes": [
                "matmul_789"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "gelu_792",
            "op_type": {
                "attrs": [
                    "none"
                ],
                "buda_attrs": {
                    "approximate_mode": "false"
                },
                "named_attrs": {},
                "type": "gelu"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_795 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_795"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn",
                "original_op_name": "gelu_792",
                "original_op_type": "gelu"
            },
            "type": "gelu",
            "unique_id": 28682
        },
        "gelu_845": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu(none,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_842 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "matmul_842": "Data"
            },
            "input_nodes": [
                "matmul_842"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "gelu_845",
            "op_type": {
                "attrs": [
                    "none"
                ],
                "buda_attrs": {
                    "approximate_mode": "false"
                },
                "named_attrs": {},
                "type": "gelu"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_848 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_848"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn",
                "original_op_name": "gelu_845",
                "original_op_type": "gelu"
            },
            "type": "gelu",
            "unique_id": 28786
        },
        "gelu_898": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu(none,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_895 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "matmul_895": "Data"
            },
            "input_nodes": [
                "matmul_895"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "gelu_898",
            "op_type": {
                "attrs": [
                    "none"
                ],
                "buda_attrs": {
                    "approximate_mode": "false"
                },
                "named_attrs": {},
                "type": "gelu"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_901 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_901"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn",
                "original_op_name": "gelu_898",
                "original_op_type": "gelu"
            },
            "type": "gelu",
            "unique_id": 28890
        },
        "gelu_951": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu(none,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_948 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "matmul_948": "Data"
            },
            "input_nodes": [
                "matmul_948"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "gelu_951",
            "op_type": {
                "attrs": [
                    "none"
                ],
                "buda_attrs": {
                    "approximate_mode": "false"
                },
                "named_attrs": {},
                "type": "gelu"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_954 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_954"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn",
                "original_op_name": "gelu_951",
                "original_op_type": "gelu"
            },
            "type": "gelu",
            "unique_id": 28994
        },
        "input_0_subtract_21": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "input_0_subtract_21",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: subtract_21 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "subtract_21"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert",
                "original_op_name": "subtract_21",
                "original_op_type": "subtract"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27165
        },
        "input_1_multiply_1029": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "input_1_multiply_1029",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_135 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_135"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "add"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29143
        },
        "input_1_multiply_1082": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "input_1_multiply_1082",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_142 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_142"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "add"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29247
        },
        "input_1_multiply_1135": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "input_1_multiply_1135",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_149 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_149"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "add"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29351
        },
        "input_1_multiply_1188": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "input_1_multiply_1188",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_156 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_156"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "add"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29455
        },
        "input_1_multiply_1241": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "input_1_multiply_1241",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_163 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_163"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "add"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29559
        },
        "input_1_multiply_128": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "input_1_multiply_128",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_16 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_16"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "add"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27375
        },
        "input_1_multiply_18": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "input_1_multiply_18",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_2 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_2"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "add"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27159
        },
        "input_1_multiply_181": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "input_1_multiply_181",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_23 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_23"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "add"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27479
        },
        "input_1_multiply_22": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "input_1_multiply_22",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: multiply_22 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "multiply_22"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert",
                "original_op_name": "multiply_22",
                "original_op_type": "multiply"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27167
        },
        "input_1_multiply_234": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "input_1_multiply_234",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_30 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_30"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "add"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27583
        },
        "input_1_multiply_287": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "input_1_multiply_287",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_37 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_37"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "add"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27687
        },
        "input_1_multiply_340": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "input_1_multiply_340",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_44 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_44"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "add"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27791
        },
        "input_1_multiply_393": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "input_1_multiply_393",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_51 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_51"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "add"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27895
        },
        "input_1_multiply_446": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "input_1_multiply_446",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_58 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_58"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "add"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27999
        },
        "input_1_multiply_499": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "input_1_multiply_499",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_65 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_65"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "add"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28103
        },
        "input_1_multiply_552": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "input_1_multiply_552",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_72 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_72"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "add"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28207
        },
        "input_1_multiply_605": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "input_1_multiply_605",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_79 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_79"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "add"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28311
        },
        "input_1_multiply_658": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "input_1_multiply_658",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_86 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_86"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "add"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28415
        },
        "input_1_multiply_711": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "input_1_multiply_711",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_93 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_93"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "add"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28519
        },
        "input_1_multiply_75": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "input_1_multiply_75",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_9 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_9"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "add"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27271
        },
        "input_1_multiply_764": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "input_1_multiply_764",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_100 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_100"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "add"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28623
        },
        "input_1_multiply_817": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "input_1_multiply_817",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_107 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_107"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "add"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28727
        },
        "input_1_multiply_870": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "input_1_multiply_870",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_114 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_114"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "add"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28831
        },
        "input_1_multiply_923": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "input_1_multiply_923",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_121 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_121"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "add"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28935
        },
        "input_1_multiply_976": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "input_1_multiply_976",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_128 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_128"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "add"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29039
        },
        "layernorm_0.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_0 (port_0) ublock_order(c)",
                "Data: _fused_op_0 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_0": "Data"
            },
            "input_nodes": [
                "_fused_op_0",
                "_fused_op_0"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_0.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_0.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_0.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEmbeddings::embeddings/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_0",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 27125
        },
        "layernorm_0.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: pybuda_6_i0 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_0.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "lc.input_tensor.layernorm_0.dc.reduce_sum.0.0": "Data",
                "pybuda_6_i0": "Data"
            },
            "input_nodes": [
                "pybuda_6_i0",
                "lc.input_tensor.layernorm_0.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_0.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_0 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_0"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEmbeddings::embeddings/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_0",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 27120
        },
        "layernorm_0.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_0.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_0.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_0.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_0.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_0.dc.multiply.4",
                "lc.input_tensor.layernorm_0.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_0.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEmbeddings::embeddings/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_0",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 27127
        },
        "layernorm_1012.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_133 (port_0) ublock_order(c)",
                "Data: _fused_op_133 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_133": "Data"
            },
            "input_nodes": [
                "_fused_op_133",
                "_fused_op_133"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1012.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1012.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1012.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1012",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 29110
        },
        "layernorm_1012.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_1011 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_1012.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_1011": "Data",
                "lc.input_tensor.layernorm_1012.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_1011",
                "lc.input_tensor.layernorm_1012.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1012.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_133 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_133"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1012",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 29106
        },
        "layernorm_1012.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_1012.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_1012.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_1012.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_1012.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_1012.dc.multiply.4",
                "lc.input_tensor.layernorm_1012.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1012.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_134 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_134"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1012",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 29112
        },
        "layernorm_1051.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_138 (port_0) ublock_order(c)",
                "Data: _fused_op_138 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_138": "Data"
            },
            "input_nodes": [
                "_fused_op_138",
                "_fused_op_138"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1051.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1051.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1051.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1051",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 29182
        },
        "layernorm_1051.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_1050 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_1051.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_1050": "Data",
                "lc.input_tensor.layernorm_1051.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_1050",
                "lc.input_tensor.layernorm_1051.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1051.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_138 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_138"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1051",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 29178
        },
        "layernorm_1051.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_1051.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_1051.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_1051.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_1051.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_1051.dc.multiply.4",
                "lc.input_tensor.layernorm_1051.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1051.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_139 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_139"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1051",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 29184
        },
        "layernorm_1065.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_140 (port_0) ublock_order(c)",
                "Data: _fused_op_140 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_140": "Data"
            },
            "input_nodes": [
                "_fused_op_140",
                "_fused_op_140"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1065.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1065.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1065.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1065",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 29214
        },
        "layernorm_1065.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_1064 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_1065.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_1064": "Data",
                "lc.input_tensor.layernorm_1065.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_1064",
                "lc.input_tensor.layernorm_1065.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1065.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_140 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_140"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1065",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 29210
        },
        "layernorm_1065.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_1065.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_1065.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_1065.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_1065.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_1065.dc.multiply.4",
                "lc.input_tensor.layernorm_1065.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1065.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_141 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_141"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1065",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 29216
        },
        "layernorm_1104.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_145 (port_0) ublock_order(c)",
                "Data: _fused_op_145 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_145": "Data"
            },
            "input_nodes": [
                "_fused_op_145",
                "_fused_op_145"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1104.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1104.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1104.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1104",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 29286
        },
        "layernorm_1104.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_1103 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_1104.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_1103": "Data",
                "lc.input_tensor.layernorm_1104.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_1103",
                "lc.input_tensor.layernorm_1104.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1104.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_145 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_145"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1104",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 29282
        },
        "layernorm_1104.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_1104.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_1104.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_1104.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_1104.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_1104.dc.multiply.4",
                "lc.input_tensor.layernorm_1104.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1104.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_146 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_146"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1104",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 29288
        },
        "layernorm_111.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_14 (port_0) ublock_order(c)",
                "Data: _fused_op_14 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_14": "Data"
            },
            "input_nodes": [
                "_fused_op_14",
                "_fused_op_14"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_111.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_111.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_111.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_111",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 27342
        },
        "layernorm_111.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_110 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_111.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_110": "Data",
                "lc.input_tensor.layernorm_111.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_110",
                "lc.input_tensor.layernorm_111.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_111.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_14 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_14"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_111",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 27338
        },
        "layernorm_111.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_111.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_111.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_111.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_111.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_111.dc.multiply.4",
                "lc.input_tensor.layernorm_111.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_111.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_15 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_15"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_111",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 27344
        },
        "layernorm_1118.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_147 (port_0) ublock_order(c)",
                "Data: _fused_op_147 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_147": "Data"
            },
            "input_nodes": [
                "_fused_op_147",
                "_fused_op_147"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1118.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1118.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1118.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1118",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 29318
        },
        "layernorm_1118.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_1117 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_1118.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_1117": "Data",
                "lc.input_tensor.layernorm_1118.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_1117",
                "lc.input_tensor.layernorm_1118.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1118.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_147 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_147"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1118",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 29314
        },
        "layernorm_1118.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_1118.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_1118.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_1118.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_1118.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_1118.dc.multiply.4",
                "lc.input_tensor.layernorm_1118.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1118.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_148 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_148"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1118",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 29320
        },
        "layernorm_1157.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_152 (port_0) ublock_order(c)",
                "Data: _fused_op_152 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_152": "Data"
            },
            "input_nodes": [
                "_fused_op_152",
                "_fused_op_152"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1157.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1157.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1157.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1157",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 29390
        },
        "layernorm_1157.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_1156 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_1157.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_1156": "Data",
                "lc.input_tensor.layernorm_1157.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_1156",
                "lc.input_tensor.layernorm_1157.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1157.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_152 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_152"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1157",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 29386
        },
        "layernorm_1157.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_1157.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_1157.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_1157.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_1157.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_1157.dc.multiply.4",
                "lc.input_tensor.layernorm_1157.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1157.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_153 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_153"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1157",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 29392
        },
        "layernorm_1171.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_154 (port_0) ublock_order(c)",
                "Data: _fused_op_154 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_154": "Data"
            },
            "input_nodes": [
                "_fused_op_154",
                "_fused_op_154"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1171.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1171.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1171.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1171",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 29422
        },
        "layernorm_1171.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_1170 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_1171.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_1170": "Data",
                "lc.input_tensor.layernorm_1171.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_1170",
                "lc.input_tensor.layernorm_1171.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1171.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_154 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_154"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1171",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 29418
        },
        "layernorm_1171.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_1171.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_1171.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_1171.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_1171.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_1171.dc.multiply.4",
                "lc.input_tensor.layernorm_1171.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1171.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_155 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_155"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1171",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 29424
        },
        "layernorm_1210.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_159 (port_0) ublock_order(c)",
                "Data: _fused_op_159 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_159": "Data"
            },
            "input_nodes": [
                "_fused_op_159",
                "_fused_op_159"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1210.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1210.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1210.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1210",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 29494
        },
        "layernorm_1210.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_1209 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_1210.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_1209": "Data",
                "lc.input_tensor.layernorm_1210.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_1209",
                "lc.input_tensor.layernorm_1210.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1210.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_159 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_159"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1210",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 29490
        },
        "layernorm_1210.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_1210.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_1210.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_1210.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_1210.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_1210.dc.multiply.4",
                "lc.input_tensor.layernorm_1210.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1210.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_160 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_160"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1210",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 29496
        },
        "layernorm_1224.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_161 (port_0) ublock_order(c)",
                "Data: _fused_op_161 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_161": "Data"
            },
            "input_nodes": [
                "_fused_op_161",
                "_fused_op_161"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1224.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1224.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1224.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1224",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 29526
        },
        "layernorm_1224.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_1223 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_1224.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_1223": "Data",
                "lc.input_tensor.layernorm_1224.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_1223",
                "lc.input_tensor.layernorm_1224.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1224.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_161 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_161"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1224",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 29522
        },
        "layernorm_1224.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_1224.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_1224.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_1224.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_1224.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_1224.dc.multiply.4",
                "lc.input_tensor.layernorm_1224.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1224.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_162 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_162"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1224",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 29528
        },
        "layernorm_1263.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_166 (port_0) ublock_order(c)",
                "Data: _fused_op_166 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_166": "Data"
            },
            "input_nodes": [
                "_fused_op_166",
                "_fused_op_166"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1263.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1263.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1263.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1263",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 29598
        },
        "layernorm_1263.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_1262 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_1263.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_1262": "Data",
                "lc.input_tensor.layernorm_1263.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_1262",
                "lc.input_tensor.layernorm_1263.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1263.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_166 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_166"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1263",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 29594
        },
        "layernorm_1263.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_1263.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_1263.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_1263.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_1263.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_1263.dc.multiply.4",
                "lc.input_tensor.layernorm_1263.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1263.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_167 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_167"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1263",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 29600
        },
        "layernorm_1277.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_168 (port_0) ublock_order(c)",
                "Data: _fused_op_168 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_168": "Data"
            },
            "input_nodes": [
                "_fused_op_168",
                "_fused_op_168"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1277.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1277.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1277.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1277",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 29630
        },
        "layernorm_1277.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_1276 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_1277.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_1276": "Data",
                "lc.input_tensor.layernorm_1277.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_1276",
                "lc.input_tensor.layernorm_1277.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1277.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_168 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_168"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1277",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 29626
        },
        "layernorm_1277.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_1277.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_1277.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_1277.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_1277.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_1277.dc.multiply.4",
                "lc.input_tensor.layernorm_1277.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1277.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_169 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_169"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1277",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 29632
        },
        "layernorm_150.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_19 (port_0) ublock_order(c)",
                "Data: _fused_op_19 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_19": "Data"
            },
            "input_nodes": [
                "_fused_op_19",
                "_fused_op_19"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_150.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_150.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_150.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_150",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 27414
        },
        "layernorm_150.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_149 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_150.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_149": "Data",
                "lc.input_tensor.layernorm_150.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_149",
                "lc.input_tensor.layernorm_150.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_150.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_19 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_19"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_150",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 27410
        },
        "layernorm_150.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_150.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_150.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_150.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_150.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_150.dc.multiply.4",
                "lc.input_tensor.layernorm_150.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_150.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_20 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_20"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_150",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 27416
        },
        "layernorm_164.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_21 (port_0) ublock_order(c)",
                "Data: _fused_op_21 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_21": "Data"
            },
            "input_nodes": [
                "_fused_op_21",
                "_fused_op_21"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_164.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_164.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_164.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_164",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 27446
        },
        "layernorm_164.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_163 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_164.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_163": "Data",
                "lc.input_tensor.layernorm_164.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_163",
                "lc.input_tensor.layernorm_164.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_164.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_21 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_21"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_164",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 27442
        },
        "layernorm_164.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_164.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_164.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_164.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_164.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_164.dc.multiply.4",
                "lc.input_tensor.layernorm_164.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_164.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_22 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_22"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_164",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 27448
        },
        "layernorm_203.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_26 (port_0) ublock_order(c)",
                "Data: _fused_op_26 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_26": "Data"
            },
            "input_nodes": [
                "_fused_op_26",
                "_fused_op_26"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_203.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_203.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_203.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_203",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 27518
        },
        "layernorm_203.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_202 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_203.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_202": "Data",
                "lc.input_tensor.layernorm_203.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_202",
                "lc.input_tensor.layernorm_203.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_203.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_26 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_26"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_203",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 27514
        },
        "layernorm_203.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_203.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_203.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_203.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_203.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_203.dc.multiply.4",
                "lc.input_tensor.layernorm_203.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_203.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_27 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_27"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_203",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 27520
        },
        "layernorm_217.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_28 (port_0) ublock_order(c)",
                "Data: _fused_op_28 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_28": "Data"
            },
            "input_nodes": [
                "_fused_op_28",
                "_fused_op_28"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_217.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_217.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_217.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_217",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 27550
        },
        "layernorm_217.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_216 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_217.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_216": "Data",
                "lc.input_tensor.layernorm_217.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_216",
                "lc.input_tensor.layernorm_217.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_217.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_28 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_28"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_217",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 27546
        },
        "layernorm_217.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_217.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_217.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_217.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_217.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_217.dc.multiply.4",
                "lc.input_tensor.layernorm_217.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_217.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_29 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_29"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_217",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 27552
        },
        "layernorm_256.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_33 (port_0) ublock_order(c)",
                "Data: _fused_op_33 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_33": "Data"
            },
            "input_nodes": [
                "_fused_op_33",
                "_fused_op_33"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_256.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_256.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_256.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_256",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 27622
        },
        "layernorm_256.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_255 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_256.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_255": "Data",
                "lc.input_tensor.layernorm_256.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_255",
                "lc.input_tensor.layernorm_256.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_256.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_33 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_33"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_256",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 27618
        },
        "layernorm_256.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_256.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_256.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_256.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_256.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_256.dc.multiply.4",
                "lc.input_tensor.layernorm_256.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_256.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_34 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_34"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_256",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 27624
        },
        "layernorm_270.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_35 (port_0) ublock_order(c)",
                "Data: _fused_op_35 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_35": "Data"
            },
            "input_nodes": [
                "_fused_op_35",
                "_fused_op_35"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_270.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_270.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_270.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_270",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 27654
        },
        "layernorm_270.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_269 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_270.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_269": "Data",
                "lc.input_tensor.layernorm_270.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_269",
                "lc.input_tensor.layernorm_270.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_270.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_35 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_35"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_270",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 27650
        },
        "layernorm_270.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_270.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_270.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_270.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_270.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_270.dc.multiply.4",
                "lc.input_tensor.layernorm_270.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_270.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_36 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_36"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_270",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 27656
        },
        "layernorm_309.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_40 (port_0) ublock_order(c)",
                "Data: _fused_op_40 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_40": "Data"
            },
            "input_nodes": [
                "_fused_op_40",
                "_fused_op_40"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_309.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_309.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_309.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_309",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 27726
        },
        "layernorm_309.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_308 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_309.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_308": "Data",
                "lc.input_tensor.layernorm_309.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_308",
                "lc.input_tensor.layernorm_309.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_309.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_40 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_40"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_309",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 27722
        },
        "layernorm_309.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_309.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_309.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_309.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_309.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_309.dc.multiply.4",
                "lc.input_tensor.layernorm_309.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_309.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_41 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_41"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_309",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 27728
        },
        "layernorm_323.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_42 (port_0) ublock_order(c)",
                "Data: _fused_op_42 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_42": "Data"
            },
            "input_nodes": [
                "_fused_op_42",
                "_fused_op_42"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_323.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_323.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_323.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_323",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 27758
        },
        "layernorm_323.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_322 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_323.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_322": "Data",
                "lc.input_tensor.layernorm_323.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_322",
                "lc.input_tensor.layernorm_323.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_323.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_42 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_42"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_323",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 27754
        },
        "layernorm_323.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_323.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_323.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_323.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_323.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_323.dc.multiply.4",
                "lc.input_tensor.layernorm_323.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_323.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_43 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_43"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_323",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 27760
        },
        "layernorm_362.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_47 (port_0) ublock_order(c)",
                "Data: _fused_op_47 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_47": "Data"
            },
            "input_nodes": [
                "_fused_op_47",
                "_fused_op_47"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_362.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_362.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_362.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_362",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 27830
        },
        "layernorm_362.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_361 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_362.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_361": "Data",
                "lc.input_tensor.layernorm_362.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_361",
                "lc.input_tensor.layernorm_362.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_362.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_47 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_47"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_362",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 27826
        },
        "layernorm_362.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_362.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_362.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_362.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_362.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_362.dc.multiply.4",
                "lc.input_tensor.layernorm_362.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_362.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_48 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_48"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_362",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 27832
        },
        "layernorm_376.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_49 (port_0) ublock_order(c)",
                "Data: _fused_op_49 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_49": "Data"
            },
            "input_nodes": [
                "_fused_op_49",
                "_fused_op_49"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_376.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_376.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_376.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_376",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 27862
        },
        "layernorm_376.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_375 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_376.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_375": "Data",
                "lc.input_tensor.layernorm_376.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_375",
                "lc.input_tensor.layernorm_376.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_376.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_49 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_49"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_376",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 27858
        },
        "layernorm_376.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_376.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_376.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_376.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_376.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_376.dc.multiply.4",
                "lc.input_tensor.layernorm_376.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_376.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_50 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_50"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_376",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 27864
        },
        "layernorm_415.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_54 (port_0) ublock_order(c)",
                "Data: _fused_op_54 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_54": "Data"
            },
            "input_nodes": [
                "_fused_op_54",
                "_fused_op_54"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_415.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_415.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_415.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_415",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 27934
        },
        "layernorm_415.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_414 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_415.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_414": "Data",
                "lc.input_tensor.layernorm_415.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_414",
                "lc.input_tensor.layernorm_415.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_415.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_54 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_54"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_415",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 27930
        },
        "layernorm_415.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_415.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_415.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_415.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_415.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_415.dc.multiply.4",
                "lc.input_tensor.layernorm_415.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_415.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_55 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_55"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_415",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 27936
        },
        "layernorm_429.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_56 (port_0) ublock_order(c)",
                "Data: _fused_op_56 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_56": "Data"
            },
            "input_nodes": [
                "_fused_op_56",
                "_fused_op_56"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_429.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_429.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_429.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_429",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 27966
        },
        "layernorm_429.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_428 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_429.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_428": "Data",
                "lc.input_tensor.layernorm_429.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_428",
                "lc.input_tensor.layernorm_429.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_429.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_56 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_56"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_429",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 27962
        },
        "layernorm_429.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_429.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_429.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_429.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_429.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_429.dc.multiply.4",
                "lc.input_tensor.layernorm_429.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_429.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_57 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_57"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_429",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 27968
        },
        "layernorm_44.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_5 (port_0) ublock_order(c)",
                "Data: _fused_op_5 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_5": "Data"
            },
            "input_nodes": [
                "_fused_op_5",
                "_fused_op_5"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_44.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_44.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_44.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_44",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 27206
        },
        "layernorm_44.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_43 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_44.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_43": "Data",
                "lc.input_tensor.layernorm_44.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_43",
                "lc.input_tensor.layernorm_44.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_44.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_5 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_5"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_44",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 27202
        },
        "layernorm_44.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_44.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_44.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_44.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_44.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_44.dc.multiply.4",
                "lc.input_tensor.layernorm_44.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_44.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_6 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_6"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_44",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 27208
        },
        "layernorm_468.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_61 (port_0) ublock_order(c)",
                "Data: _fused_op_61 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_61": "Data"
            },
            "input_nodes": [
                "_fused_op_61",
                "_fused_op_61"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_468.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_468.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_468.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_468",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 28038
        },
        "layernorm_468.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_467 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_468.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_467": "Data",
                "lc.input_tensor.layernorm_468.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_467",
                "lc.input_tensor.layernorm_468.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_468.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_61 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_61"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_468",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 28034
        },
        "layernorm_468.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_468.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_468.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_468.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_468.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_468.dc.multiply.4",
                "lc.input_tensor.layernorm_468.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_468.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_62 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_62"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_468",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 28040
        },
        "layernorm_482.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_63 (port_0) ublock_order(c)",
                "Data: _fused_op_63 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_63": "Data"
            },
            "input_nodes": [
                "_fused_op_63",
                "_fused_op_63"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_482.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_482.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_482.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_482",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 28070
        },
        "layernorm_482.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_481 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_482.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_481": "Data",
                "lc.input_tensor.layernorm_482.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_481",
                "lc.input_tensor.layernorm_482.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_482.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_63 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_63"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_482",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 28066
        },
        "layernorm_482.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_482.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_482.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_482.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_482.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_482.dc.multiply.4",
                "lc.input_tensor.layernorm_482.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_482.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_64 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_64"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_482",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 28072
        },
        "layernorm_521.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_68 (port_0) ublock_order(c)",
                "Data: _fused_op_68 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_68": "Data"
            },
            "input_nodes": [
                "_fused_op_68",
                "_fused_op_68"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_521.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_521.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_521.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_521",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 28142
        },
        "layernorm_521.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_520 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_521.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_520": "Data",
                "lc.input_tensor.layernorm_521.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_520",
                "lc.input_tensor.layernorm_521.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_521.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_68 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_68"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_521",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 28138
        },
        "layernorm_521.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_521.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_521.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_521.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_521.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_521.dc.multiply.4",
                "lc.input_tensor.layernorm_521.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_521.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_69 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_69"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_521",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 28144
        },
        "layernorm_535.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_70 (port_0) ublock_order(c)",
                "Data: _fused_op_70 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_70": "Data"
            },
            "input_nodes": [
                "_fused_op_70",
                "_fused_op_70"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_535.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_535.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_535.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_535",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 28174
        },
        "layernorm_535.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_534 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_535.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_534": "Data",
                "lc.input_tensor.layernorm_535.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_534",
                "lc.input_tensor.layernorm_535.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_535.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_70 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_70"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_535",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 28170
        },
        "layernorm_535.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_535.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_535.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_535.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_535.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_535.dc.multiply.4",
                "lc.input_tensor.layernorm_535.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_535.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_71 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_71"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_535",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 28176
        },
        "layernorm_574.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_75 (port_0) ublock_order(c)",
                "Data: _fused_op_75 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_75": "Data"
            },
            "input_nodes": [
                "_fused_op_75",
                "_fused_op_75"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_574.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_574.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_574.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_574",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 28246
        },
        "layernorm_574.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_573 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_574.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_573": "Data",
                "lc.input_tensor.layernorm_574.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_573",
                "lc.input_tensor.layernorm_574.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_574.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_75 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_75"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_574",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 28242
        },
        "layernorm_574.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_574.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_574.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_574.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_574.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_574.dc.multiply.4",
                "lc.input_tensor.layernorm_574.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_574.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_76 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_76"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_574",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 28248
        },
        "layernorm_58.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_7 (port_0) ublock_order(c)",
                "Data: _fused_op_7 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_7": "Data"
            },
            "input_nodes": [
                "_fused_op_7",
                "_fused_op_7"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_58.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_58.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_58.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_58",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 27238
        },
        "layernorm_58.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_57 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_58.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_57": "Data",
                "lc.input_tensor.layernorm_58.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_57",
                "lc.input_tensor.layernorm_58.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_58.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_7 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_7"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_58",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 27234
        },
        "layernorm_58.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_58.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_58.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_58.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_58.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_58.dc.multiply.4",
                "lc.input_tensor.layernorm_58.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_58.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_8 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_8"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_58",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 27240
        },
        "layernorm_588.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_77 (port_0) ublock_order(c)",
                "Data: _fused_op_77 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_77": "Data"
            },
            "input_nodes": [
                "_fused_op_77",
                "_fused_op_77"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_588.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_588.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_588.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_588",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 28278
        },
        "layernorm_588.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_587 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_588.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_587": "Data",
                "lc.input_tensor.layernorm_588.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_587",
                "lc.input_tensor.layernorm_588.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_588.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_77 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_77"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_588",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 28274
        },
        "layernorm_588.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_588.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_588.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_588.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_588.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_588.dc.multiply.4",
                "lc.input_tensor.layernorm_588.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_588.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_78 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_78"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_588",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 28280
        },
        "layernorm_627.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_82 (port_0) ublock_order(c)",
                "Data: _fused_op_82 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_82": "Data"
            },
            "input_nodes": [
                "_fused_op_82",
                "_fused_op_82"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_627.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_627.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_627.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_627",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 28350
        },
        "layernorm_627.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_626 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_627.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_626": "Data",
                "lc.input_tensor.layernorm_627.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_626",
                "lc.input_tensor.layernorm_627.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_627.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_82 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_82"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_627",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 28346
        },
        "layernorm_627.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_627.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_627.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_627.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_627.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_627.dc.multiply.4",
                "lc.input_tensor.layernorm_627.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_627.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_83 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_83"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_627",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 28352
        },
        "layernorm_641.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_84 (port_0) ublock_order(c)",
                "Data: _fused_op_84 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_84": "Data"
            },
            "input_nodes": [
                "_fused_op_84",
                "_fused_op_84"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_641.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_641.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_641.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_641",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 28382
        },
        "layernorm_641.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_640 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_641.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_640": "Data",
                "lc.input_tensor.layernorm_641.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_640",
                "lc.input_tensor.layernorm_641.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_641.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_84 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_84"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_641",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 28378
        },
        "layernorm_641.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_641.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_641.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_641.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_641.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_641.dc.multiply.4",
                "lc.input_tensor.layernorm_641.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_641.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_85 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_85"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_641",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 28384
        },
        "layernorm_680.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_89 (port_0) ublock_order(c)",
                "Data: _fused_op_89 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_89": "Data"
            },
            "input_nodes": [
                "_fused_op_89",
                "_fused_op_89"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_680.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_680.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_680.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_680",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 28454
        },
        "layernorm_680.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_679 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_680.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_679": "Data",
                "lc.input_tensor.layernorm_680.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_679",
                "lc.input_tensor.layernorm_680.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_680.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_89 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_89"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_680",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 28450
        },
        "layernorm_680.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_680.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_680.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_680.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_680.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_680.dc.multiply.4",
                "lc.input_tensor.layernorm_680.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_680.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_90 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_90"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_680",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 28456
        },
        "layernorm_694.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_91 (port_0) ublock_order(c)",
                "Data: _fused_op_91 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_91": "Data"
            },
            "input_nodes": [
                "_fused_op_91",
                "_fused_op_91"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_694.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_694.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_694.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_694",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 28486
        },
        "layernorm_694.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_693 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_694.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_693": "Data",
                "lc.input_tensor.layernorm_694.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_693",
                "lc.input_tensor.layernorm_694.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_694.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_91 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_91"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_694",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 28482
        },
        "layernorm_694.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_694.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_694.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_694.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_694.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_694.dc.multiply.4",
                "lc.input_tensor.layernorm_694.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_694.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_92 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_92"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_694",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 28488
        },
        "layernorm_733.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_96 (port_0) ublock_order(c)",
                "Data: _fused_op_96 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_96": "Data"
            },
            "input_nodes": [
                "_fused_op_96",
                "_fused_op_96"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_733.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_733.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_733.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_733",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 28558
        },
        "layernorm_733.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_732 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_733.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_732": "Data",
                "lc.input_tensor.layernorm_733.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_732",
                "lc.input_tensor.layernorm_733.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_733.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_96 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_96"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_733",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 28554
        },
        "layernorm_733.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_733.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_733.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_733.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_733.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_733.dc.multiply.4",
                "lc.input_tensor.layernorm_733.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_733.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_97 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_97"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_733",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 28560
        },
        "layernorm_747.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_98 (port_0) ublock_order(c)",
                "Data: _fused_op_98 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_98": "Data"
            },
            "input_nodes": [
                "_fused_op_98",
                "_fused_op_98"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_747.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_747.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_747.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_747",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 28590
        },
        "layernorm_747.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_746 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_747.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_746": "Data",
                "lc.input_tensor.layernorm_747.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_746",
                "lc.input_tensor.layernorm_747.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_747.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_98 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_98"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_747",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 28586
        },
        "layernorm_747.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_747.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_747.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_747.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_747.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_747.dc.multiply.4",
                "lc.input_tensor.layernorm_747.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_747.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_99 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_99"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_747",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 28592
        },
        "layernorm_786.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_103 (port_0) ublock_order(c)",
                "Data: _fused_op_103 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_103": "Data"
            },
            "input_nodes": [
                "_fused_op_103",
                "_fused_op_103"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_786.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_786.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_786.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_786",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 28662
        },
        "layernorm_786.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_785 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_786.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_785": "Data",
                "lc.input_tensor.layernorm_786.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_785",
                "lc.input_tensor.layernorm_786.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_786.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_103 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_103"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_786",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 28658
        },
        "layernorm_786.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_786.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_786.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_786.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_786.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_786.dc.multiply.4",
                "lc.input_tensor.layernorm_786.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_786.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_104 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_104"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_786",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 28664
        },
        "layernorm_800.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_105 (port_0) ublock_order(c)",
                "Data: _fused_op_105 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_105": "Data"
            },
            "input_nodes": [
                "_fused_op_105",
                "_fused_op_105"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_800.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_800.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_800.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_800",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 28694
        },
        "layernorm_800.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_799 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_800.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_799": "Data",
                "lc.input_tensor.layernorm_800.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_799",
                "lc.input_tensor.layernorm_800.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_800.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_105 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_105"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_800",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 28690
        },
        "layernorm_800.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_800.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_800.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_800.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_800.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_800.dc.multiply.4",
                "lc.input_tensor.layernorm_800.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_800.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_106 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_106"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_800",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 28696
        },
        "layernorm_839.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_110 (port_0) ublock_order(c)",
                "Data: _fused_op_110 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_110": "Data"
            },
            "input_nodes": [
                "_fused_op_110",
                "_fused_op_110"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_839.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_839.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_839.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_839",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 28766
        },
        "layernorm_839.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_838 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_839.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_838": "Data",
                "lc.input_tensor.layernorm_839.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_838",
                "lc.input_tensor.layernorm_839.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_839.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_110 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_110"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_839",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 28762
        },
        "layernorm_839.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_839.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_839.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_839.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_839.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_839.dc.multiply.4",
                "lc.input_tensor.layernorm_839.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_839.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_111 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_111"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_839",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 28768
        },
        "layernorm_853.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_112 (port_0) ublock_order(c)",
                "Data: _fused_op_112 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_112": "Data"
            },
            "input_nodes": [
                "_fused_op_112",
                "_fused_op_112"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_853.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_853.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_853.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_853",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 28798
        },
        "layernorm_853.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_852 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_853.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_852": "Data",
                "lc.input_tensor.layernorm_853.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_852",
                "lc.input_tensor.layernorm_853.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_853.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_112 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_112"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_853",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 28794
        },
        "layernorm_853.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_853.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_853.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_853.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_853.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_853.dc.multiply.4",
                "lc.input_tensor.layernorm_853.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_853.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_113 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_113"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_853",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 28800
        },
        "layernorm_892.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_117 (port_0) ublock_order(c)",
                "Data: _fused_op_117 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_117": "Data"
            },
            "input_nodes": [
                "_fused_op_117",
                "_fused_op_117"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_892.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_892.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_892.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_892",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 28870
        },
        "layernorm_892.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_891 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_892.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_891": "Data",
                "lc.input_tensor.layernorm_892.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_891",
                "lc.input_tensor.layernorm_892.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_892.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_117 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_117"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_892",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 28866
        },
        "layernorm_892.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_892.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_892.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_892.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_892.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_892.dc.multiply.4",
                "lc.input_tensor.layernorm_892.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_892.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_118 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_118"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_892",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 28872
        },
        "layernorm_906.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_119 (port_0) ublock_order(c)",
                "Data: _fused_op_119 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_119": "Data"
            },
            "input_nodes": [
                "_fused_op_119",
                "_fused_op_119"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_906.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_906.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_906.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_906",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 28902
        },
        "layernorm_906.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_905 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_906.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_905": "Data",
                "lc.input_tensor.layernorm_906.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_905",
                "lc.input_tensor.layernorm_906.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_906.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_119 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_119"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_906",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 28898
        },
        "layernorm_906.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_906.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_906.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_906.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_906.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_906.dc.multiply.4",
                "lc.input_tensor.layernorm_906.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_906.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_120 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_120"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_906",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 28904
        },
        "layernorm_945.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_124 (port_0) ublock_order(c)",
                "Data: _fused_op_124 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_124": "Data"
            },
            "input_nodes": [
                "_fused_op_124",
                "_fused_op_124"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_945.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_945.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_945.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_945",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 28974
        },
        "layernorm_945.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_944 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_945.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_944": "Data",
                "lc.input_tensor.layernorm_945.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_944",
                "lc.input_tensor.layernorm_945.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_945.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_124 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_124"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_945",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 28970
        },
        "layernorm_945.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_945.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_945.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_945.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_945.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_945.dc.multiply.4",
                "lc.input_tensor.layernorm_945.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_945.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_125 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_125"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_945",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 28976
        },
        "layernorm_959.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_126 (port_0) ublock_order(c)",
                "Data: _fused_op_126 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_126": "Data"
            },
            "input_nodes": [
                "_fused_op_126",
                "_fused_op_126"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_959.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_959.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_959.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_959",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 29006
        },
        "layernorm_959.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_958 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_959.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_958": "Data",
                "lc.input_tensor.layernorm_959.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_958",
                "lc.input_tensor.layernorm_959.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_959.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_126 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_126"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_959",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 29002
        },
        "layernorm_959.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_959.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_959.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_959.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_959.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_959.dc.multiply.4",
                "lc.input_tensor.layernorm_959.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_959.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_127 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_127"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_959",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 29008
        },
        "layernorm_97.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_12 (port_0) ublock_order(c)",
                "Data: _fused_op_12 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_12": "Data"
            },
            "input_nodes": [
                "_fused_op_12",
                "_fused_op_12"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_97.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_97.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_97.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_97",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 27310
        },
        "layernorm_97.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_96 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_97.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_96": "Data",
                "lc.input_tensor.layernorm_97.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_96",
                "lc.input_tensor.layernorm_97.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_97.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_12 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_12"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_97",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 27306
        },
        "layernorm_97.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_97.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_97.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_97.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_97.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_97.dc.multiply.4",
                "lc.input_tensor.layernorm_97.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_97.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_13 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_13"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_97",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 27312
        },
        "layernorm_998.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_131 (port_0) ublock_order(c)",
                "Data: _fused_op_131 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_131": "Data"
            },
            "input_nodes": [
                "_fused_op_131",
                "_fused_op_131"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_998.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_998.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_998.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_998",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 29078
        },
        "layernorm_998.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_997 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_998.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_997": "Data",
                "lc.input_tensor.layernorm_998.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_997",
                "lc.input_tensor.layernorm_998.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_998.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_131 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_131"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_998",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 29074
        },
        "layernorm_998.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_998.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_998.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_998.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_998.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_998.dc.multiply.4",
                "lc.input_tensor.layernorm_998.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_998.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_132 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_132"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_998",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 29080
        },
        "lc.input_tensor.layernorm_0.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_0.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_0.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_0.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEmbeddings::embeddings/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_0",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27119
        },
        "lc.input_tensor.layernorm_0.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_0.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_0.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_0.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEmbeddings::embeddings/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_0",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27126
        },
        "lc.input_tensor.layernorm_1012.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_1012.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_1012.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1012.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1012",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29105
        },
        "lc.input_tensor.layernorm_1012.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_1012.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_1012.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1012.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1012",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29111
        },
        "lc.input_tensor.layernorm_1051.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_1051.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_1051.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1051.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1051",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29177
        },
        "lc.input_tensor.layernorm_1051.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_1051.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_1051.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1051.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1051",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29183
        },
        "lc.input_tensor.layernorm_1065.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_1065.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_1065.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1065.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1065",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29209
        },
        "lc.input_tensor.layernorm_1065.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_1065.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_1065.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1065.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1065",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29215
        },
        "lc.input_tensor.layernorm_1104.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_1104.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_1104.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1104.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1104",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29281
        },
        "lc.input_tensor.layernorm_1104.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_1104.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_1104.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1104.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1104",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29287
        },
        "lc.input_tensor.layernorm_111.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_111.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_111.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_111.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_111",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27337
        },
        "lc.input_tensor.layernorm_111.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_111.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_111.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_111.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_111",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27343
        },
        "lc.input_tensor.layernorm_1118.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_1118.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_1118.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1118.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1118",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29313
        },
        "lc.input_tensor.layernorm_1118.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_1118.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_1118.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1118.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1118",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29319
        },
        "lc.input_tensor.layernorm_1157.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_1157.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_1157.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1157.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1157",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29385
        },
        "lc.input_tensor.layernorm_1157.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_1157.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_1157.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1157.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1157",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29391
        },
        "lc.input_tensor.layernorm_1171.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_1171.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_1171.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1171.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1171",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29417
        },
        "lc.input_tensor.layernorm_1171.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_1171.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_1171.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1171.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1171",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29423
        },
        "lc.input_tensor.layernorm_1210.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_1210.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_1210.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1210.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1210",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29489
        },
        "lc.input_tensor.layernorm_1210.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_1210.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_1210.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1210.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1210",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29495
        },
        "lc.input_tensor.layernorm_1224.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_1224.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_1224.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1224.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1224",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29521
        },
        "lc.input_tensor.layernorm_1224.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_1224.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_1224.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1224.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1224",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29527
        },
        "lc.input_tensor.layernorm_1263.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_1263.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_1263.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1263.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1263",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29593
        },
        "lc.input_tensor.layernorm_1263.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_1263.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_1263.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1263.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1263",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29599
        },
        "lc.input_tensor.layernorm_1277.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_1277.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_1277.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1277.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1277",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29625
        },
        "lc.input_tensor.layernorm_1277.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_1277.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_1277.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1277.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1277",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29631
        },
        "lc.input_tensor.layernorm_150.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_150.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_150.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_150.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_150",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27409
        },
        "lc.input_tensor.layernorm_150.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_150.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_150.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_150.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_150",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27415
        },
        "lc.input_tensor.layernorm_164.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_164.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_164.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_164.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_164",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27441
        },
        "lc.input_tensor.layernorm_164.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_164.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_164.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_164.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_164",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27447
        },
        "lc.input_tensor.layernorm_203.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_203.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_203.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_203.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_203",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27513
        },
        "lc.input_tensor.layernorm_203.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_203.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_203.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_203.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_203",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27519
        },
        "lc.input_tensor.layernorm_217.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_217.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_217.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_217.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_217",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27545
        },
        "lc.input_tensor.layernorm_217.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_217.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_217.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_217.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_217",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27551
        },
        "lc.input_tensor.layernorm_256.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_256.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_256.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_256.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_256",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27617
        },
        "lc.input_tensor.layernorm_256.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_256.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_256.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_256.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_256",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27623
        },
        "lc.input_tensor.layernorm_270.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_270.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_270.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_270.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_270",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27649
        },
        "lc.input_tensor.layernorm_270.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_270.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_270.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_270.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_270",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27655
        },
        "lc.input_tensor.layernorm_309.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_309.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_309.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_309.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_309",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27721
        },
        "lc.input_tensor.layernorm_309.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_309.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_309.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_309.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_309",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27727
        },
        "lc.input_tensor.layernorm_323.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_323.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_323.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_323.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_323",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27753
        },
        "lc.input_tensor.layernorm_323.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_323.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_323.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_323.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_323",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27759
        },
        "lc.input_tensor.layernorm_362.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_362.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_362.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_362.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_362",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27825
        },
        "lc.input_tensor.layernorm_362.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_362.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_362.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_362.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_362",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27831
        },
        "lc.input_tensor.layernorm_376.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_376.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_376.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_376.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_376",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27857
        },
        "lc.input_tensor.layernorm_376.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_376.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_376.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_376.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_376",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27863
        },
        "lc.input_tensor.layernorm_415.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_415.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_415.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_415.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_415",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27929
        },
        "lc.input_tensor.layernorm_415.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_415.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_415.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_415.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_415",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27935
        },
        "lc.input_tensor.layernorm_429.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_429.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_429.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_429.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_429",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27961
        },
        "lc.input_tensor.layernorm_429.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_429.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_429.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_429.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_429",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27967
        },
        "lc.input_tensor.layernorm_44.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_44.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_44.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_44.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_44",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27201
        },
        "lc.input_tensor.layernorm_44.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_44.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_44.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_44.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_44",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27207
        },
        "lc.input_tensor.layernorm_468.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_468.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_468.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_468.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_468",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28033
        },
        "lc.input_tensor.layernorm_468.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_468.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_468.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_468.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_468",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28039
        },
        "lc.input_tensor.layernorm_482.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_482.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_482.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_482.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_482",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28065
        },
        "lc.input_tensor.layernorm_482.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_482.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_482.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_482.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_482",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28071
        },
        "lc.input_tensor.layernorm_521.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_521.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_521.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_521.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_521",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28137
        },
        "lc.input_tensor.layernorm_521.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_521.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_521.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_521.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_521",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28143
        },
        "lc.input_tensor.layernorm_535.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_535.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_535.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_535.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_535",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28169
        },
        "lc.input_tensor.layernorm_535.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_535.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_535.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_535.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_535",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28175
        },
        "lc.input_tensor.layernorm_574.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_574.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_574.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_574.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_574",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28241
        },
        "lc.input_tensor.layernorm_574.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_574.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_574.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_574.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_574",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28247
        },
        "lc.input_tensor.layernorm_58.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_58.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_58.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_58.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_58",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27233
        },
        "lc.input_tensor.layernorm_58.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_58.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_58.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_58.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_58",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27239
        },
        "lc.input_tensor.layernorm_588.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_588.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_588.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_588.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_588",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28273
        },
        "lc.input_tensor.layernorm_588.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_588.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_588.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_588.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_588",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28279
        },
        "lc.input_tensor.layernorm_627.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_627.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_627.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_627.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_627",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28345
        },
        "lc.input_tensor.layernorm_627.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_627.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_627.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_627.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_627",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28351
        },
        "lc.input_tensor.layernorm_641.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_641.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_641.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_641.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_641",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28377
        },
        "lc.input_tensor.layernorm_641.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_641.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_641.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_641.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_641",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28383
        },
        "lc.input_tensor.layernorm_680.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_680.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_680.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_680.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_680",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28449
        },
        "lc.input_tensor.layernorm_680.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_680.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_680.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_680.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_680",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28455
        },
        "lc.input_tensor.layernorm_694.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_694.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_694.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_694.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_694",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28481
        },
        "lc.input_tensor.layernorm_694.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_694.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_694.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_694.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_694",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28487
        },
        "lc.input_tensor.layernorm_733.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_733.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_733.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_733.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_733",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28553
        },
        "lc.input_tensor.layernorm_733.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_733.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_733.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_733.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_733",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28559
        },
        "lc.input_tensor.layernorm_747.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_747.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_747.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_747.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_747",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28585
        },
        "lc.input_tensor.layernorm_747.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_747.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_747.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_747.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_747",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28591
        },
        "lc.input_tensor.layernorm_786.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_786.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_786.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_786.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_786",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28657
        },
        "lc.input_tensor.layernorm_786.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_786.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_786.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_786.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_786",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28663
        },
        "lc.input_tensor.layernorm_800.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_800.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_800.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_800.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_800",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28689
        },
        "lc.input_tensor.layernorm_800.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_800.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_800.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_800.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_800",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28695
        },
        "lc.input_tensor.layernorm_839.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_839.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_839.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_839.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_839",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28761
        },
        "lc.input_tensor.layernorm_839.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_839.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_839.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_839.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_839",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28767
        },
        "lc.input_tensor.layernorm_853.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_853.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_853.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_853.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_853",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28793
        },
        "lc.input_tensor.layernorm_853.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_853.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_853.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_853.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_853",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28799
        },
        "lc.input_tensor.layernorm_892.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_892.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_892.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_892.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_892",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28865
        },
        "lc.input_tensor.layernorm_892.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_892.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_892.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_892.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_892",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28871
        },
        "lc.input_tensor.layernorm_906.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_906.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_906.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_906.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_906",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28897
        },
        "lc.input_tensor.layernorm_906.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_906.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_906.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_906.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_906",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28903
        },
        "lc.input_tensor.layernorm_945.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_945.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_945.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_945.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_945",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28969
        },
        "lc.input_tensor.layernorm_945.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_945.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_945.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_945.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_945",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28975
        },
        "lc.input_tensor.layernorm_959.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_959.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_959.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_959.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_959",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29001
        },
        "lc.input_tensor.layernorm_959.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_959.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_959.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_959.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_959",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29007
        },
        "lc.input_tensor.layernorm_97.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_97.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_97.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_97.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_97",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27305
        },
        "lc.input_tensor.layernorm_97.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_97.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_97.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_97.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_97",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27311
        },
        "lc.input_tensor.layernorm_998.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_998.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_998.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_998.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_998",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29073
        },
        "lc.input_tensor.layernorm_998.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_998.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_998.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_998.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_998",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29079
        },
        "lc.input_tensor.softmax_1031.dc.reduce_sum.3.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.softmax_1031.dc.reduce_sum.3.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: softmax_1031.dc.reduce_sum.3.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_1031.dc.reduce_sum.3.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_1031",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29152
        },
        "lc.input_tensor.softmax_1084.dc.reduce_sum.3.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.softmax_1084.dc.reduce_sum.3.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: softmax_1084.dc.reduce_sum.3.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_1084.dc.reduce_sum.3.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_1084",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29256
        },
        "lc.input_tensor.softmax_1137.dc.reduce_sum.3.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.softmax_1137.dc.reduce_sum.3.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: softmax_1137.dc.reduce_sum.3.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_1137.dc.reduce_sum.3.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_1137",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29360
        },
        "lc.input_tensor.softmax_1190.dc.reduce_sum.3.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.softmax_1190.dc.reduce_sum.3.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: softmax_1190.dc.reduce_sum.3.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_1190.dc.reduce_sum.3.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_1190",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29464
        },
        "lc.input_tensor.softmax_1243.dc.reduce_sum.3.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.softmax_1243.dc.reduce_sum.3.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: softmax_1243.dc.reduce_sum.3.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_1243.dc.reduce_sum.3.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_1243",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29568
        },
        "lc.input_tensor.softmax_130.dc.reduce_sum.3.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.softmax_130.dc.reduce_sum.3.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: softmax_130.dc.reduce_sum.3.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_130.dc.reduce_sum.3.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_130",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27384
        },
        "lc.input_tensor.softmax_183.dc.reduce_sum.3.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.softmax_183.dc.reduce_sum.3.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: softmax_183.dc.reduce_sum.3.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_183.dc.reduce_sum.3.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_183",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27488
        },
        "lc.input_tensor.softmax_236.dc.reduce_sum.3.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.softmax_236.dc.reduce_sum.3.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: softmax_236.dc.reduce_sum.3.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_236.dc.reduce_sum.3.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_236",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27592
        },
        "lc.input_tensor.softmax_24.dc.reduce_sum.3.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.softmax_24.dc.reduce_sum.3.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: softmax_24.dc.reduce_sum.3.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_24.dc.reduce_sum.3.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_24",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27176
        },
        "lc.input_tensor.softmax_289.dc.reduce_sum.3.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.softmax_289.dc.reduce_sum.3.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: softmax_289.dc.reduce_sum.3.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_289.dc.reduce_sum.3.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_289",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27696
        },
        "lc.input_tensor.softmax_342.dc.reduce_sum.3.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.softmax_342.dc.reduce_sum.3.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: softmax_342.dc.reduce_sum.3.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_342.dc.reduce_sum.3.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_342",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27800
        },
        "lc.input_tensor.softmax_395.dc.reduce_sum.3.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.softmax_395.dc.reduce_sum.3.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: softmax_395.dc.reduce_sum.3.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_395.dc.reduce_sum.3.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_395",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27904
        },
        "lc.input_tensor.softmax_448.dc.reduce_sum.3.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.softmax_448.dc.reduce_sum.3.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: softmax_448.dc.reduce_sum.3.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_448.dc.reduce_sum.3.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_448",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28008
        },
        "lc.input_tensor.softmax_501.dc.reduce_sum.3.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.softmax_501.dc.reduce_sum.3.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: softmax_501.dc.reduce_sum.3.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_501.dc.reduce_sum.3.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_501",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28112
        },
        "lc.input_tensor.softmax_554.dc.reduce_sum.3.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.softmax_554.dc.reduce_sum.3.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: softmax_554.dc.reduce_sum.3.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_554.dc.reduce_sum.3.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_554",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28216
        },
        "lc.input_tensor.softmax_607.dc.reduce_sum.3.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.softmax_607.dc.reduce_sum.3.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: softmax_607.dc.reduce_sum.3.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_607.dc.reduce_sum.3.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_607",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28320
        },
        "lc.input_tensor.softmax_660.dc.reduce_sum.3.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.softmax_660.dc.reduce_sum.3.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: softmax_660.dc.reduce_sum.3.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_660.dc.reduce_sum.3.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_660",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28424
        },
        "lc.input_tensor.softmax_713.dc.reduce_sum.3.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.softmax_713.dc.reduce_sum.3.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: softmax_713.dc.reduce_sum.3.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_713.dc.reduce_sum.3.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_713",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28528
        },
        "lc.input_tensor.softmax_766.dc.reduce_sum.3.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.softmax_766.dc.reduce_sum.3.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: softmax_766.dc.reduce_sum.3.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_766.dc.reduce_sum.3.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_766",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28632
        },
        "lc.input_tensor.softmax_77.dc.reduce_sum.3.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.softmax_77.dc.reduce_sum.3.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: softmax_77.dc.reduce_sum.3.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_77.dc.reduce_sum.3.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_77",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27280
        },
        "lc.input_tensor.softmax_819.dc.reduce_sum.3.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.softmax_819.dc.reduce_sum.3.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: softmax_819.dc.reduce_sum.3.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_819.dc.reduce_sum.3.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_819",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28736
        },
        "lc.input_tensor.softmax_872.dc.reduce_sum.3.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.softmax_872.dc.reduce_sum.3.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: softmax_872.dc.reduce_sum.3.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_872.dc.reduce_sum.3.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_872",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28840
        },
        "lc.input_tensor.softmax_925.dc.reduce_sum.3.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.softmax_925.dc.reduce_sum.3.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: softmax_925.dc.reduce_sum.3.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_925.dc.reduce_sum.3.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_925",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28944
        },
        "lc.input_tensor.softmax_978.dc.reduce_sum.3.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.softmax_978.dc.reduce_sum.3.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: softmax_978.dc.reduce_sum.3.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_978.dc.reduce_sum.3.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_978",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 29048
        },
        "matmul_10": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_1 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.0.attention.self.key.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.0.attention.self.key.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_1": "Data",
                "bert.encoder.layer.0.attention.self.key.bias": "Data",
                "bert.encoder.layer.0.attention.self.key.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_1",
                "bert.encoder.layer.0.attention.self.key.weight",
                "bert.encoder.layer.0.attention.self.key.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_10",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_16 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_16"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key",
                "original_op_name": "matmul_10",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27149
        },
        "matmul_100": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_13 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.1.intermediate.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.1.intermediate.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_13": "Data",
                "bert.encoder.layer.1.intermediate.dense.bias": "Data",
                "bert.encoder.layer.1.intermediate.dense.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_13",
                "bert.encoder.layer.1.intermediate.dense.weight",
                "bert.encoder.layer.1.intermediate.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_100",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: gelu_103 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "gelu_103"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_100",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27327
        },
        "matmul_1001": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_132 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.18.intermediate.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.18.intermediate.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_132": "Data",
                "bert.encoder.layer.18.intermediate.dense.bias": "Data",
                "bert.encoder.layer.18.intermediate.dense.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_132",
                "bert.encoder.layer.18.intermediate.dense.weight",
                "bert.encoder.layer.18.intermediate.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1001",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: gelu_1004 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "gelu_1004"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_1001",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 29095
        },
        "matmul_1007": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: gelu_1004 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.18.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.18.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.18.output.dense.bias": "Data",
                "bert.encoder.layer.18.output.dense.weight": "Data",
                "gelu_1004": "Data"
            },
            "input_nodes": [
                "gelu_1004",
                "bert.encoder.layer.18.output.dense.weight",
                "bert.encoder.layer.18.output.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1007",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_1011 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_1011"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_1007",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 29099
        },
        "matmul_1015": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_134 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.19.attention.self.query.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.19.attention.self.query.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_134": "Data",
                "bert.encoder.layer.19.attention.self.query.bias": "Data",
                "bert.encoder.layer.19.attention.self.query.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_134",
                "bert.encoder.layer.19.attention.self.query.weight",
                "bert.encoder.layer.19.attention.self.query.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1015",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1027 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1027"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query",
                "original_op_name": "matmul_1015",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 29127
        },
        "matmul_1021": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_134 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.19.attention.self.key.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.19.attention.self.key.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_134": "Data",
                "bert.encoder.layer.19.attention.self.key.bias": "Data",
                "bert.encoder.layer.19.attention.self.key.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_134",
                "bert.encoder.layer.19.attention.self.key.weight",
                "bert.encoder.layer.19.attention.self.key.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1021",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1027 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1027"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key",
                "original_op_name": "matmul_1021",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 29133
        },
        "matmul_1027": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1015 (port_0) ublock_order(c)",
                "Data: matmul_1021 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "matmul_1015": "Data",
                "matmul_1021": "Data"
            },
            "input_nodes": [
                "matmul_1015",
                "matmul_1021"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [],
                            "buda_attrs": {},
                            "named_attrs": {
                                "dim0": -2,
                                "dim1": -1,
                                "z_dim_slice": -1
                            },
                            "type": "transpose"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "vslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1027",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_135 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_135"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_1027",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 29140
        },
        "matmul_1035": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_134 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.19.attention.self.value.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.19.attention.self.value.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_134": "Data",
                "bert.encoder.layer.19.attention.self.value.bias": "Data",
                "bert.encoder.layer.19.attention.self.value.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_134",
                "bert.encoder.layer.19.attention.self.value.weight",
                "bert.encoder.layer.19.attention.self.value.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1035",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1042 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1042"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value",
                "original_op_name": "matmul_1035",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 29162
        },
        "matmul_1042": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_137 (port_0) ublock_order(c)",
                "Data: matmul_1035 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_137": "Data",
                "matmul_1035": "Data"
            },
            "input_nodes": [
                "_fused_op_137",
                "matmul_1035"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1042",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1046 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1046"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_1042",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 29168
        },
        "matmul_1046": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1042 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.19.attention.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.19.attention.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.19.attention.output.dense.bias": "Data",
                "bert.encoder.layer.19.attention.output.dense.weight": "Data",
                "matmul_1042": "Data"
            },
            "input_nodes": [
                "matmul_1042",
                "bert.encoder.layer.19.attention.output.dense.weight",
                "bert.encoder.layer.19.attention.output.dense.bias"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hstack"
                        }
                    }
                ],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1046",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_1050 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_1050"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_1046",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 29171
        },
        "matmul_1054": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_139 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.19.intermediate.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.19.intermediate.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_139": "Data",
                "bert.encoder.layer.19.intermediate.dense.bias": "Data",
                "bert.encoder.layer.19.intermediate.dense.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_139",
                "bert.encoder.layer.19.intermediate.dense.weight",
                "bert.encoder.layer.19.intermediate.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1054",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: gelu_1057 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "gelu_1057"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_1054",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 29199
        },
        "matmul_106": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: gelu_103 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.1.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.1.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.1.output.dense.bias": "Data",
                "bert.encoder.layer.1.output.dense.weight": "Data",
                "gelu_103": "Data"
            },
            "input_nodes": [
                "gelu_103",
                "bert.encoder.layer.1.output.dense.weight",
                "bert.encoder.layer.1.output.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_106",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_110 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_110"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_106",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27331
        },
        "matmul_1060": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: gelu_1057 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.19.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.19.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.19.output.dense.bias": "Data",
                "bert.encoder.layer.19.output.dense.weight": "Data",
                "gelu_1057": "Data"
            },
            "input_nodes": [
                "gelu_1057",
                "bert.encoder.layer.19.output.dense.weight",
                "bert.encoder.layer.19.output.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1060",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_1064 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_1064"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_1060",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 29203
        },
        "matmul_1068": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_141 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.20.attention.self.query.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.20.attention.self.query.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_141": "Data",
                "bert.encoder.layer.20.attention.self.query.bias": "Data",
                "bert.encoder.layer.20.attention.self.query.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_141",
                "bert.encoder.layer.20.attention.self.query.weight",
                "bert.encoder.layer.20.attention.self.query.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1068",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1080 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1080"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query",
                "original_op_name": "matmul_1068",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 29231
        },
        "matmul_1074": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_141 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.20.attention.self.key.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.20.attention.self.key.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_141": "Data",
                "bert.encoder.layer.20.attention.self.key.bias": "Data",
                "bert.encoder.layer.20.attention.self.key.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_141",
                "bert.encoder.layer.20.attention.self.key.weight",
                "bert.encoder.layer.20.attention.self.key.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1074",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1080 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1080"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key",
                "original_op_name": "matmul_1074",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 29237
        },
        "matmul_1080": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1068 (port_0) ublock_order(c)",
                "Data: matmul_1074 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "matmul_1068": "Data",
                "matmul_1074": "Data"
            },
            "input_nodes": [
                "matmul_1068",
                "matmul_1074"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [],
                            "buda_attrs": {},
                            "named_attrs": {
                                "dim0": -2,
                                "dim1": -1,
                                "z_dim_slice": -1
                            },
                            "type": "transpose"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "vslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1080",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_142 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_142"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_1080",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 29244
        },
        "matmul_1088": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_141 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.20.attention.self.value.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.20.attention.self.value.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_141": "Data",
                "bert.encoder.layer.20.attention.self.value.bias": "Data",
                "bert.encoder.layer.20.attention.self.value.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_141",
                "bert.encoder.layer.20.attention.self.value.weight",
                "bert.encoder.layer.20.attention.self.value.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1088",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1095 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1095"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value",
                "original_op_name": "matmul_1088",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 29266
        },
        "matmul_1095": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_144 (port_0) ublock_order(c)",
                "Data: matmul_1088 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_144": "Data",
                "matmul_1088": "Data"
            },
            "input_nodes": [
                "_fused_op_144",
                "matmul_1088"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1095",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1099 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1099"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_1095",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 29272
        },
        "matmul_1099": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1095 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.20.attention.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.20.attention.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.20.attention.output.dense.bias": "Data",
                "bert.encoder.layer.20.attention.output.dense.weight": "Data",
                "matmul_1095": "Data"
            },
            "input_nodes": [
                "matmul_1095",
                "bert.encoder.layer.20.attention.output.dense.weight",
                "bert.encoder.layer.20.attention.output.dense.bias"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hstack"
                        }
                    }
                ],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1099",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_1103 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_1103"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_1099",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 29275
        },
        "matmul_1107": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_146 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.20.intermediate.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.20.intermediate.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_146": "Data",
                "bert.encoder.layer.20.intermediate.dense.bias": "Data",
                "bert.encoder.layer.20.intermediate.dense.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_146",
                "bert.encoder.layer.20.intermediate.dense.weight",
                "bert.encoder.layer.20.intermediate.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1107",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: gelu_1110 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "gelu_1110"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_1107",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 29303
        },
        "matmul_1113": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: gelu_1110 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.20.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.20.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.20.output.dense.bias": "Data",
                "bert.encoder.layer.20.output.dense.weight": "Data",
                "gelu_1110": "Data"
            },
            "input_nodes": [
                "gelu_1110",
                "bert.encoder.layer.20.output.dense.weight",
                "bert.encoder.layer.20.output.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1113",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_1117 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_1117"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_1113",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 29307
        },
        "matmul_1121": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_148 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.21.attention.self.query.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.21.attention.self.query.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_148": "Data",
                "bert.encoder.layer.21.attention.self.query.bias": "Data",
                "bert.encoder.layer.21.attention.self.query.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_148",
                "bert.encoder.layer.21.attention.self.query.weight",
                "bert.encoder.layer.21.attention.self.query.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1121",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1133 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1133"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query",
                "original_op_name": "matmul_1121",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 29335
        },
        "matmul_1127": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_148 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.21.attention.self.key.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.21.attention.self.key.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_148": "Data",
                "bert.encoder.layer.21.attention.self.key.bias": "Data",
                "bert.encoder.layer.21.attention.self.key.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_148",
                "bert.encoder.layer.21.attention.self.key.weight",
                "bert.encoder.layer.21.attention.self.key.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1127",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1133 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1133"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key",
                "original_op_name": "matmul_1127",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 29341
        },
        "matmul_1133": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1121 (port_0) ublock_order(c)",
                "Data: matmul_1127 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "matmul_1121": "Data",
                "matmul_1127": "Data"
            },
            "input_nodes": [
                "matmul_1121",
                "matmul_1127"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [],
                            "buda_attrs": {},
                            "named_attrs": {
                                "dim0": -2,
                                "dim1": -1,
                                "z_dim_slice": -1
                            },
                            "type": "transpose"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "vslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1133",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_149 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_149"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_1133",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 29348
        },
        "matmul_114": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_15 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.2.attention.self.query.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.2.attention.self.query.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_15": "Data",
                "bert.encoder.layer.2.attention.self.query.bias": "Data",
                "bert.encoder.layer.2.attention.self.query.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_15",
                "bert.encoder.layer.2.attention.self.query.weight",
                "bert.encoder.layer.2.attention.self.query.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_114",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_126 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_126"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query",
                "original_op_name": "matmul_114",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27359
        },
        "matmul_1141": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_148 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.21.attention.self.value.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.21.attention.self.value.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_148": "Data",
                "bert.encoder.layer.21.attention.self.value.bias": "Data",
                "bert.encoder.layer.21.attention.self.value.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_148",
                "bert.encoder.layer.21.attention.self.value.weight",
                "bert.encoder.layer.21.attention.self.value.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1141",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1148 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1148"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value",
                "original_op_name": "matmul_1141",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 29370
        },
        "matmul_1148": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_151 (port_0) ublock_order(c)",
                "Data: matmul_1141 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_151": "Data",
                "matmul_1141": "Data"
            },
            "input_nodes": [
                "_fused_op_151",
                "matmul_1141"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1148",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1152 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1152"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_1148",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 29376
        },
        "matmul_1152": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1148 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.21.attention.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.21.attention.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.21.attention.output.dense.bias": "Data",
                "bert.encoder.layer.21.attention.output.dense.weight": "Data",
                "matmul_1148": "Data"
            },
            "input_nodes": [
                "matmul_1148",
                "bert.encoder.layer.21.attention.output.dense.weight",
                "bert.encoder.layer.21.attention.output.dense.bias"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hstack"
                        }
                    }
                ],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1152",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_1156 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_1156"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_1152",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 29379
        },
        "matmul_1160": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_153 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.21.intermediate.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.21.intermediate.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_153": "Data",
                "bert.encoder.layer.21.intermediate.dense.bias": "Data",
                "bert.encoder.layer.21.intermediate.dense.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_153",
                "bert.encoder.layer.21.intermediate.dense.weight",
                "bert.encoder.layer.21.intermediate.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1160",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: gelu_1163 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "gelu_1163"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_1160",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 29407
        },
        "matmul_1166": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: gelu_1163 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.21.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.21.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.21.output.dense.bias": "Data",
                "bert.encoder.layer.21.output.dense.weight": "Data",
                "gelu_1163": "Data"
            },
            "input_nodes": [
                "gelu_1163",
                "bert.encoder.layer.21.output.dense.weight",
                "bert.encoder.layer.21.output.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1166",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_1170 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_1170"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_1166",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 29411
        },
        "matmul_1174": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_155 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.22.attention.self.query.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.22.attention.self.query.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_155": "Data",
                "bert.encoder.layer.22.attention.self.query.bias": "Data",
                "bert.encoder.layer.22.attention.self.query.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_155",
                "bert.encoder.layer.22.attention.self.query.weight",
                "bert.encoder.layer.22.attention.self.query.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1174",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1186 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1186"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query",
                "original_op_name": "matmul_1174",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 29439
        },
        "matmul_1180": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_155 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.22.attention.self.key.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.22.attention.self.key.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_155": "Data",
                "bert.encoder.layer.22.attention.self.key.bias": "Data",
                "bert.encoder.layer.22.attention.self.key.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_155",
                "bert.encoder.layer.22.attention.self.key.weight",
                "bert.encoder.layer.22.attention.self.key.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1180",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1186 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1186"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key",
                "original_op_name": "matmul_1180",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 29445
        },
        "matmul_1186": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1174 (port_0) ublock_order(c)",
                "Data: matmul_1180 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "matmul_1174": "Data",
                "matmul_1180": "Data"
            },
            "input_nodes": [
                "matmul_1174",
                "matmul_1180"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [],
                            "buda_attrs": {},
                            "named_attrs": {
                                "dim0": -2,
                                "dim1": -1,
                                "z_dim_slice": -1
                            },
                            "type": "transpose"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "vslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1186",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_156 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_156"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_1186",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 29452
        },
        "matmul_1194": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_155 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.22.attention.self.value.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.22.attention.self.value.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_155": "Data",
                "bert.encoder.layer.22.attention.self.value.bias": "Data",
                "bert.encoder.layer.22.attention.self.value.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_155",
                "bert.encoder.layer.22.attention.self.value.weight",
                "bert.encoder.layer.22.attention.self.value.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1194",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1201 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1201"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value",
                "original_op_name": "matmul_1194",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 29474
        },
        "matmul_120": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_15 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.2.attention.self.key.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.2.attention.self.key.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_15": "Data",
                "bert.encoder.layer.2.attention.self.key.bias": "Data",
                "bert.encoder.layer.2.attention.self.key.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_15",
                "bert.encoder.layer.2.attention.self.key.weight",
                "bert.encoder.layer.2.attention.self.key.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_120",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_126 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_126"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key",
                "original_op_name": "matmul_120",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27365
        },
        "matmul_1201": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_158 (port_0) ublock_order(c)",
                "Data: matmul_1194 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_158": "Data",
                "matmul_1194": "Data"
            },
            "input_nodes": [
                "_fused_op_158",
                "matmul_1194"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1201",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1205 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1205"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_1201",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 29480
        },
        "matmul_1205": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1201 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.22.attention.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.22.attention.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.22.attention.output.dense.bias": "Data",
                "bert.encoder.layer.22.attention.output.dense.weight": "Data",
                "matmul_1201": "Data"
            },
            "input_nodes": [
                "matmul_1201",
                "bert.encoder.layer.22.attention.output.dense.weight",
                "bert.encoder.layer.22.attention.output.dense.bias"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hstack"
                        }
                    }
                ],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1205",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_1209 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_1209"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_1205",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 29483
        },
        "matmul_1213": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_160 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.22.intermediate.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.22.intermediate.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_160": "Data",
                "bert.encoder.layer.22.intermediate.dense.bias": "Data",
                "bert.encoder.layer.22.intermediate.dense.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_160",
                "bert.encoder.layer.22.intermediate.dense.weight",
                "bert.encoder.layer.22.intermediate.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1213",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: gelu_1216 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "gelu_1216"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_1213",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 29511
        },
        "matmul_1219": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: gelu_1216 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.22.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.22.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.22.output.dense.bias": "Data",
                "bert.encoder.layer.22.output.dense.weight": "Data",
                "gelu_1216": "Data"
            },
            "input_nodes": [
                "gelu_1216",
                "bert.encoder.layer.22.output.dense.weight",
                "bert.encoder.layer.22.output.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1219",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_1223 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_1223"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_1219",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 29515
        },
        "matmul_1227": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_162 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.23.attention.self.query.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.23.attention.self.query.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_162": "Data",
                "bert.encoder.layer.23.attention.self.query.bias": "Data",
                "bert.encoder.layer.23.attention.self.query.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_162",
                "bert.encoder.layer.23.attention.self.query.weight",
                "bert.encoder.layer.23.attention.self.query.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1227",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1239 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1239"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query",
                "original_op_name": "matmul_1227",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 29543
        },
        "matmul_1233": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_162 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.23.attention.self.key.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.23.attention.self.key.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_162": "Data",
                "bert.encoder.layer.23.attention.self.key.bias": "Data",
                "bert.encoder.layer.23.attention.self.key.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_162",
                "bert.encoder.layer.23.attention.self.key.weight",
                "bert.encoder.layer.23.attention.self.key.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1233",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1239 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1239"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key",
                "original_op_name": "matmul_1233",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 29549
        },
        "matmul_1239": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1227 (port_0) ublock_order(c)",
                "Data: matmul_1233 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "matmul_1227": "Data",
                "matmul_1233": "Data"
            },
            "input_nodes": [
                "matmul_1227",
                "matmul_1233"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [],
                            "buda_attrs": {},
                            "named_attrs": {
                                "dim0": -2,
                                "dim1": -1,
                                "z_dim_slice": -1
                            },
                            "type": "transpose"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "vslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1239",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_163 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_163"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_1239",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 29556
        },
        "matmul_1247": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_162 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.23.attention.self.value.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.23.attention.self.value.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_162": "Data",
                "bert.encoder.layer.23.attention.self.value.bias": "Data",
                "bert.encoder.layer.23.attention.self.value.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_162",
                "bert.encoder.layer.23.attention.self.value.weight",
                "bert.encoder.layer.23.attention.self.value.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1247",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1254 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1254"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value",
                "original_op_name": "matmul_1247",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 29578
        },
        "matmul_1254": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_165 (port_0) ublock_order(c)",
                "Data: matmul_1247 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_165": "Data",
                "matmul_1247": "Data"
            },
            "input_nodes": [
                "_fused_op_165",
                "matmul_1247"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1254",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1258 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1258"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_1254",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 29584
        },
        "matmul_1258": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1254 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.23.attention.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.23.attention.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.23.attention.output.dense.bias": "Data",
                "bert.encoder.layer.23.attention.output.dense.weight": "Data",
                "matmul_1254": "Data"
            },
            "input_nodes": [
                "matmul_1254",
                "bert.encoder.layer.23.attention.output.dense.weight",
                "bert.encoder.layer.23.attention.output.dense.bias"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hstack"
                        }
                    }
                ],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1258",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_1262 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_1262"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_1258",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 29587
        },
        "matmul_126": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_114 (port_0) ublock_order(c)",
                "Data: matmul_120 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "matmul_114": "Data",
                "matmul_120": "Data"
            },
            "input_nodes": [
                "matmul_114",
                "matmul_120"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [],
                            "buda_attrs": {},
                            "named_attrs": {
                                "dim0": -2,
                                "dim1": -1,
                                "z_dim_slice": -1
                            },
                            "type": "transpose"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "vslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_126",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_16 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_16"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_126",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27372
        },
        "matmul_1266": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_167 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.23.intermediate.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.23.intermediate.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_167": "Data",
                "bert.encoder.layer.23.intermediate.dense.bias": "Data",
                "bert.encoder.layer.23.intermediate.dense.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_167",
                "bert.encoder.layer.23.intermediate.dense.weight",
                "bert.encoder.layer.23.intermediate.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1266",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: gelu_1269 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "gelu_1269"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_1266",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 29615
        },
        "matmul_1272": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: gelu_1269 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.23.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.23.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.23.output.dense.bias": "Data",
                "bert.encoder.layer.23.output.dense.weight": "Data",
                "gelu_1269": "Data"
            },
            "input_nodes": [
                "gelu_1269",
                "bert.encoder.layer.23.output.dense.weight",
                "bert.encoder.layer.23.output.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1272",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_1276 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_1276"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_1272",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 29619
        },
        "matmul_1281": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_169 (port_0) ublock_order(c)",
                "Data: qa_outputs.weight (port_1) ublock_order(r)",
                "Data: qa_outputs.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_169": "Data",
                "qa_outputs.bias": "Data",
                "qa_outputs.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_169",
                "qa_outputs.weight",
                "qa_outputs.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1281",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1281_output_nop_0 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1281_output_nop_0"
            ],
            "pybuda": 1,
            "tags": {
                "original_op_name": "matmul_1281",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 29647
        },
        "matmul_1281_output_nop_0": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1281 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "matmul_1281": "Data"
            },
            "input_nodes": [
                "matmul_1281"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1281_output_nop_0",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: bert_large_tt_1.output_reshape_1285 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "bert_large_tt_1.output_reshape_1285"
            ],
            "pybuda": 1,
            "tags": {
                "original_op_name": "matmul_1281",
                "original_op_type": "matmul"
            },
            "type": "nop",
            "unique_id": 29825
        },
        "matmul_1288": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_169 (port_0) ublock_order(c)",
                "Data: qa_outputs.weight_fork_clone19 (port_1) ublock_order(r)",
                "Data: qa_outputs.bias_fork_clone12 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_169": "Data",
                "qa_outputs.bias_fork_clone12": "Data",
                "qa_outputs.weight_fork_clone19": "Data"
            },
            "input_nodes": [
                "_fused_op_169",
                "qa_outputs.weight_fork_clone19",
                "qa_outputs.bias_fork_clone12"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1288",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1288_output_nop_0 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1288_output_nop_0"
            ],
            "pybuda": 1,
            "tags": {
                "original_op_name": "matmul_1288",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 29651
        },
        "matmul_1288_output_nop_0": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1288 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "matmul_1288": "Data"
            },
            "input_nodes": [
                "matmul_1288"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1288_output_nop_0",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: bert_large_tt_1.output_reshape_1292 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "bert_large_tt_1.output_reshape_1292"
            ],
            "pybuda": 1,
            "tags": {
                "original_op_name": "matmul_1288",
                "original_op_type": "matmul"
            },
            "type": "nop",
            "unique_id": 29826
        },
        "matmul_134": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_15 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.2.attention.self.value.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.2.attention.self.value.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_15": "Data",
                "bert.encoder.layer.2.attention.self.value.bias": "Data",
                "bert.encoder.layer.2.attention.self.value.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_15",
                "bert.encoder.layer.2.attention.self.value.weight",
                "bert.encoder.layer.2.attention.self.value.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_134",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_141 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_141"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value",
                "original_op_name": "matmul_134",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27394
        },
        "matmul_141": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_18 (port_0) ublock_order(c)",
                "Data: matmul_134 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_18": "Data",
                "matmul_134": "Data"
            },
            "input_nodes": [
                "_fused_op_18",
                "matmul_134"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_141",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_145 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_145"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_141",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27400
        },
        "matmul_145": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_141 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.2.attention.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.2.attention.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.2.attention.output.dense.bias": "Data",
                "bert.encoder.layer.2.attention.output.dense.weight": "Data",
                "matmul_141": "Data"
            },
            "input_nodes": [
                "matmul_141",
                "bert.encoder.layer.2.attention.output.dense.weight",
                "bert.encoder.layer.2.attention.output.dense.bias"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hstack"
                        }
                    }
                ],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_145",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_149 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_149"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_145",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27403
        },
        "matmul_153": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_20 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.2.intermediate.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.2.intermediate.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_20": "Data",
                "bert.encoder.layer.2.intermediate.dense.bias": "Data",
                "bert.encoder.layer.2.intermediate.dense.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_20",
                "bert.encoder.layer.2.intermediate.dense.weight",
                "bert.encoder.layer.2.intermediate.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_153",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: gelu_156 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "gelu_156"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_153",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27431
        },
        "matmul_159": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: gelu_156 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.2.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.2.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.2.output.dense.bias": "Data",
                "bert.encoder.layer.2.output.dense.weight": "Data",
                "gelu_156": "Data"
            },
            "input_nodes": [
                "gelu_156",
                "bert.encoder.layer.2.output.dense.weight",
                "bert.encoder.layer.2.output.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_159",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_163 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_163"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_159",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27435
        },
        "matmul_16": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_4 (port_0) ublock_order(c)",
                "Data: matmul_10 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "matmul_10": "Data",
                "matmul_4": "Data"
            },
            "input_nodes": [
                "matmul_4",
                "matmul_10"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [],
                            "buda_attrs": {},
                            "named_attrs": {
                                "dim0": -2,
                                "dim1": -1,
                                "z_dim_slice": -1
                            },
                            "type": "transpose"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "vslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_16",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_2 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_2"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_16",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27156
        },
        "matmul_167": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_22 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.3.attention.self.query.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.3.attention.self.query.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_22": "Data",
                "bert.encoder.layer.3.attention.self.query.bias": "Data",
                "bert.encoder.layer.3.attention.self.query.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_22",
                "bert.encoder.layer.3.attention.self.query.weight",
                "bert.encoder.layer.3.attention.self.query.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_167",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_179 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_179"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query",
                "original_op_name": "matmul_167",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27463
        },
        "matmul_173": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_22 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.3.attention.self.key.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.3.attention.self.key.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_22": "Data",
                "bert.encoder.layer.3.attention.self.key.bias": "Data",
                "bert.encoder.layer.3.attention.self.key.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_22",
                "bert.encoder.layer.3.attention.self.key.weight",
                "bert.encoder.layer.3.attention.self.key.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_173",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_179 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_179"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key",
                "original_op_name": "matmul_173",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27469
        },
        "matmul_179": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_167 (port_0) ublock_order(c)",
                "Data: matmul_173 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "matmul_167": "Data",
                "matmul_173": "Data"
            },
            "input_nodes": [
                "matmul_167",
                "matmul_173"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [],
                            "buda_attrs": {},
                            "named_attrs": {
                                "dim0": -2,
                                "dim1": -1,
                                "z_dim_slice": -1
                            },
                            "type": "transpose"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "vslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_179",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_23 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_23"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_179",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27476
        },
        "matmul_187": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_22 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.3.attention.self.value.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.3.attention.self.value.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_22": "Data",
                "bert.encoder.layer.3.attention.self.value.bias": "Data",
                "bert.encoder.layer.3.attention.self.value.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_22",
                "bert.encoder.layer.3.attention.self.value.weight",
                "bert.encoder.layer.3.attention.self.value.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_187",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_194 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_194"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value",
                "original_op_name": "matmul_187",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27498
        },
        "matmul_194": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_25 (port_0) ublock_order(c)",
                "Data: matmul_187 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_25": "Data",
                "matmul_187": "Data"
            },
            "input_nodes": [
                "_fused_op_25",
                "matmul_187"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_194",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_198 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_198"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_194",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27504
        },
        "matmul_198": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_194 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.3.attention.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.3.attention.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.3.attention.output.dense.bias": "Data",
                "bert.encoder.layer.3.attention.output.dense.weight": "Data",
                "matmul_194": "Data"
            },
            "input_nodes": [
                "matmul_194",
                "bert.encoder.layer.3.attention.output.dense.weight",
                "bert.encoder.layer.3.attention.output.dense.bias"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hstack"
                        }
                    }
                ],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_198",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_202 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_202"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_198",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27507
        },
        "matmul_206": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_27 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.3.intermediate.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.3.intermediate.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_27": "Data",
                "bert.encoder.layer.3.intermediate.dense.bias": "Data",
                "bert.encoder.layer.3.intermediate.dense.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_27",
                "bert.encoder.layer.3.intermediate.dense.weight",
                "bert.encoder.layer.3.intermediate.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_206",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: gelu_209 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "gelu_209"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_206",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27535
        },
        "matmul_212": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: gelu_209 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.3.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.3.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.3.output.dense.bias": "Data",
                "bert.encoder.layer.3.output.dense.weight": "Data",
                "gelu_209": "Data"
            },
            "input_nodes": [
                "gelu_209",
                "bert.encoder.layer.3.output.dense.weight",
                "bert.encoder.layer.3.output.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_212",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_216 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_216"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_212",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27539
        },
        "matmul_220": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_29 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.4.attention.self.query.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.4.attention.self.query.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_29": "Data",
                "bert.encoder.layer.4.attention.self.query.bias": "Data",
                "bert.encoder.layer.4.attention.self.query.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_29",
                "bert.encoder.layer.4.attention.self.query.weight",
                "bert.encoder.layer.4.attention.self.query.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_220",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_232 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_232"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query",
                "original_op_name": "matmul_220",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27567
        },
        "matmul_226": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_29 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.4.attention.self.key.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.4.attention.self.key.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_29": "Data",
                "bert.encoder.layer.4.attention.self.key.bias": "Data",
                "bert.encoder.layer.4.attention.self.key.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_29",
                "bert.encoder.layer.4.attention.self.key.weight",
                "bert.encoder.layer.4.attention.self.key.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_226",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_232 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_232"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key",
                "original_op_name": "matmul_226",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27573
        },
        "matmul_232": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_220 (port_0) ublock_order(c)",
                "Data: matmul_226 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "matmul_220": "Data",
                "matmul_226": "Data"
            },
            "input_nodes": [
                "matmul_220",
                "matmul_226"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [],
                            "buda_attrs": {},
                            "named_attrs": {
                                "dim0": -2,
                                "dim1": -1,
                                "z_dim_slice": -1
                            },
                            "type": "transpose"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "vslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_232",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_30 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_30"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_232",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27580
        },
        "matmul_240": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_29 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.4.attention.self.value.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.4.attention.self.value.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_29": "Data",
                "bert.encoder.layer.4.attention.self.value.bias": "Data",
                "bert.encoder.layer.4.attention.self.value.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_29",
                "bert.encoder.layer.4.attention.self.value.weight",
                "bert.encoder.layer.4.attention.self.value.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_240",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_247 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_247"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value",
                "original_op_name": "matmul_240",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27602
        },
        "matmul_247": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_32 (port_0) ublock_order(c)",
                "Data: matmul_240 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_32": "Data",
                "matmul_240": "Data"
            },
            "input_nodes": [
                "_fused_op_32",
                "matmul_240"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_247",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_251 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_251"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_247",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27608
        },
        "matmul_251": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_247 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.4.attention.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.4.attention.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.4.attention.output.dense.bias": "Data",
                "bert.encoder.layer.4.attention.output.dense.weight": "Data",
                "matmul_247": "Data"
            },
            "input_nodes": [
                "matmul_247",
                "bert.encoder.layer.4.attention.output.dense.weight",
                "bert.encoder.layer.4.attention.output.dense.bias"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hstack"
                        }
                    }
                ],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_251",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_255 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_255"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_251",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27611
        },
        "matmul_259": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_34 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.4.intermediate.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.4.intermediate.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_34": "Data",
                "bert.encoder.layer.4.intermediate.dense.bias": "Data",
                "bert.encoder.layer.4.intermediate.dense.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_34",
                "bert.encoder.layer.4.intermediate.dense.weight",
                "bert.encoder.layer.4.intermediate.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_259",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: gelu_262 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "gelu_262"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_259",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27639
        },
        "matmul_265": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: gelu_262 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.4.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.4.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.4.output.dense.bias": "Data",
                "bert.encoder.layer.4.output.dense.weight": "Data",
                "gelu_262": "Data"
            },
            "input_nodes": [
                "gelu_262",
                "bert.encoder.layer.4.output.dense.weight",
                "bert.encoder.layer.4.output.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_265",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_269 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_269"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_265",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27643
        },
        "matmul_273": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_36 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.5.attention.self.query.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.5.attention.self.query.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_36": "Data",
                "bert.encoder.layer.5.attention.self.query.bias": "Data",
                "bert.encoder.layer.5.attention.self.query.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_36",
                "bert.encoder.layer.5.attention.self.query.weight",
                "bert.encoder.layer.5.attention.self.query.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_273",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_285 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_285"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query",
                "original_op_name": "matmul_273",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27671
        },
        "matmul_279": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_36 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.5.attention.self.key.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.5.attention.self.key.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_36": "Data",
                "bert.encoder.layer.5.attention.self.key.bias": "Data",
                "bert.encoder.layer.5.attention.self.key.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_36",
                "bert.encoder.layer.5.attention.self.key.weight",
                "bert.encoder.layer.5.attention.self.key.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_279",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_285 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_285"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key",
                "original_op_name": "matmul_279",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27677
        },
        "matmul_28": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_1 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.0.attention.self.value.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.0.attention.self.value.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_1": "Data",
                "bert.encoder.layer.0.attention.self.value.bias": "Data",
                "bert.encoder.layer.0.attention.self.value.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_1",
                "bert.encoder.layer.0.attention.self.value.weight",
                "bert.encoder.layer.0.attention.self.value.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_28",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_35 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_35"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value",
                "original_op_name": "matmul_28",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27186
        },
        "matmul_285": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_273 (port_0) ublock_order(c)",
                "Data: matmul_279 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "matmul_273": "Data",
                "matmul_279": "Data"
            },
            "input_nodes": [
                "matmul_273",
                "matmul_279"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [],
                            "buda_attrs": {},
                            "named_attrs": {
                                "dim0": -2,
                                "dim1": -1,
                                "z_dim_slice": -1
                            },
                            "type": "transpose"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "vslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_285",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_37 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_37"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_285",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27684
        },
        "matmul_293": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_36 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.5.attention.self.value.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.5.attention.self.value.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_36": "Data",
                "bert.encoder.layer.5.attention.self.value.bias": "Data",
                "bert.encoder.layer.5.attention.self.value.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_36",
                "bert.encoder.layer.5.attention.self.value.weight",
                "bert.encoder.layer.5.attention.self.value.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_293",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_300 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_300"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value",
                "original_op_name": "matmul_293",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27706
        },
        "matmul_300": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_39 (port_0) ublock_order(c)",
                "Data: matmul_293 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_39": "Data",
                "matmul_293": "Data"
            },
            "input_nodes": [
                "_fused_op_39",
                "matmul_293"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_300",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_304 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_304"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_300",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27712
        },
        "matmul_304": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_300 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.5.attention.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.5.attention.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.5.attention.output.dense.bias": "Data",
                "bert.encoder.layer.5.attention.output.dense.weight": "Data",
                "matmul_300": "Data"
            },
            "input_nodes": [
                "matmul_300",
                "bert.encoder.layer.5.attention.output.dense.weight",
                "bert.encoder.layer.5.attention.output.dense.bias"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hstack"
                        }
                    }
                ],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_304",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_308 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_308"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_304",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27715
        },
        "matmul_312": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_41 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.5.intermediate.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.5.intermediate.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_41": "Data",
                "bert.encoder.layer.5.intermediate.dense.bias": "Data",
                "bert.encoder.layer.5.intermediate.dense.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_41",
                "bert.encoder.layer.5.intermediate.dense.weight",
                "bert.encoder.layer.5.intermediate.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_312",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: gelu_315 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "gelu_315"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_312",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27743
        },
        "matmul_318": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: gelu_315 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.5.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.5.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.5.output.dense.bias": "Data",
                "bert.encoder.layer.5.output.dense.weight": "Data",
                "gelu_315": "Data"
            },
            "input_nodes": [
                "gelu_315",
                "bert.encoder.layer.5.output.dense.weight",
                "bert.encoder.layer.5.output.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_318",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_322 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_322"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_318",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27747
        },
        "matmul_326": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_43 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.6.attention.self.query.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.6.attention.self.query.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_43": "Data",
                "bert.encoder.layer.6.attention.self.query.bias": "Data",
                "bert.encoder.layer.6.attention.self.query.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_43",
                "bert.encoder.layer.6.attention.self.query.weight",
                "bert.encoder.layer.6.attention.self.query.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_326",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_338 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_338"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query",
                "original_op_name": "matmul_326",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27775
        },
        "matmul_332": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_43 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.6.attention.self.key.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.6.attention.self.key.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_43": "Data",
                "bert.encoder.layer.6.attention.self.key.bias": "Data",
                "bert.encoder.layer.6.attention.self.key.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_43",
                "bert.encoder.layer.6.attention.self.key.weight",
                "bert.encoder.layer.6.attention.self.key.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_332",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_338 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_338"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key",
                "original_op_name": "matmul_332",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27781
        },
        "matmul_338": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_326 (port_0) ublock_order(c)",
                "Data: matmul_332 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "matmul_326": "Data",
                "matmul_332": "Data"
            },
            "input_nodes": [
                "matmul_326",
                "matmul_332"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [],
                            "buda_attrs": {},
                            "named_attrs": {
                                "dim0": -2,
                                "dim1": -1,
                                "z_dim_slice": -1
                            },
                            "type": "transpose"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "vslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_338",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_44 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_44"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_338",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27788
        },
        "matmul_346": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_43 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.6.attention.self.value.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.6.attention.self.value.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_43": "Data",
                "bert.encoder.layer.6.attention.self.value.bias": "Data",
                "bert.encoder.layer.6.attention.self.value.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_43",
                "bert.encoder.layer.6.attention.self.value.weight",
                "bert.encoder.layer.6.attention.self.value.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_346",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_353 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_353"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value",
                "original_op_name": "matmul_346",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27810
        },
        "matmul_35": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_4 (port_0) ublock_order(c)",
                "Data: matmul_28 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_4": "Data",
                "matmul_28": "Data"
            },
            "input_nodes": [
                "_fused_op_4",
                "matmul_28"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_35",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_39 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_39"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_35",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27192
        },
        "matmul_353": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_46 (port_0) ublock_order(c)",
                "Data: matmul_346 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_46": "Data",
                "matmul_346": "Data"
            },
            "input_nodes": [
                "_fused_op_46",
                "matmul_346"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_353",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_357 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_357"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_353",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27816
        },
        "matmul_357": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_353 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.6.attention.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.6.attention.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.6.attention.output.dense.bias": "Data",
                "bert.encoder.layer.6.attention.output.dense.weight": "Data",
                "matmul_353": "Data"
            },
            "input_nodes": [
                "matmul_353",
                "bert.encoder.layer.6.attention.output.dense.weight",
                "bert.encoder.layer.6.attention.output.dense.bias"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hstack"
                        }
                    }
                ],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_357",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_361 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_361"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_357",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27819
        },
        "matmul_365": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_48 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.6.intermediate.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.6.intermediate.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_48": "Data",
                "bert.encoder.layer.6.intermediate.dense.bias": "Data",
                "bert.encoder.layer.6.intermediate.dense.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_48",
                "bert.encoder.layer.6.intermediate.dense.weight",
                "bert.encoder.layer.6.intermediate.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_365",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: gelu_368 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "gelu_368"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_365",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27847
        },
        "matmul_371": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: gelu_368 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.6.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.6.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.6.output.dense.bias": "Data",
                "bert.encoder.layer.6.output.dense.weight": "Data",
                "gelu_368": "Data"
            },
            "input_nodes": [
                "gelu_368",
                "bert.encoder.layer.6.output.dense.weight",
                "bert.encoder.layer.6.output.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_371",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_375 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_375"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_371",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27851
        },
        "matmul_379": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_50 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.7.attention.self.query.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.7.attention.self.query.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_50": "Data",
                "bert.encoder.layer.7.attention.self.query.bias": "Data",
                "bert.encoder.layer.7.attention.self.query.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_50",
                "bert.encoder.layer.7.attention.self.query.weight",
                "bert.encoder.layer.7.attention.self.query.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_379",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_391 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_391"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query",
                "original_op_name": "matmul_379",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27879
        },
        "matmul_385": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_50 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.7.attention.self.key.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.7.attention.self.key.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_50": "Data",
                "bert.encoder.layer.7.attention.self.key.bias": "Data",
                "bert.encoder.layer.7.attention.self.key.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_50",
                "bert.encoder.layer.7.attention.self.key.weight",
                "bert.encoder.layer.7.attention.self.key.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_385",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_391 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_391"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key",
                "original_op_name": "matmul_385",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27885
        },
        "matmul_39": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_35 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.0.attention.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.0.attention.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.0.attention.output.dense.bias": "Data",
                "bert.encoder.layer.0.attention.output.dense.weight": "Data",
                "matmul_35": "Data"
            },
            "input_nodes": [
                "matmul_35",
                "bert.encoder.layer.0.attention.output.dense.weight",
                "bert.encoder.layer.0.attention.output.dense.bias"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hstack"
                        }
                    }
                ],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_39",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_43 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_43"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_39",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27195
        },
        "matmul_391": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_379 (port_0) ublock_order(c)",
                "Data: matmul_385 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "matmul_379": "Data",
                "matmul_385": "Data"
            },
            "input_nodes": [
                "matmul_379",
                "matmul_385"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [],
                            "buda_attrs": {},
                            "named_attrs": {
                                "dim0": -2,
                                "dim1": -1,
                                "z_dim_slice": -1
                            },
                            "type": "transpose"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "vslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_391",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_51 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_51"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_391",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27892
        },
        "matmul_399": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_50 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.7.attention.self.value.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.7.attention.self.value.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_50": "Data",
                "bert.encoder.layer.7.attention.self.value.bias": "Data",
                "bert.encoder.layer.7.attention.self.value.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_50",
                "bert.encoder.layer.7.attention.self.value.weight",
                "bert.encoder.layer.7.attention.self.value.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_399",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_406 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_406"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value",
                "original_op_name": "matmul_399",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27914
        },
        "matmul_4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_1 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.0.attention.self.query.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.0.attention.self.query.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_1": "Data",
                "bert.encoder.layer.0.attention.self.query.bias": "Data",
                "bert.encoder.layer.0.attention.self.query.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_1",
                "bert.encoder.layer.0.attention.self.query.weight",
                "bert.encoder.layer.0.attention.self.query.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_16 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_16"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query",
                "original_op_name": "matmul_4",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27143
        },
        "matmul_406": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_53 (port_0) ublock_order(c)",
                "Data: matmul_399 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_53": "Data",
                "matmul_399": "Data"
            },
            "input_nodes": [
                "_fused_op_53",
                "matmul_399"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_406",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_410 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_410"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_406",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27920
        },
        "matmul_410": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_406 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.7.attention.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.7.attention.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.7.attention.output.dense.bias": "Data",
                "bert.encoder.layer.7.attention.output.dense.weight": "Data",
                "matmul_406": "Data"
            },
            "input_nodes": [
                "matmul_406",
                "bert.encoder.layer.7.attention.output.dense.weight",
                "bert.encoder.layer.7.attention.output.dense.bias"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hstack"
                        }
                    }
                ],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_410",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_414 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_414"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_410",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27923
        },
        "matmul_418": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_55 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.7.intermediate.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.7.intermediate.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_55": "Data",
                "bert.encoder.layer.7.intermediate.dense.bias": "Data",
                "bert.encoder.layer.7.intermediate.dense.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_55",
                "bert.encoder.layer.7.intermediate.dense.weight",
                "bert.encoder.layer.7.intermediate.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_418",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: gelu_421 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "gelu_421"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_418",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27951
        },
        "matmul_424": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: gelu_421 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.7.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.7.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.7.output.dense.bias": "Data",
                "bert.encoder.layer.7.output.dense.weight": "Data",
                "gelu_421": "Data"
            },
            "input_nodes": [
                "gelu_421",
                "bert.encoder.layer.7.output.dense.weight",
                "bert.encoder.layer.7.output.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_424",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_428 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_428"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_424",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27955
        },
        "matmul_432": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_57 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.8.attention.self.query.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.8.attention.self.query.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_57": "Data",
                "bert.encoder.layer.8.attention.self.query.bias": "Data",
                "bert.encoder.layer.8.attention.self.query.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_57",
                "bert.encoder.layer.8.attention.self.query.weight",
                "bert.encoder.layer.8.attention.self.query.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_432",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_444 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_444"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query",
                "original_op_name": "matmul_432",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27983
        },
        "matmul_438": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_57 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.8.attention.self.key.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.8.attention.self.key.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_57": "Data",
                "bert.encoder.layer.8.attention.self.key.bias": "Data",
                "bert.encoder.layer.8.attention.self.key.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_57",
                "bert.encoder.layer.8.attention.self.key.weight",
                "bert.encoder.layer.8.attention.self.key.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_438",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_444 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_444"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key",
                "original_op_name": "matmul_438",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27989
        },
        "matmul_444": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_432 (port_0) ublock_order(c)",
                "Data: matmul_438 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "matmul_432": "Data",
                "matmul_438": "Data"
            },
            "input_nodes": [
                "matmul_432",
                "matmul_438"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [],
                            "buda_attrs": {},
                            "named_attrs": {
                                "dim0": -2,
                                "dim1": -1,
                                "z_dim_slice": -1
                            },
                            "type": "transpose"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "vslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_444",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_58 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_58"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_444",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27996
        },
        "matmul_452": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_57 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.8.attention.self.value.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.8.attention.self.value.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_57": "Data",
                "bert.encoder.layer.8.attention.self.value.bias": "Data",
                "bert.encoder.layer.8.attention.self.value.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_57",
                "bert.encoder.layer.8.attention.self.value.weight",
                "bert.encoder.layer.8.attention.self.value.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_452",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_459 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_459"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value",
                "original_op_name": "matmul_452",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28018
        },
        "matmul_459": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_60 (port_0) ublock_order(c)",
                "Data: matmul_452 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_60": "Data",
                "matmul_452": "Data"
            },
            "input_nodes": [
                "_fused_op_60",
                "matmul_452"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_459",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_463 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_463"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_459",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28024
        },
        "matmul_463": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_459 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.8.attention.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.8.attention.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.8.attention.output.dense.bias": "Data",
                "bert.encoder.layer.8.attention.output.dense.weight": "Data",
                "matmul_459": "Data"
            },
            "input_nodes": [
                "matmul_459",
                "bert.encoder.layer.8.attention.output.dense.weight",
                "bert.encoder.layer.8.attention.output.dense.bias"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hstack"
                        }
                    }
                ],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_463",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_467 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_467"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_463",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28027
        },
        "matmul_47": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_6 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.0.intermediate.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.0.intermediate.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_6": "Data",
                "bert.encoder.layer.0.intermediate.dense.bias": "Data",
                "bert.encoder.layer.0.intermediate.dense.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_6",
                "bert.encoder.layer.0.intermediate.dense.weight",
                "bert.encoder.layer.0.intermediate.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_47",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: gelu_50 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "gelu_50"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_47",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27223
        },
        "matmul_471": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_62 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.8.intermediate.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.8.intermediate.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_62": "Data",
                "bert.encoder.layer.8.intermediate.dense.bias": "Data",
                "bert.encoder.layer.8.intermediate.dense.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_62",
                "bert.encoder.layer.8.intermediate.dense.weight",
                "bert.encoder.layer.8.intermediate.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_471",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: gelu_474 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "gelu_474"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_471",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28055
        },
        "matmul_477": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: gelu_474 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.8.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.8.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.8.output.dense.bias": "Data",
                "bert.encoder.layer.8.output.dense.weight": "Data",
                "gelu_474": "Data"
            },
            "input_nodes": [
                "gelu_474",
                "bert.encoder.layer.8.output.dense.weight",
                "bert.encoder.layer.8.output.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_477",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_481 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_481"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_477",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28059
        },
        "matmul_485": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_64 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.9.attention.self.query.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.9.attention.self.query.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_64": "Data",
                "bert.encoder.layer.9.attention.self.query.bias": "Data",
                "bert.encoder.layer.9.attention.self.query.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_64",
                "bert.encoder.layer.9.attention.self.query.weight",
                "bert.encoder.layer.9.attention.self.query.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_485",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_497 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_497"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query",
                "original_op_name": "matmul_485",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28087
        },
        "matmul_491": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_64 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.9.attention.self.key.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.9.attention.self.key.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_64": "Data",
                "bert.encoder.layer.9.attention.self.key.bias": "Data",
                "bert.encoder.layer.9.attention.self.key.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_64",
                "bert.encoder.layer.9.attention.self.key.weight",
                "bert.encoder.layer.9.attention.self.key.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_491",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_497 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_497"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key",
                "original_op_name": "matmul_491",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28093
        },
        "matmul_497": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_485 (port_0) ublock_order(c)",
                "Data: matmul_491 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "matmul_485": "Data",
                "matmul_491": "Data"
            },
            "input_nodes": [
                "matmul_485",
                "matmul_491"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [],
                            "buda_attrs": {},
                            "named_attrs": {
                                "dim0": -2,
                                "dim1": -1,
                                "z_dim_slice": -1
                            },
                            "type": "transpose"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "vslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_497",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_65 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_65"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_497",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28100
        },
        "matmul_505": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_64 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.9.attention.self.value.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.9.attention.self.value.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_64": "Data",
                "bert.encoder.layer.9.attention.self.value.bias": "Data",
                "bert.encoder.layer.9.attention.self.value.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_64",
                "bert.encoder.layer.9.attention.self.value.weight",
                "bert.encoder.layer.9.attention.self.value.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_505",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_512 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_512"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value",
                "original_op_name": "matmul_505",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28122
        },
        "matmul_512": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_67 (port_0) ublock_order(c)",
                "Data: matmul_505 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_67": "Data",
                "matmul_505": "Data"
            },
            "input_nodes": [
                "_fused_op_67",
                "matmul_505"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_512",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_516 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_516"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_512",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28128
        },
        "matmul_516": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_512 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.9.attention.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.9.attention.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.9.attention.output.dense.bias": "Data",
                "bert.encoder.layer.9.attention.output.dense.weight": "Data",
                "matmul_512": "Data"
            },
            "input_nodes": [
                "matmul_512",
                "bert.encoder.layer.9.attention.output.dense.weight",
                "bert.encoder.layer.9.attention.output.dense.bias"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hstack"
                        }
                    }
                ],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_516",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_520 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_520"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_516",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28131
        },
        "matmul_524": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_69 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.9.intermediate.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.9.intermediate.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_69": "Data",
                "bert.encoder.layer.9.intermediate.dense.bias": "Data",
                "bert.encoder.layer.9.intermediate.dense.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_69",
                "bert.encoder.layer.9.intermediate.dense.weight",
                "bert.encoder.layer.9.intermediate.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_524",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: gelu_527 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "gelu_527"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_524",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28159
        },
        "matmul_53": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: gelu_50 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.0.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.0.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.0.output.dense.bias": "Data",
                "bert.encoder.layer.0.output.dense.weight": "Data",
                "gelu_50": "Data"
            },
            "input_nodes": [
                "gelu_50",
                "bert.encoder.layer.0.output.dense.weight",
                "bert.encoder.layer.0.output.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_53",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_57 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_57"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_53",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27227
        },
        "matmul_530": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: gelu_527 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.9.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.9.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.9.output.dense.bias": "Data",
                "bert.encoder.layer.9.output.dense.weight": "Data",
                "gelu_527": "Data"
            },
            "input_nodes": [
                "gelu_527",
                "bert.encoder.layer.9.output.dense.weight",
                "bert.encoder.layer.9.output.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_530",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_534 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_534"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_530",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28163
        },
        "matmul_538": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_71 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.10.attention.self.query.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.10.attention.self.query.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_71": "Data",
                "bert.encoder.layer.10.attention.self.query.bias": "Data",
                "bert.encoder.layer.10.attention.self.query.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_71",
                "bert.encoder.layer.10.attention.self.query.weight",
                "bert.encoder.layer.10.attention.self.query.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_538",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_550 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_550"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query",
                "original_op_name": "matmul_538",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28191
        },
        "matmul_544": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_71 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.10.attention.self.key.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.10.attention.self.key.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_71": "Data",
                "bert.encoder.layer.10.attention.self.key.bias": "Data",
                "bert.encoder.layer.10.attention.self.key.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_71",
                "bert.encoder.layer.10.attention.self.key.weight",
                "bert.encoder.layer.10.attention.self.key.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_544",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_550 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_550"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key",
                "original_op_name": "matmul_544",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28197
        },
        "matmul_550": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_538 (port_0) ublock_order(c)",
                "Data: matmul_544 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "matmul_538": "Data",
                "matmul_544": "Data"
            },
            "input_nodes": [
                "matmul_538",
                "matmul_544"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [],
                            "buda_attrs": {},
                            "named_attrs": {
                                "dim0": -2,
                                "dim1": -1,
                                "z_dim_slice": -1
                            },
                            "type": "transpose"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "vslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_550",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_72 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_72"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_550",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28204
        },
        "matmul_558": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_71 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.10.attention.self.value.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.10.attention.self.value.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_71": "Data",
                "bert.encoder.layer.10.attention.self.value.bias": "Data",
                "bert.encoder.layer.10.attention.self.value.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_71",
                "bert.encoder.layer.10.attention.self.value.weight",
                "bert.encoder.layer.10.attention.self.value.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_558",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_565 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_565"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value",
                "original_op_name": "matmul_558",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28226
        },
        "matmul_565": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_74 (port_0) ublock_order(c)",
                "Data: matmul_558 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_74": "Data",
                "matmul_558": "Data"
            },
            "input_nodes": [
                "_fused_op_74",
                "matmul_558"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_565",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_569 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_569"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_565",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28232
        },
        "matmul_569": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_565 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.10.attention.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.10.attention.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.10.attention.output.dense.bias": "Data",
                "bert.encoder.layer.10.attention.output.dense.weight": "Data",
                "matmul_565": "Data"
            },
            "input_nodes": [
                "matmul_565",
                "bert.encoder.layer.10.attention.output.dense.weight",
                "bert.encoder.layer.10.attention.output.dense.bias"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hstack"
                        }
                    }
                ],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_569",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_573 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_573"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_569",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28235
        },
        "matmul_577": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_76 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.10.intermediate.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.10.intermediate.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_76": "Data",
                "bert.encoder.layer.10.intermediate.dense.bias": "Data",
                "bert.encoder.layer.10.intermediate.dense.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_76",
                "bert.encoder.layer.10.intermediate.dense.weight",
                "bert.encoder.layer.10.intermediate.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_577",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: gelu_580 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "gelu_580"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_577",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28263
        },
        "matmul_583": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: gelu_580 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.10.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.10.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.10.output.dense.bias": "Data",
                "bert.encoder.layer.10.output.dense.weight": "Data",
                "gelu_580": "Data"
            },
            "input_nodes": [
                "gelu_580",
                "bert.encoder.layer.10.output.dense.weight",
                "bert.encoder.layer.10.output.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_583",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_587 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_587"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_583",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28267
        },
        "matmul_591": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_78 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.11.attention.self.query.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.11.attention.self.query.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_78": "Data",
                "bert.encoder.layer.11.attention.self.query.bias": "Data",
                "bert.encoder.layer.11.attention.self.query.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_78",
                "bert.encoder.layer.11.attention.self.query.weight",
                "bert.encoder.layer.11.attention.self.query.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_591",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_603 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_603"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query",
                "original_op_name": "matmul_591",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28295
        },
        "matmul_597": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_78 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.11.attention.self.key.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.11.attention.self.key.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_78": "Data",
                "bert.encoder.layer.11.attention.self.key.bias": "Data",
                "bert.encoder.layer.11.attention.self.key.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_78",
                "bert.encoder.layer.11.attention.self.key.weight",
                "bert.encoder.layer.11.attention.self.key.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_597",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_603 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_603"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key",
                "original_op_name": "matmul_597",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28301
        },
        "matmul_603": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_591 (port_0) ublock_order(c)",
                "Data: matmul_597 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "matmul_591": "Data",
                "matmul_597": "Data"
            },
            "input_nodes": [
                "matmul_591",
                "matmul_597"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [],
                            "buda_attrs": {},
                            "named_attrs": {
                                "dim0": -2,
                                "dim1": -1,
                                "z_dim_slice": -1
                            },
                            "type": "transpose"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "vslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_603",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_79 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_79"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_603",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28308
        },
        "matmul_61": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_8 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.1.attention.self.query.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.1.attention.self.query.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_8": "Data",
                "bert.encoder.layer.1.attention.self.query.bias": "Data",
                "bert.encoder.layer.1.attention.self.query.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_8",
                "bert.encoder.layer.1.attention.self.query.weight",
                "bert.encoder.layer.1.attention.self.query.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_61",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_73 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_73"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query",
                "original_op_name": "matmul_61",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27255
        },
        "matmul_611": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_78 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.11.attention.self.value.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.11.attention.self.value.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_78": "Data",
                "bert.encoder.layer.11.attention.self.value.bias": "Data",
                "bert.encoder.layer.11.attention.self.value.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_78",
                "bert.encoder.layer.11.attention.self.value.weight",
                "bert.encoder.layer.11.attention.self.value.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_611",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_618 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_618"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value",
                "original_op_name": "matmul_611",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28330
        },
        "matmul_618": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_81 (port_0) ublock_order(c)",
                "Data: matmul_611 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_81": "Data",
                "matmul_611": "Data"
            },
            "input_nodes": [
                "_fused_op_81",
                "matmul_611"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_618",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_622 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_622"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_618",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28336
        },
        "matmul_622": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_618 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.11.attention.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.11.attention.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.11.attention.output.dense.bias": "Data",
                "bert.encoder.layer.11.attention.output.dense.weight": "Data",
                "matmul_618": "Data"
            },
            "input_nodes": [
                "matmul_618",
                "bert.encoder.layer.11.attention.output.dense.weight",
                "bert.encoder.layer.11.attention.output.dense.bias"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hstack"
                        }
                    }
                ],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_622",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_626 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_626"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_622",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28339
        },
        "matmul_630": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_83 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.11.intermediate.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.11.intermediate.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_83": "Data",
                "bert.encoder.layer.11.intermediate.dense.bias": "Data",
                "bert.encoder.layer.11.intermediate.dense.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_83",
                "bert.encoder.layer.11.intermediate.dense.weight",
                "bert.encoder.layer.11.intermediate.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_630",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: gelu_633 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "gelu_633"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_630",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28367
        },
        "matmul_636": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: gelu_633 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.11.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.11.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.11.output.dense.bias": "Data",
                "bert.encoder.layer.11.output.dense.weight": "Data",
                "gelu_633": "Data"
            },
            "input_nodes": [
                "gelu_633",
                "bert.encoder.layer.11.output.dense.weight",
                "bert.encoder.layer.11.output.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_636",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_640 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_640"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_636",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28371
        },
        "matmul_644": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_85 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.12.attention.self.query.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.12.attention.self.query.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_85": "Data",
                "bert.encoder.layer.12.attention.self.query.bias": "Data",
                "bert.encoder.layer.12.attention.self.query.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_85",
                "bert.encoder.layer.12.attention.self.query.weight",
                "bert.encoder.layer.12.attention.self.query.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_644",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_656 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_656"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query",
                "original_op_name": "matmul_644",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28399
        },
        "matmul_650": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_85 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.12.attention.self.key.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.12.attention.self.key.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_85": "Data",
                "bert.encoder.layer.12.attention.self.key.bias": "Data",
                "bert.encoder.layer.12.attention.self.key.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_85",
                "bert.encoder.layer.12.attention.self.key.weight",
                "bert.encoder.layer.12.attention.self.key.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_650",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_656 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_656"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key",
                "original_op_name": "matmul_650",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28405
        },
        "matmul_656": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_644 (port_0) ublock_order(c)",
                "Data: matmul_650 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "matmul_644": "Data",
                "matmul_650": "Data"
            },
            "input_nodes": [
                "matmul_644",
                "matmul_650"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [],
                            "buda_attrs": {},
                            "named_attrs": {
                                "dim0": -2,
                                "dim1": -1,
                                "z_dim_slice": -1
                            },
                            "type": "transpose"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "vslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_656",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_86 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_86"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_656",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28412
        },
        "matmul_664": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_85 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.12.attention.self.value.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.12.attention.self.value.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_85": "Data",
                "bert.encoder.layer.12.attention.self.value.bias": "Data",
                "bert.encoder.layer.12.attention.self.value.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_85",
                "bert.encoder.layer.12.attention.self.value.weight",
                "bert.encoder.layer.12.attention.self.value.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_664",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_671 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_671"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value",
                "original_op_name": "matmul_664",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28434
        },
        "matmul_67": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_8 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.1.attention.self.key.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.1.attention.self.key.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_8": "Data",
                "bert.encoder.layer.1.attention.self.key.bias": "Data",
                "bert.encoder.layer.1.attention.self.key.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_8",
                "bert.encoder.layer.1.attention.self.key.weight",
                "bert.encoder.layer.1.attention.self.key.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_67",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_73 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_73"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key",
                "original_op_name": "matmul_67",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27261
        },
        "matmul_671": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_88 (port_0) ublock_order(c)",
                "Data: matmul_664 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_88": "Data",
                "matmul_664": "Data"
            },
            "input_nodes": [
                "_fused_op_88",
                "matmul_664"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_671",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_675 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_675"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_671",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28440
        },
        "matmul_675": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_671 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.12.attention.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.12.attention.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.12.attention.output.dense.bias": "Data",
                "bert.encoder.layer.12.attention.output.dense.weight": "Data",
                "matmul_671": "Data"
            },
            "input_nodes": [
                "matmul_671",
                "bert.encoder.layer.12.attention.output.dense.weight",
                "bert.encoder.layer.12.attention.output.dense.bias"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hstack"
                        }
                    }
                ],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_675",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_679 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_679"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_675",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28443
        },
        "matmul_683": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_90 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.12.intermediate.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.12.intermediate.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_90": "Data",
                "bert.encoder.layer.12.intermediate.dense.bias": "Data",
                "bert.encoder.layer.12.intermediate.dense.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_90",
                "bert.encoder.layer.12.intermediate.dense.weight",
                "bert.encoder.layer.12.intermediate.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_683",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: gelu_686 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "gelu_686"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_683",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28471
        },
        "matmul_689": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: gelu_686 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.12.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.12.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.12.output.dense.bias": "Data",
                "bert.encoder.layer.12.output.dense.weight": "Data",
                "gelu_686": "Data"
            },
            "input_nodes": [
                "gelu_686",
                "bert.encoder.layer.12.output.dense.weight",
                "bert.encoder.layer.12.output.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_689",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_693 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_693"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_689",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28475
        },
        "matmul_697": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_92 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.13.attention.self.query.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.13.attention.self.query.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_92": "Data",
                "bert.encoder.layer.13.attention.self.query.bias": "Data",
                "bert.encoder.layer.13.attention.self.query.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_92",
                "bert.encoder.layer.13.attention.self.query.weight",
                "bert.encoder.layer.13.attention.self.query.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_697",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_709 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_709"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query",
                "original_op_name": "matmul_697",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28503
        },
        "matmul_703": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_92 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.13.attention.self.key.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.13.attention.self.key.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_92": "Data",
                "bert.encoder.layer.13.attention.self.key.bias": "Data",
                "bert.encoder.layer.13.attention.self.key.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_92",
                "bert.encoder.layer.13.attention.self.key.weight",
                "bert.encoder.layer.13.attention.self.key.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_703",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_709 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_709"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key",
                "original_op_name": "matmul_703",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28509
        },
        "matmul_709": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_697 (port_0) ublock_order(c)",
                "Data: matmul_703 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "matmul_697": "Data",
                "matmul_703": "Data"
            },
            "input_nodes": [
                "matmul_697",
                "matmul_703"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [],
                            "buda_attrs": {},
                            "named_attrs": {
                                "dim0": -2,
                                "dim1": -1,
                                "z_dim_slice": -1
                            },
                            "type": "transpose"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "vslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_709",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_93 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_93"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_709",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28516
        },
        "matmul_717": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_92 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.13.attention.self.value.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.13.attention.self.value.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_92": "Data",
                "bert.encoder.layer.13.attention.self.value.bias": "Data",
                "bert.encoder.layer.13.attention.self.value.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_92",
                "bert.encoder.layer.13.attention.self.value.weight",
                "bert.encoder.layer.13.attention.self.value.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_717",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_724 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_724"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value",
                "original_op_name": "matmul_717",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28538
        },
        "matmul_724": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_95 (port_0) ublock_order(c)",
                "Data: matmul_717 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_95": "Data",
                "matmul_717": "Data"
            },
            "input_nodes": [
                "_fused_op_95",
                "matmul_717"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_724",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_728 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_728"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_724",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28544
        },
        "matmul_728": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_724 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.13.attention.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.13.attention.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.13.attention.output.dense.bias": "Data",
                "bert.encoder.layer.13.attention.output.dense.weight": "Data",
                "matmul_724": "Data"
            },
            "input_nodes": [
                "matmul_724",
                "bert.encoder.layer.13.attention.output.dense.weight",
                "bert.encoder.layer.13.attention.output.dense.bias"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hstack"
                        }
                    }
                ],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_728",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_732 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_732"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_728",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28547
        },
        "matmul_73": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_61 (port_0) ublock_order(c)",
                "Data: matmul_67 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "matmul_61": "Data",
                "matmul_67": "Data"
            },
            "input_nodes": [
                "matmul_61",
                "matmul_67"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [],
                            "buda_attrs": {},
                            "named_attrs": {
                                "dim0": -2,
                                "dim1": -1,
                                "z_dim_slice": -1
                            },
                            "type": "transpose"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "vslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_73",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_9 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_9"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_73",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27268
        },
        "matmul_736": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_97 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.13.intermediate.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.13.intermediate.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_97": "Data",
                "bert.encoder.layer.13.intermediate.dense.bias": "Data",
                "bert.encoder.layer.13.intermediate.dense.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_97",
                "bert.encoder.layer.13.intermediate.dense.weight",
                "bert.encoder.layer.13.intermediate.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_736",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: gelu_739 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "gelu_739"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_736",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28575
        },
        "matmul_742": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: gelu_739 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.13.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.13.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.13.output.dense.bias": "Data",
                "bert.encoder.layer.13.output.dense.weight": "Data",
                "gelu_739": "Data"
            },
            "input_nodes": [
                "gelu_739",
                "bert.encoder.layer.13.output.dense.weight",
                "bert.encoder.layer.13.output.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_742",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_746 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_746"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_742",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28579
        },
        "matmul_750": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_99 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.14.attention.self.query.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.14.attention.self.query.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_99": "Data",
                "bert.encoder.layer.14.attention.self.query.bias": "Data",
                "bert.encoder.layer.14.attention.self.query.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_99",
                "bert.encoder.layer.14.attention.self.query.weight",
                "bert.encoder.layer.14.attention.self.query.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_750",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_762 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_762"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query",
                "original_op_name": "matmul_750",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28607
        },
        "matmul_756": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_99 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.14.attention.self.key.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.14.attention.self.key.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_99": "Data",
                "bert.encoder.layer.14.attention.self.key.bias": "Data",
                "bert.encoder.layer.14.attention.self.key.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_99",
                "bert.encoder.layer.14.attention.self.key.weight",
                "bert.encoder.layer.14.attention.self.key.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_756",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_762 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_762"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key",
                "original_op_name": "matmul_756",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28613
        },
        "matmul_762": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_750 (port_0) ublock_order(c)",
                "Data: matmul_756 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "matmul_750": "Data",
                "matmul_756": "Data"
            },
            "input_nodes": [
                "matmul_750",
                "matmul_756"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [],
                            "buda_attrs": {},
                            "named_attrs": {
                                "dim0": -2,
                                "dim1": -1,
                                "z_dim_slice": -1
                            },
                            "type": "transpose"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "vslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_762",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_100 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_100"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_762",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28620
        },
        "matmul_770": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_99 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.14.attention.self.value.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.14.attention.self.value.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_99": "Data",
                "bert.encoder.layer.14.attention.self.value.bias": "Data",
                "bert.encoder.layer.14.attention.self.value.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_99",
                "bert.encoder.layer.14.attention.self.value.weight",
                "bert.encoder.layer.14.attention.self.value.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_770",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_777 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_777"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value",
                "original_op_name": "matmul_770",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28642
        },
        "matmul_777": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_102 (port_0) ublock_order(c)",
                "Data: matmul_770 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_102": "Data",
                "matmul_770": "Data"
            },
            "input_nodes": [
                "_fused_op_102",
                "matmul_770"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_777",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_781 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_781"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_777",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28648
        },
        "matmul_781": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_777 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.14.attention.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.14.attention.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.14.attention.output.dense.bias": "Data",
                "bert.encoder.layer.14.attention.output.dense.weight": "Data",
                "matmul_777": "Data"
            },
            "input_nodes": [
                "matmul_777",
                "bert.encoder.layer.14.attention.output.dense.weight",
                "bert.encoder.layer.14.attention.output.dense.bias"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hstack"
                        }
                    }
                ],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_781",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_785 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_785"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_781",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28651
        },
        "matmul_789": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_104 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.14.intermediate.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.14.intermediate.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_104": "Data",
                "bert.encoder.layer.14.intermediate.dense.bias": "Data",
                "bert.encoder.layer.14.intermediate.dense.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_104",
                "bert.encoder.layer.14.intermediate.dense.weight",
                "bert.encoder.layer.14.intermediate.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_789",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: gelu_792 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "gelu_792"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_789",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28679
        },
        "matmul_795": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: gelu_792 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.14.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.14.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.14.output.dense.bias": "Data",
                "bert.encoder.layer.14.output.dense.weight": "Data",
                "gelu_792": "Data"
            },
            "input_nodes": [
                "gelu_792",
                "bert.encoder.layer.14.output.dense.weight",
                "bert.encoder.layer.14.output.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_795",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_799 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_799"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_795",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28683
        },
        "matmul_803": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_106 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.15.attention.self.query.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.15.attention.self.query.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_106": "Data",
                "bert.encoder.layer.15.attention.self.query.bias": "Data",
                "bert.encoder.layer.15.attention.self.query.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_106",
                "bert.encoder.layer.15.attention.self.query.weight",
                "bert.encoder.layer.15.attention.self.query.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_803",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_815 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_815"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query",
                "original_op_name": "matmul_803",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28711
        },
        "matmul_809": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_106 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.15.attention.self.key.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.15.attention.self.key.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_106": "Data",
                "bert.encoder.layer.15.attention.self.key.bias": "Data",
                "bert.encoder.layer.15.attention.self.key.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_106",
                "bert.encoder.layer.15.attention.self.key.weight",
                "bert.encoder.layer.15.attention.self.key.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_809",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_815 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_815"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key",
                "original_op_name": "matmul_809",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28717
        },
        "matmul_81": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_8 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.1.attention.self.value.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.1.attention.self.value.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_8": "Data",
                "bert.encoder.layer.1.attention.self.value.bias": "Data",
                "bert.encoder.layer.1.attention.self.value.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_8",
                "bert.encoder.layer.1.attention.self.value.weight",
                "bert.encoder.layer.1.attention.self.value.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_81",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_88 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_88"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value",
                "original_op_name": "matmul_81",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27290
        },
        "matmul_815": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_803 (port_0) ublock_order(c)",
                "Data: matmul_809 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "matmul_803": "Data",
                "matmul_809": "Data"
            },
            "input_nodes": [
                "matmul_803",
                "matmul_809"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [],
                            "buda_attrs": {},
                            "named_attrs": {
                                "dim0": -2,
                                "dim1": -1,
                                "z_dim_slice": -1
                            },
                            "type": "transpose"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "vslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_815",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_107 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_107"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_815",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28724
        },
        "matmul_823": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_106 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.15.attention.self.value.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.15.attention.self.value.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_106": "Data",
                "bert.encoder.layer.15.attention.self.value.bias": "Data",
                "bert.encoder.layer.15.attention.self.value.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_106",
                "bert.encoder.layer.15.attention.self.value.weight",
                "bert.encoder.layer.15.attention.self.value.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_823",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_830 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_830"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value",
                "original_op_name": "matmul_823",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28746
        },
        "matmul_830": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_109 (port_0) ublock_order(c)",
                "Data: matmul_823 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_109": "Data",
                "matmul_823": "Data"
            },
            "input_nodes": [
                "_fused_op_109",
                "matmul_823"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_830",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_834 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_834"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_830",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28752
        },
        "matmul_834": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_830 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.15.attention.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.15.attention.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.15.attention.output.dense.bias": "Data",
                "bert.encoder.layer.15.attention.output.dense.weight": "Data",
                "matmul_830": "Data"
            },
            "input_nodes": [
                "matmul_830",
                "bert.encoder.layer.15.attention.output.dense.weight",
                "bert.encoder.layer.15.attention.output.dense.bias"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hstack"
                        }
                    }
                ],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_834",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_838 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_838"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_834",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28755
        },
        "matmul_842": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_111 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.15.intermediate.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.15.intermediate.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_111": "Data",
                "bert.encoder.layer.15.intermediate.dense.bias": "Data",
                "bert.encoder.layer.15.intermediate.dense.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_111",
                "bert.encoder.layer.15.intermediate.dense.weight",
                "bert.encoder.layer.15.intermediate.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_842",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: gelu_845 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "gelu_845"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_842",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28783
        },
        "matmul_848": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: gelu_845 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.15.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.15.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.15.output.dense.bias": "Data",
                "bert.encoder.layer.15.output.dense.weight": "Data",
                "gelu_845": "Data"
            },
            "input_nodes": [
                "gelu_845",
                "bert.encoder.layer.15.output.dense.weight",
                "bert.encoder.layer.15.output.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_848",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_852 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_852"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_848",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28787
        },
        "matmul_856": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_113 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.16.attention.self.query.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.16.attention.self.query.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_113": "Data",
                "bert.encoder.layer.16.attention.self.query.bias": "Data",
                "bert.encoder.layer.16.attention.self.query.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_113",
                "bert.encoder.layer.16.attention.self.query.weight",
                "bert.encoder.layer.16.attention.self.query.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_856",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_868 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_868"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query",
                "original_op_name": "matmul_856",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28815
        },
        "matmul_862": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_113 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.16.attention.self.key.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.16.attention.self.key.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_113": "Data",
                "bert.encoder.layer.16.attention.self.key.bias": "Data",
                "bert.encoder.layer.16.attention.self.key.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_113",
                "bert.encoder.layer.16.attention.self.key.weight",
                "bert.encoder.layer.16.attention.self.key.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_862",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_868 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_868"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key",
                "original_op_name": "matmul_862",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28821
        },
        "matmul_868": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_856 (port_0) ublock_order(c)",
                "Data: matmul_862 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "matmul_856": "Data",
                "matmul_862": "Data"
            },
            "input_nodes": [
                "matmul_856",
                "matmul_862"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [],
                            "buda_attrs": {},
                            "named_attrs": {
                                "dim0": -2,
                                "dim1": -1,
                                "z_dim_slice": -1
                            },
                            "type": "transpose"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "vslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_868",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_114 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_114"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_868",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28828
        },
        "matmul_876": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_113 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.16.attention.self.value.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.16.attention.self.value.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_113": "Data",
                "bert.encoder.layer.16.attention.self.value.bias": "Data",
                "bert.encoder.layer.16.attention.self.value.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_113",
                "bert.encoder.layer.16.attention.self.value.weight",
                "bert.encoder.layer.16.attention.self.value.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_876",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_883 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_883"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value",
                "original_op_name": "matmul_876",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28850
        },
        "matmul_88": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_11 (port_0) ublock_order(c)",
                "Data: matmul_81 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_11": "Data",
                "matmul_81": "Data"
            },
            "input_nodes": [
                "_fused_op_11",
                "matmul_81"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_88",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_92 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_92"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_88",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27296
        },
        "matmul_883": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_116 (port_0) ublock_order(c)",
                "Data: matmul_876 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_116": "Data",
                "matmul_876": "Data"
            },
            "input_nodes": [
                "_fused_op_116",
                "matmul_876"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_883",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_887 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_887"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_883",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28856
        },
        "matmul_887": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_883 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.16.attention.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.16.attention.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.16.attention.output.dense.bias": "Data",
                "bert.encoder.layer.16.attention.output.dense.weight": "Data",
                "matmul_883": "Data"
            },
            "input_nodes": [
                "matmul_883",
                "bert.encoder.layer.16.attention.output.dense.weight",
                "bert.encoder.layer.16.attention.output.dense.bias"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hstack"
                        }
                    }
                ],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_887",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_891 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_891"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_887",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28859
        },
        "matmul_895": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_118 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.16.intermediate.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.16.intermediate.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_118": "Data",
                "bert.encoder.layer.16.intermediate.dense.bias": "Data",
                "bert.encoder.layer.16.intermediate.dense.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_118",
                "bert.encoder.layer.16.intermediate.dense.weight",
                "bert.encoder.layer.16.intermediate.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_895",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: gelu_898 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "gelu_898"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_895",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28887
        },
        "matmul_901": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: gelu_898 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.16.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.16.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.16.output.dense.bias": "Data",
                "bert.encoder.layer.16.output.dense.weight": "Data",
                "gelu_898": "Data"
            },
            "input_nodes": [
                "gelu_898",
                "bert.encoder.layer.16.output.dense.weight",
                "bert.encoder.layer.16.output.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_901",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_905 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_905"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_901",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28891
        },
        "matmul_909": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_120 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.17.attention.self.query.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.17.attention.self.query.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_120": "Data",
                "bert.encoder.layer.17.attention.self.query.bias": "Data",
                "bert.encoder.layer.17.attention.self.query.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_120",
                "bert.encoder.layer.17.attention.self.query.weight",
                "bert.encoder.layer.17.attention.self.query.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_909",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_921 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_921"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query",
                "original_op_name": "matmul_909",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28919
        },
        "matmul_915": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_120 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.17.attention.self.key.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.17.attention.self.key.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_120": "Data",
                "bert.encoder.layer.17.attention.self.key.bias": "Data",
                "bert.encoder.layer.17.attention.self.key.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_120",
                "bert.encoder.layer.17.attention.self.key.weight",
                "bert.encoder.layer.17.attention.self.key.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_915",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_921 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_921"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key",
                "original_op_name": "matmul_915",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28925
        },
        "matmul_92": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_88 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.1.attention.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.1.attention.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.1.attention.output.dense.bias": "Data",
                "bert.encoder.layer.1.attention.output.dense.weight": "Data",
                "matmul_88": "Data"
            },
            "input_nodes": [
                "matmul_88",
                "bert.encoder.layer.1.attention.output.dense.weight",
                "bert.encoder.layer.1.attention.output.dense.bias"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hstack"
                        }
                    }
                ],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_92",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_96 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_96"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_92",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27299
        },
        "matmul_921": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_909 (port_0) ublock_order(c)",
                "Data: matmul_915 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "matmul_909": "Data",
                "matmul_915": "Data"
            },
            "input_nodes": [
                "matmul_909",
                "matmul_915"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [],
                            "buda_attrs": {},
                            "named_attrs": {
                                "dim0": -2,
                                "dim1": -1,
                                "z_dim_slice": -1
                            },
                            "type": "transpose"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "vslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_921",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_121 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_121"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_921",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28932
        },
        "matmul_929": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_120 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.17.attention.self.value.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.17.attention.self.value.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_120": "Data",
                "bert.encoder.layer.17.attention.self.value.bias": "Data",
                "bert.encoder.layer.17.attention.self.value.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_120",
                "bert.encoder.layer.17.attention.self.value.weight",
                "bert.encoder.layer.17.attention.self.value.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_929",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_936 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_936"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value",
                "original_op_name": "matmul_929",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28954
        },
        "matmul_936": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_123 (port_0) ublock_order(c)",
                "Data: matmul_929 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_123": "Data",
                "matmul_929": "Data"
            },
            "input_nodes": [
                "_fused_op_123",
                "matmul_929"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_936",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_940 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_940"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_936",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28960
        },
        "matmul_940": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_936 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.17.attention.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.17.attention.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.17.attention.output.dense.bias": "Data",
                "bert.encoder.layer.17.attention.output.dense.weight": "Data",
                "matmul_936": "Data"
            },
            "input_nodes": [
                "matmul_936",
                "bert.encoder.layer.17.attention.output.dense.weight",
                "bert.encoder.layer.17.attention.output.dense.bias"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hstack"
                        }
                    }
                ],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_940",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_944 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_944"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_940",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28963
        },
        "matmul_948": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_125 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.17.intermediate.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.17.intermediate.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_125": "Data",
                "bert.encoder.layer.17.intermediate.dense.bias": "Data",
                "bert.encoder.layer.17.intermediate.dense.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_125",
                "bert.encoder.layer.17.intermediate.dense.weight",
                "bert.encoder.layer.17.intermediate.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_948",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: gelu_951 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "gelu_951"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_948",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28991
        },
        "matmul_954": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: gelu_951 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.17.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.17.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.17.output.dense.bias": "Data",
                "bert.encoder.layer.17.output.dense.weight": "Data",
                "gelu_951": "Data"
            },
            "input_nodes": [
                "gelu_951",
                "bert.encoder.layer.17.output.dense.weight",
                "bert.encoder.layer.17.output.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_954",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_958 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_958"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_954",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28995
        },
        "matmul_962": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_127 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.18.attention.self.query.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.18.attention.self.query.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_127": "Data",
                "bert.encoder.layer.18.attention.self.query.bias": "Data",
                "bert.encoder.layer.18.attention.self.query.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_127",
                "bert.encoder.layer.18.attention.self.query.weight",
                "bert.encoder.layer.18.attention.self.query.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_962",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_974 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_974"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query",
                "original_op_name": "matmul_962",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 29023
        },
        "matmul_968": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_127 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.18.attention.self.key.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.18.attention.self.key.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_127": "Data",
                "bert.encoder.layer.18.attention.self.key.bias": "Data",
                "bert.encoder.layer.18.attention.self.key.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_127",
                "bert.encoder.layer.18.attention.self.key.weight",
                "bert.encoder.layer.18.attention.self.key.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_968",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_974 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_974"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key",
                "original_op_name": "matmul_968",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 29029
        },
        "matmul_974": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_962 (port_0) ublock_order(c)",
                "Data: matmul_968 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "matmul_962": "Data",
                "matmul_968": "Data"
            },
            "input_nodes": [
                "matmul_962",
                "matmul_968"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [],
                            "buda_attrs": {},
                            "named_attrs": {
                                "dim0": -2,
                                "dim1": -1,
                                "z_dim_slice": -1
                            },
                            "type": "transpose"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "vslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_974",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_128 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_128"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_974",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 29036
        },
        "matmul_982": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_127 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.18.attention.self.value.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.18.attention.self.value.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_127": "Data",
                "bert.encoder.layer.18.attention.self.value.bias": "Data",
                "bert.encoder.layer.18.attention.self.value.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_127",
                "bert.encoder.layer.18.attention.self.value.weight",
                "bert.encoder.layer.18.attention.self.value.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_982",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_989 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_989"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value",
                "original_op_name": "matmul_982",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 29058
        },
        "matmul_989": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_130 (port_0) ublock_order(c)",
                "Data: matmul_982 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_130": "Data",
                "matmul_982": "Data"
            },
            "input_nodes": [
                "_fused_op_130",
                "matmul_982"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_989",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_993 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_993"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_989",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 29064
        },
        "matmul_993": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_989 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.18.attention.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.18.attention.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.18.attention.output.dense.bias": "Data",
                "bert.encoder.layer.18.attention.output.dense.weight": "Data",
                "matmul_989": "Data"
            },
            "input_nodes": [
                "matmul_989",
                "bert.encoder.layer.18.attention.output.dense.weight",
                "bert.encoder.layer.18.attention.output.dense.bias"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hstack"
                        }
                    }
                ],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_993",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_997 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_997"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_993",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 29067
        },
        "multiply_22": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    384
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: subtract_21 (port_0) ublock_order(r)",
                "Data: input_1_multiply_22 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "input_1_multiply_22": "Data",
                "subtract_21": "Data"
            },
            "input_nodes": [
                "subtract_21",
                "input_1_multiply_22"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "multiply_22",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: multiply_22_attempt_1_input_op_fork_nop0 (port_0)",
                "Data: multiply_22_attempt_1_input_op_fork_nop1 (port_0)",
                "Data: multiply_22_attempt_1_input_op_fork_nop2 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "multiply_22_attempt_1_input_op_fork_nop0",
                "multiply_22_attempt_1_input_op_fork_nop1",
                "multiply_22_attempt_1_input_op_fork_nop2"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert",
                "original_op_name": "multiply_22",
                "original_op_type": "multiply"
            },
            "type": "multiply",
            "unique_id": 27166
        },
        "multiply_22_attempt_1_input_op_fork_nop0": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    384
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: multiply_22 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "multiply_22": "Data"
            },
            "input_nodes": [
                "multiply_22"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "multiply_22_attempt_1_input_op_fork_nop0",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_2 (port_0)",
                "Data: _fused_op_9 (port_0)",
                "Data: _fused_op_16 (port_0)",
                "Data: _fused_op_23 (port_0)",
                "Data: _fused_op_30 (port_0)",
                "Data: _fused_op_37 (port_0)",
                "Data: _fused_op_44 (port_0)",
                "Data: _fused_op_51 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_2",
                "_fused_op_9",
                "_fused_op_16",
                "_fused_op_23",
                "_fused_op_30",
                "_fused_op_37",
                "_fused_op_44",
                "_fused_op_51"
            ],
            "pybuda": 1,
            "tags": {},
            "type": "nop",
            "unique_id": 29827
        },
        "multiply_22_attempt_1_input_op_fork_nop1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    384
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: multiply_22 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "multiply_22": "Data"
            },
            "input_nodes": [
                "multiply_22"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "multiply_22_attempt_1_input_op_fork_nop1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_58 (port_0)",
                "Data: _fused_op_65 (port_0)",
                "Data: _fused_op_72 (port_0)",
                "Data: _fused_op_79 (port_0)",
                "Data: _fused_op_86 (port_0)",
                "Data: _fused_op_93 (port_0)",
                "Data: _fused_op_100 (port_0)",
                "Data: _fused_op_107 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_58",
                "_fused_op_65",
                "_fused_op_72",
                "_fused_op_79",
                "_fused_op_86",
                "_fused_op_93",
                "_fused_op_100",
                "_fused_op_107"
            ],
            "pybuda": 1,
            "tags": {},
            "type": "nop",
            "unique_id": 29828
        },
        "multiply_22_attempt_1_input_op_fork_nop2": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    384
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: multiply_22 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "multiply_22": "Data"
            },
            "input_nodes": [
                "multiply_22"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "multiply_22_attempt_1_input_op_fork_nop2",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_114 (port_0)",
                "Data: _fused_op_121 (port_0)",
                "Data: _fused_op_128 (port_0)",
                "Data: _fused_op_135 (port_0)",
                "Data: _fused_op_142 (port_0)",
                "Data: _fused_op_149 (port_0)",
                "Data: _fused_op_156 (port_0)",
                "Data: _fused_op_163 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_114",
                "_fused_op_121",
                "_fused_op_128",
                "_fused_op_135",
                "_fused_op_142",
                "_fused_op_149",
                "_fused_op_156",
                "_fused_op_163"
            ],
            "pybuda": 1,
            "tags": {},
            "type": "nop",
            "unique_id": 29829
        },
        "pybuda_6_i0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "pybuda_6_i0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_0.dc.reduce_sum.0.lc1 (port_0)",
                "Data: _fused_op_0 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_0.dc.reduce_sum.0.lc1",
                "_fused_op_0"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "pybuda_6_i0"
            },
            "tile_broadcast": [],
            "type": "Input::input",
            "unique_id": 27121
        },
        "qa_outputs.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "qa_outputs.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1281 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1281"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "qa_outputs.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29649
        },
        "qa_outputs.bias_fork_clone12": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "qa_outputs.bias_fork_clone12",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1288 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1288"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "qa_outputs.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29653
        },
        "qa_outputs.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    32
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "qa_outputs.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1281 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1281"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "qa_outputs.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29648
        },
        "qa_outputs.weight_fork_clone19": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    32
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "qa_outputs.weight_fork_clone19",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1288 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1288"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "qa_outputs.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 29652
        },
        "softmax_1031.dc.reduce_max.0": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "reduce(3,max,16,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_135 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_135": "Data"
            },
            "input_nodes": [
                "_fused_op_135"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_1031.dc.reduce_max.0",
            "op_type": {
                "attrs": [
                    3,
                    "max",
                    16
                ],
                "buda_attrs": {
                    "dim": "c",
                    "type": "max"
                },
                "named_attrs": {},
                "type": "reduce"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_136 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_136"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_1031",
                "original_op_type": "softmax"
            },
            "type": "reduce",
            "unique_id": 29147
        },
        "softmax_1031.dc.reduce_sum.3.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_136 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.softmax_1031.dc.reduce_sum.3.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_136": "Data",
                "lc.input_tensor.softmax_1031.dc.reduce_sum.3.0": "Data"
            },
            "input_nodes": [
                "_fused_op_136",
                "lc.input_tensor.softmax_1031.dc.reduce_sum.3.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_1031.dc.reduce_sum.3.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_137 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_137"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_1031",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 29153
        },
        "softmax_1084.dc.reduce_max.0": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "reduce(3,max,16,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_142 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_142": "Data"
            },
            "input_nodes": [
                "_fused_op_142"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_1084.dc.reduce_max.0",
            "op_type": {
                "attrs": [
                    3,
                    "max",
                    16
                ],
                "buda_attrs": {
                    "dim": "c",
                    "type": "max"
                },
                "named_attrs": {},
                "type": "reduce"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_143 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_143"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_1084",
                "original_op_type": "softmax"
            },
            "type": "reduce",
            "unique_id": 29251
        },
        "softmax_1084.dc.reduce_sum.3.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_143 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.softmax_1084.dc.reduce_sum.3.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_143": "Data",
                "lc.input_tensor.softmax_1084.dc.reduce_sum.3.0": "Data"
            },
            "input_nodes": [
                "_fused_op_143",
                "lc.input_tensor.softmax_1084.dc.reduce_sum.3.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_1084.dc.reduce_sum.3.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_144 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_144"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_1084",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 29257
        },
        "softmax_1137.dc.reduce_max.0": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "reduce(3,max,16,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_149 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_149": "Data"
            },
            "input_nodes": [
                "_fused_op_149"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_1137.dc.reduce_max.0",
            "op_type": {
                "attrs": [
                    3,
                    "max",
                    16
                ],
                "buda_attrs": {
                    "dim": "c",
                    "type": "max"
                },
                "named_attrs": {},
                "type": "reduce"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_150 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_150"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_1137",
                "original_op_type": "softmax"
            },
            "type": "reduce",
            "unique_id": 29355
        },
        "softmax_1137.dc.reduce_sum.3.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_150 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.softmax_1137.dc.reduce_sum.3.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_150": "Data",
                "lc.input_tensor.softmax_1137.dc.reduce_sum.3.0": "Data"
            },
            "input_nodes": [
                "_fused_op_150",
                "lc.input_tensor.softmax_1137.dc.reduce_sum.3.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_1137.dc.reduce_sum.3.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_151 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_151"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_1137",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 29361
        },
        "softmax_1190.dc.reduce_max.0": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "reduce(3,max,16,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_156 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_156": "Data"
            },
            "input_nodes": [
                "_fused_op_156"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_1190.dc.reduce_max.0",
            "op_type": {
                "attrs": [
                    3,
                    "max",
                    16
                ],
                "buda_attrs": {
                    "dim": "c",
                    "type": "max"
                },
                "named_attrs": {},
                "type": "reduce"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_157 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_157"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_1190",
                "original_op_type": "softmax"
            },
            "type": "reduce",
            "unique_id": 29459
        },
        "softmax_1190.dc.reduce_sum.3.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_157 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.softmax_1190.dc.reduce_sum.3.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_157": "Data",
                "lc.input_tensor.softmax_1190.dc.reduce_sum.3.0": "Data"
            },
            "input_nodes": [
                "_fused_op_157",
                "lc.input_tensor.softmax_1190.dc.reduce_sum.3.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_1190.dc.reduce_sum.3.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_158 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_158"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_1190",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 29465
        },
        "softmax_1243.dc.reduce_max.0": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "reduce(3,max,16,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_163 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_163": "Data"
            },
            "input_nodes": [
                "_fused_op_163"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_1243.dc.reduce_max.0",
            "op_type": {
                "attrs": [
                    3,
                    "max",
                    16
                ],
                "buda_attrs": {
                    "dim": "c",
                    "type": "max"
                },
                "named_attrs": {},
                "type": "reduce"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_164 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_164"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_1243",
                "original_op_type": "softmax"
            },
            "type": "reduce",
            "unique_id": 29563
        },
        "softmax_1243.dc.reduce_sum.3.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_164 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.softmax_1243.dc.reduce_sum.3.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_164": "Data",
                "lc.input_tensor.softmax_1243.dc.reduce_sum.3.0": "Data"
            },
            "input_nodes": [
                "_fused_op_164",
                "lc.input_tensor.softmax_1243.dc.reduce_sum.3.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_1243.dc.reduce_sum.3.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_165 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_165"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_1243",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 29569
        },
        "softmax_130.dc.reduce_max.0": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "reduce(3,max,16,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_16 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_16": "Data"
            },
            "input_nodes": [
                "_fused_op_16"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_130.dc.reduce_max.0",
            "op_type": {
                "attrs": [
                    3,
                    "max",
                    16
                ],
                "buda_attrs": {
                    "dim": "c",
                    "type": "max"
                },
                "named_attrs": {},
                "type": "reduce"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_17 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_17"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_130",
                "original_op_type": "softmax"
            },
            "type": "reduce",
            "unique_id": 27379
        },
        "softmax_130.dc.reduce_sum.3.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_17 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.softmax_130.dc.reduce_sum.3.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_17": "Data",
                "lc.input_tensor.softmax_130.dc.reduce_sum.3.0": "Data"
            },
            "input_nodes": [
                "_fused_op_17",
                "lc.input_tensor.softmax_130.dc.reduce_sum.3.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_130.dc.reduce_sum.3.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_18 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_18"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_130",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 27385
        },
        "softmax_183.dc.reduce_max.0": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "reduce(3,max,16,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_23 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_23": "Data"
            },
            "input_nodes": [
                "_fused_op_23"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_183.dc.reduce_max.0",
            "op_type": {
                "attrs": [
                    3,
                    "max",
                    16
                ],
                "buda_attrs": {
                    "dim": "c",
                    "type": "max"
                },
                "named_attrs": {},
                "type": "reduce"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_24 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_24"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_183",
                "original_op_type": "softmax"
            },
            "type": "reduce",
            "unique_id": 27483
        },
        "softmax_183.dc.reduce_sum.3.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_24 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.softmax_183.dc.reduce_sum.3.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_24": "Data",
                "lc.input_tensor.softmax_183.dc.reduce_sum.3.0": "Data"
            },
            "input_nodes": [
                "_fused_op_24",
                "lc.input_tensor.softmax_183.dc.reduce_sum.3.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_183.dc.reduce_sum.3.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_25 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_25"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_183",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 27489
        },
        "softmax_236.dc.reduce_max.0": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "reduce(3,max,16,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_30 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_30": "Data"
            },
            "input_nodes": [
                "_fused_op_30"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_236.dc.reduce_max.0",
            "op_type": {
                "attrs": [
                    3,
                    "max",
                    16
                ],
                "buda_attrs": {
                    "dim": "c",
                    "type": "max"
                },
                "named_attrs": {},
                "type": "reduce"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_31 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_31"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_236",
                "original_op_type": "softmax"
            },
            "type": "reduce",
            "unique_id": 27587
        },
        "softmax_236.dc.reduce_sum.3.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_31 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.softmax_236.dc.reduce_sum.3.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_31": "Data",
                "lc.input_tensor.softmax_236.dc.reduce_sum.3.0": "Data"
            },
            "input_nodes": [
                "_fused_op_31",
                "lc.input_tensor.softmax_236.dc.reduce_sum.3.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_236.dc.reduce_sum.3.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_32 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_32"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_236",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 27593
        },
        "softmax_24.dc.reduce_max.0": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "reduce(3,max,16,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_2 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_2": "Data"
            },
            "input_nodes": [
                "_fused_op_2"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_24.dc.reduce_max.0",
            "op_type": {
                "attrs": [
                    3,
                    "max",
                    16
                ],
                "buda_attrs": {
                    "dim": "c",
                    "type": "max"
                },
                "named_attrs": {},
                "type": "reduce"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_3 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_3"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_24",
                "original_op_type": "softmax"
            },
            "type": "reduce",
            "unique_id": 27171
        },
        "softmax_24.dc.reduce_sum.3.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_3 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.softmax_24.dc.reduce_sum.3.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_3": "Data",
                "lc.input_tensor.softmax_24.dc.reduce_sum.3.0": "Data"
            },
            "input_nodes": [
                "_fused_op_3",
                "lc.input_tensor.softmax_24.dc.reduce_sum.3.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_24.dc.reduce_sum.3.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_4 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_4"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_24",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 27177
        },
        "softmax_289.dc.reduce_max.0": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "reduce(3,max,16,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_37 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_37": "Data"
            },
            "input_nodes": [
                "_fused_op_37"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_289.dc.reduce_max.0",
            "op_type": {
                "attrs": [
                    3,
                    "max",
                    16
                ],
                "buda_attrs": {
                    "dim": "c",
                    "type": "max"
                },
                "named_attrs": {},
                "type": "reduce"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_38 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_38"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_289",
                "original_op_type": "softmax"
            },
            "type": "reduce",
            "unique_id": 27691
        },
        "softmax_289.dc.reduce_sum.3.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_38 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.softmax_289.dc.reduce_sum.3.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_38": "Data",
                "lc.input_tensor.softmax_289.dc.reduce_sum.3.0": "Data"
            },
            "input_nodes": [
                "_fused_op_38",
                "lc.input_tensor.softmax_289.dc.reduce_sum.3.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_289.dc.reduce_sum.3.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_39 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_39"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_289",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 27697
        },
        "softmax_342.dc.reduce_max.0": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "reduce(3,max,16,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_44 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_44": "Data"
            },
            "input_nodes": [
                "_fused_op_44"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_342.dc.reduce_max.0",
            "op_type": {
                "attrs": [
                    3,
                    "max",
                    16
                ],
                "buda_attrs": {
                    "dim": "c",
                    "type": "max"
                },
                "named_attrs": {},
                "type": "reduce"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_45 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_45"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_342",
                "original_op_type": "softmax"
            },
            "type": "reduce",
            "unique_id": 27795
        },
        "softmax_342.dc.reduce_sum.3.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_45 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.softmax_342.dc.reduce_sum.3.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_45": "Data",
                "lc.input_tensor.softmax_342.dc.reduce_sum.3.0": "Data"
            },
            "input_nodes": [
                "_fused_op_45",
                "lc.input_tensor.softmax_342.dc.reduce_sum.3.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_342.dc.reduce_sum.3.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_46 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_46"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_342",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 27801
        },
        "softmax_395.dc.reduce_max.0": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "reduce(3,max,16,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_51 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_51": "Data"
            },
            "input_nodes": [
                "_fused_op_51"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_395.dc.reduce_max.0",
            "op_type": {
                "attrs": [
                    3,
                    "max",
                    16
                ],
                "buda_attrs": {
                    "dim": "c",
                    "type": "max"
                },
                "named_attrs": {},
                "type": "reduce"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_52 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_52"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_395",
                "original_op_type": "softmax"
            },
            "type": "reduce",
            "unique_id": 27899
        },
        "softmax_395.dc.reduce_sum.3.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_52 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.softmax_395.dc.reduce_sum.3.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_52": "Data",
                "lc.input_tensor.softmax_395.dc.reduce_sum.3.0": "Data"
            },
            "input_nodes": [
                "_fused_op_52",
                "lc.input_tensor.softmax_395.dc.reduce_sum.3.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_395.dc.reduce_sum.3.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_53 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_53"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_395",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 27905
        },
        "softmax_448.dc.reduce_max.0": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "reduce(3,max,16,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_58 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_58": "Data"
            },
            "input_nodes": [
                "_fused_op_58"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_448.dc.reduce_max.0",
            "op_type": {
                "attrs": [
                    3,
                    "max",
                    16
                ],
                "buda_attrs": {
                    "dim": "c",
                    "type": "max"
                },
                "named_attrs": {},
                "type": "reduce"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_59 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_59"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_448",
                "original_op_type": "softmax"
            },
            "type": "reduce",
            "unique_id": 28003
        },
        "softmax_448.dc.reduce_sum.3.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_59 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.softmax_448.dc.reduce_sum.3.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_59": "Data",
                "lc.input_tensor.softmax_448.dc.reduce_sum.3.0": "Data"
            },
            "input_nodes": [
                "_fused_op_59",
                "lc.input_tensor.softmax_448.dc.reduce_sum.3.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_448.dc.reduce_sum.3.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_60 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_60"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_448",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 28009
        },
        "softmax_501.dc.reduce_max.0": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "reduce(3,max,16,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_65 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_65": "Data"
            },
            "input_nodes": [
                "_fused_op_65"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_501.dc.reduce_max.0",
            "op_type": {
                "attrs": [
                    3,
                    "max",
                    16
                ],
                "buda_attrs": {
                    "dim": "c",
                    "type": "max"
                },
                "named_attrs": {},
                "type": "reduce"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_66 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_66"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_501",
                "original_op_type": "softmax"
            },
            "type": "reduce",
            "unique_id": 28107
        },
        "softmax_501.dc.reduce_sum.3.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_66 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.softmax_501.dc.reduce_sum.3.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_66": "Data",
                "lc.input_tensor.softmax_501.dc.reduce_sum.3.0": "Data"
            },
            "input_nodes": [
                "_fused_op_66",
                "lc.input_tensor.softmax_501.dc.reduce_sum.3.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_501.dc.reduce_sum.3.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_67 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_67"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_501",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 28113
        },
        "softmax_554.dc.reduce_max.0": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "reduce(3,max,16,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_72 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_72": "Data"
            },
            "input_nodes": [
                "_fused_op_72"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_554.dc.reduce_max.0",
            "op_type": {
                "attrs": [
                    3,
                    "max",
                    16
                ],
                "buda_attrs": {
                    "dim": "c",
                    "type": "max"
                },
                "named_attrs": {},
                "type": "reduce"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_73 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_73"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_554",
                "original_op_type": "softmax"
            },
            "type": "reduce",
            "unique_id": 28211
        },
        "softmax_554.dc.reduce_sum.3.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_73 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.softmax_554.dc.reduce_sum.3.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_73": "Data",
                "lc.input_tensor.softmax_554.dc.reduce_sum.3.0": "Data"
            },
            "input_nodes": [
                "_fused_op_73",
                "lc.input_tensor.softmax_554.dc.reduce_sum.3.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_554.dc.reduce_sum.3.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_74 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_74"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_554",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 28217
        },
        "softmax_607.dc.reduce_max.0": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "reduce(3,max,16,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_79 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_79": "Data"
            },
            "input_nodes": [
                "_fused_op_79"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_607.dc.reduce_max.0",
            "op_type": {
                "attrs": [
                    3,
                    "max",
                    16
                ],
                "buda_attrs": {
                    "dim": "c",
                    "type": "max"
                },
                "named_attrs": {},
                "type": "reduce"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_80 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_80"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_607",
                "original_op_type": "softmax"
            },
            "type": "reduce",
            "unique_id": 28315
        },
        "softmax_607.dc.reduce_sum.3.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_80 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.softmax_607.dc.reduce_sum.3.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_80": "Data",
                "lc.input_tensor.softmax_607.dc.reduce_sum.3.0": "Data"
            },
            "input_nodes": [
                "_fused_op_80",
                "lc.input_tensor.softmax_607.dc.reduce_sum.3.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_607.dc.reduce_sum.3.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_81 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_81"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_607",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 28321
        },
        "softmax_660.dc.reduce_max.0": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "reduce(3,max,16,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_86 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_86": "Data"
            },
            "input_nodes": [
                "_fused_op_86"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_660.dc.reduce_max.0",
            "op_type": {
                "attrs": [
                    3,
                    "max",
                    16
                ],
                "buda_attrs": {
                    "dim": "c",
                    "type": "max"
                },
                "named_attrs": {},
                "type": "reduce"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_87 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_87"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_660",
                "original_op_type": "softmax"
            },
            "type": "reduce",
            "unique_id": 28419
        },
        "softmax_660.dc.reduce_sum.3.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_87 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.softmax_660.dc.reduce_sum.3.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_87": "Data",
                "lc.input_tensor.softmax_660.dc.reduce_sum.3.0": "Data"
            },
            "input_nodes": [
                "_fused_op_87",
                "lc.input_tensor.softmax_660.dc.reduce_sum.3.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_660.dc.reduce_sum.3.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_88 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_88"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_660",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 28425
        },
        "softmax_713.dc.reduce_max.0": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "reduce(3,max,16,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_93 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_93": "Data"
            },
            "input_nodes": [
                "_fused_op_93"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_713.dc.reduce_max.0",
            "op_type": {
                "attrs": [
                    3,
                    "max",
                    16
                ],
                "buda_attrs": {
                    "dim": "c",
                    "type": "max"
                },
                "named_attrs": {},
                "type": "reduce"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_94 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_94"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_713",
                "original_op_type": "softmax"
            },
            "type": "reduce",
            "unique_id": 28523
        },
        "softmax_713.dc.reduce_sum.3.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_94 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.softmax_713.dc.reduce_sum.3.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_94": "Data",
                "lc.input_tensor.softmax_713.dc.reduce_sum.3.0": "Data"
            },
            "input_nodes": [
                "_fused_op_94",
                "lc.input_tensor.softmax_713.dc.reduce_sum.3.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_713.dc.reduce_sum.3.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_95 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_95"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_713",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 28529
        },
        "softmax_766.dc.reduce_max.0": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "reduce(3,max,16,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_100 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_100": "Data"
            },
            "input_nodes": [
                "_fused_op_100"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_766.dc.reduce_max.0",
            "op_type": {
                "attrs": [
                    3,
                    "max",
                    16
                ],
                "buda_attrs": {
                    "dim": "c",
                    "type": "max"
                },
                "named_attrs": {},
                "type": "reduce"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_101 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_101"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_766",
                "original_op_type": "softmax"
            },
            "type": "reduce",
            "unique_id": 28627
        },
        "softmax_766.dc.reduce_sum.3.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_101 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.softmax_766.dc.reduce_sum.3.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_101": "Data",
                "lc.input_tensor.softmax_766.dc.reduce_sum.3.0": "Data"
            },
            "input_nodes": [
                "_fused_op_101",
                "lc.input_tensor.softmax_766.dc.reduce_sum.3.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_766.dc.reduce_sum.3.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_102 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_102"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_766",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 28633
        },
        "softmax_77.dc.reduce_max.0": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "reduce(3,max,16,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_9 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_9": "Data"
            },
            "input_nodes": [
                "_fused_op_9"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_77.dc.reduce_max.0",
            "op_type": {
                "attrs": [
                    3,
                    "max",
                    16
                ],
                "buda_attrs": {
                    "dim": "c",
                    "type": "max"
                },
                "named_attrs": {},
                "type": "reduce"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_10 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_10"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_77",
                "original_op_type": "softmax"
            },
            "type": "reduce",
            "unique_id": 27275
        },
        "softmax_77.dc.reduce_sum.3.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_10 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.softmax_77.dc.reduce_sum.3.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_10": "Data",
                "lc.input_tensor.softmax_77.dc.reduce_sum.3.0": "Data"
            },
            "input_nodes": [
                "_fused_op_10",
                "lc.input_tensor.softmax_77.dc.reduce_sum.3.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_77.dc.reduce_sum.3.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_11 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_11"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_77",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 27281
        },
        "softmax_819.dc.reduce_max.0": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "reduce(3,max,16,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_107 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_107": "Data"
            },
            "input_nodes": [
                "_fused_op_107"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_819.dc.reduce_max.0",
            "op_type": {
                "attrs": [
                    3,
                    "max",
                    16
                ],
                "buda_attrs": {
                    "dim": "c",
                    "type": "max"
                },
                "named_attrs": {},
                "type": "reduce"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_108 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_108"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_819",
                "original_op_type": "softmax"
            },
            "type": "reduce",
            "unique_id": 28731
        },
        "softmax_819.dc.reduce_sum.3.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_108 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.softmax_819.dc.reduce_sum.3.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_108": "Data",
                "lc.input_tensor.softmax_819.dc.reduce_sum.3.0": "Data"
            },
            "input_nodes": [
                "_fused_op_108",
                "lc.input_tensor.softmax_819.dc.reduce_sum.3.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_819.dc.reduce_sum.3.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_109 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_109"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_819",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 28737
        },
        "softmax_872.dc.reduce_max.0": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "reduce(3,max,16,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_114 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_114": "Data"
            },
            "input_nodes": [
                "_fused_op_114"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_872.dc.reduce_max.0",
            "op_type": {
                "attrs": [
                    3,
                    "max",
                    16
                ],
                "buda_attrs": {
                    "dim": "c",
                    "type": "max"
                },
                "named_attrs": {},
                "type": "reduce"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_115 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_115"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_872",
                "original_op_type": "softmax"
            },
            "type": "reduce",
            "unique_id": 28835
        },
        "softmax_872.dc.reduce_sum.3.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_115 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.softmax_872.dc.reduce_sum.3.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_115": "Data",
                "lc.input_tensor.softmax_872.dc.reduce_sum.3.0": "Data"
            },
            "input_nodes": [
                "_fused_op_115",
                "lc.input_tensor.softmax_872.dc.reduce_sum.3.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_872.dc.reduce_sum.3.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_116 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_116"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_872",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 28841
        },
        "softmax_925.dc.reduce_max.0": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "reduce(3,max,16,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_121 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_121": "Data"
            },
            "input_nodes": [
                "_fused_op_121"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_925.dc.reduce_max.0",
            "op_type": {
                "attrs": [
                    3,
                    "max",
                    16
                ],
                "buda_attrs": {
                    "dim": "c",
                    "type": "max"
                },
                "named_attrs": {},
                "type": "reduce"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_122 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_122"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_925",
                "original_op_type": "softmax"
            },
            "type": "reduce",
            "unique_id": 28939
        },
        "softmax_925.dc.reduce_sum.3.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_122 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.softmax_925.dc.reduce_sum.3.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_122": "Data",
                "lc.input_tensor.softmax_925.dc.reduce_sum.3.0": "Data"
            },
            "input_nodes": [
                "_fused_op_122",
                "lc.input_tensor.softmax_925.dc.reduce_sum.3.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_925.dc.reduce_sum.3.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_123 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_123"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_925",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 28945
        },
        "softmax_978.dc.reduce_max.0": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "reduce(3,max,16,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_128 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_128": "Data"
            },
            "input_nodes": [
                "_fused_op_128"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_978.dc.reduce_max.0",
            "op_type": {
                "attrs": [
                    3,
                    "max",
                    16
                ],
                "buda_attrs": {
                    "dim": "c",
                    "type": "max"
                },
                "named_attrs": {},
                "type": "reduce"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_129 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_129"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_978",
                "original_op_type": "softmax"
            },
            "type": "reduce",
            "unique_id": 29043
        },
        "softmax_978.dc.reduce_sum.3.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_129 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.softmax_978.dc.reduce_sum.3.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_129": "Data",
                "lc.input_tensor.softmax_978.dc.reduce_sum.3.0": "Data"
            },
            "input_nodes": [
                "_fused_op_129",
                "lc.input_tensor.softmax_978.dc.reduce_sum.3.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_978.dc.reduce_sum.3.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_130 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_130"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_978",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 29049
        },
        "subtract_21": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    384
                ]
            },
            "class": "subtract",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: input_0_subtract_21 (port_0) ublock_order(r)",
                "Data: attention_mask_1 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "attention_mask_1": "Data",
                "input_0_subtract_21": "Data"
            },
            "input_nodes": [
                "input_0_subtract_21",
                "attention_mask_1"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "subtract_21",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "subtract"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: multiply_22 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "multiply_22"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert",
                "original_op_name": "subtract_21",
                "original_op_type": "subtract"
            },
            "type": "subtract",
            "unique_id": 27164
        }
    },
    "topological_sorted_nodes": [
        "lc.input_tensor.layernorm_0.dc.reduce_sum.0.0",
        "pybuda_6_i0",
        "layernorm_0.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_0.1",
        "_fused_op_0",
        "layernorm_0.dc.multiply.4",
        "lc.input_tensor.layernorm_0.dc.reduce_sum.5.0",
        "layernorm_0.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_0.6",
        "dc.input_tensor.layernorm_0.8",
        "bert.embeddings.LayerNorm.weight",
        "bert.embeddings.LayerNorm.bias",
        "buffer_1_29655_29656",
        "buffer_0_29655_29656",
        "_fused_op_1",
        "bert.encoder.layer.0.attention.self.query.weight",
        "bert.encoder.layer.0.attention.self.query.bias",
        "matmul_4",
        "bert.encoder.layer.0.attention.self.key.weight",
        "bert.encoder.layer.0.attention.self.key.bias",
        "matmul_10",
        "matmul_16",
        "input_1_multiply_18",
        "attention_mask_1",
        "input_0_subtract_21",
        "subtract_21",
        "input_1_multiply_22",
        "multiply_22",
        "multiply_22_attempt_1_input_op_fork_nop0",
        "_fused_op_2",
        "softmax_24.dc.reduce_max.0",
        "lc.input_tensor.softmax_24.dc.reduce_sum.3.0",
        "_fused_op_3",
        "softmax_24.dc.reduce_sum.3.lc1",
        "dc.input_tensor.softmax_24.4",
        "bert.encoder.layer.0.attention.self.value.weight",
        "bert.encoder.layer.0.attention.self.value.bias",
        "matmul_28",
        "buffer_0_29658_29659",
        "_fused_op_4",
        "matmul_35",
        "bert.encoder.layer.0.attention.output.dense.weight",
        "bert.encoder.layer.0.attention.output.dense.bias",
        "matmul_39",
        "add_43",
        "lc.input_tensor.layernorm_44.dc.reduce_sum.0.0",
        "layernorm_44.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_44.1",
        "buffer_1_27200_29660",
        "buffer_0_27200_29660",
        "_fused_op_5",
        "layernorm_44.dc.multiply.4",
        "lc.input_tensor.layernorm_44.dc.reduce_sum.5.0",
        "layernorm_44.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_44.6",
        "dc.input_tensor.layernorm_44.8",
        "bert.encoder.layer.0.attention.output.LayerNorm.weight",
        "bert.encoder.layer.0.attention.output.LayerNorm.bias",
        "buffer_2_29660_29661",
        "buffer_1_29660_29661",
        "buffer_0_29660_29661",
        "_fused_op_6",
        "bert.encoder.layer.0.intermediate.dense.weight",
        "bert.encoder.layer.0.intermediate.dense.bias",
        "matmul_47",
        "gelu_50",
        "bert.encoder.layer.0.output.dense.weight",
        "bert.encoder.layer.0.output.dense.bias",
        "matmul_53",
        "add_57",
        "lc.input_tensor.layernorm_58.dc.reduce_sum.0.0",
        "layernorm_58.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_58.1",
        "buffer_1_27232_29662",
        "buffer_0_27232_29662",
        "_fused_op_7",
        "layernorm_58.dc.multiply.4",
        "lc.input_tensor.layernorm_58.dc.reduce_sum.5.0",
        "layernorm_58.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_58.6",
        "dc.input_tensor.layernorm_58.8",
        "bert.encoder.layer.0.output.LayerNorm.weight",
        "bert.encoder.layer.0.output.LayerNorm.bias",
        "buffer_1_29662_29663",
        "buffer_0_29662_29663",
        "_fused_op_8",
        "bert.encoder.layer.1.attention.self.query.weight",
        "bert.encoder.layer.1.attention.self.query.bias",
        "matmul_61",
        "bert.encoder.layer.1.attention.self.key.weight",
        "bert.encoder.layer.1.attention.self.key.bias",
        "matmul_67",
        "matmul_73",
        "input_1_multiply_75",
        "_fused_op_9",
        "softmax_77.dc.reduce_max.0",
        "lc.input_tensor.softmax_77.dc.reduce_sum.3.0",
        "_fused_op_10",
        "softmax_77.dc.reduce_sum.3.lc1",
        "dc.input_tensor.softmax_77.4",
        "bert.encoder.layer.1.attention.self.value.weight",
        "bert.encoder.layer.1.attention.self.value.bias",
        "matmul_81",
        "_fused_op_11",
        "matmul_88",
        "bert.encoder.layer.1.attention.output.dense.weight",
        "bert.encoder.layer.1.attention.output.dense.bias",
        "matmul_92",
        "add_96",
        "lc.input_tensor.layernorm_97.dc.reduce_sum.0.0",
        "layernorm_97.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_97.1",
        "buffer_3_27304_29667",
        "buffer_2_27304_29667",
        "buffer_1_27304_29667",
        "buffer_0_27304_29667",
        "_fused_op_12",
        "layernorm_97.dc.multiply.4",
        "lc.input_tensor.layernorm_97.dc.reduce_sum.5.0",
        "layernorm_97.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_97.6",
        "dc.input_tensor.layernorm_97.8",
        "bert.encoder.layer.1.attention.output.LayerNorm.weight",
        "bert.encoder.layer.1.attention.output.LayerNorm.bias",
        "buffer_4_29667_29668",
        "buffer_3_29667_29668",
        "buffer_2_29667_29668",
        "buffer_1_29667_29668",
        "buffer_0_29667_29668",
        "_fused_op_13",
        "bert.encoder.layer.1.intermediate.dense.weight",
        "bert.encoder.layer.1.intermediate.dense.bias",
        "matmul_100",
        "gelu_103",
        "bert.encoder.layer.1.output.dense.weight",
        "bert.encoder.layer.1.output.dense.bias",
        "matmul_106",
        "buffer_7_29668_27336",
        "buffer_6_29668_27336",
        "buffer_5_29668_27336",
        "buffer_4_29668_27336",
        "buffer_3_29668_27336",
        "buffer_2_29668_27336",
        "buffer_1_29668_27336",
        "buffer_0_29668_27336",
        "add_110",
        "lc.input_tensor.layernorm_111.dc.reduce_sum.0.0",
        "layernorm_111.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_111.1",
        "buffer_3_27336_29669",
        "buffer_2_27336_29669",
        "buffer_1_27336_29669",
        "buffer_0_27336_29669",
        "_fused_op_14",
        "layernorm_111.dc.multiply.4",
        "lc.input_tensor.layernorm_111.dc.reduce_sum.5.0",
        "layernorm_111.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_111.6",
        "dc.input_tensor.layernorm_111.8",
        "bert.encoder.layer.1.output.LayerNorm.weight",
        "bert.encoder.layer.1.output.LayerNorm.bias",
        "_fused_op_15",
        "bert.encoder.layer.2.attention.self.query.weight",
        "bert.encoder.layer.2.attention.self.query.bias",
        "matmul_114",
        "bert.encoder.layer.2.attention.self.key.weight",
        "bert.encoder.layer.2.attention.self.key.bias",
        "matmul_120",
        "matmul_126",
        "input_1_multiply_128",
        "_fused_op_16",
        "softmax_130.dc.reduce_max.0",
        "lc.input_tensor.softmax_130.dc.reduce_sum.3.0",
        "_fused_op_17",
        "softmax_130.dc.reduce_sum.3.lc1",
        "dc.input_tensor.softmax_130.4",
        "bert.encoder.layer.2.attention.self.value.weight",
        "bert.encoder.layer.2.attention.self.value.bias",
        "matmul_134",
        "buffer_0_29672_29673",
        "_fused_op_18",
        "matmul_141",
        "bert.encoder.layer.2.attention.output.dense.weight",
        "bert.encoder.layer.2.attention.output.dense.bias",
        "matmul_145",
        "add_149",
        "lc.input_tensor.layernorm_150.dc.reduce_sum.0.0",
        "layernorm_150.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_150.1",
        "buffer_1_27408_29674",
        "buffer_0_27408_29674",
        "_fused_op_19",
        "layernorm_150.dc.multiply.4",
        "lc.input_tensor.layernorm_150.dc.reduce_sum.5.0",
        "layernorm_150.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_150.6",
        "dc.input_tensor.layernorm_150.8",
        "bert.encoder.layer.2.attention.output.LayerNorm.weight",
        "bert.encoder.layer.2.attention.output.LayerNorm.bias",
        "buffer_2_29674_29675",
        "buffer_1_29674_29675",
        "buffer_0_29674_29675",
        "_fused_op_20",
        "bert.encoder.layer.2.intermediate.dense.weight",
        "bert.encoder.layer.2.intermediate.dense.bias",
        "matmul_153",
        "gelu_156",
        "bert.encoder.layer.2.output.dense.weight",
        "bert.encoder.layer.2.output.dense.bias",
        "matmul_159",
        "add_163",
        "lc.input_tensor.layernorm_164.dc.reduce_sum.0.0",
        "layernorm_164.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_164.1",
        "buffer_1_27440_29676",
        "buffer_0_27440_29676",
        "_fused_op_21",
        "layernorm_164.dc.multiply.4",
        "lc.input_tensor.layernorm_164.dc.reduce_sum.5.0",
        "layernorm_164.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_164.6",
        "dc.input_tensor.layernorm_164.8",
        "bert.encoder.layer.2.output.LayerNorm.weight",
        "bert.encoder.layer.2.output.LayerNorm.bias",
        "buffer_1_29676_29677",
        "buffer_0_29676_29677",
        "_fused_op_22",
        "bert.encoder.layer.3.attention.self.query.weight",
        "bert.encoder.layer.3.attention.self.query.bias",
        "matmul_167",
        "bert.encoder.layer.3.attention.self.key.weight",
        "bert.encoder.layer.3.attention.self.key.bias",
        "matmul_173",
        "matmul_179",
        "input_1_multiply_181",
        "_fused_op_23",
        "softmax_183.dc.reduce_max.0",
        "lc.input_tensor.softmax_183.dc.reduce_sum.3.0",
        "_fused_op_24",
        "softmax_183.dc.reduce_sum.3.lc1",
        "dc.input_tensor.softmax_183.4",
        "bert.encoder.layer.3.attention.self.value.weight",
        "bert.encoder.layer.3.attention.self.value.bias",
        "matmul_187",
        "_fused_op_25",
        "matmul_194",
        "bert.encoder.layer.3.attention.output.dense.weight",
        "bert.encoder.layer.3.attention.output.dense.bias",
        "matmul_198",
        "add_202",
        "lc.input_tensor.layernorm_203.dc.reduce_sum.0.0",
        "layernorm_203.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_203.1",
        "buffer_3_27512_29681",
        "buffer_2_27512_29681",
        "buffer_1_27512_29681",
        "buffer_0_27512_29681",
        "_fused_op_26",
        "layernorm_203.dc.multiply.4",
        "lc.input_tensor.layernorm_203.dc.reduce_sum.5.0",
        "layernorm_203.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_203.6",
        "dc.input_tensor.layernorm_203.8",
        "bert.encoder.layer.3.attention.output.LayerNorm.weight",
        "bert.encoder.layer.3.attention.output.LayerNorm.bias",
        "buffer_4_29681_29682",
        "buffer_3_29681_29682",
        "buffer_2_29681_29682",
        "buffer_1_29681_29682",
        "buffer_0_29681_29682",
        "_fused_op_27",
        "bert.encoder.layer.3.intermediate.dense.weight",
        "bert.encoder.layer.3.intermediate.dense.bias",
        "matmul_206",
        "gelu_209",
        "bert.encoder.layer.3.output.dense.weight",
        "bert.encoder.layer.3.output.dense.bias",
        "matmul_212",
        "buffer_7_29682_27544",
        "buffer_6_29682_27544",
        "buffer_5_29682_27544",
        "buffer_4_29682_27544",
        "buffer_3_29682_27544",
        "buffer_2_29682_27544",
        "buffer_1_29682_27544",
        "buffer_0_29682_27544",
        "add_216",
        "lc.input_tensor.layernorm_217.dc.reduce_sum.0.0",
        "layernorm_217.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_217.1",
        "buffer_3_27544_29683",
        "buffer_2_27544_29683",
        "buffer_1_27544_29683",
        "buffer_0_27544_29683",
        "_fused_op_28",
        "layernorm_217.dc.multiply.4",
        "lc.input_tensor.layernorm_217.dc.reduce_sum.5.0",
        "layernorm_217.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_217.6",
        "dc.input_tensor.layernorm_217.8",
        "bert.encoder.layer.3.output.LayerNorm.weight",
        "bert.encoder.layer.3.output.LayerNorm.bias",
        "_fused_op_29",
        "bert.encoder.layer.4.attention.self.query.weight",
        "bert.encoder.layer.4.attention.self.query.bias",
        "matmul_220",
        "bert.encoder.layer.4.attention.self.key.weight",
        "bert.encoder.layer.4.attention.self.key.bias",
        "matmul_226",
        "matmul_232",
        "input_1_multiply_234",
        "_fused_op_30",
        "softmax_236.dc.reduce_max.0",
        "lc.input_tensor.softmax_236.dc.reduce_sum.3.0",
        "_fused_op_31",
        "softmax_236.dc.reduce_sum.3.lc1",
        "dc.input_tensor.softmax_236.4",
        "bert.encoder.layer.4.attention.self.value.weight",
        "bert.encoder.layer.4.attention.self.value.bias",
        "matmul_240",
        "buffer_0_29686_29687",
        "_fused_op_32",
        "matmul_247",
        "bert.encoder.layer.4.attention.output.dense.weight",
        "bert.encoder.layer.4.attention.output.dense.bias",
        "matmul_251",
        "add_255",
        "lc.input_tensor.layernorm_256.dc.reduce_sum.0.0",
        "layernorm_256.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_256.1",
        "buffer_1_27616_29688",
        "buffer_0_27616_29688",
        "_fused_op_33",
        "layernorm_256.dc.multiply.4",
        "lc.input_tensor.layernorm_256.dc.reduce_sum.5.0",
        "layernorm_256.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_256.6",
        "dc.input_tensor.layernorm_256.8",
        "bert.encoder.layer.4.attention.output.LayerNorm.weight",
        "bert.encoder.layer.4.attention.output.LayerNorm.bias",
        "buffer_2_29688_29689",
        "buffer_1_29688_29689",
        "buffer_0_29688_29689",
        "_fused_op_34",
        "bert.encoder.layer.4.intermediate.dense.weight",
        "bert.encoder.layer.4.intermediate.dense.bias",
        "matmul_259",
        "gelu_262",
        "bert.encoder.layer.4.output.dense.weight",
        "bert.encoder.layer.4.output.dense.bias",
        "matmul_265",
        "add_269",
        "lc.input_tensor.layernorm_270.dc.reduce_sum.0.0",
        "layernorm_270.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_270.1",
        "buffer_1_27648_29690",
        "buffer_0_27648_29690",
        "_fused_op_35",
        "layernorm_270.dc.multiply.4",
        "lc.input_tensor.layernorm_270.dc.reduce_sum.5.0",
        "layernorm_270.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_270.6",
        "dc.input_tensor.layernorm_270.8",
        "bert.encoder.layer.4.output.LayerNorm.weight",
        "bert.encoder.layer.4.output.LayerNorm.bias",
        "buffer_1_29690_29691",
        "buffer_0_29690_29691",
        "_fused_op_36",
        "bert.encoder.layer.5.attention.self.query.weight",
        "bert.encoder.layer.5.attention.self.query.bias",
        "matmul_273",
        "bert.encoder.layer.5.attention.self.key.weight",
        "bert.encoder.layer.5.attention.self.key.bias",
        "matmul_279",
        "matmul_285",
        "input_1_multiply_287",
        "_fused_op_37",
        "softmax_289.dc.reduce_max.0",
        "lc.input_tensor.softmax_289.dc.reduce_sum.3.0",
        "_fused_op_38",
        "softmax_289.dc.reduce_sum.3.lc1",
        "dc.input_tensor.softmax_289.4",
        "bert.encoder.layer.5.attention.self.value.weight",
        "bert.encoder.layer.5.attention.self.value.bias",
        "matmul_293",
        "_fused_op_39",
        "matmul_300",
        "bert.encoder.layer.5.attention.output.dense.weight",
        "bert.encoder.layer.5.attention.output.dense.bias",
        "matmul_304",
        "add_308",
        "lc.input_tensor.layernorm_309.dc.reduce_sum.0.0",
        "layernorm_309.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_309.1",
        "buffer_3_27720_29695",
        "buffer_2_27720_29695",
        "buffer_1_27720_29695",
        "buffer_0_27720_29695",
        "_fused_op_40",
        "layernorm_309.dc.multiply.4",
        "lc.input_tensor.layernorm_309.dc.reduce_sum.5.0",
        "layernorm_309.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_309.6",
        "dc.input_tensor.layernorm_309.8",
        "bert.encoder.layer.5.attention.output.LayerNorm.weight",
        "bert.encoder.layer.5.attention.output.LayerNorm.bias",
        "buffer_4_29695_29696",
        "buffer_3_29695_29696",
        "buffer_2_29695_29696",
        "buffer_1_29695_29696",
        "buffer_0_29695_29696",
        "_fused_op_41",
        "bert.encoder.layer.5.intermediate.dense.weight",
        "bert.encoder.layer.5.intermediate.dense.bias",
        "matmul_312",
        "gelu_315",
        "bert.encoder.layer.5.output.dense.weight",
        "bert.encoder.layer.5.output.dense.bias",
        "matmul_318",
        "buffer_7_29696_27752",
        "buffer_6_29696_27752",
        "buffer_5_29696_27752",
        "buffer_4_29696_27752",
        "buffer_3_29696_27752",
        "buffer_2_29696_27752",
        "buffer_1_29696_27752",
        "buffer_0_29696_27752",
        "add_322",
        "lc.input_tensor.layernorm_323.dc.reduce_sum.0.0",
        "layernorm_323.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_323.1",
        "buffer_3_27752_29697",
        "buffer_2_27752_29697",
        "buffer_1_27752_29697",
        "buffer_0_27752_29697",
        "_fused_op_42",
        "layernorm_323.dc.multiply.4",
        "lc.input_tensor.layernorm_323.dc.reduce_sum.5.0",
        "layernorm_323.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_323.6",
        "dc.input_tensor.layernorm_323.8",
        "bert.encoder.layer.5.output.LayerNorm.weight",
        "bert.encoder.layer.5.output.LayerNorm.bias",
        "_fused_op_43",
        "bert.encoder.layer.6.attention.self.query.weight",
        "bert.encoder.layer.6.attention.self.query.bias",
        "matmul_326",
        "bert.encoder.layer.6.attention.self.key.weight",
        "bert.encoder.layer.6.attention.self.key.bias",
        "matmul_332",
        "matmul_338",
        "input_1_multiply_340",
        "_fused_op_44",
        "softmax_342.dc.reduce_max.0",
        "lc.input_tensor.softmax_342.dc.reduce_sum.3.0",
        "_fused_op_45",
        "softmax_342.dc.reduce_sum.3.lc1",
        "dc.input_tensor.softmax_342.4",
        "bert.encoder.layer.6.attention.self.value.weight",
        "bert.encoder.layer.6.attention.self.value.bias",
        "matmul_346",
        "buffer_0_29700_29701",
        "_fused_op_46",
        "matmul_353",
        "bert.encoder.layer.6.attention.output.dense.weight",
        "bert.encoder.layer.6.attention.output.dense.bias",
        "matmul_357",
        "add_361",
        "lc.input_tensor.layernorm_362.dc.reduce_sum.0.0",
        "layernorm_362.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_362.1",
        "buffer_1_27824_29702",
        "buffer_0_27824_29702",
        "_fused_op_47",
        "layernorm_362.dc.multiply.4",
        "lc.input_tensor.layernorm_362.dc.reduce_sum.5.0",
        "layernorm_362.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_362.6",
        "dc.input_tensor.layernorm_362.8",
        "bert.encoder.layer.6.attention.output.LayerNorm.weight",
        "bert.encoder.layer.6.attention.output.LayerNorm.bias",
        "buffer_2_29702_29703",
        "buffer_1_29702_29703",
        "buffer_0_29702_29703",
        "_fused_op_48",
        "bert.encoder.layer.6.intermediate.dense.weight",
        "bert.encoder.layer.6.intermediate.dense.bias",
        "matmul_365",
        "gelu_368",
        "bert.encoder.layer.6.output.dense.weight",
        "bert.encoder.layer.6.output.dense.bias",
        "matmul_371",
        "add_375",
        "lc.input_tensor.layernorm_376.dc.reduce_sum.0.0",
        "layernorm_376.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_376.1",
        "buffer_1_27856_29704",
        "buffer_0_27856_29704",
        "_fused_op_49",
        "layernorm_376.dc.multiply.4",
        "lc.input_tensor.layernorm_376.dc.reduce_sum.5.0",
        "layernorm_376.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_376.6",
        "dc.input_tensor.layernorm_376.8",
        "bert.encoder.layer.6.output.LayerNorm.weight",
        "bert.encoder.layer.6.output.LayerNorm.bias",
        "buffer_1_29704_29705",
        "buffer_0_29704_29705",
        "_fused_op_50",
        "bert.encoder.layer.7.attention.self.query.weight",
        "bert.encoder.layer.7.attention.self.query.bias",
        "matmul_379",
        "bert.encoder.layer.7.attention.self.key.weight",
        "bert.encoder.layer.7.attention.self.key.bias",
        "matmul_385",
        "matmul_391",
        "input_1_multiply_393",
        "_fused_op_51",
        "softmax_395.dc.reduce_max.0",
        "lc.input_tensor.softmax_395.dc.reduce_sum.3.0",
        "_fused_op_52",
        "softmax_395.dc.reduce_sum.3.lc1",
        "dc.input_tensor.softmax_395.4",
        "bert.encoder.layer.7.attention.self.value.weight",
        "bert.encoder.layer.7.attention.self.value.bias",
        "matmul_399",
        "_fused_op_53",
        "matmul_406",
        "bert.encoder.layer.7.attention.output.dense.weight",
        "bert.encoder.layer.7.attention.output.dense.bias",
        "matmul_410",
        "add_414",
        "lc.input_tensor.layernorm_415.dc.reduce_sum.0.0",
        "layernorm_415.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_415.1",
        "buffer_3_27928_29709",
        "buffer_2_27928_29709",
        "buffer_1_27928_29709",
        "buffer_0_27928_29709",
        "_fused_op_54",
        "layernorm_415.dc.multiply.4",
        "lc.input_tensor.layernorm_415.dc.reduce_sum.5.0",
        "layernorm_415.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_415.6",
        "dc.input_tensor.layernorm_415.8",
        "bert.encoder.layer.7.attention.output.LayerNorm.weight",
        "bert.encoder.layer.7.attention.output.LayerNorm.bias",
        "buffer_4_29709_29710",
        "buffer_3_29709_29710",
        "buffer_2_29709_29710",
        "buffer_1_29709_29710",
        "buffer_0_29709_29710",
        "_fused_op_55",
        "bert.encoder.layer.7.intermediate.dense.weight",
        "bert.encoder.layer.7.intermediate.dense.bias",
        "matmul_418",
        "gelu_421",
        "bert.encoder.layer.7.output.dense.weight",
        "bert.encoder.layer.7.output.dense.bias",
        "matmul_424",
        "buffer_7_29710_27960",
        "buffer_6_29710_27960",
        "buffer_5_29710_27960",
        "buffer_4_29710_27960",
        "buffer_3_29710_27960",
        "buffer_2_29710_27960",
        "buffer_1_29710_27960",
        "buffer_0_29710_27960",
        "add_428",
        "lc.input_tensor.layernorm_429.dc.reduce_sum.0.0",
        "layernorm_429.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_429.1",
        "buffer_3_27960_29711",
        "buffer_2_27960_29711",
        "buffer_1_27960_29711",
        "buffer_0_27960_29711",
        "_fused_op_56",
        "layernorm_429.dc.multiply.4",
        "lc.input_tensor.layernorm_429.dc.reduce_sum.5.0",
        "layernorm_429.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_429.6",
        "dc.input_tensor.layernorm_429.8",
        "bert.encoder.layer.7.output.LayerNorm.weight",
        "bert.encoder.layer.7.output.LayerNorm.bias",
        "_fused_op_57",
        "bert.encoder.layer.8.attention.self.query.weight",
        "bert.encoder.layer.8.attention.self.query.bias",
        "matmul_432",
        "bert.encoder.layer.8.attention.self.key.weight",
        "bert.encoder.layer.8.attention.self.key.bias",
        "matmul_438",
        "matmul_444",
        "input_1_multiply_446",
        "multiply_22_attempt_1_input_op_fork_nop1",
        "_fused_op_58",
        "softmax_448.dc.reduce_max.0",
        "lc.input_tensor.softmax_448.dc.reduce_sum.3.0",
        "_fused_op_59",
        "softmax_448.dc.reduce_sum.3.lc1",
        "dc.input_tensor.softmax_448.4",
        "bert.encoder.layer.8.attention.self.value.weight",
        "bert.encoder.layer.8.attention.self.value.bias",
        "matmul_452",
        "buffer_0_29714_29715",
        "_fused_op_60",
        "matmul_459",
        "bert.encoder.layer.8.attention.output.dense.weight",
        "bert.encoder.layer.8.attention.output.dense.bias",
        "matmul_463",
        "add_467",
        "lc.input_tensor.layernorm_468.dc.reduce_sum.0.0",
        "layernorm_468.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_468.1",
        "buffer_1_28032_29716",
        "buffer_0_28032_29716",
        "_fused_op_61",
        "layernorm_468.dc.multiply.4",
        "lc.input_tensor.layernorm_468.dc.reduce_sum.5.0",
        "layernorm_468.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_468.6",
        "dc.input_tensor.layernorm_468.8",
        "bert.encoder.layer.8.attention.output.LayerNorm.weight",
        "bert.encoder.layer.8.attention.output.LayerNorm.bias",
        "buffer_2_29716_29717",
        "buffer_1_29716_29717",
        "buffer_0_29716_29717",
        "_fused_op_62",
        "bert.encoder.layer.8.intermediate.dense.weight",
        "bert.encoder.layer.8.intermediate.dense.bias",
        "matmul_471",
        "gelu_474",
        "bert.encoder.layer.8.output.dense.weight",
        "bert.encoder.layer.8.output.dense.bias",
        "matmul_477",
        "add_481",
        "lc.input_tensor.layernorm_482.dc.reduce_sum.0.0",
        "layernorm_482.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_482.1",
        "buffer_1_28064_29718",
        "buffer_0_28064_29718",
        "_fused_op_63",
        "layernorm_482.dc.multiply.4",
        "lc.input_tensor.layernorm_482.dc.reduce_sum.5.0",
        "layernorm_482.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_482.6",
        "dc.input_tensor.layernorm_482.8",
        "bert.encoder.layer.8.output.LayerNorm.weight",
        "bert.encoder.layer.8.output.LayerNorm.bias",
        "buffer_1_29718_29719",
        "buffer_0_29718_29719",
        "_fused_op_64",
        "bert.encoder.layer.9.attention.self.query.weight",
        "bert.encoder.layer.9.attention.self.query.bias",
        "matmul_485",
        "bert.encoder.layer.9.attention.self.key.weight",
        "bert.encoder.layer.9.attention.self.key.bias",
        "matmul_491",
        "matmul_497",
        "input_1_multiply_499",
        "_fused_op_65",
        "softmax_501.dc.reduce_max.0",
        "lc.input_tensor.softmax_501.dc.reduce_sum.3.0",
        "_fused_op_66",
        "softmax_501.dc.reduce_sum.3.lc1",
        "dc.input_tensor.softmax_501.4",
        "bert.encoder.layer.9.attention.self.value.weight",
        "bert.encoder.layer.9.attention.self.value.bias",
        "matmul_505",
        "_fused_op_67",
        "matmul_512",
        "bert.encoder.layer.9.attention.output.dense.weight",
        "bert.encoder.layer.9.attention.output.dense.bias",
        "matmul_516",
        "add_520",
        "lc.input_tensor.layernorm_521.dc.reduce_sum.0.0",
        "layernorm_521.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_521.1",
        "buffer_3_28136_29723",
        "buffer_2_28136_29723",
        "buffer_1_28136_29723",
        "buffer_0_28136_29723",
        "_fused_op_68",
        "layernorm_521.dc.multiply.4",
        "lc.input_tensor.layernorm_521.dc.reduce_sum.5.0",
        "layernorm_521.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_521.6",
        "dc.input_tensor.layernorm_521.8",
        "bert.encoder.layer.9.attention.output.LayerNorm.weight",
        "bert.encoder.layer.9.attention.output.LayerNorm.bias",
        "buffer_4_29723_29724",
        "buffer_3_29723_29724",
        "buffer_2_29723_29724",
        "buffer_1_29723_29724",
        "buffer_0_29723_29724",
        "_fused_op_69",
        "bert.encoder.layer.9.intermediate.dense.weight",
        "bert.encoder.layer.9.intermediate.dense.bias",
        "matmul_524",
        "gelu_527",
        "bert.encoder.layer.9.output.dense.weight",
        "bert.encoder.layer.9.output.dense.bias",
        "matmul_530",
        "buffer_7_29724_28168",
        "buffer_6_29724_28168",
        "buffer_5_29724_28168",
        "buffer_4_29724_28168",
        "buffer_3_29724_28168",
        "buffer_2_29724_28168",
        "buffer_1_29724_28168",
        "buffer_0_29724_28168",
        "add_534",
        "lc.input_tensor.layernorm_535.dc.reduce_sum.0.0",
        "layernorm_535.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_535.1",
        "buffer_3_28168_29725",
        "buffer_2_28168_29725",
        "buffer_1_28168_29725",
        "buffer_0_28168_29725",
        "_fused_op_70",
        "layernorm_535.dc.multiply.4",
        "lc.input_tensor.layernorm_535.dc.reduce_sum.5.0",
        "layernorm_535.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_535.6",
        "dc.input_tensor.layernorm_535.8",
        "bert.encoder.layer.9.output.LayerNorm.weight",
        "bert.encoder.layer.9.output.LayerNorm.bias",
        "_fused_op_71",
        "bert.encoder.layer.10.attention.self.query.weight",
        "bert.encoder.layer.10.attention.self.query.bias",
        "matmul_538",
        "bert.encoder.layer.10.attention.self.key.weight",
        "bert.encoder.layer.10.attention.self.key.bias",
        "matmul_544",
        "matmul_550",
        "input_1_multiply_552",
        "_fused_op_72",
        "softmax_554.dc.reduce_max.0",
        "lc.input_tensor.softmax_554.dc.reduce_sum.3.0",
        "_fused_op_73",
        "softmax_554.dc.reduce_sum.3.lc1",
        "dc.input_tensor.softmax_554.4",
        "bert.encoder.layer.10.attention.self.value.weight",
        "bert.encoder.layer.10.attention.self.value.bias",
        "matmul_558",
        "buffer_0_29728_29729",
        "_fused_op_74",
        "matmul_565",
        "bert.encoder.layer.10.attention.output.dense.weight",
        "bert.encoder.layer.10.attention.output.dense.bias",
        "matmul_569",
        "add_573",
        "lc.input_tensor.layernorm_574.dc.reduce_sum.0.0",
        "layernorm_574.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_574.1",
        "buffer_1_28240_29730",
        "buffer_0_28240_29730",
        "_fused_op_75",
        "layernorm_574.dc.multiply.4",
        "lc.input_tensor.layernorm_574.dc.reduce_sum.5.0",
        "layernorm_574.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_574.6",
        "dc.input_tensor.layernorm_574.8",
        "bert.encoder.layer.10.attention.output.LayerNorm.weight",
        "bert.encoder.layer.10.attention.output.LayerNorm.bias",
        "buffer_2_29730_29731",
        "buffer_1_29730_29731",
        "buffer_0_29730_29731",
        "_fused_op_76",
        "bert.encoder.layer.10.intermediate.dense.weight",
        "bert.encoder.layer.10.intermediate.dense.bias",
        "matmul_577",
        "gelu_580",
        "bert.encoder.layer.10.output.dense.weight",
        "bert.encoder.layer.10.output.dense.bias",
        "matmul_583",
        "add_587",
        "lc.input_tensor.layernorm_588.dc.reduce_sum.0.0",
        "layernorm_588.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_588.1",
        "buffer_1_28272_29732",
        "buffer_0_28272_29732",
        "_fused_op_77",
        "layernorm_588.dc.multiply.4",
        "lc.input_tensor.layernorm_588.dc.reduce_sum.5.0",
        "layernorm_588.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_588.6",
        "dc.input_tensor.layernorm_588.8",
        "bert.encoder.layer.10.output.LayerNorm.weight",
        "bert.encoder.layer.10.output.LayerNorm.bias",
        "buffer_1_29732_29733",
        "buffer_0_29732_29733",
        "_fused_op_78",
        "bert.encoder.layer.11.attention.self.query.weight",
        "bert.encoder.layer.11.attention.self.query.bias",
        "matmul_591",
        "bert.encoder.layer.11.attention.self.key.weight",
        "bert.encoder.layer.11.attention.self.key.bias",
        "matmul_597",
        "matmul_603",
        "input_1_multiply_605",
        "_fused_op_79",
        "softmax_607.dc.reduce_max.0",
        "lc.input_tensor.softmax_607.dc.reduce_sum.3.0",
        "_fused_op_80",
        "softmax_607.dc.reduce_sum.3.lc1",
        "dc.input_tensor.softmax_607.4",
        "bert.encoder.layer.11.attention.self.value.weight",
        "bert.encoder.layer.11.attention.self.value.bias",
        "matmul_611",
        "_fused_op_81",
        "matmul_618",
        "bert.encoder.layer.11.attention.output.dense.weight",
        "bert.encoder.layer.11.attention.output.dense.bias",
        "matmul_622",
        "add_626",
        "lc.input_tensor.layernorm_627.dc.reduce_sum.0.0",
        "layernorm_627.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_627.1",
        "buffer_3_28344_29737",
        "buffer_2_28344_29737",
        "buffer_1_28344_29737",
        "buffer_0_28344_29737",
        "_fused_op_82",
        "layernorm_627.dc.multiply.4",
        "lc.input_tensor.layernorm_627.dc.reduce_sum.5.0",
        "layernorm_627.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_627.6",
        "dc.input_tensor.layernorm_627.8",
        "bert.encoder.layer.11.attention.output.LayerNorm.weight",
        "bert.encoder.layer.11.attention.output.LayerNorm.bias",
        "buffer_4_29737_29738",
        "buffer_3_29737_29738",
        "buffer_2_29737_29738",
        "buffer_1_29737_29738",
        "buffer_0_29737_29738",
        "_fused_op_83",
        "bert.encoder.layer.11.intermediate.dense.weight",
        "bert.encoder.layer.11.intermediate.dense.bias",
        "matmul_630",
        "gelu_633",
        "bert.encoder.layer.11.output.dense.weight",
        "bert.encoder.layer.11.output.dense.bias",
        "matmul_636",
        "buffer_7_29738_28376",
        "buffer_6_29738_28376",
        "buffer_5_29738_28376",
        "buffer_4_29738_28376",
        "buffer_3_29738_28376",
        "buffer_2_29738_28376",
        "buffer_1_29738_28376",
        "buffer_0_29738_28376",
        "add_640",
        "lc.input_tensor.layernorm_641.dc.reduce_sum.0.0",
        "layernorm_641.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_641.1",
        "buffer_3_28376_29739",
        "buffer_2_28376_29739",
        "buffer_1_28376_29739",
        "buffer_0_28376_29739",
        "_fused_op_84",
        "layernorm_641.dc.multiply.4",
        "lc.input_tensor.layernorm_641.dc.reduce_sum.5.0",
        "layernorm_641.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_641.6",
        "dc.input_tensor.layernorm_641.8",
        "bert.encoder.layer.11.output.LayerNorm.weight",
        "bert.encoder.layer.11.output.LayerNorm.bias",
        "_fused_op_85",
        "bert.encoder.layer.12.attention.self.query.weight",
        "bert.encoder.layer.12.attention.self.query.bias",
        "matmul_644",
        "bert.encoder.layer.12.attention.self.key.weight",
        "bert.encoder.layer.12.attention.self.key.bias",
        "matmul_650",
        "matmul_656",
        "input_1_multiply_658",
        "_fused_op_86",
        "softmax_660.dc.reduce_max.0",
        "lc.input_tensor.softmax_660.dc.reduce_sum.3.0",
        "_fused_op_87",
        "softmax_660.dc.reduce_sum.3.lc1",
        "dc.input_tensor.softmax_660.4",
        "bert.encoder.layer.12.attention.self.value.weight",
        "bert.encoder.layer.12.attention.self.value.bias",
        "matmul_664",
        "buffer_0_29742_29743",
        "_fused_op_88",
        "matmul_671",
        "bert.encoder.layer.12.attention.output.dense.weight",
        "bert.encoder.layer.12.attention.output.dense.bias",
        "matmul_675",
        "add_679",
        "lc.input_tensor.layernorm_680.dc.reduce_sum.0.0",
        "layernorm_680.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_680.1",
        "buffer_1_28448_29744",
        "buffer_0_28448_29744",
        "_fused_op_89",
        "layernorm_680.dc.multiply.4",
        "lc.input_tensor.layernorm_680.dc.reduce_sum.5.0",
        "layernorm_680.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_680.6",
        "dc.input_tensor.layernorm_680.8",
        "bert.encoder.layer.12.attention.output.LayerNorm.weight",
        "bert.encoder.layer.12.attention.output.LayerNorm.bias",
        "buffer_2_29744_29745",
        "buffer_1_29744_29745",
        "buffer_0_29744_29745",
        "_fused_op_90",
        "bert.encoder.layer.12.intermediate.dense.weight",
        "bert.encoder.layer.12.intermediate.dense.bias",
        "matmul_683",
        "gelu_686",
        "bert.encoder.layer.12.output.dense.weight",
        "bert.encoder.layer.12.output.dense.bias",
        "matmul_689",
        "add_693",
        "lc.input_tensor.layernorm_694.dc.reduce_sum.0.0",
        "layernorm_694.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_694.1",
        "buffer_1_28480_29746",
        "buffer_0_28480_29746",
        "_fused_op_91",
        "layernorm_694.dc.multiply.4",
        "lc.input_tensor.layernorm_694.dc.reduce_sum.5.0",
        "layernorm_694.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_694.6",
        "dc.input_tensor.layernorm_694.8",
        "bert.encoder.layer.12.output.LayerNorm.weight",
        "bert.encoder.layer.12.output.LayerNorm.bias",
        "buffer_1_29746_29747",
        "buffer_0_29746_29747",
        "_fused_op_92",
        "bert.encoder.layer.13.attention.self.query.weight",
        "bert.encoder.layer.13.attention.self.query.bias",
        "matmul_697",
        "bert.encoder.layer.13.attention.self.key.weight",
        "bert.encoder.layer.13.attention.self.key.bias",
        "matmul_703",
        "matmul_709",
        "input_1_multiply_711",
        "_fused_op_93",
        "softmax_713.dc.reduce_max.0",
        "lc.input_tensor.softmax_713.dc.reduce_sum.3.0",
        "_fused_op_94",
        "softmax_713.dc.reduce_sum.3.lc1",
        "dc.input_tensor.softmax_713.4",
        "bert.encoder.layer.13.attention.self.value.weight",
        "bert.encoder.layer.13.attention.self.value.bias",
        "matmul_717",
        "_fused_op_95",
        "matmul_724",
        "bert.encoder.layer.13.attention.output.dense.weight",
        "bert.encoder.layer.13.attention.output.dense.bias",
        "matmul_728",
        "add_732",
        "lc.input_tensor.layernorm_733.dc.reduce_sum.0.0",
        "layernorm_733.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_733.1",
        "buffer_3_28552_29751",
        "buffer_2_28552_29751",
        "buffer_1_28552_29751",
        "buffer_0_28552_29751",
        "_fused_op_96",
        "layernorm_733.dc.multiply.4",
        "lc.input_tensor.layernorm_733.dc.reduce_sum.5.0",
        "layernorm_733.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_733.6",
        "dc.input_tensor.layernorm_733.8",
        "bert.encoder.layer.13.attention.output.LayerNorm.weight",
        "bert.encoder.layer.13.attention.output.LayerNorm.bias",
        "buffer_4_29751_29752",
        "buffer_3_29751_29752",
        "buffer_2_29751_29752",
        "buffer_1_29751_29752",
        "buffer_0_29751_29752",
        "_fused_op_97",
        "bert.encoder.layer.13.intermediate.dense.weight",
        "bert.encoder.layer.13.intermediate.dense.bias",
        "matmul_736",
        "gelu_739",
        "bert.encoder.layer.13.output.dense.weight",
        "bert.encoder.layer.13.output.dense.bias",
        "matmul_742",
        "buffer_7_29752_28584",
        "buffer_6_29752_28584",
        "buffer_5_29752_28584",
        "buffer_4_29752_28584",
        "buffer_3_29752_28584",
        "buffer_2_29752_28584",
        "buffer_1_29752_28584",
        "buffer_0_29752_28584",
        "add_746",
        "lc.input_tensor.layernorm_747.dc.reduce_sum.0.0",
        "layernorm_747.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_747.1",
        "buffer_3_28584_29753",
        "buffer_2_28584_29753",
        "buffer_1_28584_29753",
        "buffer_0_28584_29753",
        "_fused_op_98",
        "layernorm_747.dc.multiply.4",
        "lc.input_tensor.layernorm_747.dc.reduce_sum.5.0",
        "layernorm_747.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_747.6",
        "dc.input_tensor.layernorm_747.8",
        "bert.encoder.layer.13.output.LayerNorm.weight",
        "bert.encoder.layer.13.output.LayerNorm.bias",
        "_fused_op_99",
        "bert.encoder.layer.14.attention.self.query.weight",
        "bert.encoder.layer.14.attention.self.query.bias",
        "matmul_750",
        "bert.encoder.layer.14.attention.self.key.weight",
        "bert.encoder.layer.14.attention.self.key.bias",
        "matmul_756",
        "matmul_762",
        "input_1_multiply_764",
        "_fused_op_100",
        "softmax_766.dc.reduce_max.0",
        "lc.input_tensor.softmax_766.dc.reduce_sum.3.0",
        "_fused_op_101",
        "softmax_766.dc.reduce_sum.3.lc1",
        "dc.input_tensor.softmax_766.4",
        "bert.encoder.layer.14.attention.self.value.weight",
        "bert.encoder.layer.14.attention.self.value.bias",
        "matmul_770",
        "buffer_0_29756_29757",
        "_fused_op_102",
        "matmul_777",
        "bert.encoder.layer.14.attention.output.dense.weight",
        "bert.encoder.layer.14.attention.output.dense.bias",
        "matmul_781",
        "add_785",
        "lc.input_tensor.layernorm_786.dc.reduce_sum.0.0",
        "layernorm_786.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_786.1",
        "buffer_1_28656_29758",
        "buffer_0_28656_29758",
        "_fused_op_103",
        "layernorm_786.dc.multiply.4",
        "lc.input_tensor.layernorm_786.dc.reduce_sum.5.0",
        "layernorm_786.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_786.6",
        "dc.input_tensor.layernorm_786.8",
        "bert.encoder.layer.14.attention.output.LayerNorm.weight",
        "bert.encoder.layer.14.attention.output.LayerNorm.bias",
        "buffer_2_29758_29759",
        "buffer_1_29758_29759",
        "buffer_0_29758_29759",
        "_fused_op_104",
        "bert.encoder.layer.14.intermediate.dense.weight",
        "bert.encoder.layer.14.intermediate.dense.bias",
        "matmul_789",
        "gelu_792",
        "bert.encoder.layer.14.output.dense.weight",
        "bert.encoder.layer.14.output.dense.bias",
        "matmul_795",
        "add_799",
        "lc.input_tensor.layernorm_800.dc.reduce_sum.0.0",
        "layernorm_800.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_800.1",
        "buffer_1_28688_29760",
        "buffer_0_28688_29760",
        "_fused_op_105",
        "layernorm_800.dc.multiply.4",
        "lc.input_tensor.layernorm_800.dc.reduce_sum.5.0",
        "layernorm_800.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_800.6",
        "dc.input_tensor.layernorm_800.8",
        "bert.encoder.layer.14.output.LayerNorm.weight",
        "bert.encoder.layer.14.output.LayerNorm.bias",
        "buffer_1_29760_29761",
        "buffer_0_29760_29761",
        "_fused_op_106",
        "bert.encoder.layer.15.attention.self.query.weight",
        "bert.encoder.layer.15.attention.self.query.bias",
        "matmul_803",
        "bert.encoder.layer.15.attention.self.key.weight",
        "bert.encoder.layer.15.attention.self.key.bias",
        "matmul_809",
        "matmul_815",
        "input_1_multiply_817",
        "_fused_op_107",
        "softmax_819.dc.reduce_max.0",
        "lc.input_tensor.softmax_819.dc.reduce_sum.3.0",
        "_fused_op_108",
        "softmax_819.dc.reduce_sum.3.lc1",
        "dc.input_tensor.softmax_819.4",
        "bert.encoder.layer.15.attention.self.value.weight",
        "bert.encoder.layer.15.attention.self.value.bias",
        "matmul_823",
        "_fused_op_109",
        "matmul_830",
        "bert.encoder.layer.15.attention.output.dense.weight",
        "bert.encoder.layer.15.attention.output.dense.bias",
        "matmul_834",
        "add_838",
        "lc.input_tensor.layernorm_839.dc.reduce_sum.0.0",
        "layernorm_839.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_839.1",
        "buffer_3_28760_29765",
        "buffer_2_28760_29765",
        "buffer_1_28760_29765",
        "buffer_0_28760_29765",
        "_fused_op_110",
        "layernorm_839.dc.multiply.4",
        "lc.input_tensor.layernorm_839.dc.reduce_sum.5.0",
        "layernorm_839.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_839.6",
        "dc.input_tensor.layernorm_839.8",
        "bert.encoder.layer.15.attention.output.LayerNorm.weight",
        "bert.encoder.layer.15.attention.output.LayerNorm.bias",
        "buffer_4_29765_29766",
        "buffer_3_29765_29766",
        "buffer_2_29765_29766",
        "buffer_1_29765_29766",
        "buffer_0_29765_29766",
        "_fused_op_111",
        "bert.encoder.layer.15.intermediate.dense.weight",
        "bert.encoder.layer.15.intermediate.dense.bias",
        "matmul_842",
        "gelu_845",
        "bert.encoder.layer.15.output.dense.weight",
        "bert.encoder.layer.15.output.dense.bias",
        "matmul_848",
        "buffer_7_29766_28792",
        "buffer_6_29766_28792",
        "buffer_5_29766_28792",
        "buffer_4_29766_28792",
        "buffer_3_29766_28792",
        "buffer_2_29766_28792",
        "buffer_1_29766_28792",
        "buffer_0_29766_28792",
        "add_852",
        "lc.input_tensor.layernorm_853.dc.reduce_sum.0.0",
        "layernorm_853.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_853.1",
        "buffer_3_28792_29767",
        "buffer_2_28792_29767",
        "buffer_1_28792_29767",
        "buffer_0_28792_29767",
        "_fused_op_112",
        "layernorm_853.dc.multiply.4",
        "lc.input_tensor.layernorm_853.dc.reduce_sum.5.0",
        "layernorm_853.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_853.6",
        "dc.input_tensor.layernorm_853.8",
        "bert.encoder.layer.15.output.LayerNorm.weight",
        "bert.encoder.layer.15.output.LayerNorm.bias",
        "_fused_op_113",
        "bert.encoder.layer.16.attention.self.query.weight",
        "bert.encoder.layer.16.attention.self.query.bias",
        "matmul_856",
        "bert.encoder.layer.16.attention.self.key.weight",
        "bert.encoder.layer.16.attention.self.key.bias",
        "matmul_862",
        "matmul_868",
        "input_1_multiply_870",
        "multiply_22_attempt_1_input_op_fork_nop2",
        "_fused_op_114",
        "softmax_872.dc.reduce_max.0",
        "lc.input_tensor.softmax_872.dc.reduce_sum.3.0",
        "_fused_op_115",
        "softmax_872.dc.reduce_sum.3.lc1",
        "dc.input_tensor.softmax_872.4",
        "bert.encoder.layer.16.attention.self.value.weight",
        "bert.encoder.layer.16.attention.self.value.bias",
        "matmul_876",
        "buffer_0_29770_29771",
        "_fused_op_116",
        "matmul_883",
        "bert.encoder.layer.16.attention.output.dense.weight",
        "bert.encoder.layer.16.attention.output.dense.bias",
        "matmul_887",
        "add_891",
        "lc.input_tensor.layernorm_892.dc.reduce_sum.0.0",
        "layernorm_892.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_892.1",
        "buffer_1_28864_29772",
        "buffer_0_28864_29772",
        "_fused_op_117",
        "layernorm_892.dc.multiply.4",
        "lc.input_tensor.layernorm_892.dc.reduce_sum.5.0",
        "layernorm_892.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_892.6",
        "dc.input_tensor.layernorm_892.8",
        "bert.encoder.layer.16.attention.output.LayerNorm.weight",
        "bert.encoder.layer.16.attention.output.LayerNorm.bias",
        "buffer_2_29772_29773",
        "buffer_1_29772_29773",
        "buffer_0_29772_29773",
        "_fused_op_118",
        "bert.encoder.layer.16.intermediate.dense.weight",
        "bert.encoder.layer.16.intermediate.dense.bias",
        "matmul_895",
        "gelu_898",
        "bert.encoder.layer.16.output.dense.weight",
        "bert.encoder.layer.16.output.dense.bias",
        "matmul_901",
        "add_905",
        "lc.input_tensor.layernorm_906.dc.reduce_sum.0.0",
        "layernorm_906.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_906.1",
        "buffer_1_28896_29774",
        "buffer_0_28896_29774",
        "_fused_op_119",
        "layernorm_906.dc.multiply.4",
        "lc.input_tensor.layernorm_906.dc.reduce_sum.5.0",
        "layernorm_906.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_906.6",
        "dc.input_tensor.layernorm_906.8",
        "bert.encoder.layer.16.output.LayerNorm.weight",
        "bert.encoder.layer.16.output.LayerNorm.bias",
        "buffer_1_29774_29775",
        "buffer_0_29774_29775",
        "_fused_op_120",
        "bert.encoder.layer.17.attention.self.query.weight",
        "bert.encoder.layer.17.attention.self.query.bias",
        "matmul_909",
        "bert.encoder.layer.17.attention.self.key.weight",
        "bert.encoder.layer.17.attention.self.key.bias",
        "matmul_915",
        "matmul_921",
        "input_1_multiply_923",
        "_fused_op_121",
        "softmax_925.dc.reduce_max.0",
        "lc.input_tensor.softmax_925.dc.reduce_sum.3.0",
        "_fused_op_122",
        "softmax_925.dc.reduce_sum.3.lc1",
        "dc.input_tensor.softmax_925.4",
        "bert.encoder.layer.17.attention.self.value.weight",
        "bert.encoder.layer.17.attention.self.value.bias",
        "matmul_929",
        "_fused_op_123",
        "matmul_936",
        "bert.encoder.layer.17.attention.output.dense.weight",
        "bert.encoder.layer.17.attention.output.dense.bias",
        "matmul_940",
        "add_944",
        "lc.input_tensor.layernorm_945.dc.reduce_sum.0.0",
        "layernorm_945.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_945.1",
        "buffer_3_28968_29779",
        "buffer_2_28968_29779",
        "buffer_1_28968_29779",
        "buffer_0_28968_29779",
        "_fused_op_124",
        "layernorm_945.dc.multiply.4",
        "lc.input_tensor.layernorm_945.dc.reduce_sum.5.0",
        "layernorm_945.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_945.6",
        "dc.input_tensor.layernorm_945.8",
        "bert.encoder.layer.17.attention.output.LayerNorm.weight",
        "bert.encoder.layer.17.attention.output.LayerNorm.bias",
        "buffer_4_29779_29780",
        "buffer_3_29779_29780",
        "buffer_2_29779_29780",
        "buffer_1_29779_29780",
        "buffer_0_29779_29780",
        "_fused_op_125",
        "bert.encoder.layer.17.intermediate.dense.weight",
        "bert.encoder.layer.17.intermediate.dense.bias",
        "matmul_948",
        "gelu_951",
        "bert.encoder.layer.17.output.dense.weight",
        "bert.encoder.layer.17.output.dense.bias",
        "matmul_954",
        "buffer_7_29780_29000",
        "buffer_6_29780_29000",
        "buffer_5_29780_29000",
        "buffer_4_29780_29000",
        "buffer_3_29780_29000",
        "buffer_2_29780_29000",
        "buffer_1_29780_29000",
        "buffer_0_29780_29000",
        "add_958",
        "lc.input_tensor.layernorm_959.dc.reduce_sum.0.0",
        "layernorm_959.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_959.1",
        "buffer_3_29000_29781",
        "buffer_2_29000_29781",
        "buffer_1_29000_29781",
        "buffer_0_29000_29781",
        "_fused_op_126",
        "layernorm_959.dc.multiply.4",
        "lc.input_tensor.layernorm_959.dc.reduce_sum.5.0",
        "layernorm_959.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_959.6",
        "dc.input_tensor.layernorm_959.8",
        "bert.encoder.layer.17.output.LayerNorm.weight",
        "bert.encoder.layer.17.output.LayerNorm.bias",
        "_fused_op_127",
        "bert.encoder.layer.18.attention.self.query.weight",
        "bert.encoder.layer.18.attention.self.query.bias",
        "matmul_962",
        "bert.encoder.layer.18.attention.self.key.weight",
        "bert.encoder.layer.18.attention.self.key.bias",
        "matmul_968",
        "matmul_974",
        "input_1_multiply_976",
        "_fused_op_128",
        "softmax_978.dc.reduce_max.0",
        "lc.input_tensor.softmax_978.dc.reduce_sum.3.0",
        "_fused_op_129",
        "softmax_978.dc.reduce_sum.3.lc1",
        "dc.input_tensor.softmax_978.4",
        "bert.encoder.layer.18.attention.self.value.weight",
        "bert.encoder.layer.18.attention.self.value.bias",
        "matmul_982",
        "buffer_0_29784_29785",
        "_fused_op_130",
        "matmul_989",
        "bert.encoder.layer.18.attention.output.dense.weight",
        "bert.encoder.layer.18.attention.output.dense.bias",
        "matmul_993",
        "add_997",
        "lc.input_tensor.layernorm_998.dc.reduce_sum.0.0",
        "layernorm_998.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_998.1",
        "buffer_1_29072_29786",
        "buffer_0_29072_29786",
        "_fused_op_131",
        "layernorm_998.dc.multiply.4",
        "lc.input_tensor.layernorm_998.dc.reduce_sum.5.0",
        "layernorm_998.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_998.6",
        "dc.input_tensor.layernorm_998.8",
        "bert.encoder.layer.18.attention.output.LayerNorm.weight",
        "bert.encoder.layer.18.attention.output.LayerNorm.bias",
        "buffer_2_29786_29787",
        "buffer_1_29786_29787",
        "buffer_0_29786_29787",
        "_fused_op_132",
        "bert.encoder.layer.18.intermediate.dense.weight",
        "bert.encoder.layer.18.intermediate.dense.bias",
        "matmul_1001",
        "gelu_1004",
        "bert.encoder.layer.18.output.dense.weight",
        "bert.encoder.layer.18.output.dense.bias",
        "matmul_1007",
        "add_1011",
        "lc.input_tensor.layernorm_1012.dc.reduce_sum.0.0",
        "layernorm_1012.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_1012.1",
        "buffer_1_29104_29788",
        "buffer_0_29104_29788",
        "_fused_op_133",
        "layernorm_1012.dc.multiply.4",
        "lc.input_tensor.layernorm_1012.dc.reduce_sum.5.0",
        "layernorm_1012.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_1012.6",
        "dc.input_tensor.layernorm_1012.8",
        "bert.encoder.layer.18.output.LayerNorm.weight",
        "bert.encoder.layer.18.output.LayerNorm.bias",
        "buffer_1_29788_29789",
        "buffer_0_29788_29789",
        "_fused_op_134",
        "bert.encoder.layer.19.attention.self.query.weight",
        "bert.encoder.layer.19.attention.self.query.bias",
        "matmul_1015",
        "bert.encoder.layer.19.attention.self.key.weight",
        "bert.encoder.layer.19.attention.self.key.bias",
        "matmul_1021",
        "matmul_1027",
        "input_1_multiply_1029",
        "_fused_op_135",
        "softmax_1031.dc.reduce_max.0",
        "lc.input_tensor.softmax_1031.dc.reduce_sum.3.0",
        "_fused_op_136",
        "softmax_1031.dc.reduce_sum.3.lc1",
        "dc.input_tensor.softmax_1031.4",
        "bert.encoder.layer.19.attention.self.value.weight",
        "bert.encoder.layer.19.attention.self.value.bias",
        "matmul_1035",
        "_fused_op_137",
        "matmul_1042",
        "bert.encoder.layer.19.attention.output.dense.weight",
        "bert.encoder.layer.19.attention.output.dense.bias",
        "matmul_1046",
        "add_1050",
        "lc.input_tensor.layernorm_1051.dc.reduce_sum.0.0",
        "layernorm_1051.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_1051.1",
        "buffer_3_29176_29793",
        "buffer_2_29176_29793",
        "buffer_1_29176_29793",
        "buffer_0_29176_29793",
        "_fused_op_138",
        "layernorm_1051.dc.multiply.4",
        "lc.input_tensor.layernorm_1051.dc.reduce_sum.5.0",
        "layernorm_1051.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_1051.6",
        "dc.input_tensor.layernorm_1051.8",
        "bert.encoder.layer.19.attention.output.LayerNorm.weight",
        "bert.encoder.layer.19.attention.output.LayerNorm.bias",
        "buffer_4_29793_29794",
        "buffer_3_29793_29794",
        "buffer_2_29793_29794",
        "buffer_1_29793_29794",
        "buffer_0_29793_29794",
        "_fused_op_139",
        "bert.encoder.layer.19.intermediate.dense.weight",
        "bert.encoder.layer.19.intermediate.dense.bias",
        "matmul_1054",
        "gelu_1057",
        "bert.encoder.layer.19.output.dense.weight",
        "bert.encoder.layer.19.output.dense.bias",
        "matmul_1060",
        "buffer_7_29794_29208",
        "buffer_6_29794_29208",
        "buffer_5_29794_29208",
        "buffer_4_29794_29208",
        "buffer_3_29794_29208",
        "buffer_2_29794_29208",
        "buffer_1_29794_29208",
        "buffer_0_29794_29208",
        "add_1064",
        "lc.input_tensor.layernorm_1065.dc.reduce_sum.0.0",
        "layernorm_1065.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_1065.1",
        "buffer_3_29208_29795",
        "buffer_2_29208_29795",
        "buffer_1_29208_29795",
        "buffer_0_29208_29795",
        "_fused_op_140",
        "layernorm_1065.dc.multiply.4",
        "lc.input_tensor.layernorm_1065.dc.reduce_sum.5.0",
        "layernorm_1065.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_1065.6",
        "dc.input_tensor.layernorm_1065.8",
        "bert.encoder.layer.19.output.LayerNorm.weight",
        "bert.encoder.layer.19.output.LayerNorm.bias",
        "_fused_op_141",
        "bert.encoder.layer.20.attention.self.query.weight",
        "bert.encoder.layer.20.attention.self.query.bias",
        "matmul_1068",
        "bert.encoder.layer.20.attention.self.key.weight",
        "bert.encoder.layer.20.attention.self.key.bias",
        "matmul_1074",
        "matmul_1080",
        "input_1_multiply_1082",
        "_fused_op_142",
        "softmax_1084.dc.reduce_max.0",
        "lc.input_tensor.softmax_1084.dc.reduce_sum.3.0",
        "_fused_op_143",
        "softmax_1084.dc.reduce_sum.3.lc1",
        "dc.input_tensor.softmax_1084.4",
        "bert.encoder.layer.20.attention.self.value.weight",
        "bert.encoder.layer.20.attention.self.value.bias",
        "matmul_1088",
        "buffer_0_29798_29799",
        "_fused_op_144",
        "matmul_1095",
        "bert.encoder.layer.20.attention.output.dense.weight",
        "bert.encoder.layer.20.attention.output.dense.bias",
        "matmul_1099",
        "add_1103",
        "lc.input_tensor.layernorm_1104.dc.reduce_sum.0.0",
        "layernorm_1104.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_1104.1",
        "buffer_1_29280_29800",
        "buffer_0_29280_29800",
        "_fused_op_145",
        "layernorm_1104.dc.multiply.4",
        "lc.input_tensor.layernorm_1104.dc.reduce_sum.5.0",
        "layernorm_1104.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_1104.6",
        "dc.input_tensor.layernorm_1104.8",
        "bert.encoder.layer.20.attention.output.LayerNorm.weight",
        "bert.encoder.layer.20.attention.output.LayerNorm.bias",
        "buffer_2_29800_29801",
        "buffer_1_29800_29801",
        "buffer_0_29800_29801",
        "_fused_op_146",
        "bert.encoder.layer.20.intermediate.dense.weight",
        "bert.encoder.layer.20.intermediate.dense.bias",
        "matmul_1107",
        "gelu_1110",
        "bert.encoder.layer.20.output.dense.weight",
        "bert.encoder.layer.20.output.dense.bias",
        "matmul_1113",
        "add_1117",
        "lc.input_tensor.layernorm_1118.dc.reduce_sum.0.0",
        "layernorm_1118.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_1118.1",
        "buffer_1_29312_29802",
        "buffer_0_29312_29802",
        "_fused_op_147",
        "layernorm_1118.dc.multiply.4",
        "lc.input_tensor.layernorm_1118.dc.reduce_sum.5.0",
        "layernorm_1118.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_1118.6",
        "dc.input_tensor.layernorm_1118.8",
        "bert.encoder.layer.20.output.LayerNorm.weight",
        "bert.encoder.layer.20.output.LayerNorm.bias",
        "buffer_1_29802_29803",
        "buffer_0_29802_29803",
        "_fused_op_148",
        "bert.encoder.layer.21.attention.self.query.weight",
        "bert.encoder.layer.21.attention.self.query.bias",
        "matmul_1121",
        "bert.encoder.layer.21.attention.self.key.weight",
        "bert.encoder.layer.21.attention.self.key.bias",
        "matmul_1127",
        "matmul_1133",
        "input_1_multiply_1135",
        "_fused_op_149",
        "softmax_1137.dc.reduce_max.0",
        "lc.input_tensor.softmax_1137.dc.reduce_sum.3.0",
        "_fused_op_150",
        "softmax_1137.dc.reduce_sum.3.lc1",
        "dc.input_tensor.softmax_1137.4",
        "bert.encoder.layer.21.attention.self.value.weight",
        "bert.encoder.layer.21.attention.self.value.bias",
        "matmul_1141",
        "_fused_op_151",
        "matmul_1148",
        "bert.encoder.layer.21.attention.output.dense.weight",
        "bert.encoder.layer.21.attention.output.dense.bias",
        "matmul_1152",
        "add_1156",
        "lc.input_tensor.layernorm_1157.dc.reduce_sum.0.0",
        "layernorm_1157.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_1157.1",
        "buffer_3_29384_29807",
        "buffer_2_29384_29807",
        "buffer_1_29384_29807",
        "buffer_0_29384_29807",
        "_fused_op_152",
        "layernorm_1157.dc.multiply.4",
        "lc.input_tensor.layernorm_1157.dc.reduce_sum.5.0",
        "layernorm_1157.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_1157.6",
        "dc.input_tensor.layernorm_1157.8",
        "bert.encoder.layer.21.attention.output.LayerNorm.weight",
        "bert.encoder.layer.21.attention.output.LayerNorm.bias",
        "buffer_4_29807_29808",
        "buffer_3_29807_29808",
        "buffer_2_29807_29808",
        "buffer_1_29807_29808",
        "buffer_0_29807_29808",
        "_fused_op_153",
        "bert.encoder.layer.21.intermediate.dense.weight",
        "bert.encoder.layer.21.intermediate.dense.bias",
        "matmul_1160",
        "gelu_1163",
        "bert.encoder.layer.21.output.dense.weight",
        "bert.encoder.layer.21.output.dense.bias",
        "matmul_1166",
        "buffer_7_29808_29416",
        "buffer_6_29808_29416",
        "buffer_5_29808_29416",
        "buffer_4_29808_29416",
        "buffer_3_29808_29416",
        "buffer_2_29808_29416",
        "buffer_1_29808_29416",
        "buffer_0_29808_29416",
        "add_1170",
        "lc.input_tensor.layernorm_1171.dc.reduce_sum.0.0",
        "layernorm_1171.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_1171.1",
        "buffer_3_29416_29809",
        "buffer_2_29416_29809",
        "buffer_1_29416_29809",
        "buffer_0_29416_29809",
        "_fused_op_154",
        "layernorm_1171.dc.multiply.4",
        "lc.input_tensor.layernorm_1171.dc.reduce_sum.5.0",
        "layernorm_1171.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_1171.6",
        "dc.input_tensor.layernorm_1171.8",
        "bert.encoder.layer.21.output.LayerNorm.weight",
        "bert.encoder.layer.21.output.LayerNorm.bias",
        "_fused_op_155",
        "bert.encoder.layer.22.attention.self.query.weight",
        "bert.encoder.layer.22.attention.self.query.bias",
        "matmul_1174",
        "bert.encoder.layer.22.attention.self.key.weight",
        "bert.encoder.layer.22.attention.self.key.bias",
        "matmul_1180",
        "matmul_1186",
        "input_1_multiply_1188",
        "_fused_op_156",
        "softmax_1190.dc.reduce_max.0",
        "lc.input_tensor.softmax_1190.dc.reduce_sum.3.0",
        "_fused_op_157",
        "softmax_1190.dc.reduce_sum.3.lc1",
        "dc.input_tensor.softmax_1190.4",
        "bert.encoder.layer.22.attention.self.value.weight",
        "bert.encoder.layer.22.attention.self.value.bias",
        "matmul_1194",
        "buffer_0_29812_29813",
        "_fused_op_158",
        "matmul_1201",
        "bert.encoder.layer.22.attention.output.dense.weight",
        "bert.encoder.layer.22.attention.output.dense.bias",
        "matmul_1205",
        "add_1209",
        "lc.input_tensor.layernorm_1210.dc.reduce_sum.0.0",
        "layernorm_1210.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_1210.1",
        "buffer_1_29488_29814",
        "buffer_0_29488_29814",
        "_fused_op_159",
        "layernorm_1210.dc.multiply.4",
        "lc.input_tensor.layernorm_1210.dc.reduce_sum.5.0",
        "layernorm_1210.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_1210.6",
        "dc.input_tensor.layernorm_1210.8",
        "bert.encoder.layer.22.attention.output.LayerNorm.weight",
        "bert.encoder.layer.22.attention.output.LayerNorm.bias",
        "buffer_2_29814_29815",
        "buffer_1_29814_29815",
        "buffer_0_29814_29815",
        "_fused_op_160",
        "bert.encoder.layer.22.intermediate.dense.weight",
        "bert.encoder.layer.22.intermediate.dense.bias",
        "matmul_1213",
        "gelu_1216",
        "bert.encoder.layer.22.output.dense.weight",
        "bert.encoder.layer.22.output.dense.bias",
        "matmul_1219",
        "add_1223",
        "lc.input_tensor.layernorm_1224.dc.reduce_sum.0.0",
        "layernorm_1224.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_1224.1",
        "buffer_1_29520_29816",
        "buffer_0_29520_29816",
        "_fused_op_161",
        "layernorm_1224.dc.multiply.4",
        "lc.input_tensor.layernorm_1224.dc.reduce_sum.5.0",
        "layernorm_1224.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_1224.6",
        "dc.input_tensor.layernorm_1224.8",
        "bert.encoder.layer.22.output.LayerNorm.weight",
        "bert.encoder.layer.22.output.LayerNorm.bias",
        "buffer_1_29816_29817",
        "buffer_0_29816_29817",
        "_fused_op_162",
        "bert.encoder.layer.23.attention.self.query.weight",
        "bert.encoder.layer.23.attention.self.query.bias",
        "matmul_1227",
        "bert.encoder.layer.23.attention.self.key.weight",
        "bert.encoder.layer.23.attention.self.key.bias",
        "matmul_1233",
        "matmul_1239",
        "input_1_multiply_1241",
        "_fused_op_163",
        "softmax_1243.dc.reduce_max.0",
        "lc.input_tensor.softmax_1243.dc.reduce_sum.3.0",
        "_fused_op_164",
        "softmax_1243.dc.reduce_sum.3.lc1",
        "dc.input_tensor.softmax_1243.4",
        "bert.encoder.layer.23.attention.self.value.weight",
        "bert.encoder.layer.23.attention.self.value.bias",
        "matmul_1247",
        "_fused_op_165",
        "matmul_1254",
        "bert.encoder.layer.23.attention.output.dense.weight",
        "bert.encoder.layer.23.attention.output.dense.bias",
        "matmul_1258",
        "add_1262",
        "lc.input_tensor.layernorm_1263.dc.reduce_sum.0.0",
        "layernorm_1263.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_1263.1",
        "buffer_3_29592_29821",
        "buffer_2_29592_29821",
        "buffer_1_29592_29821",
        "buffer_0_29592_29821",
        "_fused_op_166",
        "layernorm_1263.dc.multiply.4",
        "lc.input_tensor.layernorm_1263.dc.reduce_sum.5.0",
        "layernorm_1263.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_1263.6",
        "dc.input_tensor.layernorm_1263.8",
        "bert.encoder.layer.23.attention.output.LayerNorm.weight",
        "bert.encoder.layer.23.attention.output.LayerNorm.bias",
        "buffer_4_29821_29822",
        "buffer_3_29821_29822",
        "buffer_2_29821_29822",
        "buffer_1_29821_29822",
        "buffer_0_29821_29822",
        "_fused_op_167",
        "bert.encoder.layer.23.intermediate.dense.weight",
        "bert.encoder.layer.23.intermediate.dense.bias",
        "matmul_1266",
        "gelu_1269",
        "bert.encoder.layer.23.output.dense.weight",
        "bert.encoder.layer.23.output.dense.bias",
        "matmul_1272",
        "buffer_7_29822_29624",
        "buffer_6_29822_29624",
        "buffer_5_29822_29624",
        "buffer_4_29822_29624",
        "buffer_3_29822_29624",
        "buffer_2_29822_29624",
        "buffer_1_29822_29624",
        "buffer_0_29822_29624",
        "add_1276",
        "lc.input_tensor.layernorm_1277.dc.reduce_sum.0.0",
        "layernorm_1277.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_1277.1",
        "buffer_3_29624_29823",
        "buffer_2_29624_29823",
        "buffer_1_29624_29823",
        "buffer_0_29624_29823",
        "_fused_op_168",
        "layernorm_1277.dc.multiply.4",
        "lc.input_tensor.layernorm_1277.dc.reduce_sum.5.0",
        "layernorm_1277.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_1277.6",
        "dc.input_tensor.layernorm_1277.8",
        "bert.encoder.layer.23.output.LayerNorm.weight",
        "bert.encoder.layer.23.output.LayerNorm.bias",
        "buffer_2_29823_29824",
        "buffer_1_29823_29824",
        "buffer_0_29823_29824",
        "_fused_op_169",
        "qa_outputs.weight",
        "qa_outputs.bias",
        "matmul_1281",
        "matmul_1281_output_nop_0",
        "bert_large_tt_1.output_reshape_1285",
        "qa_outputs.weight_fork_clone19",
        "qa_outputs.bias_fork_clone12",
        "matmul_1288",
        "matmul_1288_output_nop_0",
        "bert_large_tt_1.output_reshape_1292"
    ]
}