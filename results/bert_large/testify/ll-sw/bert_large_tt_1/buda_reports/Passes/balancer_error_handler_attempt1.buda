{
    "graph": {},
    "nodes": {
        "_fused_op_0": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_0.1 (port_0) ublock_order(c)",
                "Data: layernorm_0.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: pybuda_6_i0 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "dc.input_tensor.layernorm_0.1": "Data",
                "layernorm_0.dc.reduce_sum.0.lc1": "Data",
                "pybuda_6_i0": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_0.1",
                "layernorm_0.dc.reduce_sum.0.lc1",
                "pybuda_6_i0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_0",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_0.dc.multiply.4 (port_0)",
                "Data: layernorm_0.dc.multiply.4 (port_0)",
                "Data: _fused_op_1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_0.dc.multiply.4",
                "layernorm_0.dc.multiply.4",
                "_fused_op_1"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_0.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_0.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34128
        },
        "_fused_op_1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_0.6 (port_0) ublock_order(r)",
                "Data: layernorm_0.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_0.8 (port_2) ublock_order(r)",
                "Data: _fused_op_0 (port_3) ublock_order(r)",
                "Data: bert.embeddings.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.embeddings.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_0": "Data",
                "bert.embeddings.LayerNorm.bias": "Data",
                "bert.embeddings.LayerNorm.weight": "Data",
                "dc.input_tensor.layernorm_0.6": "Data",
                "dc.input_tensor.layernorm_0.8": "Data",
                "layernorm_0.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_0.6",
                "layernorm_0.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_0.8",
                "_fused_op_0",
                "bert.embeddings.LayerNorm.weight",
                "bert.embeddings.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_1",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_4 (port_0)",
                "Data: matmul_10 (port_0)",
                "Data: matmul_28 (port_0)",
                "Data: add_43 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_4",
                "matmul_10",
                "matmul_28",
                "add_43"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_0.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_0.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_0.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_0.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_0.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_0.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_0.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34129
        },
        "_fused_op_10": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_9 (port_0) ublock_order(c)",
                "Data: softmax_77.dc.reduce_max.0 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_9": "Data",
                "softmax_77.dc.reduce_max.0": "Data"
            },
            "input_nodes": [
                "_fused_op_9",
                "softmax_77.dc.reduce_max.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_10",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_77.dc.reduce_sum.3.lc1 (port_0)",
                "Data: _fused_op_11 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_77.dc.reduce_sum.3.lc1",
                "_fused_op_11"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_77.dc.subtract.1: subtract (1,16,12,12), out: 0",
                    "softmax_77.dc.exp.2: exp (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 34138
        },
        "_fused_op_100": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_762 (port_0) ublock_order(r)",
                "Data: input_1_multiply_764 (port_1) ublock_order(r)",
                "Data: multiply_22_attempt_1_input_op_fork_nop1 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "input_1_multiply_764": "Data",
                "matmul_762": "Data",
                "multiply_22_attempt_1_input_op_fork_nop1": "Data"
            },
            "input_nodes": [
                "matmul_762",
                "input_1_multiply_764",
                "multiply_22_attempt_1_input_op_fork_nop1"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_100",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_766.dc.reduce_max.0 (port_0)",
                "Data: _fused_op_101 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_766.dc.reduce_max.0",
                "_fused_op_101"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "multiply_764: multiply (1,16,12,12), out: 0",
                    "add_765: add (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "add"
            },
            "type": "fused_op",
            "unique_id": 34228
        },
        "_fused_op_101": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_100 (port_0) ublock_order(c)",
                "Data: softmax_766.dc.reduce_max.0 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_100": "Data",
                "softmax_766.dc.reduce_max.0": "Data"
            },
            "input_nodes": [
                "_fused_op_100",
                "softmax_766.dc.reduce_max.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_101",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_766.dc.reduce_sum.3.lc1 (port_0)",
                "Data: _fused_op_102 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_766.dc.reduce_sum.3.lc1",
                "_fused_op_102"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_766.dc.subtract.1: subtract (1,16,12,12), out: 0",
                    "softmax_766.dc.exp.2: exp (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 34229
        },
        "_fused_op_102": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: softmax_766.dc.reduce_sum.3.lc1 (port_0) ublock_order(r)",
                "Data: dc.input_tensor.softmax_766.4 (port_1) ublock_order(r)",
                "Data: _fused_op_101 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_101": "Data",
                "dc.input_tensor.softmax_766.4": "Data",
                "softmax_766.dc.reduce_sum.3.lc1": "Data"
            },
            "input_nodes": [
                "softmax_766.dc.reduce_sum.3.lc1",
                "dc.input_tensor.softmax_766.4",
                "_fused_op_101"
            ],
            "input_tms": [
                [],
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_102",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_777 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_777"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_766.dc.add.5: add (1,16,12,1), out: 0",
                    "softmax_766.dc.reciprocal.6: reciprocal (1,16,12,1), out: 0",
                    "softmax_766.dc.multiply.7: multiply (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 34230
        },
        "_fused_op_103": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_786.1 (port_0) ublock_order(c)",
                "Data: layernorm_786.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: add_785 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_785": "Data",
                "dc.input_tensor.layernorm_786.1": "Data",
                "layernorm_786.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_786.1",
                "layernorm_786.dc.reduce_sum.0.lc1",
                "add_785"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_103",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_786.dc.multiply.4 (port_0)",
                "Data: layernorm_786.dc.multiply.4 (port_0)",
                "Data: _fused_op_104 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_786.dc.multiply.4",
                "layernorm_786.dc.multiply.4",
                "_fused_op_104"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_786.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_786.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34231
        },
        "_fused_op_104": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_786.6 (port_0) ublock_order(r)",
                "Data: layernorm_786.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_786.8 (port_2) ublock_order(r)",
                "Data: _fused_op_103 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.14.attention.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.14.attention.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_103": "Data",
                "bert.encoder.layer.14.attention.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.14.attention.output.LayerNorm.weight": "Data",
                "dc.input_tensor.layernorm_786.6": "Data",
                "dc.input_tensor.layernorm_786.8": "Data",
                "layernorm_786.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_786.6",
                "layernorm_786.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_786.8",
                "_fused_op_103",
                "bert.encoder.layer.14.attention.output.LayerNorm.weight",
                "bert.encoder.layer.14.attention.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_104",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_789 (port_0)",
                "Data: add_799 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_789",
                "add_799"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_786.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_786.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_786.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_786.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_786.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_786.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_786.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34232
        },
        "_fused_op_105": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_800.1 (port_0) ublock_order(c)",
                "Data: layernorm_800.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: add_799 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_799": "Data",
                "dc.input_tensor.layernorm_800.1": "Data",
                "layernorm_800.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_800.1",
                "layernorm_800.dc.reduce_sum.0.lc1",
                "add_799"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_105",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_800.dc.multiply.4 (port_0)",
                "Data: layernorm_800.dc.multiply.4 (port_0)",
                "Data: _fused_op_106 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_800.dc.multiply.4",
                "layernorm_800.dc.multiply.4",
                "_fused_op_106"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_800.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_800.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34233
        },
        "_fused_op_106": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_800.6 (port_0) ublock_order(r)",
                "Data: layernorm_800.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_800.8 (port_2) ublock_order(r)",
                "Data: _fused_op_105 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.14.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.14.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_105": "Data",
                "bert.encoder.layer.14.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.14.output.LayerNorm.weight": "Data",
                "dc.input_tensor.layernorm_800.6": "Data",
                "dc.input_tensor.layernorm_800.8": "Data",
                "layernorm_800.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_800.6",
                "layernorm_800.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_800.8",
                "_fused_op_105",
                "bert.encoder.layer.14.output.LayerNorm.weight",
                "bert.encoder.layer.14.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_106",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_803 (port_0)",
                "Data: matmul_809 (port_0)",
                "Data: matmul_823 (port_0)",
                "Data: add_838 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_803",
                "matmul_809",
                "matmul_823",
                "add_838"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_800.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_800.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_800.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_800.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_800.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_800.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_800.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34234
        },
        "_fused_op_107": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_815 (port_0) ublock_order(r)",
                "Data: input_1_multiply_817 (port_1) ublock_order(r)",
                "Data: multiply_22_attempt_1_input_op_fork_nop1 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "input_1_multiply_817": "Data",
                "matmul_815": "Data",
                "multiply_22_attempt_1_input_op_fork_nop1": "Data"
            },
            "input_nodes": [
                "matmul_815",
                "input_1_multiply_817",
                "multiply_22_attempt_1_input_op_fork_nop1"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_107",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_819.dc.reduce_max.0 (port_0)",
                "Data: _fused_op_108 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_819.dc.reduce_max.0",
                "_fused_op_108"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "multiply_817: multiply (1,16,12,12), out: 0",
                    "add_818: add (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "add"
            },
            "type": "fused_op",
            "unique_id": 34235
        },
        "_fused_op_108": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_107 (port_0) ublock_order(c)",
                "Data: softmax_819.dc.reduce_max.0 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_107": "Data",
                "softmax_819.dc.reduce_max.0": "Data"
            },
            "input_nodes": [
                "_fused_op_107",
                "softmax_819.dc.reduce_max.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_108",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_819.dc.reduce_sum.3.lc1 (port_0)",
                "Data: _fused_op_109 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_819.dc.reduce_sum.3.lc1",
                "_fused_op_109"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_819.dc.subtract.1: subtract (1,16,12,12), out: 0",
                    "softmax_819.dc.exp.2: exp (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 34236
        },
        "_fused_op_109": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: softmax_819.dc.reduce_sum.3.lc1 (port_0) ublock_order(r)",
                "Data: dc.input_tensor.softmax_819.4 (port_1) ublock_order(r)",
                "Data: _fused_op_108 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_108": "Data",
                "dc.input_tensor.softmax_819.4": "Data",
                "softmax_819.dc.reduce_sum.3.lc1": "Data"
            },
            "input_nodes": [
                "softmax_819.dc.reduce_sum.3.lc1",
                "dc.input_tensor.softmax_819.4",
                "_fused_op_108"
            ],
            "input_tms": [
                [],
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_109",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_830 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_830"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_819.dc.add.5: add (1,16,12,1), out: 0",
                    "softmax_819.dc.reciprocal.6: reciprocal (1,16,12,1), out: 0",
                    "softmax_819.dc.multiply.7: multiply (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 34237
        },
        "_fused_op_11": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: softmax_77.dc.reduce_sum.3.lc1 (port_0) ublock_order(r)",
                "Data: dc.input_tensor.softmax_77.4 (port_1) ublock_order(r)",
                "Data: _fused_op_10 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_10": "Data",
                "dc.input_tensor.softmax_77.4": "Data",
                "softmax_77.dc.reduce_sum.3.lc1": "Data"
            },
            "input_nodes": [
                "softmax_77.dc.reduce_sum.3.lc1",
                "dc.input_tensor.softmax_77.4",
                "_fused_op_10"
            ],
            "input_tms": [
                [],
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_11",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_88 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_88"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_77.dc.add.5: add (1,16,12,1), out: 0",
                    "softmax_77.dc.reciprocal.6: reciprocal (1,16,12,1), out: 0",
                    "softmax_77.dc.multiply.7: multiply (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 34139
        },
        "_fused_op_110": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_839.1 (port_0) ublock_order(c)",
                "Data: layernorm_839.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: add_838 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_838": "Data",
                "dc.input_tensor.layernorm_839.1": "Data",
                "layernorm_839.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_839.1",
                "layernorm_839.dc.reduce_sum.0.lc1",
                "add_838"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_110",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_839.dc.multiply.4 (port_0)",
                "Data: layernorm_839.dc.multiply.4 (port_0)",
                "Data: _fused_op_111 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_839.dc.multiply.4",
                "layernorm_839.dc.multiply.4",
                "_fused_op_111"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_839.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_839.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34238
        },
        "_fused_op_111": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_839.6 (port_0) ublock_order(r)",
                "Data: layernorm_839.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_839.8 (port_2) ublock_order(r)",
                "Data: _fused_op_110 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.15.attention.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.15.attention.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_110": "Data",
                "bert.encoder.layer.15.attention.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.15.attention.output.LayerNorm.weight": "Data",
                "dc.input_tensor.layernorm_839.6": "Data",
                "dc.input_tensor.layernorm_839.8": "Data",
                "layernorm_839.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_839.6",
                "layernorm_839.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_839.8",
                "_fused_op_110",
                "bert.encoder.layer.15.attention.output.LayerNorm.weight",
                "bert.encoder.layer.15.attention.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_111",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_842 (port_0)",
                "Data: add_852 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_842",
                "add_852"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_839.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_839.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_839.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_839.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_839.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_839.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_839.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34239
        },
        "_fused_op_112": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_853.1 (port_0) ublock_order(c)",
                "Data: layernorm_853.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: add_852 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_852": "Data",
                "dc.input_tensor.layernorm_853.1": "Data",
                "layernorm_853.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_853.1",
                "layernorm_853.dc.reduce_sum.0.lc1",
                "add_852"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_112",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_853.dc.multiply.4 (port_0)",
                "Data: layernorm_853.dc.multiply.4 (port_0)",
                "Data: _fused_op_113 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_853.dc.multiply.4",
                "layernorm_853.dc.multiply.4",
                "_fused_op_113"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_853.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_853.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34240
        },
        "_fused_op_113": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_853.6 (port_0) ublock_order(r)",
                "Data: layernorm_853.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_853.8 (port_2) ublock_order(r)",
                "Data: _fused_op_112 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.15.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.15.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_112": "Data",
                "bert.encoder.layer.15.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.15.output.LayerNorm.weight": "Data",
                "dc.input_tensor.layernorm_853.6": "Data",
                "dc.input_tensor.layernorm_853.8": "Data",
                "layernorm_853.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_853.6",
                "layernorm_853.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_853.8",
                "_fused_op_112",
                "bert.encoder.layer.15.output.LayerNorm.weight",
                "bert.encoder.layer.15.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_113",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_856 (port_0)",
                "Data: matmul_862 (port_0)",
                "Data: matmul_876 (port_0)",
                "Data: add_891 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_856",
                "matmul_862",
                "matmul_876",
                "add_891"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_853.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_853.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_853.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_853.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_853.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_853.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_853.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34241
        },
        "_fused_op_114": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_868 (port_0) ublock_order(r)",
                "Data: input_1_multiply_870 (port_1) ublock_order(r)",
                "Data: multiply_22_attempt_1_input_op_fork_nop2 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "input_1_multiply_870": "Data",
                "matmul_868": "Data",
                "multiply_22_attempt_1_input_op_fork_nop2": "Data"
            },
            "input_nodes": [
                "matmul_868",
                "input_1_multiply_870",
                "multiply_22_attempt_1_input_op_fork_nop2"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_114",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_872.dc.reduce_max.0 (port_0)",
                "Data: _fused_op_115 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_872.dc.reduce_max.0",
                "_fused_op_115"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "multiply_870: multiply (1,16,12,12), out: 0",
                    "add_871: add (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "add"
            },
            "type": "fused_op",
            "unique_id": 34242
        },
        "_fused_op_115": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_114 (port_0) ublock_order(c)",
                "Data: softmax_872.dc.reduce_max.0 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_114": "Data",
                "softmax_872.dc.reduce_max.0": "Data"
            },
            "input_nodes": [
                "_fused_op_114",
                "softmax_872.dc.reduce_max.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_115",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_872.dc.reduce_sum.3.lc1 (port_0)",
                "Data: _fused_op_116 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_872.dc.reduce_sum.3.lc1",
                "_fused_op_116"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_872.dc.subtract.1: subtract (1,16,12,12), out: 0",
                    "softmax_872.dc.exp.2: exp (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 34243
        },
        "_fused_op_116": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: softmax_872.dc.reduce_sum.3.lc1 (port_0) ublock_order(r)",
                "Data: dc.input_tensor.softmax_872.4 (port_1) ublock_order(r)",
                "Data: _fused_op_115 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_115": "Data",
                "dc.input_tensor.softmax_872.4": "Data",
                "softmax_872.dc.reduce_sum.3.lc1": "Data"
            },
            "input_nodes": [
                "softmax_872.dc.reduce_sum.3.lc1",
                "dc.input_tensor.softmax_872.4",
                "_fused_op_115"
            ],
            "input_tms": [
                [],
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_116",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_883 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_883"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_872.dc.add.5: add (1,16,12,1), out: 0",
                    "softmax_872.dc.reciprocal.6: reciprocal (1,16,12,1), out: 0",
                    "softmax_872.dc.multiply.7: multiply (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 34244
        },
        "_fused_op_117": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_892.1 (port_0) ublock_order(c)",
                "Data: layernorm_892.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: add_891 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_891": "Data",
                "dc.input_tensor.layernorm_892.1": "Data",
                "layernorm_892.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_892.1",
                "layernorm_892.dc.reduce_sum.0.lc1",
                "add_891"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_117",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_892.dc.multiply.4 (port_0)",
                "Data: layernorm_892.dc.multiply.4 (port_0)",
                "Data: _fused_op_118 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_892.dc.multiply.4",
                "layernorm_892.dc.multiply.4",
                "_fused_op_118"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_892.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_892.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34245
        },
        "_fused_op_118": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_892.6 (port_0) ublock_order(r)",
                "Data: layernorm_892.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_892.8 (port_2) ublock_order(r)",
                "Data: _fused_op_117 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.16.attention.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.16.attention.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_117": "Data",
                "bert.encoder.layer.16.attention.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.16.attention.output.LayerNorm.weight": "Data",
                "dc.input_tensor.layernorm_892.6": "Data",
                "dc.input_tensor.layernorm_892.8": "Data",
                "layernorm_892.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_892.6",
                "layernorm_892.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_892.8",
                "_fused_op_117",
                "bert.encoder.layer.16.attention.output.LayerNorm.weight",
                "bert.encoder.layer.16.attention.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_118",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_895 (port_0)",
                "Data: add_905 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_895",
                "add_905"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_892.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_892.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_892.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_892.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_892.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_892.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_892.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34246
        },
        "_fused_op_119": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_906.1 (port_0) ublock_order(c)",
                "Data: layernorm_906.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: add_905 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_905": "Data",
                "dc.input_tensor.layernorm_906.1": "Data",
                "layernorm_906.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_906.1",
                "layernorm_906.dc.reduce_sum.0.lc1",
                "add_905"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_119",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_906.dc.multiply.4 (port_0)",
                "Data: layernorm_906.dc.multiply.4 (port_0)",
                "Data: _fused_op_120 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_906.dc.multiply.4",
                "layernorm_906.dc.multiply.4",
                "_fused_op_120"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_906.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_906.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34247
        },
        "_fused_op_12": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_97.1 (port_0) ublock_order(c)",
                "Data: layernorm_97.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: add_96 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_96": "Data",
                "dc.input_tensor.layernorm_97.1": "Data",
                "layernorm_97.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_97.1",
                "layernorm_97.dc.reduce_sum.0.lc1",
                "add_96"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_12",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_97.dc.multiply.4 (port_0)",
                "Data: layernorm_97.dc.multiply.4 (port_0)",
                "Data: _fused_op_13 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_97.dc.multiply.4",
                "layernorm_97.dc.multiply.4",
                "_fused_op_13"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_97.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_97.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34140
        },
        "_fused_op_120": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_906.6 (port_0) ublock_order(r)",
                "Data: layernorm_906.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_906.8 (port_2) ublock_order(r)",
                "Data: _fused_op_119 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.16.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.16.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_119": "Data",
                "bert.encoder.layer.16.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.16.output.LayerNorm.weight": "Data",
                "dc.input_tensor.layernorm_906.6": "Data",
                "dc.input_tensor.layernorm_906.8": "Data",
                "layernorm_906.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_906.6",
                "layernorm_906.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_906.8",
                "_fused_op_119",
                "bert.encoder.layer.16.output.LayerNorm.weight",
                "bert.encoder.layer.16.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_120",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_909 (port_0)",
                "Data: matmul_915 (port_0)",
                "Data: matmul_929 (port_0)",
                "Data: add_944 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_909",
                "matmul_915",
                "matmul_929",
                "add_944"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_906.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_906.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_906.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_906.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_906.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_906.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_906.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34248
        },
        "_fused_op_121": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_921 (port_0) ublock_order(r)",
                "Data: input_1_multiply_923 (port_1) ublock_order(r)",
                "Data: multiply_22_attempt_1_input_op_fork_nop2 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "input_1_multiply_923": "Data",
                "matmul_921": "Data",
                "multiply_22_attempt_1_input_op_fork_nop2": "Data"
            },
            "input_nodes": [
                "matmul_921",
                "input_1_multiply_923",
                "multiply_22_attempt_1_input_op_fork_nop2"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_121",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_925.dc.reduce_max.0 (port_0)",
                "Data: _fused_op_122 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_925.dc.reduce_max.0",
                "_fused_op_122"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "multiply_923: multiply (1,16,12,12), out: 0",
                    "add_924: add (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "add"
            },
            "type": "fused_op",
            "unique_id": 34249
        },
        "_fused_op_122": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_121 (port_0) ublock_order(c)",
                "Data: softmax_925.dc.reduce_max.0 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_121": "Data",
                "softmax_925.dc.reduce_max.0": "Data"
            },
            "input_nodes": [
                "_fused_op_121",
                "softmax_925.dc.reduce_max.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_122",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_925.dc.reduce_sum.3.lc1 (port_0)",
                "Data: _fused_op_123 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_925.dc.reduce_sum.3.lc1",
                "_fused_op_123"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_925.dc.subtract.1: subtract (1,16,12,12), out: 0",
                    "softmax_925.dc.exp.2: exp (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 34250
        },
        "_fused_op_123": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: softmax_925.dc.reduce_sum.3.lc1 (port_0) ublock_order(r)",
                "Data: dc.input_tensor.softmax_925.4 (port_1) ublock_order(r)",
                "Data: _fused_op_122 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_122": "Data",
                "dc.input_tensor.softmax_925.4": "Data",
                "softmax_925.dc.reduce_sum.3.lc1": "Data"
            },
            "input_nodes": [
                "softmax_925.dc.reduce_sum.3.lc1",
                "dc.input_tensor.softmax_925.4",
                "_fused_op_122"
            ],
            "input_tms": [
                [],
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_123",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_936 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_936"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_925.dc.add.5: add (1,16,12,1), out: 0",
                    "softmax_925.dc.reciprocal.6: reciprocal (1,16,12,1), out: 0",
                    "softmax_925.dc.multiply.7: multiply (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 34251
        },
        "_fused_op_124": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_945.1 (port_0) ublock_order(c)",
                "Data: layernorm_945.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: add_944 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_944": "Data",
                "dc.input_tensor.layernorm_945.1": "Data",
                "layernorm_945.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_945.1",
                "layernorm_945.dc.reduce_sum.0.lc1",
                "add_944"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_124",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_945.dc.multiply.4 (port_0)",
                "Data: layernorm_945.dc.multiply.4 (port_0)",
                "Data: _fused_op_125 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_945.dc.multiply.4",
                "layernorm_945.dc.multiply.4",
                "_fused_op_125"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_945.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_945.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34252
        },
        "_fused_op_125": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_945.6 (port_0) ublock_order(r)",
                "Data: layernorm_945.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_945.8 (port_2) ublock_order(r)",
                "Data: _fused_op_124 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.17.attention.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.17.attention.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_124": "Data",
                "bert.encoder.layer.17.attention.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.17.attention.output.LayerNorm.weight": "Data",
                "dc.input_tensor.layernorm_945.6": "Data",
                "dc.input_tensor.layernorm_945.8": "Data",
                "layernorm_945.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_945.6",
                "layernorm_945.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_945.8",
                "_fused_op_124",
                "bert.encoder.layer.17.attention.output.LayerNorm.weight",
                "bert.encoder.layer.17.attention.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_125",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_948 (port_0)",
                "Data: add_958 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_948",
                "add_958"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_945.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_945.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_945.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_945.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_945.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_945.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_945.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34253
        },
        "_fused_op_126": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_959.1 (port_0) ublock_order(c)",
                "Data: layernorm_959.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: add_958 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_958": "Data",
                "dc.input_tensor.layernorm_959.1": "Data",
                "layernorm_959.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_959.1",
                "layernorm_959.dc.reduce_sum.0.lc1",
                "add_958"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_126",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_959.dc.multiply.4 (port_0)",
                "Data: layernorm_959.dc.multiply.4 (port_0)",
                "Data: _fused_op_127 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_959.dc.multiply.4",
                "layernorm_959.dc.multiply.4",
                "_fused_op_127"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_959.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_959.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34254
        },
        "_fused_op_127": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_959.6 (port_0) ublock_order(r)",
                "Data: layernorm_959.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_959.8 (port_2) ublock_order(r)",
                "Data: _fused_op_126 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.17.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.17.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_126": "Data",
                "bert.encoder.layer.17.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.17.output.LayerNorm.weight": "Data",
                "dc.input_tensor.layernorm_959.6": "Data",
                "dc.input_tensor.layernorm_959.8": "Data",
                "layernorm_959.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_959.6",
                "layernorm_959.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_959.8",
                "_fused_op_126",
                "bert.encoder.layer.17.output.LayerNorm.weight",
                "bert.encoder.layer.17.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_127",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_962 (port_0)",
                "Data: matmul_968 (port_0)",
                "Data: matmul_982 (port_0)",
                "Data: add_997 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_962",
                "matmul_968",
                "matmul_982",
                "add_997"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_959.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_959.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_959.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_959.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_959.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_959.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_959.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34255
        },
        "_fused_op_128": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_974 (port_0) ublock_order(r)",
                "Data: input_1_multiply_976 (port_1) ublock_order(r)",
                "Data: multiply_22_attempt_1_input_op_fork_nop2 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "input_1_multiply_976": "Data",
                "matmul_974": "Data",
                "multiply_22_attempt_1_input_op_fork_nop2": "Data"
            },
            "input_nodes": [
                "matmul_974",
                "input_1_multiply_976",
                "multiply_22_attempt_1_input_op_fork_nop2"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_128",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_978.dc.reduce_max.0 (port_0)",
                "Data: _fused_op_129 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_978.dc.reduce_max.0",
                "_fused_op_129"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "multiply_976: multiply (1,16,12,12), out: 0",
                    "add_977: add (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "add"
            },
            "type": "fused_op",
            "unique_id": 34256
        },
        "_fused_op_129": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_128 (port_0) ublock_order(c)",
                "Data: softmax_978.dc.reduce_max.0 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_128": "Data",
                "softmax_978.dc.reduce_max.0": "Data"
            },
            "input_nodes": [
                "_fused_op_128",
                "softmax_978.dc.reduce_max.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_129",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_978.dc.reduce_sum.3.lc1 (port_0)",
                "Data: _fused_op_130 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_978.dc.reduce_sum.3.lc1",
                "_fused_op_130"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_978.dc.subtract.1: subtract (1,16,12,12), out: 0",
                    "softmax_978.dc.exp.2: exp (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 34257
        },
        "_fused_op_13": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_97.6 (port_0) ublock_order(r)",
                "Data: layernorm_97.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_97.8 (port_2) ublock_order(r)",
                "Data: _fused_op_12 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.1.attention.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.1.attention.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_12": "Data",
                "bert.encoder.layer.1.attention.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.1.attention.output.LayerNorm.weight": "Data",
                "dc.input_tensor.layernorm_97.6": "Data",
                "dc.input_tensor.layernorm_97.8": "Data",
                "layernorm_97.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_97.6",
                "layernorm_97.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_97.8",
                "_fused_op_12",
                "bert.encoder.layer.1.attention.output.LayerNorm.weight",
                "bert.encoder.layer.1.attention.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_13",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_100 (port_0)",
                "Data: add_110 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_100",
                "add_110"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_97.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_97.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_97.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_97.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_97.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_97.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_97.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34141
        },
        "_fused_op_130": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: softmax_978.dc.reduce_sum.3.lc1 (port_0) ublock_order(r)",
                "Data: dc.input_tensor.softmax_978.4 (port_1) ublock_order(r)",
                "Data: _fused_op_129 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_129": "Data",
                "dc.input_tensor.softmax_978.4": "Data",
                "softmax_978.dc.reduce_sum.3.lc1": "Data"
            },
            "input_nodes": [
                "softmax_978.dc.reduce_sum.3.lc1",
                "dc.input_tensor.softmax_978.4",
                "_fused_op_129"
            ],
            "input_tms": [
                [],
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_130",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_989 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_989"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_978.dc.add.5: add (1,16,12,1), out: 0",
                    "softmax_978.dc.reciprocal.6: reciprocal (1,16,12,1), out: 0",
                    "softmax_978.dc.multiply.7: multiply (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 34258
        },
        "_fused_op_131": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_998.1 (port_0) ublock_order(c)",
                "Data: layernorm_998.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: add_997 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_997": "Data",
                "dc.input_tensor.layernorm_998.1": "Data",
                "layernorm_998.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_998.1",
                "layernorm_998.dc.reduce_sum.0.lc1",
                "add_997"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_131",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_998.dc.multiply.4 (port_0)",
                "Data: layernorm_998.dc.multiply.4 (port_0)",
                "Data: _fused_op_132 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_998.dc.multiply.4",
                "layernorm_998.dc.multiply.4",
                "_fused_op_132"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_998.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_998.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34259
        },
        "_fused_op_132": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_998.6 (port_0) ublock_order(r)",
                "Data: layernorm_998.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_998.8 (port_2) ublock_order(r)",
                "Data: _fused_op_131 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.18.attention.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.18.attention.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_131": "Data",
                "bert.encoder.layer.18.attention.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.18.attention.output.LayerNorm.weight": "Data",
                "dc.input_tensor.layernorm_998.6": "Data",
                "dc.input_tensor.layernorm_998.8": "Data",
                "layernorm_998.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_998.6",
                "layernorm_998.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_998.8",
                "_fused_op_131",
                "bert.encoder.layer.18.attention.output.LayerNorm.weight",
                "bert.encoder.layer.18.attention.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_132",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1001 (port_0)",
                "Data: add_1011 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1001",
                "add_1011"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_998.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_998.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_998.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_998.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_998.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_998.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_998.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34260
        },
        "_fused_op_133": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_1012.1 (port_0) ublock_order(c)",
                "Data: layernorm_1012.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: add_1011 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_1011": "Data",
                "dc.input_tensor.layernorm_1012.1": "Data",
                "layernorm_1012.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_1012.1",
                "layernorm_1012.dc.reduce_sum.0.lc1",
                "add_1011"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_133",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1012.dc.multiply.4 (port_0)",
                "Data: layernorm_1012.dc.multiply.4 (port_0)",
                "Data: _fused_op_134 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1012.dc.multiply.4",
                "layernorm_1012.dc.multiply.4",
                "_fused_op_134"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_1012.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_1012.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34261
        },
        "_fused_op_134": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_1012.6 (port_0) ublock_order(r)",
                "Data: layernorm_1012.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_1012.8 (port_2) ublock_order(r)",
                "Data: _fused_op_133 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.18.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.18.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_133": "Data",
                "bert.encoder.layer.18.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.18.output.LayerNorm.weight": "Data",
                "dc.input_tensor.layernorm_1012.6": "Data",
                "dc.input_tensor.layernorm_1012.8": "Data",
                "layernorm_1012.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_1012.6",
                "layernorm_1012.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_1012.8",
                "_fused_op_133",
                "bert.encoder.layer.18.output.LayerNorm.weight",
                "bert.encoder.layer.18.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_134",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1015 (port_0)",
                "Data: matmul_1021 (port_0)",
                "Data: matmul_1035 (port_0)",
                "Data: add_1050 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1015",
                "matmul_1021",
                "matmul_1035",
                "add_1050"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_1012.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_1012.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_1012.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_1012.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_1012.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_1012.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_1012.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34262
        },
        "_fused_op_135": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1027 (port_0) ublock_order(r)",
                "Data: input_1_multiply_1029 (port_1) ublock_order(r)",
                "Data: multiply_22_attempt_1_input_op_fork_nop2 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "input_1_multiply_1029": "Data",
                "matmul_1027": "Data",
                "multiply_22_attempt_1_input_op_fork_nop2": "Data"
            },
            "input_nodes": [
                "matmul_1027",
                "input_1_multiply_1029",
                "multiply_22_attempt_1_input_op_fork_nop2"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_135",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_1031.dc.reduce_max.0 (port_0)",
                "Data: _fused_op_136 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_1031.dc.reduce_max.0",
                "_fused_op_136"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "multiply_1029: multiply (1,16,12,12), out: 0",
                    "add_1030: add (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "add"
            },
            "type": "fused_op",
            "unique_id": 34263
        },
        "_fused_op_136": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_135 (port_0) ublock_order(c)",
                "Data: softmax_1031.dc.reduce_max.0 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_135": "Data",
                "softmax_1031.dc.reduce_max.0": "Data"
            },
            "input_nodes": [
                "_fused_op_135",
                "softmax_1031.dc.reduce_max.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_136",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_1031.dc.reduce_sum.3.lc1 (port_0)",
                "Data: _fused_op_137 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_1031.dc.reduce_sum.3.lc1",
                "_fused_op_137"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_1031.dc.subtract.1: subtract (1,16,12,12), out: 0",
                    "softmax_1031.dc.exp.2: exp (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 34264
        },
        "_fused_op_137": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: softmax_1031.dc.reduce_sum.3.lc1 (port_0) ublock_order(r)",
                "Data: dc.input_tensor.softmax_1031.4 (port_1) ublock_order(r)",
                "Data: _fused_op_136 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_136": "Data",
                "dc.input_tensor.softmax_1031.4": "Data",
                "softmax_1031.dc.reduce_sum.3.lc1": "Data"
            },
            "input_nodes": [
                "softmax_1031.dc.reduce_sum.3.lc1",
                "dc.input_tensor.softmax_1031.4",
                "_fused_op_136"
            ],
            "input_tms": [
                [],
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_137",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1042 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1042"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_1031.dc.add.5: add (1,16,12,1), out: 0",
                    "softmax_1031.dc.reciprocal.6: reciprocal (1,16,12,1), out: 0",
                    "softmax_1031.dc.multiply.7: multiply (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 34265
        },
        "_fused_op_138": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_1051.1 (port_0) ublock_order(c)",
                "Data: layernorm_1051.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: add_1050 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_1050": "Data",
                "dc.input_tensor.layernorm_1051.1": "Data",
                "layernorm_1051.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_1051.1",
                "layernorm_1051.dc.reduce_sum.0.lc1",
                "add_1050"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_138",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1051.dc.multiply.4 (port_0)",
                "Data: layernorm_1051.dc.multiply.4 (port_0)",
                "Data: _fused_op_139 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1051.dc.multiply.4",
                "layernorm_1051.dc.multiply.4",
                "_fused_op_139"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_1051.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_1051.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34266
        },
        "_fused_op_139": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_1051.6 (port_0) ublock_order(r)",
                "Data: layernorm_1051.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_1051.8 (port_2) ublock_order(r)",
                "Data: _fused_op_138 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.19.attention.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.19.attention.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_138": "Data",
                "bert.encoder.layer.19.attention.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.19.attention.output.LayerNorm.weight": "Data",
                "dc.input_tensor.layernorm_1051.6": "Data",
                "dc.input_tensor.layernorm_1051.8": "Data",
                "layernorm_1051.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_1051.6",
                "layernorm_1051.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_1051.8",
                "_fused_op_138",
                "bert.encoder.layer.19.attention.output.LayerNorm.weight",
                "bert.encoder.layer.19.attention.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_139",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1054 (port_0)",
                "Data: add_1064 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1054",
                "add_1064"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_1051.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_1051.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_1051.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_1051.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_1051.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_1051.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_1051.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34267
        },
        "_fused_op_14": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_111.1 (port_0) ublock_order(c)",
                "Data: layernorm_111.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: add_110 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_110": "Data",
                "dc.input_tensor.layernorm_111.1": "Data",
                "layernorm_111.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_111.1",
                "layernorm_111.dc.reduce_sum.0.lc1",
                "add_110"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_14",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_111.dc.multiply.4 (port_0)",
                "Data: layernorm_111.dc.multiply.4 (port_0)",
                "Data: _fused_op_15 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_111.dc.multiply.4",
                "layernorm_111.dc.multiply.4",
                "_fused_op_15"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_111.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_111.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34142
        },
        "_fused_op_140": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_1065.1 (port_0) ublock_order(c)",
                "Data: layernorm_1065.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: add_1064 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_1064": "Data",
                "dc.input_tensor.layernorm_1065.1": "Data",
                "layernorm_1065.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_1065.1",
                "layernorm_1065.dc.reduce_sum.0.lc1",
                "add_1064"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_140",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1065.dc.multiply.4 (port_0)",
                "Data: layernorm_1065.dc.multiply.4 (port_0)",
                "Data: _fused_op_141 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1065.dc.multiply.4",
                "layernorm_1065.dc.multiply.4",
                "_fused_op_141"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_1065.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_1065.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34268
        },
        "_fused_op_141": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_1065.6 (port_0) ublock_order(r)",
                "Data: layernorm_1065.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_1065.8 (port_2) ublock_order(r)",
                "Data: _fused_op_140 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.19.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.19.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_140": "Data",
                "bert.encoder.layer.19.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.19.output.LayerNorm.weight": "Data",
                "dc.input_tensor.layernorm_1065.6": "Data",
                "dc.input_tensor.layernorm_1065.8": "Data",
                "layernorm_1065.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_1065.6",
                "layernorm_1065.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_1065.8",
                "_fused_op_140",
                "bert.encoder.layer.19.output.LayerNorm.weight",
                "bert.encoder.layer.19.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_141",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1068 (port_0)",
                "Data: matmul_1074 (port_0)",
                "Data: matmul_1088 (port_0)",
                "Data: add_1103 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1068",
                "matmul_1074",
                "matmul_1088",
                "add_1103"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_1065.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_1065.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_1065.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_1065.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_1065.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_1065.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_1065.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34269
        },
        "_fused_op_142": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1080 (port_0) ublock_order(r)",
                "Data: input_1_multiply_1082 (port_1) ublock_order(r)",
                "Data: multiply_22_attempt_1_input_op_fork_nop2 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "input_1_multiply_1082": "Data",
                "matmul_1080": "Data",
                "multiply_22_attempt_1_input_op_fork_nop2": "Data"
            },
            "input_nodes": [
                "matmul_1080",
                "input_1_multiply_1082",
                "multiply_22_attempt_1_input_op_fork_nop2"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_142",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_1084.dc.reduce_max.0 (port_0)",
                "Data: _fused_op_143 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_1084.dc.reduce_max.0",
                "_fused_op_143"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "multiply_1082: multiply (1,16,12,12), out: 0",
                    "add_1083: add (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "add"
            },
            "type": "fused_op",
            "unique_id": 34270
        },
        "_fused_op_143": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_142 (port_0) ublock_order(c)",
                "Data: softmax_1084.dc.reduce_max.0 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_142": "Data",
                "softmax_1084.dc.reduce_max.0": "Data"
            },
            "input_nodes": [
                "_fused_op_142",
                "softmax_1084.dc.reduce_max.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_143",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_1084.dc.reduce_sum.3.lc1 (port_0)",
                "Data: _fused_op_144 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_1084.dc.reduce_sum.3.lc1",
                "_fused_op_144"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_1084.dc.subtract.1: subtract (1,16,12,12), out: 0",
                    "softmax_1084.dc.exp.2: exp (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 34271
        },
        "_fused_op_144": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: softmax_1084.dc.reduce_sum.3.lc1 (port_0) ublock_order(r)",
                "Data: dc.input_tensor.softmax_1084.4 (port_1) ublock_order(r)",
                "Data: _fused_op_143 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_143": "Data",
                "dc.input_tensor.softmax_1084.4": "Data",
                "softmax_1084.dc.reduce_sum.3.lc1": "Data"
            },
            "input_nodes": [
                "softmax_1084.dc.reduce_sum.3.lc1",
                "dc.input_tensor.softmax_1084.4",
                "_fused_op_143"
            ],
            "input_tms": [
                [],
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_144",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1095 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1095"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_1084.dc.add.5: add (1,16,12,1), out: 0",
                    "softmax_1084.dc.reciprocal.6: reciprocal (1,16,12,1), out: 0",
                    "softmax_1084.dc.multiply.7: multiply (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 34272
        },
        "_fused_op_145": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_1104.1 (port_0) ublock_order(c)",
                "Data: layernorm_1104.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: add_1103 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_1103": "Data",
                "dc.input_tensor.layernorm_1104.1": "Data",
                "layernorm_1104.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_1104.1",
                "layernorm_1104.dc.reduce_sum.0.lc1",
                "add_1103"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_145",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1104.dc.multiply.4 (port_0)",
                "Data: layernorm_1104.dc.multiply.4 (port_0)",
                "Data: _fused_op_146 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1104.dc.multiply.4",
                "layernorm_1104.dc.multiply.4",
                "_fused_op_146"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_1104.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_1104.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34273
        },
        "_fused_op_146": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_1104.6 (port_0) ublock_order(r)",
                "Data: layernorm_1104.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_1104.8 (port_2) ublock_order(r)",
                "Data: _fused_op_145 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.20.attention.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.20.attention.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_145": "Data",
                "bert.encoder.layer.20.attention.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.20.attention.output.LayerNorm.weight": "Data",
                "dc.input_tensor.layernorm_1104.6": "Data",
                "dc.input_tensor.layernorm_1104.8": "Data",
                "layernorm_1104.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_1104.6",
                "layernorm_1104.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_1104.8",
                "_fused_op_145",
                "bert.encoder.layer.20.attention.output.LayerNorm.weight",
                "bert.encoder.layer.20.attention.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_146",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1107 (port_0)",
                "Data: add_1117 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1107",
                "add_1117"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_1104.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_1104.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_1104.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_1104.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_1104.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_1104.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_1104.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34274
        },
        "_fused_op_147": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_1118.1 (port_0) ublock_order(c)",
                "Data: layernorm_1118.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: add_1117 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_1117": "Data",
                "dc.input_tensor.layernorm_1118.1": "Data",
                "layernorm_1118.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_1118.1",
                "layernorm_1118.dc.reduce_sum.0.lc1",
                "add_1117"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_147",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1118.dc.multiply.4 (port_0)",
                "Data: layernorm_1118.dc.multiply.4 (port_0)",
                "Data: _fused_op_148 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1118.dc.multiply.4",
                "layernorm_1118.dc.multiply.4",
                "_fused_op_148"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_1118.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_1118.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34275
        },
        "_fused_op_148": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_1118.6 (port_0) ublock_order(r)",
                "Data: layernorm_1118.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_1118.8 (port_2) ublock_order(r)",
                "Data: _fused_op_147 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.20.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.20.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_147": "Data",
                "bert.encoder.layer.20.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.20.output.LayerNorm.weight": "Data",
                "dc.input_tensor.layernorm_1118.6": "Data",
                "dc.input_tensor.layernorm_1118.8": "Data",
                "layernorm_1118.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_1118.6",
                "layernorm_1118.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_1118.8",
                "_fused_op_147",
                "bert.encoder.layer.20.output.LayerNorm.weight",
                "bert.encoder.layer.20.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_148",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1121 (port_0)",
                "Data: matmul_1127 (port_0)",
                "Data: matmul_1141 (port_0)",
                "Data: add_1156 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1121",
                "matmul_1127",
                "matmul_1141",
                "add_1156"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_1118.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_1118.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_1118.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_1118.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_1118.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_1118.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_1118.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34276
        },
        "_fused_op_149": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1133 (port_0) ublock_order(r)",
                "Data: input_1_multiply_1135 (port_1) ublock_order(r)",
                "Data: multiply_22_attempt_1_input_op_fork_nop2 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "input_1_multiply_1135": "Data",
                "matmul_1133": "Data",
                "multiply_22_attempt_1_input_op_fork_nop2": "Data"
            },
            "input_nodes": [
                "matmul_1133",
                "input_1_multiply_1135",
                "multiply_22_attempt_1_input_op_fork_nop2"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_149",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_1137.dc.reduce_max.0 (port_0)",
                "Data: _fused_op_150 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_1137.dc.reduce_max.0",
                "_fused_op_150"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "multiply_1135: multiply (1,16,12,12), out: 0",
                    "add_1136: add (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "add"
            },
            "type": "fused_op",
            "unique_id": 34277
        },
        "_fused_op_15": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_111.6 (port_0) ublock_order(r)",
                "Data: layernorm_111.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_111.8 (port_2) ublock_order(r)",
                "Data: _fused_op_14 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.1.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.1.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_14": "Data",
                "bert.encoder.layer.1.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.1.output.LayerNorm.weight": "Data",
                "dc.input_tensor.layernorm_111.6": "Data",
                "dc.input_tensor.layernorm_111.8": "Data",
                "layernorm_111.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_111.6",
                "layernorm_111.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_111.8",
                "_fused_op_14",
                "bert.encoder.layer.1.output.LayerNorm.weight",
                "bert.encoder.layer.1.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_15",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_114 (port_0)",
                "Data: matmul_120 (port_0)",
                "Data: matmul_134 (port_0)",
                "Data: add_149 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_114",
                "matmul_120",
                "matmul_134",
                "add_149"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_111.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_111.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_111.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_111.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_111.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_111.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_111.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34143
        },
        "_fused_op_150": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_149 (port_0) ublock_order(c)",
                "Data: softmax_1137.dc.reduce_max.0 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_149": "Data",
                "softmax_1137.dc.reduce_max.0": "Data"
            },
            "input_nodes": [
                "_fused_op_149",
                "softmax_1137.dc.reduce_max.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_150",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_1137.dc.reduce_sum.3.lc1 (port_0)",
                "Data: _fused_op_151 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_1137.dc.reduce_sum.3.lc1",
                "_fused_op_151"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_1137.dc.subtract.1: subtract (1,16,12,12), out: 0",
                    "softmax_1137.dc.exp.2: exp (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 34278
        },
        "_fused_op_151": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: softmax_1137.dc.reduce_sum.3.lc1 (port_0) ublock_order(r)",
                "Data: dc.input_tensor.softmax_1137.4 (port_1) ublock_order(r)",
                "Data: _fused_op_150 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_150": "Data",
                "dc.input_tensor.softmax_1137.4": "Data",
                "softmax_1137.dc.reduce_sum.3.lc1": "Data"
            },
            "input_nodes": [
                "softmax_1137.dc.reduce_sum.3.lc1",
                "dc.input_tensor.softmax_1137.4",
                "_fused_op_150"
            ],
            "input_tms": [
                [],
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_151",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1148 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1148"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_1137.dc.add.5: add (1,16,12,1), out: 0",
                    "softmax_1137.dc.reciprocal.6: reciprocal (1,16,12,1), out: 0",
                    "softmax_1137.dc.multiply.7: multiply (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 34279
        },
        "_fused_op_152": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_1157.1 (port_0) ublock_order(c)",
                "Data: layernorm_1157.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: add_1156 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_1156": "Data",
                "dc.input_tensor.layernorm_1157.1": "Data",
                "layernorm_1157.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_1157.1",
                "layernorm_1157.dc.reduce_sum.0.lc1",
                "add_1156"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_152",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1157.dc.multiply.4 (port_0)",
                "Data: layernorm_1157.dc.multiply.4 (port_0)",
                "Data: _fused_op_153 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1157.dc.multiply.4",
                "layernorm_1157.dc.multiply.4",
                "_fused_op_153"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_1157.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_1157.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34280
        },
        "_fused_op_153": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_1157.6 (port_0) ublock_order(r)",
                "Data: layernorm_1157.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_1157.8 (port_2) ublock_order(r)",
                "Data: _fused_op_152 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.21.attention.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.21.attention.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_152": "Data",
                "bert.encoder.layer.21.attention.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.21.attention.output.LayerNorm.weight": "Data",
                "dc.input_tensor.layernorm_1157.6": "Data",
                "dc.input_tensor.layernorm_1157.8": "Data",
                "layernorm_1157.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_1157.6",
                "layernorm_1157.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_1157.8",
                "_fused_op_152",
                "bert.encoder.layer.21.attention.output.LayerNorm.weight",
                "bert.encoder.layer.21.attention.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_153",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1160 (port_0)",
                "Data: add_1170 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1160",
                "add_1170"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_1157.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_1157.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_1157.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_1157.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_1157.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_1157.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_1157.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34281
        },
        "_fused_op_154": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_1171.1 (port_0) ublock_order(c)",
                "Data: layernorm_1171.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: add_1170 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_1170": "Data",
                "dc.input_tensor.layernorm_1171.1": "Data",
                "layernorm_1171.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_1171.1",
                "layernorm_1171.dc.reduce_sum.0.lc1",
                "add_1170"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_154",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1171.dc.multiply.4 (port_0)",
                "Data: layernorm_1171.dc.multiply.4 (port_0)",
                "Data: _fused_op_155 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1171.dc.multiply.4",
                "layernorm_1171.dc.multiply.4",
                "_fused_op_155"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_1171.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_1171.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34282
        },
        "_fused_op_155": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_1171.6 (port_0) ublock_order(r)",
                "Data: layernorm_1171.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_1171.8 (port_2) ublock_order(r)",
                "Data: _fused_op_154 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.21.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.21.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_154": "Data",
                "bert.encoder.layer.21.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.21.output.LayerNorm.weight": "Data",
                "dc.input_tensor.layernorm_1171.6": "Data",
                "dc.input_tensor.layernorm_1171.8": "Data",
                "layernorm_1171.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_1171.6",
                "layernorm_1171.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_1171.8",
                "_fused_op_154",
                "bert.encoder.layer.21.output.LayerNorm.weight",
                "bert.encoder.layer.21.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_155",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1174 (port_0)",
                "Data: matmul_1180 (port_0)",
                "Data: matmul_1194 (port_0)",
                "Data: add_1209 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1174",
                "matmul_1180",
                "matmul_1194",
                "add_1209"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_1171.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_1171.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_1171.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_1171.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_1171.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_1171.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_1171.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34283
        },
        "_fused_op_156": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1186 (port_0) ublock_order(r)",
                "Data: input_1_multiply_1188 (port_1) ublock_order(r)",
                "Data: multiply_22_attempt_1_input_op_fork_nop2 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "input_1_multiply_1188": "Data",
                "matmul_1186": "Data",
                "multiply_22_attempt_1_input_op_fork_nop2": "Data"
            },
            "input_nodes": [
                "matmul_1186",
                "input_1_multiply_1188",
                "multiply_22_attempt_1_input_op_fork_nop2"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_156",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_1190.dc.reduce_max.0 (port_0)",
                "Data: _fused_op_157 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_1190.dc.reduce_max.0",
                "_fused_op_157"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "multiply_1188: multiply (1,16,12,12), out: 0",
                    "add_1189: add (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "add"
            },
            "type": "fused_op",
            "unique_id": 34284
        },
        "_fused_op_157": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_156 (port_0) ublock_order(c)",
                "Data: softmax_1190.dc.reduce_max.0 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_156": "Data",
                "softmax_1190.dc.reduce_max.0": "Data"
            },
            "input_nodes": [
                "_fused_op_156",
                "softmax_1190.dc.reduce_max.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_157",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_1190.dc.reduce_sum.3.lc1 (port_0)",
                "Data: _fused_op_158 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_1190.dc.reduce_sum.3.lc1",
                "_fused_op_158"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_1190.dc.subtract.1: subtract (1,16,12,12), out: 0",
                    "softmax_1190.dc.exp.2: exp (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 34285
        },
        "_fused_op_158": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: softmax_1190.dc.reduce_sum.3.lc1 (port_0) ublock_order(r)",
                "Data: dc.input_tensor.softmax_1190.4 (port_1) ublock_order(r)",
                "Data: _fused_op_157 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_157": "Data",
                "dc.input_tensor.softmax_1190.4": "Data",
                "softmax_1190.dc.reduce_sum.3.lc1": "Data"
            },
            "input_nodes": [
                "softmax_1190.dc.reduce_sum.3.lc1",
                "dc.input_tensor.softmax_1190.4",
                "_fused_op_157"
            ],
            "input_tms": [
                [],
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_158",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1201 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1201"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_1190.dc.add.5: add (1,16,12,1), out: 0",
                    "softmax_1190.dc.reciprocal.6: reciprocal (1,16,12,1), out: 0",
                    "softmax_1190.dc.multiply.7: multiply (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 34286
        },
        "_fused_op_159": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_1210.1 (port_0) ublock_order(c)",
                "Data: layernorm_1210.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: add_1209 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_1209": "Data",
                "dc.input_tensor.layernorm_1210.1": "Data",
                "layernorm_1210.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_1210.1",
                "layernorm_1210.dc.reduce_sum.0.lc1",
                "add_1209"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_159",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1210.dc.multiply.4 (port_0)",
                "Data: layernorm_1210.dc.multiply.4 (port_0)",
                "Data: _fused_op_160 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1210.dc.multiply.4",
                "layernorm_1210.dc.multiply.4",
                "_fused_op_160"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_1210.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_1210.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34287
        },
        "_fused_op_16": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_126 (port_0) ublock_order(r)",
                "Data: input_1_multiply_128 (port_1) ublock_order(r)",
                "Data: multiply_22_attempt_1_input_op_fork_nop0 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "input_1_multiply_128": "Data",
                "matmul_126": "Data",
                "multiply_22_attempt_1_input_op_fork_nop0": "Data"
            },
            "input_nodes": [
                "matmul_126",
                "input_1_multiply_128",
                "multiply_22_attempt_1_input_op_fork_nop0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_16",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_130.dc.reduce_max.0 (port_0)",
                "Data: _fused_op_17 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_130.dc.reduce_max.0",
                "_fused_op_17"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "multiply_128: multiply (1,16,12,12), out: 0",
                    "add_129: add (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "add"
            },
            "type": "fused_op",
            "unique_id": 34144
        },
        "_fused_op_160": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_1210.6 (port_0) ublock_order(r)",
                "Data: layernorm_1210.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_1210.8 (port_2) ublock_order(r)",
                "Data: _fused_op_159 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.22.attention.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.22.attention.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_159": "Data",
                "bert.encoder.layer.22.attention.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.22.attention.output.LayerNorm.weight": "Data",
                "dc.input_tensor.layernorm_1210.6": "Data",
                "dc.input_tensor.layernorm_1210.8": "Data",
                "layernorm_1210.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_1210.6",
                "layernorm_1210.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_1210.8",
                "_fused_op_159",
                "bert.encoder.layer.22.attention.output.LayerNorm.weight",
                "bert.encoder.layer.22.attention.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_160",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1213 (port_0)",
                "Data: add_1223 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1213",
                "add_1223"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_1210.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_1210.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_1210.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_1210.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_1210.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_1210.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_1210.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34288
        },
        "_fused_op_161": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_1224.1 (port_0) ublock_order(c)",
                "Data: layernorm_1224.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: add_1223 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_1223": "Data",
                "dc.input_tensor.layernorm_1224.1": "Data",
                "layernorm_1224.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_1224.1",
                "layernorm_1224.dc.reduce_sum.0.lc1",
                "add_1223"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_161",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1224.dc.multiply.4 (port_0)",
                "Data: layernorm_1224.dc.multiply.4 (port_0)",
                "Data: _fused_op_162 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1224.dc.multiply.4",
                "layernorm_1224.dc.multiply.4",
                "_fused_op_162"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_1224.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_1224.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34289
        },
        "_fused_op_162": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_1224.6 (port_0) ublock_order(r)",
                "Data: layernorm_1224.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_1224.8 (port_2) ublock_order(r)",
                "Data: _fused_op_161 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.22.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.22.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_161": "Data",
                "bert.encoder.layer.22.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.22.output.LayerNorm.weight": "Data",
                "dc.input_tensor.layernorm_1224.6": "Data",
                "dc.input_tensor.layernorm_1224.8": "Data",
                "layernorm_1224.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_1224.6",
                "layernorm_1224.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_1224.8",
                "_fused_op_161",
                "bert.encoder.layer.22.output.LayerNorm.weight",
                "bert.encoder.layer.22.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_162",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1227 (port_0)",
                "Data: matmul_1233 (port_0)",
                "Data: matmul_1247 (port_0)",
                "Data: add_1262 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1227",
                "matmul_1233",
                "matmul_1247",
                "add_1262"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_1224.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_1224.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_1224.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_1224.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_1224.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_1224.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_1224.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34290
        },
        "_fused_op_163": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1239 (port_0) ublock_order(r)",
                "Data: input_1_multiply_1241 (port_1) ublock_order(r)",
                "Data: multiply_22_attempt_1_input_op_fork_nop2 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "input_1_multiply_1241": "Data",
                "matmul_1239": "Data",
                "multiply_22_attempt_1_input_op_fork_nop2": "Data"
            },
            "input_nodes": [
                "matmul_1239",
                "input_1_multiply_1241",
                "multiply_22_attempt_1_input_op_fork_nop2"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_163",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_1243.dc.reduce_max.0 (port_0)",
                "Data: _fused_op_164 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_1243.dc.reduce_max.0",
                "_fused_op_164"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "multiply_1241: multiply (1,16,12,12), out: 0",
                    "add_1242: add (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "add"
            },
            "type": "fused_op",
            "unique_id": 34291
        },
        "_fused_op_164": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_163 (port_0) ublock_order(c)",
                "Data: softmax_1243.dc.reduce_max.0 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_163": "Data",
                "softmax_1243.dc.reduce_max.0": "Data"
            },
            "input_nodes": [
                "_fused_op_163",
                "softmax_1243.dc.reduce_max.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_164",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_1243.dc.reduce_sum.3.lc1 (port_0)",
                "Data: _fused_op_165 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_1243.dc.reduce_sum.3.lc1",
                "_fused_op_165"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_1243.dc.subtract.1: subtract (1,16,12,12), out: 0",
                    "softmax_1243.dc.exp.2: exp (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 34292
        },
        "_fused_op_165": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: softmax_1243.dc.reduce_sum.3.lc1 (port_0) ublock_order(r)",
                "Data: dc.input_tensor.softmax_1243.4 (port_1) ublock_order(r)",
                "Data: _fused_op_164 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_164": "Data",
                "dc.input_tensor.softmax_1243.4": "Data",
                "softmax_1243.dc.reduce_sum.3.lc1": "Data"
            },
            "input_nodes": [
                "softmax_1243.dc.reduce_sum.3.lc1",
                "dc.input_tensor.softmax_1243.4",
                "_fused_op_164"
            ],
            "input_tms": [
                [],
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_165",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1254 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1254"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_1243.dc.add.5: add (1,16,12,1), out: 0",
                    "softmax_1243.dc.reciprocal.6: reciprocal (1,16,12,1), out: 0",
                    "softmax_1243.dc.multiply.7: multiply (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 34293
        },
        "_fused_op_166": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_1263.1 (port_0) ublock_order(c)",
                "Data: layernorm_1263.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: add_1262 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_1262": "Data",
                "dc.input_tensor.layernorm_1263.1": "Data",
                "layernorm_1263.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_1263.1",
                "layernorm_1263.dc.reduce_sum.0.lc1",
                "add_1262"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_166",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1263.dc.multiply.4 (port_0)",
                "Data: layernorm_1263.dc.multiply.4 (port_0)",
                "Data: _fused_op_167 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1263.dc.multiply.4",
                "layernorm_1263.dc.multiply.4",
                "_fused_op_167"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_1263.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_1263.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34294
        },
        "_fused_op_167": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_1263.6 (port_0) ublock_order(r)",
                "Data: layernorm_1263.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_1263.8 (port_2) ublock_order(r)",
                "Data: _fused_op_166 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.23.attention.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.23.attention.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_166": "Data",
                "bert.encoder.layer.23.attention.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.23.attention.output.LayerNorm.weight": "Data",
                "dc.input_tensor.layernorm_1263.6": "Data",
                "dc.input_tensor.layernorm_1263.8": "Data",
                "layernorm_1263.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_1263.6",
                "layernorm_1263.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_1263.8",
                "_fused_op_166",
                "bert.encoder.layer.23.attention.output.LayerNorm.weight",
                "bert.encoder.layer.23.attention.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_167",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1266 (port_0)",
                "Data: add_1276 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1266",
                "add_1276"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_1263.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_1263.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_1263.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_1263.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_1263.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_1263.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_1263.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34295
        },
        "_fused_op_168": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_1277.1 (port_0) ublock_order(c)",
                "Data: layernorm_1277.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: add_1276 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_1276": "Data",
                "dc.input_tensor.layernorm_1277.1": "Data",
                "layernorm_1277.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_1277.1",
                "layernorm_1277.dc.reduce_sum.0.lc1",
                "add_1276"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_168",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1277.dc.multiply.4 (port_0)",
                "Data: layernorm_1277.dc.multiply.4 (port_0)",
                "Data: _fused_op_169 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1277.dc.multiply.4",
                "layernorm_1277.dc.multiply.4",
                "_fused_op_169"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_1277.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_1277.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34296
        },
        "_fused_op_169": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_1277.6 (port_0) ublock_order(r)",
                "Data: layernorm_1277.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_1277.8 (port_2) ublock_order(r)",
                "Data: _fused_op_168 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.23.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.23.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_168": "Data",
                "bert.encoder.layer.23.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.23.output.LayerNorm.weight": "Data",
                "dc.input_tensor.layernorm_1277.6": "Data",
                "dc.input_tensor.layernorm_1277.8": "Data",
                "layernorm_1277.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_1277.6",
                "layernorm_1277.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_1277.8",
                "_fused_op_168",
                "bert.encoder.layer.23.output.LayerNorm.weight",
                "bert.encoder.layer.23.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_169",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1281 (port_0)",
                "Data: matmul_1288 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1281",
                "matmul_1288"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_1277.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_1277.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_1277.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_1277.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_1277.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_1277.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_1277.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34297
        },
        "_fused_op_17": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_16 (port_0) ublock_order(c)",
                "Data: softmax_130.dc.reduce_max.0 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_16": "Data",
                "softmax_130.dc.reduce_max.0": "Data"
            },
            "input_nodes": [
                "_fused_op_16",
                "softmax_130.dc.reduce_max.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_17",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_130.dc.reduce_sum.3.lc1 (port_0)",
                "Data: _fused_op_18 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_130.dc.reduce_sum.3.lc1",
                "_fused_op_18"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_130.dc.subtract.1: subtract (1,16,12,12), out: 0",
                    "softmax_130.dc.exp.2: exp (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 34145
        },
        "_fused_op_18": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: softmax_130.dc.reduce_sum.3.lc1 (port_0) ublock_order(r)",
                "Data: dc.input_tensor.softmax_130.4 (port_1) ublock_order(r)",
                "Data: _fused_op_17 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_17": "Data",
                "dc.input_tensor.softmax_130.4": "Data",
                "softmax_130.dc.reduce_sum.3.lc1": "Data"
            },
            "input_nodes": [
                "softmax_130.dc.reduce_sum.3.lc1",
                "dc.input_tensor.softmax_130.4",
                "_fused_op_17"
            ],
            "input_tms": [
                [],
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_18",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_141 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_141"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_130.dc.add.5: add (1,16,12,1), out: 0",
                    "softmax_130.dc.reciprocal.6: reciprocal (1,16,12,1), out: 0",
                    "softmax_130.dc.multiply.7: multiply (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 34146
        },
        "_fused_op_19": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_150.1 (port_0) ublock_order(c)",
                "Data: layernorm_150.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: add_149 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_149": "Data",
                "dc.input_tensor.layernorm_150.1": "Data",
                "layernorm_150.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_150.1",
                "layernorm_150.dc.reduce_sum.0.lc1",
                "add_149"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_19",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_150.dc.multiply.4 (port_0)",
                "Data: layernorm_150.dc.multiply.4 (port_0)",
                "Data: _fused_op_20 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_150.dc.multiply.4",
                "layernorm_150.dc.multiply.4",
                "_fused_op_20"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_150.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_150.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34147
        },
        "_fused_op_2": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_16 (port_0) ublock_order(r)",
                "Data: input_1_multiply_18 (port_1) ublock_order(r)",
                "Data: multiply_22_attempt_1_input_op_fork_nop0 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "input_1_multiply_18": "Data",
                "matmul_16": "Data",
                "multiply_22_attempt_1_input_op_fork_nop0": "Data"
            },
            "input_nodes": [
                "matmul_16",
                "input_1_multiply_18",
                "multiply_22_attempt_1_input_op_fork_nop0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_2",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_24.dc.reduce_max.0 (port_0)",
                "Data: _fused_op_3 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_24.dc.reduce_max.0",
                "_fused_op_3"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "multiply_18: multiply (1,16,12,12), out: 0",
                    "add_23: add (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "add"
            },
            "type": "fused_op",
            "unique_id": 34130
        },
        "_fused_op_20": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_150.6 (port_0) ublock_order(r)",
                "Data: layernorm_150.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_150.8 (port_2) ublock_order(r)",
                "Data: _fused_op_19 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.2.attention.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.2.attention.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_19": "Data",
                "bert.encoder.layer.2.attention.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.2.attention.output.LayerNorm.weight": "Data",
                "dc.input_tensor.layernorm_150.6": "Data",
                "dc.input_tensor.layernorm_150.8": "Data",
                "layernorm_150.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_150.6",
                "layernorm_150.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_150.8",
                "_fused_op_19",
                "bert.encoder.layer.2.attention.output.LayerNorm.weight",
                "bert.encoder.layer.2.attention.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_20",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_153 (port_0)",
                "Data: add_163 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_153",
                "add_163"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_150.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_150.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_150.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_150.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_150.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_150.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_150.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34148
        },
        "_fused_op_21": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_164.1 (port_0) ublock_order(c)",
                "Data: layernorm_164.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: add_163 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_163": "Data",
                "dc.input_tensor.layernorm_164.1": "Data",
                "layernorm_164.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_164.1",
                "layernorm_164.dc.reduce_sum.0.lc1",
                "add_163"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_21",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_164.dc.multiply.4 (port_0)",
                "Data: layernorm_164.dc.multiply.4 (port_0)",
                "Data: _fused_op_22 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_164.dc.multiply.4",
                "layernorm_164.dc.multiply.4",
                "_fused_op_22"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_164.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_164.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34149
        },
        "_fused_op_22": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_164.6 (port_0) ublock_order(r)",
                "Data: layernorm_164.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_164.8 (port_2) ublock_order(r)",
                "Data: _fused_op_21 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.2.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.2.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_21": "Data",
                "bert.encoder.layer.2.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.2.output.LayerNorm.weight": "Data",
                "dc.input_tensor.layernorm_164.6": "Data",
                "dc.input_tensor.layernorm_164.8": "Data",
                "layernorm_164.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_164.6",
                "layernorm_164.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_164.8",
                "_fused_op_21",
                "bert.encoder.layer.2.output.LayerNorm.weight",
                "bert.encoder.layer.2.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_22",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_167 (port_0)",
                "Data: matmul_173 (port_0)",
                "Data: matmul_187 (port_0)",
                "Data: add_202 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_167",
                "matmul_173",
                "matmul_187",
                "add_202"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_164.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_164.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_164.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_164.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_164.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_164.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_164.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34150
        },
        "_fused_op_23": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_179 (port_0) ublock_order(r)",
                "Data: input_1_multiply_181 (port_1) ublock_order(r)",
                "Data: multiply_22_attempt_1_input_op_fork_nop0 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "input_1_multiply_181": "Data",
                "matmul_179": "Data",
                "multiply_22_attempt_1_input_op_fork_nop0": "Data"
            },
            "input_nodes": [
                "matmul_179",
                "input_1_multiply_181",
                "multiply_22_attempt_1_input_op_fork_nop0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_23",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_183.dc.reduce_max.0 (port_0)",
                "Data: _fused_op_24 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_183.dc.reduce_max.0",
                "_fused_op_24"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "multiply_181: multiply (1,16,12,12), out: 0",
                    "add_182: add (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "add"
            },
            "type": "fused_op",
            "unique_id": 34151
        },
        "_fused_op_24": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_23 (port_0) ublock_order(c)",
                "Data: softmax_183.dc.reduce_max.0 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_23": "Data",
                "softmax_183.dc.reduce_max.0": "Data"
            },
            "input_nodes": [
                "_fused_op_23",
                "softmax_183.dc.reduce_max.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_24",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_183.dc.reduce_sum.3.lc1 (port_0)",
                "Data: _fused_op_25 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_183.dc.reduce_sum.3.lc1",
                "_fused_op_25"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_183.dc.subtract.1: subtract (1,16,12,12), out: 0",
                    "softmax_183.dc.exp.2: exp (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 34152
        },
        "_fused_op_25": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: softmax_183.dc.reduce_sum.3.lc1 (port_0) ublock_order(r)",
                "Data: dc.input_tensor.softmax_183.4 (port_1) ublock_order(r)",
                "Data: _fused_op_24 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_24": "Data",
                "dc.input_tensor.softmax_183.4": "Data",
                "softmax_183.dc.reduce_sum.3.lc1": "Data"
            },
            "input_nodes": [
                "softmax_183.dc.reduce_sum.3.lc1",
                "dc.input_tensor.softmax_183.4",
                "_fused_op_24"
            ],
            "input_tms": [
                [],
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_25",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_194 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_194"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_183.dc.add.5: add (1,16,12,1), out: 0",
                    "softmax_183.dc.reciprocal.6: reciprocal (1,16,12,1), out: 0",
                    "softmax_183.dc.multiply.7: multiply (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 34153
        },
        "_fused_op_26": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_203.1 (port_0) ublock_order(c)",
                "Data: layernorm_203.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: add_202 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_202": "Data",
                "dc.input_tensor.layernorm_203.1": "Data",
                "layernorm_203.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_203.1",
                "layernorm_203.dc.reduce_sum.0.lc1",
                "add_202"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_26",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_203.dc.multiply.4 (port_0)",
                "Data: layernorm_203.dc.multiply.4 (port_0)",
                "Data: _fused_op_27 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_203.dc.multiply.4",
                "layernorm_203.dc.multiply.4",
                "_fused_op_27"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_203.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_203.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34154
        },
        "_fused_op_27": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_203.6 (port_0) ublock_order(r)",
                "Data: layernorm_203.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_203.8 (port_2) ublock_order(r)",
                "Data: _fused_op_26 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.3.attention.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.3.attention.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_26": "Data",
                "bert.encoder.layer.3.attention.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.3.attention.output.LayerNorm.weight": "Data",
                "dc.input_tensor.layernorm_203.6": "Data",
                "dc.input_tensor.layernorm_203.8": "Data",
                "layernorm_203.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_203.6",
                "layernorm_203.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_203.8",
                "_fused_op_26",
                "bert.encoder.layer.3.attention.output.LayerNorm.weight",
                "bert.encoder.layer.3.attention.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_27",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_206 (port_0)",
                "Data: add_216 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_206",
                "add_216"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_203.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_203.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_203.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_203.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_203.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_203.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_203.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34155
        },
        "_fused_op_28": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_217.1 (port_0) ublock_order(c)",
                "Data: layernorm_217.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: add_216 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_216": "Data",
                "dc.input_tensor.layernorm_217.1": "Data",
                "layernorm_217.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_217.1",
                "layernorm_217.dc.reduce_sum.0.lc1",
                "add_216"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_28",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_217.dc.multiply.4 (port_0)",
                "Data: layernorm_217.dc.multiply.4 (port_0)",
                "Data: _fused_op_29 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_217.dc.multiply.4",
                "layernorm_217.dc.multiply.4",
                "_fused_op_29"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_217.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_217.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34156
        },
        "_fused_op_29": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_217.6 (port_0) ublock_order(r)",
                "Data: layernorm_217.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_217.8 (port_2) ublock_order(r)",
                "Data: _fused_op_28 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.3.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.3.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_28": "Data",
                "bert.encoder.layer.3.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.3.output.LayerNorm.weight": "Data",
                "dc.input_tensor.layernorm_217.6": "Data",
                "dc.input_tensor.layernorm_217.8": "Data",
                "layernorm_217.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_217.6",
                "layernorm_217.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_217.8",
                "_fused_op_28",
                "bert.encoder.layer.3.output.LayerNorm.weight",
                "bert.encoder.layer.3.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_29",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_220 (port_0)",
                "Data: matmul_226 (port_0)",
                "Data: matmul_240 (port_0)",
                "Data: add_255 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_220",
                "matmul_226",
                "matmul_240",
                "add_255"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_217.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_217.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_217.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_217.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_217.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_217.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_217.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34157
        },
        "_fused_op_3": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_2 (port_0) ublock_order(c)",
                "Data: softmax_24.dc.reduce_max.0 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_2": "Data",
                "softmax_24.dc.reduce_max.0": "Data"
            },
            "input_nodes": [
                "_fused_op_2",
                "softmax_24.dc.reduce_max.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_3",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_24.dc.reduce_sum.3.lc1 (port_0)",
                "Data: _fused_op_4 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_24.dc.reduce_sum.3.lc1",
                "_fused_op_4"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_24.dc.subtract.1: subtract (1,16,12,12), out: 0",
                    "softmax_24.dc.exp.2: exp (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 34131
        },
        "_fused_op_30": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_232 (port_0) ublock_order(r)",
                "Data: input_1_multiply_234 (port_1) ublock_order(r)",
                "Data: multiply_22_attempt_1_input_op_fork_nop0 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "input_1_multiply_234": "Data",
                "matmul_232": "Data",
                "multiply_22_attempt_1_input_op_fork_nop0": "Data"
            },
            "input_nodes": [
                "matmul_232",
                "input_1_multiply_234",
                "multiply_22_attempt_1_input_op_fork_nop0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_30",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_236.dc.reduce_max.0 (port_0)",
                "Data: _fused_op_31 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_236.dc.reduce_max.0",
                "_fused_op_31"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "multiply_234: multiply (1,16,12,12), out: 0",
                    "add_235: add (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "add"
            },
            "type": "fused_op",
            "unique_id": 34158
        },
        "_fused_op_31": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_30 (port_0) ublock_order(c)",
                "Data: softmax_236.dc.reduce_max.0 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_30": "Data",
                "softmax_236.dc.reduce_max.0": "Data"
            },
            "input_nodes": [
                "_fused_op_30",
                "softmax_236.dc.reduce_max.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_31",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_236.dc.reduce_sum.3.lc1 (port_0)",
                "Data: _fused_op_32 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_236.dc.reduce_sum.3.lc1",
                "_fused_op_32"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_236.dc.subtract.1: subtract (1,16,12,12), out: 0",
                    "softmax_236.dc.exp.2: exp (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 34159
        },
        "_fused_op_32": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: softmax_236.dc.reduce_sum.3.lc1 (port_0) ublock_order(r)",
                "Data: dc.input_tensor.softmax_236.4 (port_1) ublock_order(r)",
                "Data: _fused_op_31 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_31": "Data",
                "dc.input_tensor.softmax_236.4": "Data",
                "softmax_236.dc.reduce_sum.3.lc1": "Data"
            },
            "input_nodes": [
                "softmax_236.dc.reduce_sum.3.lc1",
                "dc.input_tensor.softmax_236.4",
                "_fused_op_31"
            ],
            "input_tms": [
                [],
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_32",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_247 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_247"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_236.dc.add.5: add (1,16,12,1), out: 0",
                    "softmax_236.dc.reciprocal.6: reciprocal (1,16,12,1), out: 0",
                    "softmax_236.dc.multiply.7: multiply (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 34160
        },
        "_fused_op_33": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_256.1 (port_0) ublock_order(c)",
                "Data: layernorm_256.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: add_255 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_255": "Data",
                "dc.input_tensor.layernorm_256.1": "Data",
                "layernorm_256.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_256.1",
                "layernorm_256.dc.reduce_sum.0.lc1",
                "add_255"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_33",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_256.dc.multiply.4 (port_0)",
                "Data: layernorm_256.dc.multiply.4 (port_0)",
                "Data: _fused_op_34 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_256.dc.multiply.4",
                "layernorm_256.dc.multiply.4",
                "_fused_op_34"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_256.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_256.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34161
        },
        "_fused_op_34": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_256.6 (port_0) ublock_order(r)",
                "Data: layernorm_256.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_256.8 (port_2) ublock_order(r)",
                "Data: _fused_op_33 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.4.attention.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.4.attention.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_33": "Data",
                "bert.encoder.layer.4.attention.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.4.attention.output.LayerNorm.weight": "Data",
                "dc.input_tensor.layernorm_256.6": "Data",
                "dc.input_tensor.layernorm_256.8": "Data",
                "layernorm_256.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_256.6",
                "layernorm_256.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_256.8",
                "_fused_op_33",
                "bert.encoder.layer.4.attention.output.LayerNorm.weight",
                "bert.encoder.layer.4.attention.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_34",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_259 (port_0)",
                "Data: add_269 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_259",
                "add_269"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_256.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_256.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_256.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_256.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_256.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_256.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_256.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34162
        },
        "_fused_op_35": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_270.1 (port_0) ublock_order(c)",
                "Data: layernorm_270.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: add_269 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_269": "Data",
                "dc.input_tensor.layernorm_270.1": "Data",
                "layernorm_270.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_270.1",
                "layernorm_270.dc.reduce_sum.0.lc1",
                "add_269"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_35",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_270.dc.multiply.4 (port_0)",
                "Data: layernorm_270.dc.multiply.4 (port_0)",
                "Data: _fused_op_36 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_270.dc.multiply.4",
                "layernorm_270.dc.multiply.4",
                "_fused_op_36"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_270.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_270.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34163
        },
        "_fused_op_36": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_270.6 (port_0) ublock_order(r)",
                "Data: layernorm_270.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_270.8 (port_2) ublock_order(r)",
                "Data: _fused_op_35 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.4.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.4.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_35": "Data",
                "bert.encoder.layer.4.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.4.output.LayerNorm.weight": "Data",
                "dc.input_tensor.layernorm_270.6": "Data",
                "dc.input_tensor.layernorm_270.8": "Data",
                "layernorm_270.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_270.6",
                "layernorm_270.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_270.8",
                "_fused_op_35",
                "bert.encoder.layer.4.output.LayerNorm.weight",
                "bert.encoder.layer.4.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_36",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_273 (port_0)",
                "Data: matmul_279 (port_0)",
                "Data: matmul_293 (port_0)",
                "Data: add_308 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_273",
                "matmul_279",
                "matmul_293",
                "add_308"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_270.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_270.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_270.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_270.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_270.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_270.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_270.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34164
        },
        "_fused_op_37": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_285 (port_0) ublock_order(r)",
                "Data: input_1_multiply_287 (port_1) ublock_order(r)",
                "Data: multiply_22_attempt_1_input_op_fork_nop0 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "input_1_multiply_287": "Data",
                "matmul_285": "Data",
                "multiply_22_attempt_1_input_op_fork_nop0": "Data"
            },
            "input_nodes": [
                "matmul_285",
                "input_1_multiply_287",
                "multiply_22_attempt_1_input_op_fork_nop0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_37",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_289.dc.reduce_max.0 (port_0)",
                "Data: _fused_op_38 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_289.dc.reduce_max.0",
                "_fused_op_38"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "multiply_287: multiply (1,16,12,12), out: 0",
                    "add_288: add (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "add"
            },
            "type": "fused_op",
            "unique_id": 34165
        },
        "_fused_op_38": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_37 (port_0) ublock_order(c)",
                "Data: softmax_289.dc.reduce_max.0 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_37": "Data",
                "softmax_289.dc.reduce_max.0": "Data"
            },
            "input_nodes": [
                "_fused_op_37",
                "softmax_289.dc.reduce_max.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_38",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_289.dc.reduce_sum.3.lc1 (port_0)",
                "Data: _fused_op_39 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_289.dc.reduce_sum.3.lc1",
                "_fused_op_39"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_289.dc.subtract.1: subtract (1,16,12,12), out: 0",
                    "softmax_289.dc.exp.2: exp (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 34166
        },
        "_fused_op_39": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: softmax_289.dc.reduce_sum.3.lc1 (port_0) ublock_order(r)",
                "Data: dc.input_tensor.softmax_289.4 (port_1) ublock_order(r)",
                "Data: _fused_op_38 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_38": "Data",
                "dc.input_tensor.softmax_289.4": "Data",
                "softmax_289.dc.reduce_sum.3.lc1": "Data"
            },
            "input_nodes": [
                "softmax_289.dc.reduce_sum.3.lc1",
                "dc.input_tensor.softmax_289.4",
                "_fused_op_38"
            ],
            "input_tms": [
                [],
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_39",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_300 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_300"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_289.dc.add.5: add (1,16,12,1), out: 0",
                    "softmax_289.dc.reciprocal.6: reciprocal (1,16,12,1), out: 0",
                    "softmax_289.dc.multiply.7: multiply (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 34167
        },
        "_fused_op_4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: softmax_24.dc.reduce_sum.3.lc1 (port_0) ublock_order(r)",
                "Data: dc.input_tensor.softmax_24.4 (port_1) ublock_order(r)",
                "Data: _fused_op_3 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_3": "Data",
                "dc.input_tensor.softmax_24.4": "Data",
                "softmax_24.dc.reduce_sum.3.lc1": "Data"
            },
            "input_nodes": [
                "softmax_24.dc.reduce_sum.3.lc1",
                "dc.input_tensor.softmax_24.4",
                "_fused_op_3"
            ],
            "input_tms": [
                [],
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_4",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_35 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_35"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_24.dc.add.5: add (1,16,12,1), out: 0",
                    "softmax_24.dc.reciprocal.6: reciprocal (1,16,12,1), out: 0",
                    "softmax_24.dc.multiply.7: multiply (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 34132
        },
        "_fused_op_40": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_309.1 (port_0) ublock_order(c)",
                "Data: layernorm_309.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: add_308 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_308": "Data",
                "dc.input_tensor.layernorm_309.1": "Data",
                "layernorm_309.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_309.1",
                "layernorm_309.dc.reduce_sum.0.lc1",
                "add_308"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_40",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_309.dc.multiply.4 (port_0)",
                "Data: layernorm_309.dc.multiply.4 (port_0)",
                "Data: _fused_op_41 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_309.dc.multiply.4",
                "layernorm_309.dc.multiply.4",
                "_fused_op_41"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_309.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_309.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34168
        },
        "_fused_op_41": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_309.6 (port_0) ublock_order(r)",
                "Data: layernorm_309.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_309.8 (port_2) ublock_order(r)",
                "Data: _fused_op_40 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.5.attention.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.5.attention.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_40": "Data",
                "bert.encoder.layer.5.attention.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.5.attention.output.LayerNorm.weight": "Data",
                "dc.input_tensor.layernorm_309.6": "Data",
                "dc.input_tensor.layernorm_309.8": "Data",
                "layernorm_309.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_309.6",
                "layernorm_309.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_309.8",
                "_fused_op_40",
                "bert.encoder.layer.5.attention.output.LayerNorm.weight",
                "bert.encoder.layer.5.attention.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_41",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_312 (port_0)",
                "Data: add_322 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_312",
                "add_322"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_309.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_309.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_309.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_309.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_309.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_309.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_309.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34169
        },
        "_fused_op_42": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_323.1 (port_0) ublock_order(c)",
                "Data: layernorm_323.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: add_322 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_322": "Data",
                "dc.input_tensor.layernorm_323.1": "Data",
                "layernorm_323.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_323.1",
                "layernorm_323.dc.reduce_sum.0.lc1",
                "add_322"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_42",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_323.dc.multiply.4 (port_0)",
                "Data: layernorm_323.dc.multiply.4 (port_0)",
                "Data: _fused_op_43 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_323.dc.multiply.4",
                "layernorm_323.dc.multiply.4",
                "_fused_op_43"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_323.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_323.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34170
        },
        "_fused_op_43": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_323.6 (port_0) ublock_order(r)",
                "Data: layernorm_323.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_323.8 (port_2) ublock_order(r)",
                "Data: _fused_op_42 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.5.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.5.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_42": "Data",
                "bert.encoder.layer.5.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.5.output.LayerNorm.weight": "Data",
                "dc.input_tensor.layernorm_323.6": "Data",
                "dc.input_tensor.layernorm_323.8": "Data",
                "layernorm_323.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_323.6",
                "layernorm_323.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_323.8",
                "_fused_op_42",
                "bert.encoder.layer.5.output.LayerNorm.weight",
                "bert.encoder.layer.5.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_43",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_326 (port_0)",
                "Data: matmul_332 (port_0)",
                "Data: matmul_346 (port_0)",
                "Data: add_361 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_326",
                "matmul_332",
                "matmul_346",
                "add_361"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_323.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_323.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_323.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_323.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_323.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_323.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_323.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34171
        },
        "_fused_op_44": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_338 (port_0) ublock_order(r)",
                "Data: input_1_multiply_340 (port_1) ublock_order(r)",
                "Data: multiply_22_attempt_1_input_op_fork_nop0 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "input_1_multiply_340": "Data",
                "matmul_338": "Data",
                "multiply_22_attempt_1_input_op_fork_nop0": "Data"
            },
            "input_nodes": [
                "matmul_338",
                "input_1_multiply_340",
                "multiply_22_attempt_1_input_op_fork_nop0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_44",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_342.dc.reduce_max.0 (port_0)",
                "Data: _fused_op_45 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_342.dc.reduce_max.0",
                "_fused_op_45"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "multiply_340: multiply (1,16,12,12), out: 0",
                    "add_341: add (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "add"
            },
            "type": "fused_op",
            "unique_id": 34172
        },
        "_fused_op_45": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_44 (port_0) ublock_order(c)",
                "Data: softmax_342.dc.reduce_max.0 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_44": "Data",
                "softmax_342.dc.reduce_max.0": "Data"
            },
            "input_nodes": [
                "_fused_op_44",
                "softmax_342.dc.reduce_max.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_45",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_342.dc.reduce_sum.3.lc1 (port_0)",
                "Data: _fused_op_46 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_342.dc.reduce_sum.3.lc1",
                "_fused_op_46"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_342.dc.subtract.1: subtract (1,16,12,12), out: 0",
                    "softmax_342.dc.exp.2: exp (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 34173
        },
        "_fused_op_46": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: softmax_342.dc.reduce_sum.3.lc1 (port_0) ublock_order(r)",
                "Data: dc.input_tensor.softmax_342.4 (port_1) ublock_order(r)",
                "Data: _fused_op_45 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_45": "Data",
                "dc.input_tensor.softmax_342.4": "Data",
                "softmax_342.dc.reduce_sum.3.lc1": "Data"
            },
            "input_nodes": [
                "softmax_342.dc.reduce_sum.3.lc1",
                "dc.input_tensor.softmax_342.4",
                "_fused_op_45"
            ],
            "input_tms": [
                [],
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_46",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_353 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_353"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_342.dc.add.5: add (1,16,12,1), out: 0",
                    "softmax_342.dc.reciprocal.6: reciprocal (1,16,12,1), out: 0",
                    "softmax_342.dc.multiply.7: multiply (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 34174
        },
        "_fused_op_47": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_362.1 (port_0) ublock_order(c)",
                "Data: layernorm_362.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: add_361 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_361": "Data",
                "dc.input_tensor.layernorm_362.1": "Data",
                "layernorm_362.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_362.1",
                "layernorm_362.dc.reduce_sum.0.lc1",
                "add_361"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_47",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_362.dc.multiply.4 (port_0)",
                "Data: layernorm_362.dc.multiply.4 (port_0)",
                "Data: _fused_op_48 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_362.dc.multiply.4",
                "layernorm_362.dc.multiply.4",
                "_fused_op_48"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_362.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_362.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34175
        },
        "_fused_op_48": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_362.6 (port_0) ublock_order(r)",
                "Data: layernorm_362.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_362.8 (port_2) ublock_order(r)",
                "Data: _fused_op_47 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.6.attention.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.6.attention.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_47": "Data",
                "bert.encoder.layer.6.attention.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.6.attention.output.LayerNorm.weight": "Data",
                "dc.input_tensor.layernorm_362.6": "Data",
                "dc.input_tensor.layernorm_362.8": "Data",
                "layernorm_362.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_362.6",
                "layernorm_362.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_362.8",
                "_fused_op_47",
                "bert.encoder.layer.6.attention.output.LayerNorm.weight",
                "bert.encoder.layer.6.attention.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_48",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_365 (port_0)",
                "Data: add_375 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_365",
                "add_375"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_362.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_362.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_362.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_362.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_362.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_362.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_362.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34176
        },
        "_fused_op_49": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_376.1 (port_0) ublock_order(c)",
                "Data: layernorm_376.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: add_375 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_375": "Data",
                "dc.input_tensor.layernorm_376.1": "Data",
                "layernorm_376.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_376.1",
                "layernorm_376.dc.reduce_sum.0.lc1",
                "add_375"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_49",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_376.dc.multiply.4 (port_0)",
                "Data: layernorm_376.dc.multiply.4 (port_0)",
                "Data: _fused_op_50 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_376.dc.multiply.4",
                "layernorm_376.dc.multiply.4",
                "_fused_op_50"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_376.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_376.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34177
        },
        "_fused_op_5": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_44.1 (port_0) ublock_order(c)",
                "Data: layernorm_44.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: add_43 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_43": "Data",
                "dc.input_tensor.layernorm_44.1": "Data",
                "layernorm_44.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_44.1",
                "layernorm_44.dc.reduce_sum.0.lc1",
                "add_43"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_5",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_44.dc.multiply.4 (port_0)",
                "Data: layernorm_44.dc.multiply.4 (port_0)",
                "Data: _fused_op_6 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_44.dc.multiply.4",
                "layernorm_44.dc.multiply.4",
                "_fused_op_6"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_44.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_44.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34133
        },
        "_fused_op_50": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_376.6 (port_0) ublock_order(r)",
                "Data: layernorm_376.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_376.8 (port_2) ublock_order(r)",
                "Data: _fused_op_49 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.6.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.6.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_49": "Data",
                "bert.encoder.layer.6.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.6.output.LayerNorm.weight": "Data",
                "dc.input_tensor.layernorm_376.6": "Data",
                "dc.input_tensor.layernorm_376.8": "Data",
                "layernorm_376.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_376.6",
                "layernorm_376.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_376.8",
                "_fused_op_49",
                "bert.encoder.layer.6.output.LayerNorm.weight",
                "bert.encoder.layer.6.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_50",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_379 (port_0)",
                "Data: matmul_385 (port_0)",
                "Data: matmul_399 (port_0)",
                "Data: add_414 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_379",
                "matmul_385",
                "matmul_399",
                "add_414"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_376.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_376.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_376.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_376.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_376.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_376.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_376.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34178
        },
        "_fused_op_51": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_391 (port_0) ublock_order(r)",
                "Data: input_1_multiply_393 (port_1) ublock_order(r)",
                "Data: multiply_22_attempt_1_input_op_fork_nop0 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "input_1_multiply_393": "Data",
                "matmul_391": "Data",
                "multiply_22_attempt_1_input_op_fork_nop0": "Data"
            },
            "input_nodes": [
                "matmul_391",
                "input_1_multiply_393",
                "multiply_22_attempt_1_input_op_fork_nop0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_51",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_395.dc.reduce_max.0 (port_0)",
                "Data: _fused_op_52 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_395.dc.reduce_max.0",
                "_fused_op_52"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "multiply_393: multiply (1,16,12,12), out: 0",
                    "add_394: add (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "add"
            },
            "type": "fused_op",
            "unique_id": 34179
        },
        "_fused_op_52": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_51 (port_0) ublock_order(c)",
                "Data: softmax_395.dc.reduce_max.0 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_51": "Data",
                "softmax_395.dc.reduce_max.0": "Data"
            },
            "input_nodes": [
                "_fused_op_51",
                "softmax_395.dc.reduce_max.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_52",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_395.dc.reduce_sum.3.lc1 (port_0)",
                "Data: _fused_op_53 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_395.dc.reduce_sum.3.lc1",
                "_fused_op_53"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_395.dc.subtract.1: subtract (1,16,12,12), out: 0",
                    "softmax_395.dc.exp.2: exp (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 34180
        },
        "_fused_op_53": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: softmax_395.dc.reduce_sum.3.lc1 (port_0) ublock_order(r)",
                "Data: dc.input_tensor.softmax_395.4 (port_1) ublock_order(r)",
                "Data: _fused_op_52 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_52": "Data",
                "dc.input_tensor.softmax_395.4": "Data",
                "softmax_395.dc.reduce_sum.3.lc1": "Data"
            },
            "input_nodes": [
                "softmax_395.dc.reduce_sum.3.lc1",
                "dc.input_tensor.softmax_395.4",
                "_fused_op_52"
            ],
            "input_tms": [
                [],
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_53",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_406 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_406"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_395.dc.add.5: add (1,16,12,1), out: 0",
                    "softmax_395.dc.reciprocal.6: reciprocal (1,16,12,1), out: 0",
                    "softmax_395.dc.multiply.7: multiply (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 34181
        },
        "_fused_op_54": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_415.1 (port_0) ublock_order(c)",
                "Data: layernorm_415.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: add_414 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_414": "Data",
                "dc.input_tensor.layernorm_415.1": "Data",
                "layernorm_415.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_415.1",
                "layernorm_415.dc.reduce_sum.0.lc1",
                "add_414"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_54",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_415.dc.multiply.4 (port_0)",
                "Data: layernorm_415.dc.multiply.4 (port_0)",
                "Data: _fused_op_55 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_415.dc.multiply.4",
                "layernorm_415.dc.multiply.4",
                "_fused_op_55"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_415.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_415.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34182
        },
        "_fused_op_55": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_415.6 (port_0) ublock_order(r)",
                "Data: layernorm_415.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_415.8 (port_2) ublock_order(r)",
                "Data: _fused_op_54 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.7.attention.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.7.attention.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_54": "Data",
                "bert.encoder.layer.7.attention.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.7.attention.output.LayerNorm.weight": "Data",
                "dc.input_tensor.layernorm_415.6": "Data",
                "dc.input_tensor.layernorm_415.8": "Data",
                "layernorm_415.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_415.6",
                "layernorm_415.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_415.8",
                "_fused_op_54",
                "bert.encoder.layer.7.attention.output.LayerNorm.weight",
                "bert.encoder.layer.7.attention.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_55",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_418 (port_0)",
                "Data: add_428 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_418",
                "add_428"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_415.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_415.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_415.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_415.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_415.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_415.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_415.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34183
        },
        "_fused_op_56": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_429.1 (port_0) ublock_order(c)",
                "Data: layernorm_429.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: add_428 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_428": "Data",
                "dc.input_tensor.layernorm_429.1": "Data",
                "layernorm_429.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_429.1",
                "layernorm_429.dc.reduce_sum.0.lc1",
                "add_428"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_56",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_429.dc.multiply.4 (port_0)",
                "Data: layernorm_429.dc.multiply.4 (port_0)",
                "Data: _fused_op_57 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_429.dc.multiply.4",
                "layernorm_429.dc.multiply.4",
                "_fused_op_57"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_429.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_429.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34184
        },
        "_fused_op_57": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_429.6 (port_0) ublock_order(r)",
                "Data: layernorm_429.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_429.8 (port_2) ublock_order(r)",
                "Data: _fused_op_56 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.7.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.7.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_56": "Data",
                "bert.encoder.layer.7.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.7.output.LayerNorm.weight": "Data",
                "dc.input_tensor.layernorm_429.6": "Data",
                "dc.input_tensor.layernorm_429.8": "Data",
                "layernorm_429.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_429.6",
                "layernorm_429.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_429.8",
                "_fused_op_56",
                "bert.encoder.layer.7.output.LayerNorm.weight",
                "bert.encoder.layer.7.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_57",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_432 (port_0)",
                "Data: matmul_438 (port_0)",
                "Data: matmul_452 (port_0)",
                "Data: add_467 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_432",
                "matmul_438",
                "matmul_452",
                "add_467"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_429.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_429.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_429.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_429.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_429.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_429.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_429.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34185
        },
        "_fused_op_58": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_444 (port_0) ublock_order(r)",
                "Data: input_1_multiply_446 (port_1) ublock_order(r)",
                "Data: multiply_22_attempt_1_input_op_fork_nop1 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "input_1_multiply_446": "Data",
                "matmul_444": "Data",
                "multiply_22_attempt_1_input_op_fork_nop1": "Data"
            },
            "input_nodes": [
                "matmul_444",
                "input_1_multiply_446",
                "multiply_22_attempt_1_input_op_fork_nop1"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_58",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_448.dc.reduce_max.0 (port_0)",
                "Data: _fused_op_59 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_448.dc.reduce_max.0",
                "_fused_op_59"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "multiply_446: multiply (1,16,12,12), out: 0",
                    "add_447: add (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "add"
            },
            "type": "fused_op",
            "unique_id": 34186
        },
        "_fused_op_59": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_58 (port_0) ublock_order(c)",
                "Data: softmax_448.dc.reduce_max.0 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_58": "Data",
                "softmax_448.dc.reduce_max.0": "Data"
            },
            "input_nodes": [
                "_fused_op_58",
                "softmax_448.dc.reduce_max.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_59",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_448.dc.reduce_sum.3.lc1 (port_0)",
                "Data: _fused_op_60 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_448.dc.reduce_sum.3.lc1",
                "_fused_op_60"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_448.dc.subtract.1: subtract (1,16,12,12), out: 0",
                    "softmax_448.dc.exp.2: exp (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 34187
        },
        "_fused_op_6": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_44.6 (port_0) ublock_order(r)",
                "Data: layernorm_44.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_44.8 (port_2) ublock_order(r)",
                "Data: _fused_op_5 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.0.attention.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.0.attention.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_5": "Data",
                "bert.encoder.layer.0.attention.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.0.attention.output.LayerNorm.weight": "Data",
                "dc.input_tensor.layernorm_44.6": "Data",
                "dc.input_tensor.layernorm_44.8": "Data",
                "layernorm_44.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_44.6",
                "layernorm_44.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_44.8",
                "_fused_op_5",
                "bert.encoder.layer.0.attention.output.LayerNorm.weight",
                "bert.encoder.layer.0.attention.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_6",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_47 (port_0)",
                "Data: add_57 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_47",
                "add_57"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_44.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_44.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_44.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_44.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_44.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_44.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_44.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34134
        },
        "_fused_op_60": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: softmax_448.dc.reduce_sum.3.lc1 (port_0) ublock_order(r)",
                "Data: dc.input_tensor.softmax_448.4 (port_1) ublock_order(r)",
                "Data: _fused_op_59 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_59": "Data",
                "dc.input_tensor.softmax_448.4": "Data",
                "softmax_448.dc.reduce_sum.3.lc1": "Data"
            },
            "input_nodes": [
                "softmax_448.dc.reduce_sum.3.lc1",
                "dc.input_tensor.softmax_448.4",
                "_fused_op_59"
            ],
            "input_tms": [
                [],
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_60",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_459 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_459"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_448.dc.add.5: add (1,16,12,1), out: 0",
                    "softmax_448.dc.reciprocal.6: reciprocal (1,16,12,1), out: 0",
                    "softmax_448.dc.multiply.7: multiply (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 34188
        },
        "_fused_op_61": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_468.1 (port_0) ublock_order(c)",
                "Data: layernorm_468.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: add_467 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_467": "Data",
                "dc.input_tensor.layernorm_468.1": "Data",
                "layernorm_468.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_468.1",
                "layernorm_468.dc.reduce_sum.0.lc1",
                "add_467"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_61",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_468.dc.multiply.4 (port_0)",
                "Data: layernorm_468.dc.multiply.4 (port_0)",
                "Data: _fused_op_62 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_468.dc.multiply.4",
                "layernorm_468.dc.multiply.4",
                "_fused_op_62"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_468.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_468.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34189
        },
        "_fused_op_62": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_468.6 (port_0) ublock_order(r)",
                "Data: layernorm_468.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_468.8 (port_2) ublock_order(r)",
                "Data: _fused_op_61 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.8.attention.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.8.attention.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_61": "Data",
                "bert.encoder.layer.8.attention.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.8.attention.output.LayerNorm.weight": "Data",
                "dc.input_tensor.layernorm_468.6": "Data",
                "dc.input_tensor.layernorm_468.8": "Data",
                "layernorm_468.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_468.6",
                "layernorm_468.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_468.8",
                "_fused_op_61",
                "bert.encoder.layer.8.attention.output.LayerNorm.weight",
                "bert.encoder.layer.8.attention.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_62",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_471 (port_0)",
                "Data: add_481 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_471",
                "add_481"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_468.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_468.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_468.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_468.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_468.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_468.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_468.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34190
        },
        "_fused_op_63": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_482.1 (port_0) ublock_order(c)",
                "Data: layernorm_482.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: add_481 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_481": "Data",
                "dc.input_tensor.layernorm_482.1": "Data",
                "layernorm_482.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_482.1",
                "layernorm_482.dc.reduce_sum.0.lc1",
                "add_481"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_63",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_482.dc.multiply.4 (port_0)",
                "Data: layernorm_482.dc.multiply.4 (port_0)",
                "Data: _fused_op_64 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_482.dc.multiply.4",
                "layernorm_482.dc.multiply.4",
                "_fused_op_64"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_482.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_482.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34191
        },
        "_fused_op_64": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_482.6 (port_0) ublock_order(r)",
                "Data: layernorm_482.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_482.8 (port_2) ublock_order(r)",
                "Data: _fused_op_63 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.8.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.8.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_63": "Data",
                "bert.encoder.layer.8.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.8.output.LayerNorm.weight": "Data",
                "dc.input_tensor.layernorm_482.6": "Data",
                "dc.input_tensor.layernorm_482.8": "Data",
                "layernorm_482.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_482.6",
                "layernorm_482.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_482.8",
                "_fused_op_63",
                "bert.encoder.layer.8.output.LayerNorm.weight",
                "bert.encoder.layer.8.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_64",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_485 (port_0)",
                "Data: matmul_491 (port_0)",
                "Data: matmul_505 (port_0)",
                "Data: add_520 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_485",
                "matmul_491",
                "matmul_505",
                "add_520"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_482.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_482.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_482.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_482.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_482.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_482.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_482.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34192
        },
        "_fused_op_65": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_497 (port_0) ublock_order(r)",
                "Data: input_1_multiply_499 (port_1) ublock_order(r)",
                "Data: multiply_22_attempt_1_input_op_fork_nop1 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "input_1_multiply_499": "Data",
                "matmul_497": "Data",
                "multiply_22_attempt_1_input_op_fork_nop1": "Data"
            },
            "input_nodes": [
                "matmul_497",
                "input_1_multiply_499",
                "multiply_22_attempt_1_input_op_fork_nop1"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_65",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_501.dc.reduce_max.0 (port_0)",
                "Data: _fused_op_66 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_501.dc.reduce_max.0",
                "_fused_op_66"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "multiply_499: multiply (1,16,12,12), out: 0",
                    "add_500: add (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "add"
            },
            "type": "fused_op",
            "unique_id": 34193
        },
        "_fused_op_66": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_65 (port_0) ublock_order(c)",
                "Data: softmax_501.dc.reduce_max.0 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_65": "Data",
                "softmax_501.dc.reduce_max.0": "Data"
            },
            "input_nodes": [
                "_fused_op_65",
                "softmax_501.dc.reduce_max.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_66",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_501.dc.reduce_sum.3.lc1 (port_0)",
                "Data: _fused_op_67 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_501.dc.reduce_sum.3.lc1",
                "_fused_op_67"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_501.dc.subtract.1: subtract (1,16,12,12), out: 0",
                    "softmax_501.dc.exp.2: exp (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 34194
        },
        "_fused_op_67": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: softmax_501.dc.reduce_sum.3.lc1 (port_0) ublock_order(r)",
                "Data: dc.input_tensor.softmax_501.4 (port_1) ublock_order(r)",
                "Data: _fused_op_66 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_66": "Data",
                "dc.input_tensor.softmax_501.4": "Data",
                "softmax_501.dc.reduce_sum.3.lc1": "Data"
            },
            "input_nodes": [
                "softmax_501.dc.reduce_sum.3.lc1",
                "dc.input_tensor.softmax_501.4",
                "_fused_op_66"
            ],
            "input_tms": [
                [],
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_67",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_512 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_512"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_501.dc.add.5: add (1,16,12,1), out: 0",
                    "softmax_501.dc.reciprocal.6: reciprocal (1,16,12,1), out: 0",
                    "softmax_501.dc.multiply.7: multiply (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 34195
        },
        "_fused_op_68": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_521.1 (port_0) ublock_order(c)",
                "Data: layernorm_521.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: add_520 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_520": "Data",
                "dc.input_tensor.layernorm_521.1": "Data",
                "layernorm_521.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_521.1",
                "layernorm_521.dc.reduce_sum.0.lc1",
                "add_520"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_68",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_521.dc.multiply.4 (port_0)",
                "Data: layernorm_521.dc.multiply.4 (port_0)",
                "Data: _fused_op_69 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_521.dc.multiply.4",
                "layernorm_521.dc.multiply.4",
                "_fused_op_69"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_521.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_521.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34196
        },
        "_fused_op_69": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_521.6 (port_0) ublock_order(r)",
                "Data: layernorm_521.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_521.8 (port_2) ublock_order(r)",
                "Data: _fused_op_68 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.9.attention.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.9.attention.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_68": "Data",
                "bert.encoder.layer.9.attention.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.9.attention.output.LayerNorm.weight": "Data",
                "dc.input_tensor.layernorm_521.6": "Data",
                "dc.input_tensor.layernorm_521.8": "Data",
                "layernorm_521.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_521.6",
                "layernorm_521.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_521.8",
                "_fused_op_68",
                "bert.encoder.layer.9.attention.output.LayerNorm.weight",
                "bert.encoder.layer.9.attention.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_69",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_524 (port_0)",
                "Data: add_534 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_524",
                "add_534"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_521.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_521.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_521.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_521.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_521.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_521.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_521.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34197
        },
        "_fused_op_7": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_58.1 (port_0) ublock_order(c)",
                "Data: layernorm_58.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: add_57 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_57": "Data",
                "dc.input_tensor.layernorm_58.1": "Data",
                "layernorm_58.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_58.1",
                "layernorm_58.dc.reduce_sum.0.lc1",
                "add_57"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_7",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_58.dc.multiply.4 (port_0)",
                "Data: layernorm_58.dc.multiply.4 (port_0)",
                "Data: _fused_op_8 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_58.dc.multiply.4",
                "layernorm_58.dc.multiply.4",
                "_fused_op_8"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_58.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_58.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34135
        },
        "_fused_op_70": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_535.1 (port_0) ublock_order(c)",
                "Data: layernorm_535.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: add_534 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_534": "Data",
                "dc.input_tensor.layernorm_535.1": "Data",
                "layernorm_535.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_535.1",
                "layernorm_535.dc.reduce_sum.0.lc1",
                "add_534"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_70",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_535.dc.multiply.4 (port_0)",
                "Data: layernorm_535.dc.multiply.4 (port_0)",
                "Data: _fused_op_71 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_535.dc.multiply.4",
                "layernorm_535.dc.multiply.4",
                "_fused_op_71"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_535.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_535.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34198
        },
        "_fused_op_71": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_535.6 (port_0) ublock_order(r)",
                "Data: layernorm_535.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_535.8 (port_2) ublock_order(r)",
                "Data: _fused_op_70 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.9.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.9.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_70": "Data",
                "bert.encoder.layer.9.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.9.output.LayerNorm.weight": "Data",
                "dc.input_tensor.layernorm_535.6": "Data",
                "dc.input_tensor.layernorm_535.8": "Data",
                "layernorm_535.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_535.6",
                "layernorm_535.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_535.8",
                "_fused_op_70",
                "bert.encoder.layer.9.output.LayerNorm.weight",
                "bert.encoder.layer.9.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_71",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_538 (port_0)",
                "Data: matmul_544 (port_0)",
                "Data: matmul_558 (port_0)",
                "Data: add_573 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_538",
                "matmul_544",
                "matmul_558",
                "add_573"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_535.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_535.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_535.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_535.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_535.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_535.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_535.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34199
        },
        "_fused_op_72": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_550 (port_0) ublock_order(r)",
                "Data: input_1_multiply_552 (port_1) ublock_order(r)",
                "Data: multiply_22_attempt_1_input_op_fork_nop1 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "input_1_multiply_552": "Data",
                "matmul_550": "Data",
                "multiply_22_attempt_1_input_op_fork_nop1": "Data"
            },
            "input_nodes": [
                "matmul_550",
                "input_1_multiply_552",
                "multiply_22_attempt_1_input_op_fork_nop1"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_72",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_554.dc.reduce_max.0 (port_0)",
                "Data: _fused_op_73 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_554.dc.reduce_max.0",
                "_fused_op_73"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "multiply_552: multiply (1,16,12,12), out: 0",
                    "add_553: add (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "add"
            },
            "type": "fused_op",
            "unique_id": 34200
        },
        "_fused_op_73": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_72 (port_0) ublock_order(c)",
                "Data: softmax_554.dc.reduce_max.0 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_72": "Data",
                "softmax_554.dc.reduce_max.0": "Data"
            },
            "input_nodes": [
                "_fused_op_72",
                "softmax_554.dc.reduce_max.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_73",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_554.dc.reduce_sum.3.lc1 (port_0)",
                "Data: _fused_op_74 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_554.dc.reduce_sum.3.lc1",
                "_fused_op_74"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_554.dc.subtract.1: subtract (1,16,12,12), out: 0",
                    "softmax_554.dc.exp.2: exp (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 34201
        },
        "_fused_op_74": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: softmax_554.dc.reduce_sum.3.lc1 (port_0) ublock_order(r)",
                "Data: dc.input_tensor.softmax_554.4 (port_1) ublock_order(r)",
                "Data: _fused_op_73 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_73": "Data",
                "dc.input_tensor.softmax_554.4": "Data",
                "softmax_554.dc.reduce_sum.3.lc1": "Data"
            },
            "input_nodes": [
                "softmax_554.dc.reduce_sum.3.lc1",
                "dc.input_tensor.softmax_554.4",
                "_fused_op_73"
            ],
            "input_tms": [
                [],
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_74",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_565 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_565"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_554.dc.add.5: add (1,16,12,1), out: 0",
                    "softmax_554.dc.reciprocal.6: reciprocal (1,16,12,1), out: 0",
                    "softmax_554.dc.multiply.7: multiply (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 34202
        },
        "_fused_op_75": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_574.1 (port_0) ublock_order(c)",
                "Data: layernorm_574.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: add_573 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_573": "Data",
                "dc.input_tensor.layernorm_574.1": "Data",
                "layernorm_574.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_574.1",
                "layernorm_574.dc.reduce_sum.0.lc1",
                "add_573"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_75",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_574.dc.multiply.4 (port_0)",
                "Data: layernorm_574.dc.multiply.4 (port_0)",
                "Data: _fused_op_76 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_574.dc.multiply.4",
                "layernorm_574.dc.multiply.4",
                "_fused_op_76"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_574.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_574.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34203
        },
        "_fused_op_76": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_574.6 (port_0) ublock_order(r)",
                "Data: layernorm_574.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_574.8 (port_2) ublock_order(r)",
                "Data: _fused_op_75 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.10.attention.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.10.attention.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_75": "Data",
                "bert.encoder.layer.10.attention.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.10.attention.output.LayerNorm.weight": "Data",
                "dc.input_tensor.layernorm_574.6": "Data",
                "dc.input_tensor.layernorm_574.8": "Data",
                "layernorm_574.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_574.6",
                "layernorm_574.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_574.8",
                "_fused_op_75",
                "bert.encoder.layer.10.attention.output.LayerNorm.weight",
                "bert.encoder.layer.10.attention.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_76",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_577 (port_0)",
                "Data: add_587 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_577",
                "add_587"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_574.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_574.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_574.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_574.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_574.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_574.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_574.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34204
        },
        "_fused_op_77": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_588.1 (port_0) ublock_order(c)",
                "Data: layernorm_588.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: add_587 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_587": "Data",
                "dc.input_tensor.layernorm_588.1": "Data",
                "layernorm_588.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_588.1",
                "layernorm_588.dc.reduce_sum.0.lc1",
                "add_587"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_77",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_588.dc.multiply.4 (port_0)",
                "Data: layernorm_588.dc.multiply.4 (port_0)",
                "Data: _fused_op_78 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_588.dc.multiply.4",
                "layernorm_588.dc.multiply.4",
                "_fused_op_78"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_588.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_588.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34205
        },
        "_fused_op_78": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_588.6 (port_0) ublock_order(r)",
                "Data: layernorm_588.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_588.8 (port_2) ublock_order(r)",
                "Data: _fused_op_77 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.10.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.10.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_77": "Data",
                "bert.encoder.layer.10.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.10.output.LayerNorm.weight": "Data",
                "dc.input_tensor.layernorm_588.6": "Data",
                "dc.input_tensor.layernorm_588.8": "Data",
                "layernorm_588.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_588.6",
                "layernorm_588.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_588.8",
                "_fused_op_77",
                "bert.encoder.layer.10.output.LayerNorm.weight",
                "bert.encoder.layer.10.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_78",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_591 (port_0)",
                "Data: matmul_597 (port_0)",
                "Data: matmul_611 (port_0)",
                "Data: add_626 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_591",
                "matmul_597",
                "matmul_611",
                "add_626"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_588.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_588.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_588.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_588.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_588.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_588.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_588.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34206
        },
        "_fused_op_79": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_603 (port_0) ublock_order(r)",
                "Data: input_1_multiply_605 (port_1) ublock_order(r)",
                "Data: multiply_22_attempt_1_input_op_fork_nop1 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "input_1_multiply_605": "Data",
                "matmul_603": "Data",
                "multiply_22_attempt_1_input_op_fork_nop1": "Data"
            },
            "input_nodes": [
                "matmul_603",
                "input_1_multiply_605",
                "multiply_22_attempt_1_input_op_fork_nop1"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_79",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_607.dc.reduce_max.0 (port_0)",
                "Data: _fused_op_80 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_607.dc.reduce_max.0",
                "_fused_op_80"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "multiply_605: multiply (1,16,12,12), out: 0",
                    "add_606: add (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "add"
            },
            "type": "fused_op",
            "unique_id": 34207
        },
        "_fused_op_8": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_58.6 (port_0) ublock_order(r)",
                "Data: layernorm_58.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_58.8 (port_2) ublock_order(r)",
                "Data: _fused_op_7 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.0.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.0.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_7": "Data",
                "bert.encoder.layer.0.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.0.output.LayerNorm.weight": "Data",
                "dc.input_tensor.layernorm_58.6": "Data",
                "dc.input_tensor.layernorm_58.8": "Data",
                "layernorm_58.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_58.6",
                "layernorm_58.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_58.8",
                "_fused_op_7",
                "bert.encoder.layer.0.output.LayerNorm.weight",
                "bert.encoder.layer.0.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_8",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_61 (port_0)",
                "Data: matmul_67 (port_0)",
                "Data: matmul_81 (port_0)",
                "Data: add_96 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_61",
                "matmul_67",
                "matmul_81",
                "add_96"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_58.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_58.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_58.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_58.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_58.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_58.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_58.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34136
        },
        "_fused_op_80": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_79 (port_0) ublock_order(c)",
                "Data: softmax_607.dc.reduce_max.0 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_79": "Data",
                "softmax_607.dc.reduce_max.0": "Data"
            },
            "input_nodes": [
                "_fused_op_79",
                "softmax_607.dc.reduce_max.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_80",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_607.dc.reduce_sum.3.lc1 (port_0)",
                "Data: _fused_op_81 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_607.dc.reduce_sum.3.lc1",
                "_fused_op_81"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_607.dc.subtract.1: subtract (1,16,12,12), out: 0",
                    "softmax_607.dc.exp.2: exp (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 34208
        },
        "_fused_op_81": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: softmax_607.dc.reduce_sum.3.lc1 (port_0) ublock_order(r)",
                "Data: dc.input_tensor.softmax_607.4 (port_1) ublock_order(r)",
                "Data: _fused_op_80 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_80": "Data",
                "dc.input_tensor.softmax_607.4": "Data",
                "softmax_607.dc.reduce_sum.3.lc1": "Data"
            },
            "input_nodes": [
                "softmax_607.dc.reduce_sum.3.lc1",
                "dc.input_tensor.softmax_607.4",
                "_fused_op_80"
            ],
            "input_tms": [
                [],
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_81",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_618 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_618"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_607.dc.add.5: add (1,16,12,1), out: 0",
                    "softmax_607.dc.reciprocal.6: reciprocal (1,16,12,1), out: 0",
                    "softmax_607.dc.multiply.7: multiply (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 34209
        },
        "_fused_op_82": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_627.1 (port_0) ublock_order(c)",
                "Data: layernorm_627.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: add_626 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_626": "Data",
                "dc.input_tensor.layernorm_627.1": "Data",
                "layernorm_627.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_627.1",
                "layernorm_627.dc.reduce_sum.0.lc1",
                "add_626"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_82",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_627.dc.multiply.4 (port_0)",
                "Data: layernorm_627.dc.multiply.4 (port_0)",
                "Data: _fused_op_83 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_627.dc.multiply.4",
                "layernorm_627.dc.multiply.4",
                "_fused_op_83"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_627.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_627.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34210
        },
        "_fused_op_83": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_627.6 (port_0) ublock_order(r)",
                "Data: layernorm_627.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_627.8 (port_2) ublock_order(r)",
                "Data: _fused_op_82 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.11.attention.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.11.attention.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_82": "Data",
                "bert.encoder.layer.11.attention.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.11.attention.output.LayerNorm.weight": "Data",
                "dc.input_tensor.layernorm_627.6": "Data",
                "dc.input_tensor.layernorm_627.8": "Data",
                "layernorm_627.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_627.6",
                "layernorm_627.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_627.8",
                "_fused_op_82",
                "bert.encoder.layer.11.attention.output.LayerNorm.weight",
                "bert.encoder.layer.11.attention.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_83",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_630 (port_0)",
                "Data: add_640 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_630",
                "add_640"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_627.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_627.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_627.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_627.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_627.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_627.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_627.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34211
        },
        "_fused_op_84": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_641.1 (port_0) ublock_order(c)",
                "Data: layernorm_641.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: add_640 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_640": "Data",
                "dc.input_tensor.layernorm_641.1": "Data",
                "layernorm_641.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_641.1",
                "layernorm_641.dc.reduce_sum.0.lc1",
                "add_640"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_84",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_641.dc.multiply.4 (port_0)",
                "Data: layernorm_641.dc.multiply.4 (port_0)",
                "Data: _fused_op_85 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_641.dc.multiply.4",
                "layernorm_641.dc.multiply.4",
                "_fused_op_85"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_641.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_641.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34212
        },
        "_fused_op_85": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_641.6 (port_0) ublock_order(r)",
                "Data: layernorm_641.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_641.8 (port_2) ublock_order(r)",
                "Data: _fused_op_84 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.11.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.11.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_84": "Data",
                "bert.encoder.layer.11.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.11.output.LayerNorm.weight": "Data",
                "dc.input_tensor.layernorm_641.6": "Data",
                "dc.input_tensor.layernorm_641.8": "Data",
                "layernorm_641.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_641.6",
                "layernorm_641.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_641.8",
                "_fused_op_84",
                "bert.encoder.layer.11.output.LayerNorm.weight",
                "bert.encoder.layer.11.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_85",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_644 (port_0)",
                "Data: matmul_650 (port_0)",
                "Data: matmul_664 (port_0)",
                "Data: add_679 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_644",
                "matmul_650",
                "matmul_664",
                "add_679"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_641.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_641.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_641.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_641.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_641.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_641.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_641.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34213
        },
        "_fused_op_86": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_656 (port_0) ublock_order(r)",
                "Data: input_1_multiply_658 (port_1) ublock_order(r)",
                "Data: multiply_22_attempt_1_input_op_fork_nop1 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "input_1_multiply_658": "Data",
                "matmul_656": "Data",
                "multiply_22_attempt_1_input_op_fork_nop1": "Data"
            },
            "input_nodes": [
                "matmul_656",
                "input_1_multiply_658",
                "multiply_22_attempt_1_input_op_fork_nop1"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_86",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_660.dc.reduce_max.0 (port_0)",
                "Data: _fused_op_87 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_660.dc.reduce_max.0",
                "_fused_op_87"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "multiply_658: multiply (1,16,12,12), out: 0",
                    "add_659: add (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "add"
            },
            "type": "fused_op",
            "unique_id": 34214
        },
        "_fused_op_87": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_86 (port_0) ublock_order(c)",
                "Data: softmax_660.dc.reduce_max.0 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_86": "Data",
                "softmax_660.dc.reduce_max.0": "Data"
            },
            "input_nodes": [
                "_fused_op_86",
                "softmax_660.dc.reduce_max.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_87",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_660.dc.reduce_sum.3.lc1 (port_0)",
                "Data: _fused_op_88 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_660.dc.reduce_sum.3.lc1",
                "_fused_op_88"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_660.dc.subtract.1: subtract (1,16,12,12), out: 0",
                    "softmax_660.dc.exp.2: exp (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 34215
        },
        "_fused_op_88": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: softmax_660.dc.reduce_sum.3.lc1 (port_0) ublock_order(r)",
                "Data: dc.input_tensor.softmax_660.4 (port_1) ublock_order(r)",
                "Data: _fused_op_87 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_87": "Data",
                "dc.input_tensor.softmax_660.4": "Data",
                "softmax_660.dc.reduce_sum.3.lc1": "Data"
            },
            "input_nodes": [
                "softmax_660.dc.reduce_sum.3.lc1",
                "dc.input_tensor.softmax_660.4",
                "_fused_op_87"
            ],
            "input_tms": [
                [],
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_88",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_671 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_671"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_660.dc.add.5: add (1,16,12,1), out: 0",
                    "softmax_660.dc.reciprocal.6: reciprocal (1,16,12,1), out: 0",
                    "softmax_660.dc.multiply.7: multiply (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 34216
        },
        "_fused_op_89": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_680.1 (port_0) ublock_order(c)",
                "Data: layernorm_680.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: add_679 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_679": "Data",
                "dc.input_tensor.layernorm_680.1": "Data",
                "layernorm_680.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_680.1",
                "layernorm_680.dc.reduce_sum.0.lc1",
                "add_679"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_89",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_680.dc.multiply.4 (port_0)",
                "Data: layernorm_680.dc.multiply.4 (port_0)",
                "Data: _fused_op_90 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_680.dc.multiply.4",
                "layernorm_680.dc.multiply.4",
                "_fused_op_90"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_680.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_680.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34217
        },
        "_fused_op_9": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_73 (port_0) ublock_order(r)",
                "Data: input_1_multiply_75 (port_1) ublock_order(r)",
                "Data: multiply_22_attempt_1_input_op_fork_nop0 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "input_1_multiply_75": "Data",
                "matmul_73": "Data",
                "multiply_22_attempt_1_input_op_fork_nop0": "Data"
            },
            "input_nodes": [
                "matmul_73",
                "input_1_multiply_75",
                "multiply_22_attempt_1_input_op_fork_nop0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_9",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_77.dc.reduce_max.0 (port_0)",
                "Data: _fused_op_10 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_77.dc.reduce_max.0",
                "_fused_op_10"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "multiply_75: multiply (1,16,12,12), out: 0",
                    "add_76: add (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "add"
            },
            "type": "fused_op",
            "unique_id": 34137
        },
        "_fused_op_90": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_680.6 (port_0) ublock_order(r)",
                "Data: layernorm_680.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_680.8 (port_2) ublock_order(r)",
                "Data: _fused_op_89 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.12.attention.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.12.attention.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_89": "Data",
                "bert.encoder.layer.12.attention.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.12.attention.output.LayerNorm.weight": "Data",
                "dc.input_tensor.layernorm_680.6": "Data",
                "dc.input_tensor.layernorm_680.8": "Data",
                "layernorm_680.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_680.6",
                "layernorm_680.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_680.8",
                "_fused_op_89",
                "bert.encoder.layer.12.attention.output.LayerNorm.weight",
                "bert.encoder.layer.12.attention.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_90",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_683 (port_0)",
                "Data: add_693 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_683",
                "add_693"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_680.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_680.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_680.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_680.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_680.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_680.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_680.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34218
        },
        "_fused_op_91": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_694.1 (port_0) ublock_order(c)",
                "Data: layernorm_694.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: add_693 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_693": "Data",
                "dc.input_tensor.layernorm_694.1": "Data",
                "layernorm_694.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_694.1",
                "layernorm_694.dc.reduce_sum.0.lc1",
                "add_693"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_91",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_694.dc.multiply.4 (port_0)",
                "Data: layernorm_694.dc.multiply.4 (port_0)",
                "Data: _fused_op_92 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_694.dc.multiply.4",
                "layernorm_694.dc.multiply.4",
                "_fused_op_92"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_694.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_694.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34219
        },
        "_fused_op_92": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_694.6 (port_0) ublock_order(r)",
                "Data: layernorm_694.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_694.8 (port_2) ublock_order(r)",
                "Data: _fused_op_91 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.12.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.12.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_91": "Data",
                "bert.encoder.layer.12.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.12.output.LayerNorm.weight": "Data",
                "dc.input_tensor.layernorm_694.6": "Data",
                "dc.input_tensor.layernorm_694.8": "Data",
                "layernorm_694.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_694.6",
                "layernorm_694.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_694.8",
                "_fused_op_91",
                "bert.encoder.layer.12.output.LayerNorm.weight",
                "bert.encoder.layer.12.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_92",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_697 (port_0)",
                "Data: matmul_703 (port_0)",
                "Data: matmul_717 (port_0)",
                "Data: add_732 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_697",
                "matmul_703",
                "matmul_717",
                "add_732"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_694.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_694.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_694.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_694.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_694.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_694.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_694.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34220
        },
        "_fused_op_93": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_709 (port_0) ublock_order(r)",
                "Data: input_1_multiply_711 (port_1) ublock_order(r)",
                "Data: multiply_22_attempt_1_input_op_fork_nop1 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "input_1_multiply_711": "Data",
                "matmul_709": "Data",
                "multiply_22_attempt_1_input_op_fork_nop1": "Data"
            },
            "input_nodes": [
                "matmul_709",
                "input_1_multiply_711",
                "multiply_22_attempt_1_input_op_fork_nop1"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_93",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_713.dc.reduce_max.0 (port_0)",
                "Data: _fused_op_94 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_713.dc.reduce_max.0",
                "_fused_op_94"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "multiply_711: multiply (1,16,12,12), out: 0",
                    "add_712: add (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "add"
            },
            "type": "fused_op",
            "unique_id": 34221
        },
        "_fused_op_94": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_93 (port_0) ublock_order(c)",
                "Data: softmax_713.dc.reduce_max.0 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_93": "Data",
                "softmax_713.dc.reduce_max.0": "Data"
            },
            "input_nodes": [
                "_fused_op_93",
                "softmax_713.dc.reduce_max.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_94",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_713.dc.reduce_sum.3.lc1 (port_0)",
                "Data: _fused_op_95 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_713.dc.reduce_sum.3.lc1",
                "_fused_op_95"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_713.dc.subtract.1: subtract (1,16,12,12), out: 0",
                    "softmax_713.dc.exp.2: exp (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 34222
        },
        "_fused_op_95": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: softmax_713.dc.reduce_sum.3.lc1 (port_0) ublock_order(r)",
                "Data: dc.input_tensor.softmax_713.4 (port_1) ublock_order(r)",
                "Data: _fused_op_94 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_94": "Data",
                "dc.input_tensor.softmax_713.4": "Data",
                "softmax_713.dc.reduce_sum.3.lc1": "Data"
            },
            "input_nodes": [
                "softmax_713.dc.reduce_sum.3.lc1",
                "dc.input_tensor.softmax_713.4",
                "_fused_op_94"
            ],
            "input_tms": [
                [],
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_95",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_724 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_724"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_713.dc.add.5: add (1,16,12,1), out: 0",
                    "softmax_713.dc.reciprocal.6: reciprocal (1,16,12,1), out: 0",
                    "softmax_713.dc.multiply.7: multiply (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 34223
        },
        "_fused_op_96": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_733.1 (port_0) ublock_order(c)",
                "Data: layernorm_733.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: add_732 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_732": "Data",
                "dc.input_tensor.layernorm_733.1": "Data",
                "layernorm_733.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_733.1",
                "layernorm_733.dc.reduce_sum.0.lc1",
                "add_732"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_96",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_733.dc.multiply.4 (port_0)",
                "Data: layernorm_733.dc.multiply.4 (port_0)",
                "Data: _fused_op_97 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_733.dc.multiply.4",
                "layernorm_733.dc.multiply.4",
                "_fused_op_97"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_733.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_733.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34224
        },
        "_fused_op_97": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_733.6 (port_0) ublock_order(r)",
                "Data: layernorm_733.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_733.8 (port_2) ublock_order(r)",
                "Data: _fused_op_96 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.13.attention.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.13.attention.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_96": "Data",
                "bert.encoder.layer.13.attention.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.13.attention.output.LayerNorm.weight": "Data",
                "dc.input_tensor.layernorm_733.6": "Data",
                "dc.input_tensor.layernorm_733.8": "Data",
                "layernorm_733.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_733.6",
                "layernorm_733.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_733.8",
                "_fused_op_96",
                "bert.encoder.layer.13.attention.output.LayerNorm.weight",
                "bert.encoder.layer.13.attention.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_97",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_736 (port_0)",
                "Data: add_746 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_736",
                "add_746"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_733.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_733.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_733.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_733.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_733.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_733.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_733.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34225
        },
        "_fused_op_98": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_747.1 (port_0) ublock_order(c)",
                "Data: layernorm_747.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: add_746 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_746": "Data",
                "dc.input_tensor.layernorm_747.1": "Data",
                "layernorm_747.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_747.1",
                "layernorm_747.dc.reduce_sum.0.lc1",
                "add_746"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_98",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_747.dc.multiply.4 (port_0)",
                "Data: layernorm_747.dc.multiply.4 (port_0)",
                "Data: _fused_op_99 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_747.dc.multiply.4",
                "layernorm_747.dc.multiply.4",
                "_fused_op_99"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_747.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_747.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34226
        },
        "_fused_op_99": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_747.6 (port_0) ublock_order(r)",
                "Data: layernorm_747.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_747.8 (port_2) ublock_order(r)",
                "Data: _fused_op_98 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.13.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.13.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_98": "Data",
                "bert.encoder.layer.13.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.13.output.LayerNorm.weight": "Data",
                "dc.input_tensor.layernorm_747.6": "Data",
                "dc.input_tensor.layernorm_747.8": "Data",
                "layernorm_747.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_747.6",
                "layernorm_747.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_747.8",
                "_fused_op_98",
                "bert.encoder.layer.13.output.LayerNorm.weight",
                "bert.encoder.layer.13.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_99",
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_750 (port_0)",
                "Data: matmul_756 (port_0)",
                "Data: matmul_770 (port_0)",
                "Data: add_785 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_750",
                "matmul_756",
                "matmul_770",
                "add_785"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_747.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_747.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_747.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_747.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_747.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_747.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_747.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 34227
        },
        "add_1011": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1007 (port_0) ublock_order(c)",
                "Data: _fused_op_132 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_132": "Data",
                "matmul_1007": "Data"
            },
            "input_nodes": [
                "matmul_1007",
                "_fused_op_132"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_1011",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1012.dc.reduce_sum.0.lc1 (port_0)",
                "Data: _fused_op_133 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1012.dc.reduce_sum.0.lc1",
                "_fused_op_133"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertOutput::output",
                "original_op_name": "add_1011",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 33577
        },
        "add_1050": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1046 (port_0) ublock_order(c)",
                "Data: _fused_op_134 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_134": "Data",
                "matmul_1046": "Data"
            },
            "input_nodes": [
                "matmul_1046",
                "_fused_op_134"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_1050",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1051.dc.reduce_sum.0.lc1 (port_0)",
                "Data: _fused_op_138 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1051.dc.reduce_sum.0.lc1",
                "_fused_op_138"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output",
                "original_op_name": "add_1050",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 33649
        },
        "add_1064": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1060 (port_0) ublock_order(c)",
                "Data: _fused_op_139 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_139": "Data",
                "matmul_1060": "Data"
            },
            "input_nodes": [
                "matmul_1060",
                "_fused_op_139"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_1064",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1065.dc.reduce_sum.0.lc1 (port_0)",
                "Data: _fused_op_140 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1065.dc.reduce_sum.0.lc1",
                "_fused_op_140"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertOutput::output",
                "original_op_name": "add_1064",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 33681
        },
        "add_110": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_106 (port_0) ublock_order(c)",
                "Data: _fused_op_13 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_13": "Data",
                "matmul_106": "Data"
            },
            "input_nodes": [
                "matmul_106",
                "_fused_op_13"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_110",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_111.dc.reduce_sum.0.lc1 (port_0)",
                "Data: _fused_op_14 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_111.dc.reduce_sum.0.lc1",
                "_fused_op_14"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertOutput::output",
                "original_op_name": "add_110",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 31809
        },
        "add_1103": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1099 (port_0) ublock_order(c)",
                "Data: _fused_op_141 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_141": "Data",
                "matmul_1099": "Data"
            },
            "input_nodes": [
                "matmul_1099",
                "_fused_op_141"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_1103",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1104.dc.reduce_sum.0.lc1 (port_0)",
                "Data: _fused_op_145 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1104.dc.reduce_sum.0.lc1",
                "_fused_op_145"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output",
                "original_op_name": "add_1103",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 33753
        },
        "add_1117": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1113 (port_0) ublock_order(c)",
                "Data: _fused_op_146 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_146": "Data",
                "matmul_1113": "Data"
            },
            "input_nodes": [
                "matmul_1113",
                "_fused_op_146"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_1117",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1118.dc.reduce_sum.0.lc1 (port_0)",
                "Data: _fused_op_147 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1118.dc.reduce_sum.0.lc1",
                "_fused_op_147"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertOutput::output",
                "original_op_name": "add_1117",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 33785
        },
        "add_1156": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1152 (port_0) ublock_order(c)",
                "Data: _fused_op_148 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_148": "Data",
                "matmul_1152": "Data"
            },
            "input_nodes": [
                "matmul_1152",
                "_fused_op_148"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_1156",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1157.dc.reduce_sum.0.lc1 (port_0)",
                "Data: _fused_op_152 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1157.dc.reduce_sum.0.lc1",
                "_fused_op_152"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output",
                "original_op_name": "add_1156",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 33857
        },
        "add_1170": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1166 (port_0) ublock_order(c)",
                "Data: _fused_op_153 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_153": "Data",
                "matmul_1166": "Data"
            },
            "input_nodes": [
                "matmul_1166",
                "_fused_op_153"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_1170",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1171.dc.reduce_sum.0.lc1 (port_0)",
                "Data: _fused_op_154 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1171.dc.reduce_sum.0.lc1",
                "_fused_op_154"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertOutput::output",
                "original_op_name": "add_1170",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 33889
        },
        "add_1209": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1205 (port_0) ublock_order(c)",
                "Data: _fused_op_155 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_155": "Data",
                "matmul_1205": "Data"
            },
            "input_nodes": [
                "matmul_1205",
                "_fused_op_155"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_1209",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1210.dc.reduce_sum.0.lc1 (port_0)",
                "Data: _fused_op_159 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1210.dc.reduce_sum.0.lc1",
                "_fused_op_159"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output",
                "original_op_name": "add_1209",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 33961
        },
        "add_1223": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1219 (port_0) ublock_order(c)",
                "Data: _fused_op_160 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_160": "Data",
                "matmul_1219": "Data"
            },
            "input_nodes": [
                "matmul_1219",
                "_fused_op_160"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_1223",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1224.dc.reduce_sum.0.lc1 (port_0)",
                "Data: _fused_op_161 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1224.dc.reduce_sum.0.lc1",
                "_fused_op_161"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertOutput::output",
                "original_op_name": "add_1223",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 33993
        },
        "add_1262": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1258 (port_0) ublock_order(c)",
                "Data: _fused_op_162 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_162": "Data",
                "matmul_1258": "Data"
            },
            "input_nodes": [
                "matmul_1258",
                "_fused_op_162"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_1262",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1263.dc.reduce_sum.0.lc1 (port_0)",
                "Data: _fused_op_166 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1263.dc.reduce_sum.0.lc1",
                "_fused_op_166"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output",
                "original_op_name": "add_1262",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 34065
        },
        "add_1276": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1272 (port_0) ublock_order(c)",
                "Data: _fused_op_167 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_167": "Data",
                "matmul_1272": "Data"
            },
            "input_nodes": [
                "matmul_1272",
                "_fused_op_167"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_1276",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1277.dc.reduce_sum.0.lc1 (port_0)",
                "Data: _fused_op_168 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1277.dc.reduce_sum.0.lc1",
                "_fused_op_168"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertOutput::output",
                "original_op_name": "add_1276",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 34097
        },
        "add_149": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_145 (port_0) ublock_order(c)",
                "Data: _fused_op_15 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_15": "Data",
                "matmul_145": "Data"
            },
            "input_nodes": [
                "matmul_145",
                "_fused_op_15"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_149",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_150.dc.reduce_sum.0.lc1 (port_0)",
                "Data: _fused_op_19 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_150.dc.reduce_sum.0.lc1",
                "_fused_op_19"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output",
                "original_op_name": "add_149",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 31881
        },
        "add_163": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_159 (port_0) ublock_order(c)",
                "Data: _fused_op_20 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_20": "Data",
                "matmul_159": "Data"
            },
            "input_nodes": [
                "matmul_159",
                "_fused_op_20"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_163",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_164.dc.reduce_sum.0.lc1 (port_0)",
                "Data: _fused_op_21 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_164.dc.reduce_sum.0.lc1",
                "_fused_op_21"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertOutput::output",
                "original_op_name": "add_163",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 31913
        },
        "add_202": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_198 (port_0) ublock_order(c)",
                "Data: _fused_op_22 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_22": "Data",
                "matmul_198": "Data"
            },
            "input_nodes": [
                "matmul_198",
                "_fused_op_22"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_202",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_203.dc.reduce_sum.0.lc1 (port_0)",
                "Data: _fused_op_26 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_203.dc.reduce_sum.0.lc1",
                "_fused_op_26"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output",
                "original_op_name": "add_202",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 31985
        },
        "add_216": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_212 (port_0) ublock_order(c)",
                "Data: _fused_op_27 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_27": "Data",
                "matmul_212": "Data"
            },
            "input_nodes": [
                "matmul_212",
                "_fused_op_27"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_216",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_217.dc.reduce_sum.0.lc1 (port_0)",
                "Data: _fused_op_28 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_217.dc.reduce_sum.0.lc1",
                "_fused_op_28"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertOutput::output",
                "original_op_name": "add_216",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 32017
        },
        "add_255": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_251 (port_0) ublock_order(c)",
                "Data: _fused_op_29 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_29": "Data",
                "matmul_251": "Data"
            },
            "input_nodes": [
                "matmul_251",
                "_fused_op_29"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_255",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_256.dc.reduce_sum.0.lc1 (port_0)",
                "Data: _fused_op_33 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_256.dc.reduce_sum.0.lc1",
                "_fused_op_33"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output",
                "original_op_name": "add_255",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 32089
        },
        "add_269": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_265 (port_0) ublock_order(c)",
                "Data: _fused_op_34 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_34": "Data",
                "matmul_265": "Data"
            },
            "input_nodes": [
                "matmul_265",
                "_fused_op_34"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_269",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_270.dc.reduce_sum.0.lc1 (port_0)",
                "Data: _fused_op_35 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_270.dc.reduce_sum.0.lc1",
                "_fused_op_35"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertOutput::output",
                "original_op_name": "add_269",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 32121
        },
        "add_308": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_304 (port_0) ublock_order(c)",
                "Data: _fused_op_36 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_36": "Data",
                "matmul_304": "Data"
            },
            "input_nodes": [
                "matmul_304",
                "_fused_op_36"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_308",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_309.dc.reduce_sum.0.lc1 (port_0)",
                "Data: _fused_op_40 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_309.dc.reduce_sum.0.lc1",
                "_fused_op_40"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output",
                "original_op_name": "add_308",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 32193
        },
        "add_322": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_318 (port_0) ublock_order(c)",
                "Data: _fused_op_41 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_41": "Data",
                "matmul_318": "Data"
            },
            "input_nodes": [
                "matmul_318",
                "_fused_op_41"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_322",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_323.dc.reduce_sum.0.lc1 (port_0)",
                "Data: _fused_op_42 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_323.dc.reduce_sum.0.lc1",
                "_fused_op_42"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertOutput::output",
                "original_op_name": "add_322",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 32225
        },
        "add_361": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_357 (port_0) ublock_order(c)",
                "Data: _fused_op_43 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_43": "Data",
                "matmul_357": "Data"
            },
            "input_nodes": [
                "matmul_357",
                "_fused_op_43"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_361",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_362.dc.reduce_sum.0.lc1 (port_0)",
                "Data: _fused_op_47 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_362.dc.reduce_sum.0.lc1",
                "_fused_op_47"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output",
                "original_op_name": "add_361",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 32297
        },
        "add_375": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_371 (port_0) ublock_order(c)",
                "Data: _fused_op_48 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_48": "Data",
                "matmul_371": "Data"
            },
            "input_nodes": [
                "matmul_371",
                "_fused_op_48"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_375",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_376.dc.reduce_sum.0.lc1 (port_0)",
                "Data: _fused_op_49 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_376.dc.reduce_sum.0.lc1",
                "_fused_op_49"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertOutput::output",
                "original_op_name": "add_375",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 32329
        },
        "add_414": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_410 (port_0) ublock_order(c)",
                "Data: _fused_op_50 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_50": "Data",
                "matmul_410": "Data"
            },
            "input_nodes": [
                "matmul_410",
                "_fused_op_50"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_414",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_415.dc.reduce_sum.0.lc1 (port_0)",
                "Data: _fused_op_54 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_415.dc.reduce_sum.0.lc1",
                "_fused_op_54"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output",
                "original_op_name": "add_414",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 32401
        },
        "add_428": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_424 (port_0) ublock_order(c)",
                "Data: _fused_op_55 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_55": "Data",
                "matmul_424": "Data"
            },
            "input_nodes": [
                "matmul_424",
                "_fused_op_55"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_428",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_429.dc.reduce_sum.0.lc1 (port_0)",
                "Data: _fused_op_56 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_429.dc.reduce_sum.0.lc1",
                "_fused_op_56"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertOutput::output",
                "original_op_name": "add_428",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 32433
        },
        "add_43": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_39 (port_0) ublock_order(c)",
                "Data: _fused_op_1 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_1": "Data",
                "matmul_39": "Data"
            },
            "input_nodes": [
                "matmul_39",
                "_fused_op_1"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_43",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_44.dc.reduce_sum.0.lc1 (port_0)",
                "Data: _fused_op_5 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_44.dc.reduce_sum.0.lc1",
                "_fused_op_5"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output",
                "original_op_name": "add_43",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 31673
        },
        "add_467": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_463 (port_0) ublock_order(c)",
                "Data: _fused_op_57 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_57": "Data",
                "matmul_463": "Data"
            },
            "input_nodes": [
                "matmul_463",
                "_fused_op_57"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_467",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_468.dc.reduce_sum.0.lc1 (port_0)",
                "Data: _fused_op_61 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_468.dc.reduce_sum.0.lc1",
                "_fused_op_61"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output",
                "original_op_name": "add_467",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 32505
        },
        "add_481": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_477 (port_0) ublock_order(c)",
                "Data: _fused_op_62 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_62": "Data",
                "matmul_477": "Data"
            },
            "input_nodes": [
                "matmul_477",
                "_fused_op_62"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_481",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_482.dc.reduce_sum.0.lc1 (port_0)",
                "Data: _fused_op_63 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_482.dc.reduce_sum.0.lc1",
                "_fused_op_63"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertOutput::output",
                "original_op_name": "add_481",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 32537
        },
        "add_520": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_516 (port_0) ublock_order(c)",
                "Data: _fused_op_64 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_64": "Data",
                "matmul_516": "Data"
            },
            "input_nodes": [
                "matmul_516",
                "_fused_op_64"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_520",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_521.dc.reduce_sum.0.lc1 (port_0)",
                "Data: _fused_op_68 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_521.dc.reduce_sum.0.lc1",
                "_fused_op_68"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output",
                "original_op_name": "add_520",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 32609
        },
        "add_534": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_530 (port_0) ublock_order(c)",
                "Data: _fused_op_69 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_69": "Data",
                "matmul_530": "Data"
            },
            "input_nodes": [
                "matmul_530",
                "_fused_op_69"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_534",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_535.dc.reduce_sum.0.lc1 (port_0)",
                "Data: _fused_op_70 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_535.dc.reduce_sum.0.lc1",
                "_fused_op_70"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertOutput::output",
                "original_op_name": "add_534",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 32641
        },
        "add_57": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_53 (port_0) ublock_order(c)",
                "Data: _fused_op_6 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_6": "Data",
                "matmul_53": "Data"
            },
            "input_nodes": [
                "matmul_53",
                "_fused_op_6"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_57",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_58.dc.reduce_sum.0.lc1 (port_0)",
                "Data: _fused_op_7 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_58.dc.reduce_sum.0.lc1",
                "_fused_op_7"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertOutput::output",
                "original_op_name": "add_57",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 31705
        },
        "add_573": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_569 (port_0) ublock_order(c)",
                "Data: _fused_op_71 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_71": "Data",
                "matmul_569": "Data"
            },
            "input_nodes": [
                "matmul_569",
                "_fused_op_71"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_573",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_574.dc.reduce_sum.0.lc1 (port_0)",
                "Data: _fused_op_75 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_574.dc.reduce_sum.0.lc1",
                "_fused_op_75"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output",
                "original_op_name": "add_573",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 32713
        },
        "add_587": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_583 (port_0) ublock_order(c)",
                "Data: _fused_op_76 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_76": "Data",
                "matmul_583": "Data"
            },
            "input_nodes": [
                "matmul_583",
                "_fused_op_76"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_587",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_588.dc.reduce_sum.0.lc1 (port_0)",
                "Data: _fused_op_77 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_588.dc.reduce_sum.0.lc1",
                "_fused_op_77"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertOutput::output",
                "original_op_name": "add_587",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 32745
        },
        "add_626": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_622 (port_0) ublock_order(c)",
                "Data: _fused_op_78 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_78": "Data",
                "matmul_622": "Data"
            },
            "input_nodes": [
                "matmul_622",
                "_fused_op_78"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_626",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_627.dc.reduce_sum.0.lc1 (port_0)",
                "Data: _fused_op_82 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_627.dc.reduce_sum.0.lc1",
                "_fused_op_82"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output",
                "original_op_name": "add_626",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 32817
        },
        "add_640": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_636 (port_0) ublock_order(c)",
                "Data: _fused_op_83 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_83": "Data",
                "matmul_636": "Data"
            },
            "input_nodes": [
                "matmul_636",
                "_fused_op_83"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_640",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_641.dc.reduce_sum.0.lc1 (port_0)",
                "Data: _fused_op_84 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_641.dc.reduce_sum.0.lc1",
                "_fused_op_84"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertOutput::output",
                "original_op_name": "add_640",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 32849
        },
        "add_679": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_675 (port_0) ublock_order(c)",
                "Data: _fused_op_85 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_85": "Data",
                "matmul_675": "Data"
            },
            "input_nodes": [
                "matmul_675",
                "_fused_op_85"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_679",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_680.dc.reduce_sum.0.lc1 (port_0)",
                "Data: _fused_op_89 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_680.dc.reduce_sum.0.lc1",
                "_fused_op_89"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output",
                "original_op_name": "add_679",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 32921
        },
        "add_693": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_689 (port_0) ublock_order(c)",
                "Data: _fused_op_90 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_90": "Data",
                "matmul_689": "Data"
            },
            "input_nodes": [
                "matmul_689",
                "_fused_op_90"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_693",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_694.dc.reduce_sum.0.lc1 (port_0)",
                "Data: _fused_op_91 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_694.dc.reduce_sum.0.lc1",
                "_fused_op_91"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertOutput::output",
                "original_op_name": "add_693",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 32953
        },
        "add_732": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_728 (port_0) ublock_order(c)",
                "Data: _fused_op_92 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_92": "Data",
                "matmul_728": "Data"
            },
            "input_nodes": [
                "matmul_728",
                "_fused_op_92"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_732",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_733.dc.reduce_sum.0.lc1 (port_0)",
                "Data: _fused_op_96 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_733.dc.reduce_sum.0.lc1",
                "_fused_op_96"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output",
                "original_op_name": "add_732",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 33025
        },
        "add_746": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_742 (port_0) ublock_order(c)",
                "Data: _fused_op_97 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_97": "Data",
                "matmul_742": "Data"
            },
            "input_nodes": [
                "matmul_742",
                "_fused_op_97"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_746",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_747.dc.reduce_sum.0.lc1 (port_0)",
                "Data: _fused_op_98 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_747.dc.reduce_sum.0.lc1",
                "_fused_op_98"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertOutput::output",
                "original_op_name": "add_746",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 33057
        },
        "add_785": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_781 (port_0) ublock_order(c)",
                "Data: _fused_op_99 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_99": "Data",
                "matmul_781": "Data"
            },
            "input_nodes": [
                "matmul_781",
                "_fused_op_99"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_785",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_786.dc.reduce_sum.0.lc1 (port_0)",
                "Data: _fused_op_103 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_786.dc.reduce_sum.0.lc1",
                "_fused_op_103"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output",
                "original_op_name": "add_785",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 33129
        },
        "add_799": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_795 (port_0) ublock_order(c)",
                "Data: _fused_op_104 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_104": "Data",
                "matmul_795": "Data"
            },
            "input_nodes": [
                "matmul_795",
                "_fused_op_104"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_799",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_800.dc.reduce_sum.0.lc1 (port_0)",
                "Data: _fused_op_105 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_800.dc.reduce_sum.0.lc1",
                "_fused_op_105"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertOutput::output",
                "original_op_name": "add_799",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 33161
        },
        "add_838": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_834 (port_0) ublock_order(c)",
                "Data: _fused_op_106 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_106": "Data",
                "matmul_834": "Data"
            },
            "input_nodes": [
                "matmul_834",
                "_fused_op_106"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_838",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_839.dc.reduce_sum.0.lc1 (port_0)",
                "Data: _fused_op_110 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_839.dc.reduce_sum.0.lc1",
                "_fused_op_110"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output",
                "original_op_name": "add_838",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 33233
        },
        "add_852": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_848 (port_0) ublock_order(c)",
                "Data: _fused_op_111 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_111": "Data",
                "matmul_848": "Data"
            },
            "input_nodes": [
                "matmul_848",
                "_fused_op_111"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_852",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_853.dc.reduce_sum.0.lc1 (port_0)",
                "Data: _fused_op_112 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_853.dc.reduce_sum.0.lc1",
                "_fused_op_112"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertOutput::output",
                "original_op_name": "add_852",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 33265
        },
        "add_891": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_887 (port_0) ublock_order(c)",
                "Data: _fused_op_113 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_113": "Data",
                "matmul_887": "Data"
            },
            "input_nodes": [
                "matmul_887",
                "_fused_op_113"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_891",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_892.dc.reduce_sum.0.lc1 (port_0)",
                "Data: _fused_op_117 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_892.dc.reduce_sum.0.lc1",
                "_fused_op_117"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output",
                "original_op_name": "add_891",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 33337
        },
        "add_905": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_901 (port_0) ublock_order(c)",
                "Data: _fused_op_118 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_118": "Data",
                "matmul_901": "Data"
            },
            "input_nodes": [
                "matmul_901",
                "_fused_op_118"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_905",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_906.dc.reduce_sum.0.lc1 (port_0)",
                "Data: _fused_op_119 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_906.dc.reduce_sum.0.lc1",
                "_fused_op_119"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertOutput::output",
                "original_op_name": "add_905",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 33369
        },
        "add_944": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_940 (port_0) ublock_order(c)",
                "Data: _fused_op_120 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_120": "Data",
                "matmul_940": "Data"
            },
            "input_nodes": [
                "matmul_940",
                "_fused_op_120"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_944",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_945.dc.reduce_sum.0.lc1 (port_0)",
                "Data: _fused_op_124 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_945.dc.reduce_sum.0.lc1",
                "_fused_op_124"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output",
                "original_op_name": "add_944",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 33441
        },
        "add_958": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_954 (port_0) ublock_order(c)",
                "Data: _fused_op_125 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_125": "Data",
                "matmul_954": "Data"
            },
            "input_nodes": [
                "matmul_954",
                "_fused_op_125"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_958",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_959.dc.reduce_sum.0.lc1 (port_0)",
                "Data: _fused_op_126 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_959.dc.reduce_sum.0.lc1",
                "_fused_op_126"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertOutput::output",
                "original_op_name": "add_958",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 33473
        },
        "add_96": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_92 (port_0) ublock_order(c)",
                "Data: _fused_op_8 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_8": "Data",
                "matmul_92": "Data"
            },
            "input_nodes": [
                "matmul_92",
                "_fused_op_8"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_96",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_97.dc.reduce_sum.0.lc1 (port_0)",
                "Data: _fused_op_12 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_97.dc.reduce_sum.0.lc1",
                "_fused_op_12"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output",
                "original_op_name": "add_96",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 31777
        },
        "add_997": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_993 (port_0) ublock_order(c)",
                "Data: _fused_op_127 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_127": "Data",
                "matmul_993": "Data"
            },
            "input_nodes": [
                "matmul_993",
                "_fused_op_127"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_997",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_998.dc.reduce_sum.0.lc1 (port_0)",
                "Data: _fused_op_131 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_998.dc.reduce_sum.0.lc1",
                "_fused_op_131"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output",
                "original_op_name": "add_997",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 33545
        },
        "attention_mask_1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    384
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "attention_mask_1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: subtract_21 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "subtract_21"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_name": "attention_mask_1"
            },
            "tile_broadcast": [],
            "type": "Input::input",
            "unique_id": 31634
        },
        "bert.embeddings.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.embeddings.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.embeddings.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 31613
        },
        "bert.embeddings.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.embeddings.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.embeddings.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 31611
        },
        "bert.encoder.layer.0.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.0.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_6 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_6"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.0.attention.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 31694
        },
        "bert.encoder.layer.0.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.0.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_6 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_6"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.0.attention.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 31692
        },
        "bert.encoder.layer.0.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.0.attention.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_39 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_39"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.0.attention.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 31670
        },
        "bert.encoder.layer.0.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.0.attention.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_39 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_39"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.0.attention.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 31669
        },
        "bert.encoder.layer.0.attention.self.key.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.0.attention.self.key.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_10 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_10"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.0.attention.self.key.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 31624
        },
        "bert.encoder.layer.0.attention.self.key.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.0.attention.self.key.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_10 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_10"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.0.attention.self.key.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 31623
        },
        "bert.encoder.layer.0.attention.self.query.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.0.attention.self.query.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_4 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_4"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.0.attention.self.query.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 31618
        },
        "bert.encoder.layer.0.attention.self.query.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.0.attention.self.query.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_4 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_4"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.0.attention.self.query.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 31617
        },
        "bert.encoder.layer.0.attention.self.value.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.0.attention.self.value.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_28 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_28"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.0.attention.self.value.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 31661
        },
        "bert.encoder.layer.0.attention.self.value.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.0.attention.self.value.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_28 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_28"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.0.attention.self.value.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 31660
        },
        "bert.encoder.layer.0.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.0.intermediate.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_47 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_47"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.0.intermediate.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 31698
        },
        "bert.encoder.layer.0.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.0.intermediate.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_47 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_47"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.0.intermediate.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 31697
        },
        "bert.encoder.layer.0.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.0.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_8 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_8"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.0.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 31726
        },
        "bert.encoder.layer.0.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.0.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_8 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_8"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.0.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 31724
        },
        "bert.encoder.layer.0.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.0.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_53 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_53"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.0.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 31702
        },
        "bert.encoder.layer.0.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    4096,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.0.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_53 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_53"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.0.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 31701
        },
        "bert.encoder.layer.1.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.1.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_13 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_13"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.1.attention.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 31798
        },
        "bert.encoder.layer.1.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.1.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_13 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_13"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.1.attention.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 31796
        },
        "bert.encoder.layer.1.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.1.attention.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_92 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_92"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.1.attention.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 31774
        },
        "bert.encoder.layer.1.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.1.attention.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_92 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_92"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.1.attention.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 31773
        },
        "bert.encoder.layer.1.attention.self.key.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.1.attention.self.key.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_67 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_67"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.1.attention.self.key.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 31736
        },
        "bert.encoder.layer.1.attention.self.key.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.1.attention.self.key.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_67 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_67"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.1.attention.self.key.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 31735
        },
        "bert.encoder.layer.1.attention.self.query.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.1.attention.self.query.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_61 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_61"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.1.attention.self.query.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 31730
        },
        "bert.encoder.layer.1.attention.self.query.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.1.attention.self.query.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_61 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_61"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.1.attention.self.query.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 31729
        },
        "bert.encoder.layer.1.attention.self.value.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.1.attention.self.value.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_81 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_81"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.1.attention.self.value.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 31765
        },
        "bert.encoder.layer.1.attention.self.value.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.1.attention.self.value.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_81 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_81"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.1.attention.self.value.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 31764
        },
        "bert.encoder.layer.1.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.1.intermediate.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_100 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_100"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.1.intermediate.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 31802
        },
        "bert.encoder.layer.1.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.1.intermediate.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_100 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_100"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.1.intermediate.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 31801
        },
        "bert.encoder.layer.1.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.1.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_15 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_15"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.1.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 31830
        },
        "bert.encoder.layer.1.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.1.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_15 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_15"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.1.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 31828
        },
        "bert.encoder.layer.1.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.1.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_106 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_106"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.1.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 31806
        },
        "bert.encoder.layer.1.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    4096,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.1.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_106 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_106"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.1.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 31805
        },
        "bert.encoder.layer.10.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.10.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_76 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_76"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.10.attention.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32734
        },
        "bert.encoder.layer.10.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.10.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_76 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_76"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.10.attention.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32732
        },
        "bert.encoder.layer.10.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.10.attention.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_569 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_569"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.10.attention.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32710
        },
        "bert.encoder.layer.10.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.10.attention.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_569 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_569"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.10.attention.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32709
        },
        "bert.encoder.layer.10.attention.self.key.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.10.attention.self.key.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_544 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_544"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.10.attention.self.key.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32672
        },
        "bert.encoder.layer.10.attention.self.key.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.10.attention.self.key.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_544 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_544"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.10.attention.self.key.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32671
        },
        "bert.encoder.layer.10.attention.self.query.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.10.attention.self.query.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_538 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_538"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.10.attention.self.query.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32666
        },
        "bert.encoder.layer.10.attention.self.query.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.10.attention.self.query.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_538 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_538"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.10.attention.self.query.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32665
        },
        "bert.encoder.layer.10.attention.self.value.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.10.attention.self.value.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_558 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_558"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.10.attention.self.value.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32701
        },
        "bert.encoder.layer.10.attention.self.value.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.10.attention.self.value.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_558 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_558"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.10.attention.self.value.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32700
        },
        "bert.encoder.layer.10.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.10.intermediate.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_577 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_577"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.10.intermediate.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32738
        },
        "bert.encoder.layer.10.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.10.intermediate.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_577 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_577"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.10.intermediate.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32737
        },
        "bert.encoder.layer.10.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.10.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_78 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_78"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.10.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32766
        },
        "bert.encoder.layer.10.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.10.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_78 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_78"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.10.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32764
        },
        "bert.encoder.layer.10.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.10.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_583 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_583"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.10.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32742
        },
        "bert.encoder.layer.10.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    4096,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.10.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_583 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_583"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.10.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32741
        },
        "bert.encoder.layer.11.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.11.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_83 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_83"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.11.attention.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32838
        },
        "bert.encoder.layer.11.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.11.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_83 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_83"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.11.attention.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32836
        },
        "bert.encoder.layer.11.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.11.attention.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_622 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_622"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.11.attention.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32814
        },
        "bert.encoder.layer.11.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.11.attention.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_622 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_622"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.11.attention.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32813
        },
        "bert.encoder.layer.11.attention.self.key.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.11.attention.self.key.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_597 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_597"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.11.attention.self.key.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32776
        },
        "bert.encoder.layer.11.attention.self.key.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.11.attention.self.key.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_597 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_597"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.11.attention.self.key.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32775
        },
        "bert.encoder.layer.11.attention.self.query.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.11.attention.self.query.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_591 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_591"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.11.attention.self.query.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32770
        },
        "bert.encoder.layer.11.attention.self.query.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.11.attention.self.query.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_591 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_591"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.11.attention.self.query.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32769
        },
        "bert.encoder.layer.11.attention.self.value.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.11.attention.self.value.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_611 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_611"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.11.attention.self.value.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32805
        },
        "bert.encoder.layer.11.attention.self.value.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.11.attention.self.value.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_611 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_611"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.11.attention.self.value.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32804
        },
        "bert.encoder.layer.11.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.11.intermediate.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_630 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_630"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.11.intermediate.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32842
        },
        "bert.encoder.layer.11.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.11.intermediate.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_630 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_630"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.11.intermediate.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32841
        },
        "bert.encoder.layer.11.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.11.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_85 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_85"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.11.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32870
        },
        "bert.encoder.layer.11.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.11.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_85 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_85"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.11.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32868
        },
        "bert.encoder.layer.11.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.11.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_636 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_636"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.11.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32846
        },
        "bert.encoder.layer.11.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    4096,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.11.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_636 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_636"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.11.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32845
        },
        "bert.encoder.layer.12.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.12.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_90 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_90"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.12.attention.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32942
        },
        "bert.encoder.layer.12.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.12.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_90 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_90"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.12.attention.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32940
        },
        "bert.encoder.layer.12.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.12.attention.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_675 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_675"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.12.attention.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32918
        },
        "bert.encoder.layer.12.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.12.attention.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_675 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_675"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.12.attention.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32917
        },
        "bert.encoder.layer.12.attention.self.key.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.12.attention.self.key.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_650 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_650"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.12.attention.self.key.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32880
        },
        "bert.encoder.layer.12.attention.self.key.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.12.attention.self.key.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_650 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_650"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.12.attention.self.key.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32879
        },
        "bert.encoder.layer.12.attention.self.query.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.12.attention.self.query.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_644 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_644"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.12.attention.self.query.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32874
        },
        "bert.encoder.layer.12.attention.self.query.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.12.attention.self.query.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_644 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_644"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.12.attention.self.query.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32873
        },
        "bert.encoder.layer.12.attention.self.value.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.12.attention.self.value.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_664 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_664"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.12.attention.self.value.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32909
        },
        "bert.encoder.layer.12.attention.self.value.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.12.attention.self.value.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_664 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_664"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.12.attention.self.value.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32908
        },
        "bert.encoder.layer.12.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.12.intermediate.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_683 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_683"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.12.intermediate.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32946
        },
        "bert.encoder.layer.12.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.12.intermediate.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_683 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_683"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.12.intermediate.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32945
        },
        "bert.encoder.layer.12.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.12.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_92 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_92"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.12.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32974
        },
        "bert.encoder.layer.12.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.12.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_92 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_92"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.12.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32972
        },
        "bert.encoder.layer.12.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.12.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_689 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_689"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.12.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32950
        },
        "bert.encoder.layer.12.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    4096,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.12.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_689 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_689"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.12.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32949
        },
        "bert.encoder.layer.13.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.13.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_97 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_97"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.13.attention.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33046
        },
        "bert.encoder.layer.13.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.13.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_97 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_97"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.13.attention.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33044
        },
        "bert.encoder.layer.13.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.13.attention.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_728 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_728"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.13.attention.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33022
        },
        "bert.encoder.layer.13.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.13.attention.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_728 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_728"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.13.attention.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33021
        },
        "bert.encoder.layer.13.attention.self.key.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.13.attention.self.key.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_703 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_703"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.13.attention.self.key.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32984
        },
        "bert.encoder.layer.13.attention.self.key.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.13.attention.self.key.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_703 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_703"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.13.attention.self.key.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32983
        },
        "bert.encoder.layer.13.attention.self.query.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.13.attention.self.query.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_697 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_697"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.13.attention.self.query.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32978
        },
        "bert.encoder.layer.13.attention.self.query.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.13.attention.self.query.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_697 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_697"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.13.attention.self.query.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32977
        },
        "bert.encoder.layer.13.attention.self.value.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.13.attention.self.value.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_717 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_717"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.13.attention.self.value.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33013
        },
        "bert.encoder.layer.13.attention.self.value.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.13.attention.self.value.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_717 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_717"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.13.attention.self.value.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33012
        },
        "bert.encoder.layer.13.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.13.intermediate.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_736 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_736"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.13.intermediate.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33050
        },
        "bert.encoder.layer.13.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.13.intermediate.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_736 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_736"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.13.intermediate.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33049
        },
        "bert.encoder.layer.13.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.13.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_99 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_99"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.13.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33078
        },
        "bert.encoder.layer.13.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.13.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_99 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_99"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.13.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33076
        },
        "bert.encoder.layer.13.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.13.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_742 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_742"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.13.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33054
        },
        "bert.encoder.layer.13.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    4096,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.13.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_742 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_742"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.13.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33053
        },
        "bert.encoder.layer.14.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.14.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_104 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_104"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.14.attention.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33150
        },
        "bert.encoder.layer.14.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.14.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_104 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_104"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.14.attention.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33148
        },
        "bert.encoder.layer.14.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.14.attention.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_781 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_781"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.14.attention.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33126
        },
        "bert.encoder.layer.14.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.14.attention.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_781 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_781"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.14.attention.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33125
        },
        "bert.encoder.layer.14.attention.self.key.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.14.attention.self.key.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_756 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_756"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.14.attention.self.key.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33088
        },
        "bert.encoder.layer.14.attention.self.key.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.14.attention.self.key.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_756 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_756"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.14.attention.self.key.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33087
        },
        "bert.encoder.layer.14.attention.self.query.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.14.attention.self.query.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_750 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_750"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.14.attention.self.query.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33082
        },
        "bert.encoder.layer.14.attention.self.query.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.14.attention.self.query.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_750 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_750"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.14.attention.self.query.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33081
        },
        "bert.encoder.layer.14.attention.self.value.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.14.attention.self.value.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_770 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_770"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.14.attention.self.value.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33117
        },
        "bert.encoder.layer.14.attention.self.value.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.14.attention.self.value.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_770 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_770"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.14.attention.self.value.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33116
        },
        "bert.encoder.layer.14.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.14.intermediate.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_789 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_789"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.14.intermediate.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33154
        },
        "bert.encoder.layer.14.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.14.intermediate.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_789 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_789"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.14.intermediate.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33153
        },
        "bert.encoder.layer.14.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.14.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_106 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_106"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.14.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33182
        },
        "bert.encoder.layer.14.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.14.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_106 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_106"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.14.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33180
        },
        "bert.encoder.layer.14.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.14.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_795 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_795"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.14.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33158
        },
        "bert.encoder.layer.14.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    4096,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.14.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_795 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_795"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.14.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33157
        },
        "bert.encoder.layer.15.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.15.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_111 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_111"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.15.attention.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33254
        },
        "bert.encoder.layer.15.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.15.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_111 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_111"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.15.attention.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33252
        },
        "bert.encoder.layer.15.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.15.attention.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_834 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_834"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.15.attention.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33230
        },
        "bert.encoder.layer.15.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.15.attention.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_834 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_834"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.15.attention.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33229
        },
        "bert.encoder.layer.15.attention.self.key.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.15.attention.self.key.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_809 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_809"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.15.attention.self.key.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33192
        },
        "bert.encoder.layer.15.attention.self.key.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.15.attention.self.key.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_809 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_809"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.15.attention.self.key.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33191
        },
        "bert.encoder.layer.15.attention.self.query.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.15.attention.self.query.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_803 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_803"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.15.attention.self.query.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33186
        },
        "bert.encoder.layer.15.attention.self.query.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.15.attention.self.query.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_803 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_803"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.15.attention.self.query.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33185
        },
        "bert.encoder.layer.15.attention.self.value.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.15.attention.self.value.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_823 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_823"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.15.attention.self.value.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33221
        },
        "bert.encoder.layer.15.attention.self.value.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.15.attention.self.value.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_823 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_823"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.15.attention.self.value.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33220
        },
        "bert.encoder.layer.15.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.15.intermediate.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_842 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_842"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.15.intermediate.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33258
        },
        "bert.encoder.layer.15.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.15.intermediate.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_842 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_842"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.15.intermediate.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33257
        },
        "bert.encoder.layer.15.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.15.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_113 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_113"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.15.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33286
        },
        "bert.encoder.layer.15.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.15.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_113 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_113"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.15.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33284
        },
        "bert.encoder.layer.15.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.15.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_848 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_848"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.15.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33262
        },
        "bert.encoder.layer.15.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    4096,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.15.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_848 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_848"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.15.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33261
        },
        "bert.encoder.layer.16.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.16.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_118 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_118"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.16.attention.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33358
        },
        "bert.encoder.layer.16.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.16.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_118 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_118"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.16.attention.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33356
        },
        "bert.encoder.layer.16.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.16.attention.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_887 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_887"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.16.attention.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33334
        },
        "bert.encoder.layer.16.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.16.attention.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_887 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_887"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.16.attention.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33333
        },
        "bert.encoder.layer.16.attention.self.key.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.16.attention.self.key.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_862 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_862"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.16.attention.self.key.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33296
        },
        "bert.encoder.layer.16.attention.self.key.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.16.attention.self.key.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_862 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_862"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.16.attention.self.key.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33295
        },
        "bert.encoder.layer.16.attention.self.query.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.16.attention.self.query.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_856 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_856"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.16.attention.self.query.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33290
        },
        "bert.encoder.layer.16.attention.self.query.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.16.attention.self.query.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_856 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_856"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.16.attention.self.query.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33289
        },
        "bert.encoder.layer.16.attention.self.value.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.16.attention.self.value.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_876 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_876"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.16.attention.self.value.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33325
        },
        "bert.encoder.layer.16.attention.self.value.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.16.attention.self.value.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_876 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_876"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.16.attention.self.value.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33324
        },
        "bert.encoder.layer.16.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.16.intermediate.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_895 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_895"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.16.intermediate.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33362
        },
        "bert.encoder.layer.16.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.16.intermediate.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_895 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_895"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.16.intermediate.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33361
        },
        "bert.encoder.layer.16.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.16.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_120 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_120"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.16.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33390
        },
        "bert.encoder.layer.16.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.16.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_120 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_120"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.16.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33388
        },
        "bert.encoder.layer.16.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.16.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_901 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_901"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.16.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33366
        },
        "bert.encoder.layer.16.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    4096,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.16.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_901 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_901"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.16.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33365
        },
        "bert.encoder.layer.17.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.17.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_125 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_125"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.17.attention.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33462
        },
        "bert.encoder.layer.17.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.17.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_125 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_125"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.17.attention.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33460
        },
        "bert.encoder.layer.17.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.17.attention.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_940 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_940"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.17.attention.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33438
        },
        "bert.encoder.layer.17.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.17.attention.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_940 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_940"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.17.attention.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33437
        },
        "bert.encoder.layer.17.attention.self.key.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.17.attention.self.key.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_915 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_915"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.17.attention.self.key.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33400
        },
        "bert.encoder.layer.17.attention.self.key.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.17.attention.self.key.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_915 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_915"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.17.attention.self.key.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33399
        },
        "bert.encoder.layer.17.attention.self.query.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.17.attention.self.query.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_909 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_909"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.17.attention.self.query.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33394
        },
        "bert.encoder.layer.17.attention.self.query.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.17.attention.self.query.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_909 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_909"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.17.attention.self.query.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33393
        },
        "bert.encoder.layer.17.attention.self.value.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.17.attention.self.value.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_929 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_929"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.17.attention.self.value.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33429
        },
        "bert.encoder.layer.17.attention.self.value.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.17.attention.self.value.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_929 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_929"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.17.attention.self.value.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33428
        },
        "bert.encoder.layer.17.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.17.intermediate.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_948 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_948"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.17.intermediate.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33466
        },
        "bert.encoder.layer.17.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.17.intermediate.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_948 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_948"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.17.intermediate.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33465
        },
        "bert.encoder.layer.17.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.17.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_127 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_127"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.17.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33494
        },
        "bert.encoder.layer.17.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.17.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_127 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_127"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.17.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33492
        },
        "bert.encoder.layer.17.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.17.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_954 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_954"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.17.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33470
        },
        "bert.encoder.layer.17.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    4096,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.17.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_954 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_954"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.17.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33469
        },
        "bert.encoder.layer.18.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.18.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_132 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_132"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.18.attention.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33566
        },
        "bert.encoder.layer.18.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.18.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_132 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_132"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.18.attention.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33564
        },
        "bert.encoder.layer.18.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.18.attention.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_993 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_993"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.18.attention.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33542
        },
        "bert.encoder.layer.18.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.18.attention.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_993 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_993"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.18.attention.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33541
        },
        "bert.encoder.layer.18.attention.self.key.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.18.attention.self.key.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_968 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_968"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.18.attention.self.key.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33504
        },
        "bert.encoder.layer.18.attention.self.key.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.18.attention.self.key.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_968 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_968"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.18.attention.self.key.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33503
        },
        "bert.encoder.layer.18.attention.self.query.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.18.attention.self.query.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_962 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_962"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.18.attention.self.query.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33498
        },
        "bert.encoder.layer.18.attention.self.query.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.18.attention.self.query.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_962 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_962"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.18.attention.self.query.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33497
        },
        "bert.encoder.layer.18.attention.self.value.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.18.attention.self.value.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_982 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_982"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.18.attention.self.value.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33533
        },
        "bert.encoder.layer.18.attention.self.value.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.18.attention.self.value.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_982 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_982"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.18.attention.self.value.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33532
        },
        "bert.encoder.layer.18.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.18.intermediate.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1001 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1001"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.18.intermediate.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33570
        },
        "bert.encoder.layer.18.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.18.intermediate.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1001 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1001"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.18.intermediate.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33569
        },
        "bert.encoder.layer.18.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.18.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_134 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_134"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.18.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33598
        },
        "bert.encoder.layer.18.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.18.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_134 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_134"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.18.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33596
        },
        "bert.encoder.layer.18.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.18.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1007 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1007"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.18.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33574
        },
        "bert.encoder.layer.18.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    4096,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.18.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1007 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1007"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.18.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33573
        },
        "bert.encoder.layer.19.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.19.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_139 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_139"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.19.attention.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33670
        },
        "bert.encoder.layer.19.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.19.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_139 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_139"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.19.attention.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33668
        },
        "bert.encoder.layer.19.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.19.attention.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1046 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1046"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.19.attention.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33646
        },
        "bert.encoder.layer.19.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.19.attention.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1046 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1046"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.19.attention.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33645
        },
        "bert.encoder.layer.19.attention.self.key.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.19.attention.self.key.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1021 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1021"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.19.attention.self.key.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33608
        },
        "bert.encoder.layer.19.attention.self.key.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.19.attention.self.key.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1021 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1021"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.19.attention.self.key.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33607
        },
        "bert.encoder.layer.19.attention.self.query.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.19.attention.self.query.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1015 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1015"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.19.attention.self.query.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33602
        },
        "bert.encoder.layer.19.attention.self.query.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.19.attention.self.query.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1015 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1015"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.19.attention.self.query.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33601
        },
        "bert.encoder.layer.19.attention.self.value.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.19.attention.self.value.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1035 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1035"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.19.attention.self.value.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33637
        },
        "bert.encoder.layer.19.attention.self.value.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.19.attention.self.value.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1035 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1035"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.19.attention.self.value.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33636
        },
        "bert.encoder.layer.19.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.19.intermediate.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1054 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1054"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.19.intermediate.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33674
        },
        "bert.encoder.layer.19.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.19.intermediate.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1054 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1054"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.19.intermediate.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33673
        },
        "bert.encoder.layer.19.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.19.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_141 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_141"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.19.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33702
        },
        "bert.encoder.layer.19.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.19.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_141 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_141"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.19.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33700
        },
        "bert.encoder.layer.19.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.19.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1060 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1060"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.19.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33678
        },
        "bert.encoder.layer.19.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    4096,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.19.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1060 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1060"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.19.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33677
        },
        "bert.encoder.layer.2.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.2.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_20 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_20"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.2.attention.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 31902
        },
        "bert.encoder.layer.2.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.2.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_20 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_20"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.2.attention.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 31900
        },
        "bert.encoder.layer.2.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.2.attention.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_145 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_145"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.2.attention.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 31878
        },
        "bert.encoder.layer.2.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.2.attention.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_145 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_145"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.2.attention.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 31877
        },
        "bert.encoder.layer.2.attention.self.key.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.2.attention.self.key.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_120 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_120"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.2.attention.self.key.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 31840
        },
        "bert.encoder.layer.2.attention.self.key.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.2.attention.self.key.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_120 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_120"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.2.attention.self.key.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 31839
        },
        "bert.encoder.layer.2.attention.self.query.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.2.attention.self.query.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_114 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_114"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.2.attention.self.query.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 31834
        },
        "bert.encoder.layer.2.attention.self.query.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.2.attention.self.query.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_114 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_114"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.2.attention.self.query.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 31833
        },
        "bert.encoder.layer.2.attention.self.value.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.2.attention.self.value.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_134 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_134"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.2.attention.self.value.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 31869
        },
        "bert.encoder.layer.2.attention.self.value.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.2.attention.self.value.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_134 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_134"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.2.attention.self.value.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 31868
        },
        "bert.encoder.layer.2.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.2.intermediate.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_153 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_153"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.2.intermediate.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 31906
        },
        "bert.encoder.layer.2.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.2.intermediate.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_153 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_153"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.2.intermediate.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 31905
        },
        "bert.encoder.layer.2.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.2.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_22 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_22"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.2.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 31934
        },
        "bert.encoder.layer.2.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.2.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_22 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_22"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.2.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 31932
        },
        "bert.encoder.layer.2.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.2.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_159 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_159"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.2.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 31910
        },
        "bert.encoder.layer.2.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    4096,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.2.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_159 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_159"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.2.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 31909
        },
        "bert.encoder.layer.20.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.20.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_146 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_146"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.20.attention.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33774
        },
        "bert.encoder.layer.20.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.20.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_146 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_146"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.20.attention.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33772
        },
        "bert.encoder.layer.20.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.20.attention.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1099 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1099"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.20.attention.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33750
        },
        "bert.encoder.layer.20.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.20.attention.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1099 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1099"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.20.attention.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33749
        },
        "bert.encoder.layer.20.attention.self.key.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.20.attention.self.key.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1074 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1074"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.20.attention.self.key.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33712
        },
        "bert.encoder.layer.20.attention.self.key.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.20.attention.self.key.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1074 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1074"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.20.attention.self.key.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33711
        },
        "bert.encoder.layer.20.attention.self.query.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.20.attention.self.query.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1068 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1068"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.20.attention.self.query.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33706
        },
        "bert.encoder.layer.20.attention.self.query.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.20.attention.self.query.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1068 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1068"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.20.attention.self.query.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33705
        },
        "bert.encoder.layer.20.attention.self.value.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.20.attention.self.value.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1088 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1088"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.20.attention.self.value.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33741
        },
        "bert.encoder.layer.20.attention.self.value.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.20.attention.self.value.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1088 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1088"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.20.attention.self.value.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33740
        },
        "bert.encoder.layer.20.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.20.intermediate.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1107 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1107"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.20.intermediate.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33778
        },
        "bert.encoder.layer.20.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.20.intermediate.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1107 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1107"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.20.intermediate.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33777
        },
        "bert.encoder.layer.20.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.20.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_148 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_148"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.20.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33806
        },
        "bert.encoder.layer.20.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.20.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_148 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_148"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.20.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33804
        },
        "bert.encoder.layer.20.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.20.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1113 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1113"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.20.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33782
        },
        "bert.encoder.layer.20.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    4096,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.20.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1113 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1113"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.20.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33781
        },
        "bert.encoder.layer.21.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.21.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_153 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_153"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.21.attention.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33878
        },
        "bert.encoder.layer.21.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.21.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_153 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_153"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.21.attention.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33876
        },
        "bert.encoder.layer.21.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.21.attention.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1152 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1152"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.21.attention.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33854
        },
        "bert.encoder.layer.21.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.21.attention.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1152 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1152"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.21.attention.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33853
        },
        "bert.encoder.layer.21.attention.self.key.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.21.attention.self.key.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1127 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1127"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.21.attention.self.key.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33816
        },
        "bert.encoder.layer.21.attention.self.key.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.21.attention.self.key.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1127 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1127"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.21.attention.self.key.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33815
        },
        "bert.encoder.layer.21.attention.self.query.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.21.attention.self.query.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1121 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1121"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.21.attention.self.query.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33810
        },
        "bert.encoder.layer.21.attention.self.query.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.21.attention.self.query.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1121 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1121"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.21.attention.self.query.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33809
        },
        "bert.encoder.layer.21.attention.self.value.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.21.attention.self.value.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1141 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1141"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.21.attention.self.value.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33845
        },
        "bert.encoder.layer.21.attention.self.value.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.21.attention.self.value.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1141 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1141"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.21.attention.self.value.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33844
        },
        "bert.encoder.layer.21.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.21.intermediate.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1160 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1160"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.21.intermediate.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33882
        },
        "bert.encoder.layer.21.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.21.intermediate.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1160 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1160"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.21.intermediate.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33881
        },
        "bert.encoder.layer.21.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.21.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_155 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_155"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.21.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33910
        },
        "bert.encoder.layer.21.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.21.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_155 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_155"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.21.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33908
        },
        "bert.encoder.layer.21.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.21.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1166 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1166"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.21.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33886
        },
        "bert.encoder.layer.21.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    4096,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.21.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1166 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1166"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.21.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33885
        },
        "bert.encoder.layer.22.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.22.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_160 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_160"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.22.attention.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33982
        },
        "bert.encoder.layer.22.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.22.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_160 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_160"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.22.attention.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33980
        },
        "bert.encoder.layer.22.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.22.attention.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1205 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1205"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.22.attention.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33958
        },
        "bert.encoder.layer.22.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.22.attention.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1205 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1205"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.22.attention.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33957
        },
        "bert.encoder.layer.22.attention.self.key.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.22.attention.self.key.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1180 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1180"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.22.attention.self.key.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33920
        },
        "bert.encoder.layer.22.attention.self.key.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.22.attention.self.key.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1180 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1180"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.22.attention.self.key.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33919
        },
        "bert.encoder.layer.22.attention.self.query.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.22.attention.self.query.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1174 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1174"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.22.attention.self.query.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33914
        },
        "bert.encoder.layer.22.attention.self.query.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.22.attention.self.query.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1174 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1174"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.22.attention.self.query.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33913
        },
        "bert.encoder.layer.22.attention.self.value.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.22.attention.self.value.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1194 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1194"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.22.attention.self.value.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33949
        },
        "bert.encoder.layer.22.attention.self.value.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.22.attention.self.value.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1194 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1194"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.22.attention.self.value.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33948
        },
        "bert.encoder.layer.22.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.22.intermediate.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1213 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1213"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.22.intermediate.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33986
        },
        "bert.encoder.layer.22.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.22.intermediate.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1213 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1213"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.22.intermediate.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33985
        },
        "bert.encoder.layer.22.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.22.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_162 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_162"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.22.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 34014
        },
        "bert.encoder.layer.22.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.22.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_162 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_162"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.22.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 34012
        },
        "bert.encoder.layer.22.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.22.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1219 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1219"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.22.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33990
        },
        "bert.encoder.layer.22.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    4096,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.22.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1219 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1219"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.22.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 33989
        },
        "bert.encoder.layer.23.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.23.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_167 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_167"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.23.attention.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 34086
        },
        "bert.encoder.layer.23.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.23.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_167 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_167"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.23.attention.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 34084
        },
        "bert.encoder.layer.23.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.23.attention.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1258 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1258"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.23.attention.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 34062
        },
        "bert.encoder.layer.23.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.23.attention.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1258 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1258"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.23.attention.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 34061
        },
        "bert.encoder.layer.23.attention.self.key.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.23.attention.self.key.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1233 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1233"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.23.attention.self.key.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 34024
        },
        "bert.encoder.layer.23.attention.self.key.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.23.attention.self.key.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1233 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1233"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.23.attention.self.key.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 34023
        },
        "bert.encoder.layer.23.attention.self.query.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.23.attention.self.query.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1227 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1227"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.23.attention.self.query.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 34018
        },
        "bert.encoder.layer.23.attention.self.query.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.23.attention.self.query.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1227 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1227"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.23.attention.self.query.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 34017
        },
        "bert.encoder.layer.23.attention.self.value.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.23.attention.self.value.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1247 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1247"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.23.attention.self.value.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 34053
        },
        "bert.encoder.layer.23.attention.self.value.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.23.attention.self.value.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1247 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1247"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.23.attention.self.value.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 34052
        },
        "bert.encoder.layer.23.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.23.intermediate.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1266 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1266"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.23.intermediate.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 34090
        },
        "bert.encoder.layer.23.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.23.intermediate.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1266 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1266"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.23.intermediate.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 34089
        },
        "bert.encoder.layer.23.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.23.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_169 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_169"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.23.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 34118
        },
        "bert.encoder.layer.23.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.23.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_169 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_169"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.23.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 34116
        },
        "bert.encoder.layer.23.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.23.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1272 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1272"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.23.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 34094
        },
        "bert.encoder.layer.23.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    4096,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.23.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1272 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1272"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.23.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 34093
        },
        "bert.encoder.layer.3.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.3.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_27 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_27"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.3.attention.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32006
        },
        "bert.encoder.layer.3.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.3.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_27 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_27"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.3.attention.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32004
        },
        "bert.encoder.layer.3.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.3.attention.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_198 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_198"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.3.attention.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 31982
        },
        "bert.encoder.layer.3.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.3.attention.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_198 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_198"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.3.attention.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 31981
        },
        "bert.encoder.layer.3.attention.self.key.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.3.attention.self.key.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_173 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_173"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.3.attention.self.key.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 31944
        },
        "bert.encoder.layer.3.attention.self.key.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.3.attention.self.key.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_173 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_173"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.3.attention.self.key.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 31943
        },
        "bert.encoder.layer.3.attention.self.query.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.3.attention.self.query.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_167 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_167"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.3.attention.self.query.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 31938
        },
        "bert.encoder.layer.3.attention.self.query.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.3.attention.self.query.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_167 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_167"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.3.attention.self.query.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 31937
        },
        "bert.encoder.layer.3.attention.self.value.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.3.attention.self.value.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_187 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_187"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.3.attention.self.value.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 31973
        },
        "bert.encoder.layer.3.attention.self.value.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.3.attention.self.value.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_187 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_187"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.3.attention.self.value.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 31972
        },
        "bert.encoder.layer.3.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.3.intermediate.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_206 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_206"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.3.intermediate.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32010
        },
        "bert.encoder.layer.3.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.3.intermediate.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_206 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_206"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.3.intermediate.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32009
        },
        "bert.encoder.layer.3.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.3.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_29 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_29"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.3.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32038
        },
        "bert.encoder.layer.3.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.3.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_29 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_29"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.3.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32036
        },
        "bert.encoder.layer.3.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.3.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_212 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_212"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.3.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32014
        },
        "bert.encoder.layer.3.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    4096,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.3.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_212 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_212"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.3.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32013
        },
        "bert.encoder.layer.4.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.4.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_34 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_34"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.4.attention.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32110
        },
        "bert.encoder.layer.4.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.4.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_34 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_34"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.4.attention.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32108
        },
        "bert.encoder.layer.4.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.4.attention.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_251 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_251"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.4.attention.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32086
        },
        "bert.encoder.layer.4.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.4.attention.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_251 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_251"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.4.attention.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32085
        },
        "bert.encoder.layer.4.attention.self.key.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.4.attention.self.key.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_226 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_226"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.4.attention.self.key.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32048
        },
        "bert.encoder.layer.4.attention.self.key.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.4.attention.self.key.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_226 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_226"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.4.attention.self.key.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32047
        },
        "bert.encoder.layer.4.attention.self.query.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.4.attention.self.query.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_220 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_220"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.4.attention.self.query.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32042
        },
        "bert.encoder.layer.4.attention.self.query.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.4.attention.self.query.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_220 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_220"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.4.attention.self.query.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32041
        },
        "bert.encoder.layer.4.attention.self.value.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.4.attention.self.value.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_240 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_240"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.4.attention.self.value.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32077
        },
        "bert.encoder.layer.4.attention.self.value.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.4.attention.self.value.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_240 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_240"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.4.attention.self.value.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32076
        },
        "bert.encoder.layer.4.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.4.intermediate.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_259 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_259"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.4.intermediate.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32114
        },
        "bert.encoder.layer.4.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.4.intermediate.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_259 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_259"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.4.intermediate.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32113
        },
        "bert.encoder.layer.4.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.4.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_36 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_36"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.4.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32142
        },
        "bert.encoder.layer.4.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.4.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_36 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_36"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.4.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32140
        },
        "bert.encoder.layer.4.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.4.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_265 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_265"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.4.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32118
        },
        "bert.encoder.layer.4.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    4096,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.4.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_265 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_265"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.4.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32117
        },
        "bert.encoder.layer.5.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.5.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_41 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_41"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.5.attention.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32214
        },
        "bert.encoder.layer.5.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.5.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_41 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_41"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.5.attention.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32212
        },
        "bert.encoder.layer.5.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.5.attention.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_304 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_304"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.5.attention.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32190
        },
        "bert.encoder.layer.5.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.5.attention.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_304 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_304"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.5.attention.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32189
        },
        "bert.encoder.layer.5.attention.self.key.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.5.attention.self.key.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_279 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_279"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.5.attention.self.key.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32152
        },
        "bert.encoder.layer.5.attention.self.key.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.5.attention.self.key.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_279 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_279"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.5.attention.self.key.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32151
        },
        "bert.encoder.layer.5.attention.self.query.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.5.attention.self.query.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_273 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_273"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.5.attention.self.query.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32146
        },
        "bert.encoder.layer.5.attention.self.query.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.5.attention.self.query.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_273 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_273"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.5.attention.self.query.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32145
        },
        "bert.encoder.layer.5.attention.self.value.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.5.attention.self.value.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_293 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_293"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.5.attention.self.value.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32181
        },
        "bert.encoder.layer.5.attention.self.value.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.5.attention.self.value.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_293 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_293"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.5.attention.self.value.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32180
        },
        "bert.encoder.layer.5.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.5.intermediate.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_312 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_312"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.5.intermediate.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32218
        },
        "bert.encoder.layer.5.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.5.intermediate.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_312 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_312"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.5.intermediate.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32217
        },
        "bert.encoder.layer.5.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.5.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_43 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_43"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.5.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32246
        },
        "bert.encoder.layer.5.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.5.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_43 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_43"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.5.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32244
        },
        "bert.encoder.layer.5.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.5.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_318 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_318"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.5.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32222
        },
        "bert.encoder.layer.5.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    4096,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.5.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_318 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_318"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.5.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32221
        },
        "bert.encoder.layer.6.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.6.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_48 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_48"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.6.attention.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32318
        },
        "bert.encoder.layer.6.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.6.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_48 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_48"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.6.attention.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32316
        },
        "bert.encoder.layer.6.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.6.attention.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_357 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_357"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.6.attention.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32294
        },
        "bert.encoder.layer.6.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.6.attention.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_357 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_357"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.6.attention.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32293
        },
        "bert.encoder.layer.6.attention.self.key.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.6.attention.self.key.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_332 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_332"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.6.attention.self.key.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32256
        },
        "bert.encoder.layer.6.attention.self.key.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.6.attention.self.key.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_332 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_332"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.6.attention.self.key.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32255
        },
        "bert.encoder.layer.6.attention.self.query.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.6.attention.self.query.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_326 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_326"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.6.attention.self.query.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32250
        },
        "bert.encoder.layer.6.attention.self.query.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.6.attention.self.query.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_326 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_326"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.6.attention.self.query.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32249
        },
        "bert.encoder.layer.6.attention.self.value.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.6.attention.self.value.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_346 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_346"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.6.attention.self.value.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32285
        },
        "bert.encoder.layer.6.attention.self.value.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.6.attention.self.value.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_346 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_346"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.6.attention.self.value.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32284
        },
        "bert.encoder.layer.6.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.6.intermediate.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_365 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_365"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.6.intermediate.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32322
        },
        "bert.encoder.layer.6.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.6.intermediate.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_365 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_365"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.6.intermediate.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32321
        },
        "bert.encoder.layer.6.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.6.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_50 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_50"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.6.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32350
        },
        "bert.encoder.layer.6.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.6.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_50 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_50"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.6.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32348
        },
        "bert.encoder.layer.6.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.6.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_371 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_371"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.6.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32326
        },
        "bert.encoder.layer.6.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    4096,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.6.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_371 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_371"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.6.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32325
        },
        "bert.encoder.layer.7.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.7.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_55 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_55"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.7.attention.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32422
        },
        "bert.encoder.layer.7.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.7.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_55 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_55"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.7.attention.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32420
        },
        "bert.encoder.layer.7.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.7.attention.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_410 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_410"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.7.attention.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32398
        },
        "bert.encoder.layer.7.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.7.attention.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_410 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_410"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.7.attention.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32397
        },
        "bert.encoder.layer.7.attention.self.key.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.7.attention.self.key.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_385 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_385"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.7.attention.self.key.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32360
        },
        "bert.encoder.layer.7.attention.self.key.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.7.attention.self.key.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_385 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_385"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.7.attention.self.key.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32359
        },
        "bert.encoder.layer.7.attention.self.query.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.7.attention.self.query.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_379 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_379"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.7.attention.self.query.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32354
        },
        "bert.encoder.layer.7.attention.self.query.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.7.attention.self.query.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_379 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_379"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.7.attention.self.query.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32353
        },
        "bert.encoder.layer.7.attention.self.value.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.7.attention.self.value.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_399 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_399"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.7.attention.self.value.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32389
        },
        "bert.encoder.layer.7.attention.self.value.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.7.attention.self.value.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_399 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_399"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.7.attention.self.value.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32388
        },
        "bert.encoder.layer.7.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.7.intermediate.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_418 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_418"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.7.intermediate.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32426
        },
        "bert.encoder.layer.7.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.7.intermediate.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_418 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_418"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.7.intermediate.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32425
        },
        "bert.encoder.layer.7.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.7.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_57 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_57"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.7.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32454
        },
        "bert.encoder.layer.7.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.7.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_57 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_57"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.7.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32452
        },
        "bert.encoder.layer.7.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.7.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_424 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_424"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.7.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32430
        },
        "bert.encoder.layer.7.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    4096,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.7.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_424 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_424"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.7.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32429
        },
        "bert.encoder.layer.8.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.8.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_62 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_62"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.8.attention.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32526
        },
        "bert.encoder.layer.8.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.8.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_62 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_62"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.8.attention.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32524
        },
        "bert.encoder.layer.8.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.8.attention.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_463 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_463"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.8.attention.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32502
        },
        "bert.encoder.layer.8.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.8.attention.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_463 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_463"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.8.attention.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32501
        },
        "bert.encoder.layer.8.attention.self.key.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.8.attention.self.key.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_438 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_438"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.8.attention.self.key.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32464
        },
        "bert.encoder.layer.8.attention.self.key.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.8.attention.self.key.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_438 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_438"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.8.attention.self.key.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32463
        },
        "bert.encoder.layer.8.attention.self.query.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.8.attention.self.query.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_432 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_432"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.8.attention.self.query.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32458
        },
        "bert.encoder.layer.8.attention.self.query.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.8.attention.self.query.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_432 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_432"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.8.attention.self.query.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32457
        },
        "bert.encoder.layer.8.attention.self.value.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.8.attention.self.value.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_452 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_452"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.8.attention.self.value.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32493
        },
        "bert.encoder.layer.8.attention.self.value.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.8.attention.self.value.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_452 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_452"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.8.attention.self.value.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32492
        },
        "bert.encoder.layer.8.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.8.intermediate.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_471 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_471"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.8.intermediate.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32530
        },
        "bert.encoder.layer.8.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.8.intermediate.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_471 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_471"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.8.intermediate.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32529
        },
        "bert.encoder.layer.8.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.8.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_64 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_64"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.8.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32558
        },
        "bert.encoder.layer.8.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.8.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_64 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_64"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.8.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32556
        },
        "bert.encoder.layer.8.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.8.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_477 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_477"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.8.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32534
        },
        "bert.encoder.layer.8.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    4096,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.8.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_477 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_477"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.8.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32533
        },
        "bert.encoder.layer.9.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.9.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_69 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_69"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.9.attention.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32630
        },
        "bert.encoder.layer.9.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.9.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_69 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_69"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.9.attention.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32628
        },
        "bert.encoder.layer.9.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.9.attention.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_516 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_516"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.9.attention.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32606
        },
        "bert.encoder.layer.9.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.9.attention.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_516 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_516"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.9.attention.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32605
        },
        "bert.encoder.layer.9.attention.self.key.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.9.attention.self.key.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_491 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_491"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.9.attention.self.key.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32568
        },
        "bert.encoder.layer.9.attention.self.key.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.9.attention.self.key.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_491 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_491"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.9.attention.self.key.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32567
        },
        "bert.encoder.layer.9.attention.self.query.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.9.attention.self.query.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_485 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_485"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.9.attention.self.query.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32562
        },
        "bert.encoder.layer.9.attention.self.query.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.9.attention.self.query.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_485 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_485"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.9.attention.self.query.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32561
        },
        "bert.encoder.layer.9.attention.self.value.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.9.attention.self.value.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_505 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_505"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.9.attention.self.value.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32597
        },
        "bert.encoder.layer.9.attention.self.value.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.9.attention.self.value.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_505 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_505"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.9.attention.self.value.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32596
        },
        "bert.encoder.layer.9.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.9.intermediate.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_524 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_524"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.9.intermediate.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32634
        },
        "bert.encoder.layer.9.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    4096
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.9.intermediate.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_524 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_524"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.9.intermediate.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32633
        },
        "bert.encoder.layer.9.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.9.output.LayerNorm.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_71 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_71"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.9.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32662
        },
        "bert.encoder.layer.9.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.9.output.LayerNorm.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_71 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_71"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.9.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32660
        },
        "bert.encoder.layer.9.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.9.output.dense.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_530 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_530"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.9.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32638
        },
        "bert.encoder.layer.9.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    4096,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.9.output.dense.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_530 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_530"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.9.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 32637
        },
        "bert_large_tt_1.output_reshape_1285": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "Output",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [
                "Data: matmul_1281_output_nop_0 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "matmul_1281_output_nop_0": "Data"
            },
            "input_nodes": [
                "matmul_1281_output_nop_0"
            ],
            "input_tms": [
                []
            ],
            "is_cross_epoch_type": false,
            "is_saved_intermediate": false,
            "memory_access": "FIFO",
            "name": "bert_large_tt_1.output_reshape_1285",
            "opcode": "Output",
            "outgoing_edge_port_info": [],
            "output_df": "Float16_b",
            "output_nodes": [],
            "pybuda": 1,
            "queue_type": "output",
            "tags": {},
            "type": "Output",
            "unique_id": 34123
        },
        "bert_large_tt_1.output_reshape_1292": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "Output",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [
                "Data: matmul_1288_output_nop_0 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "matmul_1288_output_nop_0": "Data"
            },
            "input_nodes": [
                "matmul_1288_output_nop_0"
            ],
            "input_tms": [
                []
            ],
            "is_cross_epoch_type": false,
            "is_saved_intermediate": false,
            "memory_access": "FIFO",
            "name": "bert_large_tt_1.output_reshape_1292",
            "opcode": "Output",
            "outgoing_edge_port_info": [],
            "output_df": "Float16_b",
            "output_nodes": [],
            "pybuda": 1,
            "queue_type": "output",
            "tags": {},
            "type": "Output",
            "unique_id": 34127
        },
        "dc.input_tensor.layernorm_0.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_0.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_0 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_0"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 31596
        },
        "dc.input_tensor.layernorm_0.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_0.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 31602
        },
        "dc.input_tensor.layernorm_0.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_0.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 31604
        },
        "dc.input_tensor.layernorm_1012.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1012.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_133 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_133"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33581
        },
        "dc.input_tensor.layernorm_1012.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1012.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_134 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_134"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33587
        },
        "dc.input_tensor.layernorm_1012.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1012.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_134 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_134"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33589
        },
        "dc.input_tensor.layernorm_1051.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1051.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_138 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_138"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33653
        },
        "dc.input_tensor.layernorm_1051.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1051.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_139 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_139"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33659
        },
        "dc.input_tensor.layernorm_1051.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1051.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_139 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_139"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33661
        },
        "dc.input_tensor.layernorm_1065.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1065.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_140 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_140"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33685
        },
        "dc.input_tensor.layernorm_1065.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1065.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_141 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_141"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33691
        },
        "dc.input_tensor.layernorm_1065.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1065.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_141 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_141"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33693
        },
        "dc.input_tensor.layernorm_1104.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1104.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_145 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_145"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33757
        },
        "dc.input_tensor.layernorm_1104.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1104.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_146 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_146"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33763
        },
        "dc.input_tensor.layernorm_1104.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1104.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_146 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_146"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33765
        },
        "dc.input_tensor.layernorm_111.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_111.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_14 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_14"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 31813
        },
        "dc.input_tensor.layernorm_111.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_111.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_15 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_15"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 31819
        },
        "dc.input_tensor.layernorm_111.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_111.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_15 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_15"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 31821
        },
        "dc.input_tensor.layernorm_1118.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1118.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_147 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_147"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33789
        },
        "dc.input_tensor.layernorm_1118.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1118.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_148 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_148"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33795
        },
        "dc.input_tensor.layernorm_1118.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1118.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_148 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_148"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33797
        },
        "dc.input_tensor.layernorm_1157.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1157.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_152 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_152"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33861
        },
        "dc.input_tensor.layernorm_1157.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1157.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_153 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_153"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33867
        },
        "dc.input_tensor.layernorm_1157.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1157.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_153 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_153"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33869
        },
        "dc.input_tensor.layernorm_1171.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1171.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_154 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_154"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33893
        },
        "dc.input_tensor.layernorm_1171.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1171.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_155 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_155"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33899
        },
        "dc.input_tensor.layernorm_1171.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1171.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_155 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_155"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33901
        },
        "dc.input_tensor.layernorm_1210.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1210.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_159 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_159"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33965
        },
        "dc.input_tensor.layernorm_1210.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1210.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_160 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_160"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33971
        },
        "dc.input_tensor.layernorm_1210.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1210.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_160 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_160"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33973
        },
        "dc.input_tensor.layernorm_1224.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1224.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_161 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_161"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33997
        },
        "dc.input_tensor.layernorm_1224.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1224.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_162 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_162"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 34003
        },
        "dc.input_tensor.layernorm_1224.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1224.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_162 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_162"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 34005
        },
        "dc.input_tensor.layernorm_1263.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1263.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_166 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_166"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 34069
        },
        "dc.input_tensor.layernorm_1263.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1263.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_167 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_167"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 34075
        },
        "dc.input_tensor.layernorm_1263.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1263.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_167 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_167"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 34077
        },
        "dc.input_tensor.layernorm_1277.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1277.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_168 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_168"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 34101
        },
        "dc.input_tensor.layernorm_1277.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1277.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_169 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_169"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 34107
        },
        "dc.input_tensor.layernorm_1277.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1277.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_169 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_169"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 34109
        },
        "dc.input_tensor.layernorm_150.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_150.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_19 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_19"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 31885
        },
        "dc.input_tensor.layernorm_150.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_150.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_20 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_20"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 31891
        },
        "dc.input_tensor.layernorm_150.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_150.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_20 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_20"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 31893
        },
        "dc.input_tensor.layernorm_164.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_164.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_21 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_21"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 31917
        },
        "dc.input_tensor.layernorm_164.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_164.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_22 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_22"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 31923
        },
        "dc.input_tensor.layernorm_164.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_164.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_22 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_22"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 31925
        },
        "dc.input_tensor.layernorm_203.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_203.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_26 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_26"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 31989
        },
        "dc.input_tensor.layernorm_203.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_203.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_27 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_27"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 31995
        },
        "dc.input_tensor.layernorm_203.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_203.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_27 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_27"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 31997
        },
        "dc.input_tensor.layernorm_217.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_217.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_28 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_28"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32021
        },
        "dc.input_tensor.layernorm_217.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_217.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_29 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_29"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32027
        },
        "dc.input_tensor.layernorm_217.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_217.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_29 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_29"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32029
        },
        "dc.input_tensor.layernorm_256.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_256.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_33 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_33"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32093
        },
        "dc.input_tensor.layernorm_256.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_256.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_34 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_34"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32099
        },
        "dc.input_tensor.layernorm_256.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_256.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_34 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_34"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32101
        },
        "dc.input_tensor.layernorm_270.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_270.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_35 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_35"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32125
        },
        "dc.input_tensor.layernorm_270.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_270.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_36 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_36"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32131
        },
        "dc.input_tensor.layernorm_270.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_270.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_36 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_36"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32133
        },
        "dc.input_tensor.layernorm_309.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_309.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_40 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_40"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32197
        },
        "dc.input_tensor.layernorm_309.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_309.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_41 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_41"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32203
        },
        "dc.input_tensor.layernorm_309.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_309.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_41 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_41"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32205
        },
        "dc.input_tensor.layernorm_323.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_323.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_42 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_42"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32229
        },
        "dc.input_tensor.layernorm_323.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_323.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_43 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_43"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32235
        },
        "dc.input_tensor.layernorm_323.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_323.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_43 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_43"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32237
        },
        "dc.input_tensor.layernorm_362.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_362.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_47 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_47"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32301
        },
        "dc.input_tensor.layernorm_362.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_362.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_48 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_48"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32307
        },
        "dc.input_tensor.layernorm_362.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_362.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_48 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_48"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32309
        },
        "dc.input_tensor.layernorm_376.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_376.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_49 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_49"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32333
        },
        "dc.input_tensor.layernorm_376.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_376.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_50 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_50"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32339
        },
        "dc.input_tensor.layernorm_376.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_376.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_50 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_50"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32341
        },
        "dc.input_tensor.layernorm_415.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_415.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_54 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_54"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32405
        },
        "dc.input_tensor.layernorm_415.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_415.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_55 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_55"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32411
        },
        "dc.input_tensor.layernorm_415.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_415.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_55 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_55"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32413
        },
        "dc.input_tensor.layernorm_429.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_429.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_56 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_56"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32437
        },
        "dc.input_tensor.layernorm_429.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_429.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_57 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_57"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32443
        },
        "dc.input_tensor.layernorm_429.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_429.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_57 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_57"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32445
        },
        "dc.input_tensor.layernorm_44.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_44.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_5 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_5"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 31677
        },
        "dc.input_tensor.layernorm_44.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_44.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_6 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_6"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 31683
        },
        "dc.input_tensor.layernorm_44.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_44.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_6 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_6"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 31685
        },
        "dc.input_tensor.layernorm_468.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_468.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_61 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_61"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32509
        },
        "dc.input_tensor.layernorm_468.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_468.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_62 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_62"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32515
        },
        "dc.input_tensor.layernorm_468.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_468.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_62 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_62"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32517
        },
        "dc.input_tensor.layernorm_482.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_482.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_63 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_63"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32541
        },
        "dc.input_tensor.layernorm_482.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_482.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_64 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_64"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32547
        },
        "dc.input_tensor.layernorm_482.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_482.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_64 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_64"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32549
        },
        "dc.input_tensor.layernorm_521.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_521.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_68 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_68"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32613
        },
        "dc.input_tensor.layernorm_521.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_521.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_69 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_69"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32619
        },
        "dc.input_tensor.layernorm_521.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_521.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_69 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_69"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32621
        },
        "dc.input_tensor.layernorm_535.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_535.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_70 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_70"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32645
        },
        "dc.input_tensor.layernorm_535.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_535.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_71 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_71"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32651
        },
        "dc.input_tensor.layernorm_535.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_535.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_71 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_71"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32653
        },
        "dc.input_tensor.layernorm_574.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_574.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_75 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_75"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32717
        },
        "dc.input_tensor.layernorm_574.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_574.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_76 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_76"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32723
        },
        "dc.input_tensor.layernorm_574.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_574.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_76 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_76"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32725
        },
        "dc.input_tensor.layernorm_58.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_58.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_7 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_7"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 31709
        },
        "dc.input_tensor.layernorm_58.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_58.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_8 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_8"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 31715
        },
        "dc.input_tensor.layernorm_58.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_58.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_8 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_8"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 31717
        },
        "dc.input_tensor.layernorm_588.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_588.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_77 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_77"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32749
        },
        "dc.input_tensor.layernorm_588.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_588.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_78 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_78"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32755
        },
        "dc.input_tensor.layernorm_588.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_588.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_78 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_78"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32757
        },
        "dc.input_tensor.layernorm_627.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_627.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_82 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_82"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32821
        },
        "dc.input_tensor.layernorm_627.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_627.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_83 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_83"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32827
        },
        "dc.input_tensor.layernorm_627.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_627.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_83 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_83"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32829
        },
        "dc.input_tensor.layernorm_641.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_641.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_84 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_84"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32853
        },
        "dc.input_tensor.layernorm_641.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_641.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_85 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_85"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32859
        },
        "dc.input_tensor.layernorm_641.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_641.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_85 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_85"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32861
        },
        "dc.input_tensor.layernorm_680.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_680.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_89 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_89"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32925
        },
        "dc.input_tensor.layernorm_680.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_680.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_90 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_90"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32931
        },
        "dc.input_tensor.layernorm_680.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_680.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_90 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_90"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32933
        },
        "dc.input_tensor.layernorm_694.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_694.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_91 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_91"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32957
        },
        "dc.input_tensor.layernorm_694.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_694.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_92 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_92"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32963
        },
        "dc.input_tensor.layernorm_694.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_694.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_92 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_92"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32965
        },
        "dc.input_tensor.layernorm_733.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_733.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_96 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_96"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33029
        },
        "dc.input_tensor.layernorm_733.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_733.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_97 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_97"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33035
        },
        "dc.input_tensor.layernorm_733.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_733.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_97 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_97"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33037
        },
        "dc.input_tensor.layernorm_747.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_747.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_98 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_98"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33061
        },
        "dc.input_tensor.layernorm_747.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_747.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_99 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_99"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33067
        },
        "dc.input_tensor.layernorm_747.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_747.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_99 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_99"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33069
        },
        "dc.input_tensor.layernorm_786.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_786.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_103 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_103"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33133
        },
        "dc.input_tensor.layernorm_786.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_786.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_104 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_104"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33139
        },
        "dc.input_tensor.layernorm_786.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_786.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_104 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_104"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33141
        },
        "dc.input_tensor.layernorm_800.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_800.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_105 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_105"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33165
        },
        "dc.input_tensor.layernorm_800.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_800.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_106 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_106"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33171
        },
        "dc.input_tensor.layernorm_800.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_800.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_106 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_106"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33173
        },
        "dc.input_tensor.layernorm_839.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_839.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_110 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_110"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33237
        },
        "dc.input_tensor.layernorm_839.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_839.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_111 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_111"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33243
        },
        "dc.input_tensor.layernorm_839.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_839.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_111 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_111"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33245
        },
        "dc.input_tensor.layernorm_853.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_853.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_112 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_112"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33269
        },
        "dc.input_tensor.layernorm_853.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_853.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_113 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_113"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33275
        },
        "dc.input_tensor.layernorm_853.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_853.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_113 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_113"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33277
        },
        "dc.input_tensor.layernorm_892.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_892.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_117 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_117"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33341
        },
        "dc.input_tensor.layernorm_892.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_892.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_118 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_118"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33347
        },
        "dc.input_tensor.layernorm_892.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_892.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_118 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_118"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33349
        },
        "dc.input_tensor.layernorm_906.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_906.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_119 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_119"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33373
        },
        "dc.input_tensor.layernorm_906.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_906.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_120 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_120"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33379
        },
        "dc.input_tensor.layernorm_906.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_906.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_120 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_120"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33381
        },
        "dc.input_tensor.layernorm_945.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_945.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_124 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_124"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33445
        },
        "dc.input_tensor.layernorm_945.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_945.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_125 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_125"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33451
        },
        "dc.input_tensor.layernorm_945.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_945.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_125 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_125"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33453
        },
        "dc.input_tensor.layernorm_959.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_959.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_126 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_126"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33477
        },
        "dc.input_tensor.layernorm_959.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_959.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_127 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_127"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33483
        },
        "dc.input_tensor.layernorm_959.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_959.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_127 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_127"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33485
        },
        "dc.input_tensor.layernorm_97.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_97.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_12 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_12"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 31781
        },
        "dc.input_tensor.layernorm_97.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_97.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_13 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_13"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 31787
        },
        "dc.input_tensor.layernorm_97.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_97.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_13 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_13"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 31789
        },
        "dc.input_tensor.layernorm_998.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_998.1",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_131 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_131"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33549
        },
        "dc.input_tensor.layernorm_998.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_998.6",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_132 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_132"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33555
        },
        "dc.input_tensor.layernorm_998.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_998.8",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_132 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_132"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33557
        },
        "dc.input_tensor.softmax_1031.4": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                16,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.softmax_1031.4",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_137 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_137"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "softmax"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33628
        },
        "dc.input_tensor.softmax_1084.4": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                16,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.softmax_1084.4",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_144 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_144"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "softmax"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33732
        },
        "dc.input_tensor.softmax_1137.4": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                16,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.softmax_1137.4",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_151 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_151"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "softmax"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33836
        },
        "dc.input_tensor.softmax_1190.4": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                16,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.softmax_1190.4",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_158 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_158"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "softmax"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33940
        },
        "dc.input_tensor.softmax_1243.4": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                16,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.softmax_1243.4",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_165 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_165"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "softmax"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 34044
        },
        "dc.input_tensor.softmax_130.4": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                16,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.softmax_130.4",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_18 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_18"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "softmax"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 31860
        },
        "dc.input_tensor.softmax_183.4": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                16,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.softmax_183.4",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_25 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_25"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "softmax"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 31964
        },
        "dc.input_tensor.softmax_236.4": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                16,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.softmax_236.4",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_32 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_32"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "softmax"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32068
        },
        "dc.input_tensor.softmax_24.4": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                16,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.softmax_24.4",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_4 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_4"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "softmax"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 31652
        },
        "dc.input_tensor.softmax_289.4": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                16,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.softmax_289.4",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_39 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_39"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "softmax"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32172
        },
        "dc.input_tensor.softmax_342.4": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                16,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.softmax_342.4",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_46 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_46"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "softmax"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32276
        },
        "dc.input_tensor.softmax_395.4": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                16,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.softmax_395.4",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_53 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_53"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "softmax"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32380
        },
        "dc.input_tensor.softmax_448.4": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                16,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.softmax_448.4",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_60 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_60"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "softmax"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32484
        },
        "dc.input_tensor.softmax_501.4": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                16,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.softmax_501.4",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_67 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_67"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "softmax"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32588
        },
        "dc.input_tensor.softmax_554.4": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                16,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.softmax_554.4",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_74 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_74"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "softmax"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32692
        },
        "dc.input_tensor.softmax_607.4": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                16,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.softmax_607.4",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_81 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_81"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "softmax"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32796
        },
        "dc.input_tensor.softmax_660.4": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                16,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.softmax_660.4",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_88 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_88"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "softmax"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32900
        },
        "dc.input_tensor.softmax_713.4": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                16,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.softmax_713.4",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_95 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_95"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "softmax"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33004
        },
        "dc.input_tensor.softmax_766.4": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                16,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.softmax_766.4",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_102 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_102"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "softmax"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33108
        },
        "dc.input_tensor.softmax_77.4": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                16,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.softmax_77.4",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_11 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_11"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "softmax"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 31756
        },
        "dc.input_tensor.softmax_819.4": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                16,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.softmax_819.4",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_109 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_109"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "softmax"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33212
        },
        "dc.input_tensor.softmax_872.4": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                16,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.softmax_872.4",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_116 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_116"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "softmax"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33316
        },
        "dc.input_tensor.softmax_925.4": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                16,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.softmax_925.4",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_123 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_123"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "softmax"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33420
        },
        "dc.input_tensor.softmax_978.4": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                16,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.softmax_978.4",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_130 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_130"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "softmax"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33524
        },
        "gelu_1004": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu(none,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1001 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "matmul_1001": "Data"
            },
            "input_nodes": [
                "matmul_1001"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "gelu_1004",
            "op_type": {
                "attrs": [
                    "none"
                ],
                "buda_attrs": {
                    "approximate_mode": "false"
                },
                "named_attrs": {},
                "type": "gelu"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1007 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1007"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn",
                "original_op_name": "gelu_1004",
                "original_op_type": "gelu"
            },
            "type": "gelu",
            "unique_id": 33571
        },
        "gelu_103": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu(none,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_100 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "matmul_100": "Data"
            },
            "input_nodes": [
                "matmul_100"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "gelu_103",
            "op_type": {
                "attrs": [
                    "none"
                ],
                "buda_attrs": {
                    "approximate_mode": "false"
                },
                "named_attrs": {},
                "type": "gelu"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_106 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_106"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn",
                "original_op_name": "gelu_103",
                "original_op_type": "gelu"
            },
            "type": "gelu",
            "unique_id": 31803
        },
        "gelu_1057": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu(none,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1054 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "matmul_1054": "Data"
            },
            "input_nodes": [
                "matmul_1054"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "gelu_1057",
            "op_type": {
                "attrs": [
                    "none"
                ],
                "buda_attrs": {
                    "approximate_mode": "false"
                },
                "named_attrs": {},
                "type": "gelu"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1060 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1060"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn",
                "original_op_name": "gelu_1057",
                "original_op_type": "gelu"
            },
            "type": "gelu",
            "unique_id": 33675
        },
        "gelu_1110": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu(none,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1107 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "matmul_1107": "Data"
            },
            "input_nodes": [
                "matmul_1107"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "gelu_1110",
            "op_type": {
                "attrs": [
                    "none"
                ],
                "buda_attrs": {
                    "approximate_mode": "false"
                },
                "named_attrs": {},
                "type": "gelu"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1113 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1113"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn",
                "original_op_name": "gelu_1110",
                "original_op_type": "gelu"
            },
            "type": "gelu",
            "unique_id": 33779
        },
        "gelu_1163": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu(none,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1160 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "matmul_1160": "Data"
            },
            "input_nodes": [
                "matmul_1160"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "gelu_1163",
            "op_type": {
                "attrs": [
                    "none"
                ],
                "buda_attrs": {
                    "approximate_mode": "false"
                },
                "named_attrs": {},
                "type": "gelu"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1166 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1166"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn",
                "original_op_name": "gelu_1163",
                "original_op_type": "gelu"
            },
            "type": "gelu",
            "unique_id": 33883
        },
        "gelu_1216": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu(none,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1213 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "matmul_1213": "Data"
            },
            "input_nodes": [
                "matmul_1213"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "gelu_1216",
            "op_type": {
                "attrs": [
                    "none"
                ],
                "buda_attrs": {
                    "approximate_mode": "false"
                },
                "named_attrs": {},
                "type": "gelu"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1219 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1219"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn",
                "original_op_name": "gelu_1216",
                "original_op_type": "gelu"
            },
            "type": "gelu",
            "unique_id": 33987
        },
        "gelu_1269": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu(none,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1266 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "matmul_1266": "Data"
            },
            "input_nodes": [
                "matmul_1266"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "gelu_1269",
            "op_type": {
                "attrs": [
                    "none"
                ],
                "buda_attrs": {
                    "approximate_mode": "false"
                },
                "named_attrs": {},
                "type": "gelu"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1272 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1272"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn",
                "original_op_name": "gelu_1269",
                "original_op_type": "gelu"
            },
            "type": "gelu",
            "unique_id": 34091
        },
        "gelu_156": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu(none,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_153 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "matmul_153": "Data"
            },
            "input_nodes": [
                "matmul_153"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "gelu_156",
            "op_type": {
                "attrs": [
                    "none"
                ],
                "buda_attrs": {
                    "approximate_mode": "false"
                },
                "named_attrs": {},
                "type": "gelu"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_159 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_159"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn",
                "original_op_name": "gelu_156",
                "original_op_type": "gelu"
            },
            "type": "gelu",
            "unique_id": 31907
        },
        "gelu_209": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu(none,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_206 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "matmul_206": "Data"
            },
            "input_nodes": [
                "matmul_206"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "gelu_209",
            "op_type": {
                "attrs": [
                    "none"
                ],
                "buda_attrs": {
                    "approximate_mode": "false"
                },
                "named_attrs": {},
                "type": "gelu"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_212 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_212"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn",
                "original_op_name": "gelu_209",
                "original_op_type": "gelu"
            },
            "type": "gelu",
            "unique_id": 32011
        },
        "gelu_262": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu(none,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_259 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "matmul_259": "Data"
            },
            "input_nodes": [
                "matmul_259"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "gelu_262",
            "op_type": {
                "attrs": [
                    "none"
                ],
                "buda_attrs": {
                    "approximate_mode": "false"
                },
                "named_attrs": {},
                "type": "gelu"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_265 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_265"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn",
                "original_op_name": "gelu_262",
                "original_op_type": "gelu"
            },
            "type": "gelu",
            "unique_id": 32115
        },
        "gelu_315": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu(none,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_312 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "matmul_312": "Data"
            },
            "input_nodes": [
                "matmul_312"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "gelu_315",
            "op_type": {
                "attrs": [
                    "none"
                ],
                "buda_attrs": {
                    "approximate_mode": "false"
                },
                "named_attrs": {},
                "type": "gelu"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_318 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_318"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn",
                "original_op_name": "gelu_315",
                "original_op_type": "gelu"
            },
            "type": "gelu",
            "unique_id": 32219
        },
        "gelu_368": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu(none,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_365 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "matmul_365": "Data"
            },
            "input_nodes": [
                "matmul_365"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "gelu_368",
            "op_type": {
                "attrs": [
                    "none"
                ],
                "buda_attrs": {
                    "approximate_mode": "false"
                },
                "named_attrs": {},
                "type": "gelu"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_371 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_371"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn",
                "original_op_name": "gelu_368",
                "original_op_type": "gelu"
            },
            "type": "gelu",
            "unique_id": 32323
        },
        "gelu_421": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu(none,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_418 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "matmul_418": "Data"
            },
            "input_nodes": [
                "matmul_418"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "gelu_421",
            "op_type": {
                "attrs": [
                    "none"
                ],
                "buda_attrs": {
                    "approximate_mode": "false"
                },
                "named_attrs": {},
                "type": "gelu"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_424 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_424"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn",
                "original_op_name": "gelu_421",
                "original_op_type": "gelu"
            },
            "type": "gelu",
            "unique_id": 32427
        },
        "gelu_474": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu(none,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_471 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "matmul_471": "Data"
            },
            "input_nodes": [
                "matmul_471"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "gelu_474",
            "op_type": {
                "attrs": [
                    "none"
                ],
                "buda_attrs": {
                    "approximate_mode": "false"
                },
                "named_attrs": {},
                "type": "gelu"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_477 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_477"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn",
                "original_op_name": "gelu_474",
                "original_op_type": "gelu"
            },
            "type": "gelu",
            "unique_id": 32531
        },
        "gelu_50": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu(none,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_47 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "matmul_47": "Data"
            },
            "input_nodes": [
                "matmul_47"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "gelu_50",
            "op_type": {
                "attrs": [
                    "none"
                ],
                "buda_attrs": {
                    "approximate_mode": "false"
                },
                "named_attrs": {},
                "type": "gelu"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_53 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_53"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn",
                "original_op_name": "gelu_50",
                "original_op_type": "gelu"
            },
            "type": "gelu",
            "unique_id": 31699
        },
        "gelu_527": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu(none,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_524 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "matmul_524": "Data"
            },
            "input_nodes": [
                "matmul_524"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "gelu_527",
            "op_type": {
                "attrs": [
                    "none"
                ],
                "buda_attrs": {
                    "approximate_mode": "false"
                },
                "named_attrs": {},
                "type": "gelu"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_530 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_530"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn",
                "original_op_name": "gelu_527",
                "original_op_type": "gelu"
            },
            "type": "gelu",
            "unique_id": 32635
        },
        "gelu_580": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu(none,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_577 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "matmul_577": "Data"
            },
            "input_nodes": [
                "matmul_577"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "gelu_580",
            "op_type": {
                "attrs": [
                    "none"
                ],
                "buda_attrs": {
                    "approximate_mode": "false"
                },
                "named_attrs": {},
                "type": "gelu"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_583 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_583"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn",
                "original_op_name": "gelu_580",
                "original_op_type": "gelu"
            },
            "type": "gelu",
            "unique_id": 32739
        },
        "gelu_633": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu(none,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_630 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "matmul_630": "Data"
            },
            "input_nodes": [
                "matmul_630"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "gelu_633",
            "op_type": {
                "attrs": [
                    "none"
                ],
                "buda_attrs": {
                    "approximate_mode": "false"
                },
                "named_attrs": {},
                "type": "gelu"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_636 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_636"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn",
                "original_op_name": "gelu_633",
                "original_op_type": "gelu"
            },
            "type": "gelu",
            "unique_id": 32843
        },
        "gelu_686": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu(none,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_683 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "matmul_683": "Data"
            },
            "input_nodes": [
                "matmul_683"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "gelu_686",
            "op_type": {
                "attrs": [
                    "none"
                ],
                "buda_attrs": {
                    "approximate_mode": "false"
                },
                "named_attrs": {},
                "type": "gelu"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_689 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_689"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn",
                "original_op_name": "gelu_686",
                "original_op_type": "gelu"
            },
            "type": "gelu",
            "unique_id": 32947
        },
        "gelu_739": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu(none,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_736 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "matmul_736": "Data"
            },
            "input_nodes": [
                "matmul_736"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "gelu_739",
            "op_type": {
                "attrs": [
                    "none"
                ],
                "buda_attrs": {
                    "approximate_mode": "false"
                },
                "named_attrs": {},
                "type": "gelu"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_742 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_742"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn",
                "original_op_name": "gelu_739",
                "original_op_type": "gelu"
            },
            "type": "gelu",
            "unique_id": 33051
        },
        "gelu_792": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu(none,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_789 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "matmul_789": "Data"
            },
            "input_nodes": [
                "matmul_789"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "gelu_792",
            "op_type": {
                "attrs": [
                    "none"
                ],
                "buda_attrs": {
                    "approximate_mode": "false"
                },
                "named_attrs": {},
                "type": "gelu"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_795 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_795"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn",
                "original_op_name": "gelu_792",
                "original_op_type": "gelu"
            },
            "type": "gelu",
            "unique_id": 33155
        },
        "gelu_845": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu(none,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_842 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "matmul_842": "Data"
            },
            "input_nodes": [
                "matmul_842"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "gelu_845",
            "op_type": {
                "attrs": [
                    "none"
                ],
                "buda_attrs": {
                    "approximate_mode": "false"
                },
                "named_attrs": {},
                "type": "gelu"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_848 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_848"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn",
                "original_op_name": "gelu_845",
                "original_op_type": "gelu"
            },
            "type": "gelu",
            "unique_id": 33259
        },
        "gelu_898": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu(none,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_895 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "matmul_895": "Data"
            },
            "input_nodes": [
                "matmul_895"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "gelu_898",
            "op_type": {
                "attrs": [
                    "none"
                ],
                "buda_attrs": {
                    "approximate_mode": "false"
                },
                "named_attrs": {},
                "type": "gelu"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_901 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_901"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn",
                "original_op_name": "gelu_898",
                "original_op_type": "gelu"
            },
            "type": "gelu",
            "unique_id": 33363
        },
        "gelu_951": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu(none,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_948 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "matmul_948": "Data"
            },
            "input_nodes": [
                "matmul_948"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "gelu_951",
            "op_type": {
                "attrs": [
                    "none"
                ],
                "buda_attrs": {
                    "approximate_mode": "false"
                },
                "named_attrs": {},
                "type": "gelu"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_954 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_954"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn",
                "original_op_name": "gelu_951",
                "original_op_type": "gelu"
            },
            "type": "gelu",
            "unique_id": 33467
        },
        "input_0_subtract_21": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "input_0_subtract_21",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: subtract_21 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "subtract_21"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert",
                "original_op_name": "subtract_21",
                "original_op_type": "subtract"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 31638
        },
        "input_1_multiply_1029": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "input_1_multiply_1029",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_135 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_135"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "add"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33616
        },
        "input_1_multiply_1082": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "input_1_multiply_1082",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_142 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_142"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "add"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33720
        },
        "input_1_multiply_1135": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "input_1_multiply_1135",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_149 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_149"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "add"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33824
        },
        "input_1_multiply_1188": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "input_1_multiply_1188",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_156 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_156"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "add"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33928
        },
        "input_1_multiply_1241": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "input_1_multiply_1241",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_163 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_163"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "add"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 34032
        },
        "input_1_multiply_128": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "input_1_multiply_128",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_16 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_16"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "add"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 31848
        },
        "input_1_multiply_18": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "input_1_multiply_18",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_2 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_2"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "add"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 31632
        },
        "input_1_multiply_181": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "input_1_multiply_181",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_23 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_23"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "add"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 31952
        },
        "input_1_multiply_22": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "input_1_multiply_22",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: multiply_22 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "multiply_22"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert",
                "original_op_name": "multiply_22",
                "original_op_type": "multiply"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 31640
        },
        "input_1_multiply_234": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "input_1_multiply_234",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_30 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_30"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "add"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32056
        },
        "input_1_multiply_287": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "input_1_multiply_287",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_37 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_37"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "add"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32160
        },
        "input_1_multiply_340": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "input_1_multiply_340",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_44 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_44"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "add"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32264
        },
        "input_1_multiply_393": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "input_1_multiply_393",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_51 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_51"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "add"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32368
        },
        "input_1_multiply_446": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "input_1_multiply_446",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_58 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_58"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "add"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32472
        },
        "input_1_multiply_499": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "input_1_multiply_499",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_65 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_65"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "add"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32576
        },
        "input_1_multiply_552": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "input_1_multiply_552",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_72 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_72"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "add"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32680
        },
        "input_1_multiply_605": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "input_1_multiply_605",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_79 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_79"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "add"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32784
        },
        "input_1_multiply_658": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "input_1_multiply_658",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_86 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_86"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "add"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32888
        },
        "input_1_multiply_711": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "input_1_multiply_711",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_93 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_93"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "add"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32992
        },
        "input_1_multiply_75": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "input_1_multiply_75",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_9 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_9"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "add"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 31744
        },
        "input_1_multiply_764": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "input_1_multiply_764",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_100 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_100"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "add"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33096
        },
        "input_1_multiply_817": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "input_1_multiply_817",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_107 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_107"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "add"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33200
        },
        "input_1_multiply_870": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "input_1_multiply_870",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_114 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_114"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "add"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33304
        },
        "input_1_multiply_923": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "input_1_multiply_923",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_121 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_121"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "add"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33408
        },
        "input_1_multiply_976": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "input_1_multiply_976",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_128 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_128"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "add"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33512
        },
        "layernorm_0.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_0 (port_0) ublock_order(c)",
                "Data: _fused_op_0 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_0": "Data"
            },
            "input_nodes": [
                "_fused_op_0",
                "_fused_op_0"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_0.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_0.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_0.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEmbeddings::embeddings/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_0",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 31598
        },
        "layernorm_0.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: pybuda_6_i0 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_0.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "lc.input_tensor.layernorm_0.dc.reduce_sum.0.0": "Data",
                "pybuda_6_i0": "Data"
            },
            "input_nodes": [
                "pybuda_6_i0",
                "lc.input_tensor.layernorm_0.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_0.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_0 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_0"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEmbeddings::embeddings/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_0",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 31593
        },
        "layernorm_0.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_0.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_0.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_0.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_0.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_0.dc.multiply.4",
                "lc.input_tensor.layernorm_0.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_0.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEmbeddings::embeddings/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_0",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 31600
        },
        "layernorm_1012.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_133 (port_0) ublock_order(c)",
                "Data: _fused_op_133 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_133": "Data"
            },
            "input_nodes": [
                "_fused_op_133",
                "_fused_op_133"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1012.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1012.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1012.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1012",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 33583
        },
        "layernorm_1012.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_1011 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_1012.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_1011": "Data",
                "lc.input_tensor.layernorm_1012.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_1011",
                "lc.input_tensor.layernorm_1012.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1012.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_133 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_133"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1012",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 33579
        },
        "layernorm_1012.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_1012.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_1012.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_1012.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_1012.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_1012.dc.multiply.4",
                "lc.input_tensor.layernorm_1012.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1012.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_134 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_134"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1012",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 33585
        },
        "layernorm_1051.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_138 (port_0) ublock_order(c)",
                "Data: _fused_op_138 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_138": "Data"
            },
            "input_nodes": [
                "_fused_op_138",
                "_fused_op_138"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1051.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1051.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1051.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1051",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 33655
        },
        "layernorm_1051.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_1050 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_1051.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_1050": "Data",
                "lc.input_tensor.layernorm_1051.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_1050",
                "lc.input_tensor.layernorm_1051.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1051.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_138 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_138"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1051",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 33651
        },
        "layernorm_1051.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_1051.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_1051.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_1051.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_1051.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_1051.dc.multiply.4",
                "lc.input_tensor.layernorm_1051.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1051.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_139 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_139"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1051",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 33657
        },
        "layernorm_1065.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_140 (port_0) ublock_order(c)",
                "Data: _fused_op_140 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_140": "Data"
            },
            "input_nodes": [
                "_fused_op_140",
                "_fused_op_140"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1065.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1065.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1065.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1065",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 33687
        },
        "layernorm_1065.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_1064 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_1065.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_1064": "Data",
                "lc.input_tensor.layernorm_1065.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_1064",
                "lc.input_tensor.layernorm_1065.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1065.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_140 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_140"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1065",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 33683
        },
        "layernorm_1065.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_1065.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_1065.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_1065.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_1065.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_1065.dc.multiply.4",
                "lc.input_tensor.layernorm_1065.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1065.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_141 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_141"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1065",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 33689
        },
        "layernorm_1104.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_145 (port_0) ublock_order(c)",
                "Data: _fused_op_145 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_145": "Data"
            },
            "input_nodes": [
                "_fused_op_145",
                "_fused_op_145"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1104.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1104.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1104.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1104",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 33759
        },
        "layernorm_1104.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_1103 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_1104.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_1103": "Data",
                "lc.input_tensor.layernorm_1104.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_1103",
                "lc.input_tensor.layernorm_1104.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1104.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_145 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_145"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1104",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 33755
        },
        "layernorm_1104.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_1104.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_1104.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_1104.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_1104.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_1104.dc.multiply.4",
                "lc.input_tensor.layernorm_1104.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1104.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_146 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_146"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1104",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 33761
        },
        "layernorm_111.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_14 (port_0) ublock_order(c)",
                "Data: _fused_op_14 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_14": "Data"
            },
            "input_nodes": [
                "_fused_op_14",
                "_fused_op_14"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_111.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_111.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_111.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_111",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 31815
        },
        "layernorm_111.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_110 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_111.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_110": "Data",
                "lc.input_tensor.layernorm_111.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_110",
                "lc.input_tensor.layernorm_111.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_111.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_14 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_14"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_111",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 31811
        },
        "layernorm_111.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_111.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_111.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_111.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_111.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_111.dc.multiply.4",
                "lc.input_tensor.layernorm_111.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_111.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_15 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_15"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_111",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 31817
        },
        "layernorm_1118.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_147 (port_0) ublock_order(c)",
                "Data: _fused_op_147 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_147": "Data"
            },
            "input_nodes": [
                "_fused_op_147",
                "_fused_op_147"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1118.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1118.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1118.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1118",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 33791
        },
        "layernorm_1118.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_1117 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_1118.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_1117": "Data",
                "lc.input_tensor.layernorm_1118.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_1117",
                "lc.input_tensor.layernorm_1118.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1118.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_147 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_147"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1118",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 33787
        },
        "layernorm_1118.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_1118.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_1118.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_1118.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_1118.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_1118.dc.multiply.4",
                "lc.input_tensor.layernorm_1118.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1118.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_148 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_148"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1118",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 33793
        },
        "layernorm_1157.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_152 (port_0) ublock_order(c)",
                "Data: _fused_op_152 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_152": "Data"
            },
            "input_nodes": [
                "_fused_op_152",
                "_fused_op_152"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1157.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1157.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1157.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1157",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 33863
        },
        "layernorm_1157.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_1156 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_1157.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_1156": "Data",
                "lc.input_tensor.layernorm_1157.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_1156",
                "lc.input_tensor.layernorm_1157.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1157.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_152 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_152"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1157",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 33859
        },
        "layernorm_1157.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_1157.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_1157.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_1157.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_1157.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_1157.dc.multiply.4",
                "lc.input_tensor.layernorm_1157.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1157.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_153 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_153"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1157",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 33865
        },
        "layernorm_1171.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_154 (port_0) ublock_order(c)",
                "Data: _fused_op_154 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_154": "Data"
            },
            "input_nodes": [
                "_fused_op_154",
                "_fused_op_154"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1171.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1171.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1171.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1171",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 33895
        },
        "layernorm_1171.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_1170 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_1171.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_1170": "Data",
                "lc.input_tensor.layernorm_1171.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_1170",
                "lc.input_tensor.layernorm_1171.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1171.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_154 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_154"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1171",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 33891
        },
        "layernorm_1171.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_1171.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_1171.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_1171.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_1171.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_1171.dc.multiply.4",
                "lc.input_tensor.layernorm_1171.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1171.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_155 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_155"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1171",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 33897
        },
        "layernorm_1210.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_159 (port_0) ublock_order(c)",
                "Data: _fused_op_159 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_159": "Data"
            },
            "input_nodes": [
                "_fused_op_159",
                "_fused_op_159"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1210.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1210.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1210.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1210",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 33967
        },
        "layernorm_1210.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_1209 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_1210.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_1209": "Data",
                "lc.input_tensor.layernorm_1210.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_1209",
                "lc.input_tensor.layernorm_1210.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1210.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_159 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_159"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1210",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 33963
        },
        "layernorm_1210.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_1210.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_1210.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_1210.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_1210.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_1210.dc.multiply.4",
                "lc.input_tensor.layernorm_1210.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1210.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_160 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_160"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1210",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 33969
        },
        "layernorm_1224.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_161 (port_0) ublock_order(c)",
                "Data: _fused_op_161 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_161": "Data"
            },
            "input_nodes": [
                "_fused_op_161",
                "_fused_op_161"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1224.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1224.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1224.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1224",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 33999
        },
        "layernorm_1224.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_1223 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_1224.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_1223": "Data",
                "lc.input_tensor.layernorm_1224.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_1223",
                "lc.input_tensor.layernorm_1224.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1224.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_161 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_161"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1224",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 33995
        },
        "layernorm_1224.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_1224.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_1224.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_1224.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_1224.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_1224.dc.multiply.4",
                "lc.input_tensor.layernorm_1224.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1224.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_162 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_162"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1224",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 34001
        },
        "layernorm_1263.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_166 (port_0) ublock_order(c)",
                "Data: _fused_op_166 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_166": "Data"
            },
            "input_nodes": [
                "_fused_op_166",
                "_fused_op_166"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1263.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1263.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1263.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1263",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 34071
        },
        "layernorm_1263.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_1262 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_1263.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_1262": "Data",
                "lc.input_tensor.layernorm_1263.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_1262",
                "lc.input_tensor.layernorm_1263.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1263.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_166 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_166"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1263",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 34067
        },
        "layernorm_1263.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_1263.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_1263.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_1263.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_1263.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_1263.dc.multiply.4",
                "lc.input_tensor.layernorm_1263.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1263.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_167 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_167"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1263",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 34073
        },
        "layernorm_1277.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_168 (port_0) ublock_order(c)",
                "Data: _fused_op_168 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_168": "Data"
            },
            "input_nodes": [
                "_fused_op_168",
                "_fused_op_168"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1277.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_1277.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1277.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1277",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 34103
        },
        "layernorm_1277.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_1276 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_1277.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_1276": "Data",
                "lc.input_tensor.layernorm_1277.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_1276",
                "lc.input_tensor.layernorm_1277.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1277.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_168 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_168"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1277",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 34099
        },
        "layernorm_1277.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_1277.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_1277.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_1277.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_1277.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_1277.dc.multiply.4",
                "lc.input_tensor.layernorm_1277.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_1277.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_169 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_169"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1277",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 34105
        },
        "layernorm_150.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_19 (port_0) ublock_order(c)",
                "Data: _fused_op_19 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_19": "Data"
            },
            "input_nodes": [
                "_fused_op_19",
                "_fused_op_19"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_150.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_150.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_150.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_150",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 31887
        },
        "layernorm_150.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_149 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_150.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_149": "Data",
                "lc.input_tensor.layernorm_150.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_149",
                "lc.input_tensor.layernorm_150.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_150.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_19 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_19"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_150",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 31883
        },
        "layernorm_150.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_150.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_150.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_150.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_150.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_150.dc.multiply.4",
                "lc.input_tensor.layernorm_150.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_150.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_20 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_20"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_150",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 31889
        },
        "layernorm_164.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_21 (port_0) ublock_order(c)",
                "Data: _fused_op_21 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_21": "Data"
            },
            "input_nodes": [
                "_fused_op_21",
                "_fused_op_21"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_164.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_164.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_164.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_164",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 31919
        },
        "layernorm_164.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_163 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_164.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_163": "Data",
                "lc.input_tensor.layernorm_164.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_163",
                "lc.input_tensor.layernorm_164.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_164.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_21 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_21"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_164",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 31915
        },
        "layernorm_164.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_164.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_164.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_164.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_164.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_164.dc.multiply.4",
                "lc.input_tensor.layernorm_164.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_164.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_22 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_22"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_164",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 31921
        },
        "layernorm_203.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_26 (port_0) ublock_order(c)",
                "Data: _fused_op_26 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_26": "Data"
            },
            "input_nodes": [
                "_fused_op_26",
                "_fused_op_26"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_203.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_203.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_203.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_203",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 31991
        },
        "layernorm_203.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_202 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_203.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_202": "Data",
                "lc.input_tensor.layernorm_203.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_202",
                "lc.input_tensor.layernorm_203.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_203.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_26 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_26"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_203",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 31987
        },
        "layernorm_203.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_203.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_203.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_203.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_203.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_203.dc.multiply.4",
                "lc.input_tensor.layernorm_203.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_203.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_27 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_27"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_203",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 31993
        },
        "layernorm_217.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_28 (port_0) ublock_order(c)",
                "Data: _fused_op_28 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_28": "Data"
            },
            "input_nodes": [
                "_fused_op_28",
                "_fused_op_28"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_217.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_217.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_217.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_217",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 32023
        },
        "layernorm_217.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_216 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_217.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_216": "Data",
                "lc.input_tensor.layernorm_217.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_216",
                "lc.input_tensor.layernorm_217.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_217.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_28 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_28"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_217",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 32019
        },
        "layernorm_217.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_217.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_217.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_217.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_217.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_217.dc.multiply.4",
                "lc.input_tensor.layernorm_217.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_217.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_29 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_29"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_217",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 32025
        },
        "layernorm_256.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_33 (port_0) ublock_order(c)",
                "Data: _fused_op_33 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_33": "Data"
            },
            "input_nodes": [
                "_fused_op_33",
                "_fused_op_33"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_256.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_256.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_256.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_256",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 32095
        },
        "layernorm_256.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_255 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_256.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_255": "Data",
                "lc.input_tensor.layernorm_256.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_255",
                "lc.input_tensor.layernorm_256.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_256.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_33 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_33"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_256",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 32091
        },
        "layernorm_256.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_256.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_256.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_256.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_256.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_256.dc.multiply.4",
                "lc.input_tensor.layernorm_256.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_256.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_34 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_34"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_256",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 32097
        },
        "layernorm_270.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_35 (port_0) ublock_order(c)",
                "Data: _fused_op_35 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_35": "Data"
            },
            "input_nodes": [
                "_fused_op_35",
                "_fused_op_35"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_270.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_270.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_270.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_270",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 32127
        },
        "layernorm_270.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_269 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_270.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_269": "Data",
                "lc.input_tensor.layernorm_270.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_269",
                "lc.input_tensor.layernorm_270.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_270.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_35 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_35"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_270",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 32123
        },
        "layernorm_270.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_270.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_270.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_270.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_270.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_270.dc.multiply.4",
                "lc.input_tensor.layernorm_270.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_270.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_36 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_36"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_270",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 32129
        },
        "layernorm_309.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_40 (port_0) ublock_order(c)",
                "Data: _fused_op_40 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_40": "Data"
            },
            "input_nodes": [
                "_fused_op_40",
                "_fused_op_40"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_309.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_309.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_309.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_309",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 32199
        },
        "layernorm_309.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_308 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_309.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_308": "Data",
                "lc.input_tensor.layernorm_309.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_308",
                "lc.input_tensor.layernorm_309.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_309.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_40 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_40"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_309",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 32195
        },
        "layernorm_309.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_309.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_309.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_309.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_309.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_309.dc.multiply.4",
                "lc.input_tensor.layernorm_309.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_309.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_41 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_41"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_309",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 32201
        },
        "layernorm_323.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_42 (port_0) ublock_order(c)",
                "Data: _fused_op_42 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_42": "Data"
            },
            "input_nodes": [
                "_fused_op_42",
                "_fused_op_42"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_323.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_323.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_323.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_323",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 32231
        },
        "layernorm_323.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_322 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_323.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_322": "Data",
                "lc.input_tensor.layernorm_323.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_322",
                "lc.input_tensor.layernorm_323.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_323.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_42 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_42"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_323",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 32227
        },
        "layernorm_323.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_323.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_323.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_323.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_323.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_323.dc.multiply.4",
                "lc.input_tensor.layernorm_323.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_323.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_43 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_43"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_323",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 32233
        },
        "layernorm_362.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_47 (port_0) ublock_order(c)",
                "Data: _fused_op_47 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_47": "Data"
            },
            "input_nodes": [
                "_fused_op_47",
                "_fused_op_47"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_362.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_362.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_362.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_362",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 32303
        },
        "layernorm_362.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_361 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_362.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_361": "Data",
                "lc.input_tensor.layernorm_362.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_361",
                "lc.input_tensor.layernorm_362.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_362.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_47 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_47"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_362",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 32299
        },
        "layernorm_362.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_362.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_362.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_362.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_362.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_362.dc.multiply.4",
                "lc.input_tensor.layernorm_362.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_362.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_48 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_48"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_362",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 32305
        },
        "layernorm_376.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_49 (port_0) ublock_order(c)",
                "Data: _fused_op_49 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_49": "Data"
            },
            "input_nodes": [
                "_fused_op_49",
                "_fused_op_49"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_376.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_376.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_376.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_376",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 32335
        },
        "layernorm_376.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_375 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_376.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_375": "Data",
                "lc.input_tensor.layernorm_376.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_375",
                "lc.input_tensor.layernorm_376.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_376.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_49 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_49"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_376",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 32331
        },
        "layernorm_376.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_376.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_376.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_376.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_376.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_376.dc.multiply.4",
                "lc.input_tensor.layernorm_376.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_376.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_50 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_50"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_376",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 32337
        },
        "layernorm_415.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_54 (port_0) ublock_order(c)",
                "Data: _fused_op_54 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_54": "Data"
            },
            "input_nodes": [
                "_fused_op_54",
                "_fused_op_54"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_415.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_415.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_415.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_415",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 32407
        },
        "layernorm_415.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_414 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_415.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_414": "Data",
                "lc.input_tensor.layernorm_415.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_414",
                "lc.input_tensor.layernorm_415.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_415.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_54 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_54"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_415",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 32403
        },
        "layernorm_415.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_415.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_415.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_415.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_415.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_415.dc.multiply.4",
                "lc.input_tensor.layernorm_415.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_415.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_55 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_55"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_415",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 32409
        },
        "layernorm_429.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_56 (port_0) ublock_order(c)",
                "Data: _fused_op_56 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_56": "Data"
            },
            "input_nodes": [
                "_fused_op_56",
                "_fused_op_56"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_429.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_429.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_429.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_429",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 32439
        },
        "layernorm_429.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_428 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_429.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_428": "Data",
                "lc.input_tensor.layernorm_429.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_428",
                "lc.input_tensor.layernorm_429.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_429.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_56 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_56"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_429",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 32435
        },
        "layernorm_429.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_429.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_429.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_429.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_429.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_429.dc.multiply.4",
                "lc.input_tensor.layernorm_429.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_429.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_57 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_57"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_429",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 32441
        },
        "layernorm_44.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_5 (port_0) ublock_order(c)",
                "Data: _fused_op_5 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_5": "Data"
            },
            "input_nodes": [
                "_fused_op_5",
                "_fused_op_5"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_44.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_44.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_44.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_44",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 31679
        },
        "layernorm_44.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_43 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_44.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_43": "Data",
                "lc.input_tensor.layernorm_44.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_43",
                "lc.input_tensor.layernorm_44.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_44.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_5 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_5"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_44",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 31675
        },
        "layernorm_44.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_44.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_44.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_44.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_44.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_44.dc.multiply.4",
                "lc.input_tensor.layernorm_44.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_44.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_6 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_6"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_44",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 31681
        },
        "layernorm_468.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_61 (port_0) ublock_order(c)",
                "Data: _fused_op_61 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_61": "Data"
            },
            "input_nodes": [
                "_fused_op_61",
                "_fused_op_61"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_468.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_468.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_468.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_468",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 32511
        },
        "layernorm_468.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_467 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_468.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_467": "Data",
                "lc.input_tensor.layernorm_468.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_467",
                "lc.input_tensor.layernorm_468.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_468.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_61 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_61"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_468",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 32507
        },
        "layernorm_468.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_468.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_468.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_468.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_468.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_468.dc.multiply.4",
                "lc.input_tensor.layernorm_468.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_468.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_62 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_62"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_468",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 32513
        },
        "layernorm_482.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_63 (port_0) ublock_order(c)",
                "Data: _fused_op_63 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_63": "Data"
            },
            "input_nodes": [
                "_fused_op_63",
                "_fused_op_63"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_482.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_482.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_482.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_482",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 32543
        },
        "layernorm_482.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_481 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_482.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_481": "Data",
                "lc.input_tensor.layernorm_482.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_481",
                "lc.input_tensor.layernorm_482.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_482.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_63 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_63"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_482",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 32539
        },
        "layernorm_482.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_482.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_482.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_482.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_482.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_482.dc.multiply.4",
                "lc.input_tensor.layernorm_482.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_482.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_64 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_64"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_482",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 32545
        },
        "layernorm_521.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_68 (port_0) ublock_order(c)",
                "Data: _fused_op_68 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_68": "Data"
            },
            "input_nodes": [
                "_fused_op_68",
                "_fused_op_68"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_521.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_521.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_521.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_521",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 32615
        },
        "layernorm_521.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_520 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_521.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_520": "Data",
                "lc.input_tensor.layernorm_521.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_520",
                "lc.input_tensor.layernorm_521.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_521.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_68 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_68"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_521",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 32611
        },
        "layernorm_521.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_521.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_521.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_521.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_521.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_521.dc.multiply.4",
                "lc.input_tensor.layernorm_521.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_521.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_69 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_69"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_521",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 32617
        },
        "layernorm_535.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_70 (port_0) ublock_order(c)",
                "Data: _fused_op_70 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_70": "Data"
            },
            "input_nodes": [
                "_fused_op_70",
                "_fused_op_70"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_535.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_535.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_535.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_535",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 32647
        },
        "layernorm_535.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_534 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_535.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_534": "Data",
                "lc.input_tensor.layernorm_535.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_534",
                "lc.input_tensor.layernorm_535.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_535.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_70 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_70"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_535",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 32643
        },
        "layernorm_535.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_535.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_535.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_535.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_535.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_535.dc.multiply.4",
                "lc.input_tensor.layernorm_535.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_535.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_71 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_71"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_535",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 32649
        },
        "layernorm_574.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_75 (port_0) ublock_order(c)",
                "Data: _fused_op_75 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_75": "Data"
            },
            "input_nodes": [
                "_fused_op_75",
                "_fused_op_75"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_574.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_574.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_574.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_574",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 32719
        },
        "layernorm_574.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_573 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_574.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_573": "Data",
                "lc.input_tensor.layernorm_574.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_573",
                "lc.input_tensor.layernorm_574.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_574.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_75 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_75"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_574",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 32715
        },
        "layernorm_574.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_574.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_574.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_574.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_574.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_574.dc.multiply.4",
                "lc.input_tensor.layernorm_574.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_574.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_76 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_76"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_574",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 32721
        },
        "layernorm_58.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_7 (port_0) ublock_order(c)",
                "Data: _fused_op_7 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_7": "Data"
            },
            "input_nodes": [
                "_fused_op_7",
                "_fused_op_7"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_58.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_58.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_58.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_58",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 31711
        },
        "layernorm_58.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_57 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_58.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_57": "Data",
                "lc.input_tensor.layernorm_58.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_57",
                "lc.input_tensor.layernorm_58.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_58.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_7 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_7"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_58",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 31707
        },
        "layernorm_58.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_58.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_58.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_58.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_58.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_58.dc.multiply.4",
                "lc.input_tensor.layernorm_58.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_58.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_8 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_8"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_58",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 31713
        },
        "layernorm_588.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_77 (port_0) ublock_order(c)",
                "Data: _fused_op_77 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_77": "Data"
            },
            "input_nodes": [
                "_fused_op_77",
                "_fused_op_77"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_588.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_588.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_588.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_588",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 32751
        },
        "layernorm_588.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_587 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_588.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_587": "Data",
                "lc.input_tensor.layernorm_588.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_587",
                "lc.input_tensor.layernorm_588.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_588.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_77 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_77"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_588",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 32747
        },
        "layernorm_588.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_588.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_588.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_588.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_588.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_588.dc.multiply.4",
                "lc.input_tensor.layernorm_588.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_588.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_78 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_78"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_588",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 32753
        },
        "layernorm_627.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_82 (port_0) ublock_order(c)",
                "Data: _fused_op_82 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_82": "Data"
            },
            "input_nodes": [
                "_fused_op_82",
                "_fused_op_82"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_627.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_627.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_627.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_627",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 32823
        },
        "layernorm_627.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_626 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_627.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_626": "Data",
                "lc.input_tensor.layernorm_627.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_626",
                "lc.input_tensor.layernorm_627.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_627.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_82 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_82"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_627",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 32819
        },
        "layernorm_627.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_627.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_627.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_627.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_627.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_627.dc.multiply.4",
                "lc.input_tensor.layernorm_627.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_627.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_83 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_83"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_627",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 32825
        },
        "layernorm_641.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_84 (port_0) ublock_order(c)",
                "Data: _fused_op_84 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_84": "Data"
            },
            "input_nodes": [
                "_fused_op_84",
                "_fused_op_84"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_641.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_641.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_641.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_641",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 32855
        },
        "layernorm_641.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_640 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_641.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_640": "Data",
                "lc.input_tensor.layernorm_641.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_640",
                "lc.input_tensor.layernorm_641.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_641.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_84 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_84"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_641",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 32851
        },
        "layernorm_641.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_641.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_641.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_641.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_641.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_641.dc.multiply.4",
                "lc.input_tensor.layernorm_641.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_641.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_85 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_85"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_641",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 32857
        },
        "layernorm_680.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_89 (port_0) ublock_order(c)",
                "Data: _fused_op_89 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_89": "Data"
            },
            "input_nodes": [
                "_fused_op_89",
                "_fused_op_89"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_680.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_680.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_680.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_680",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 32927
        },
        "layernorm_680.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_679 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_680.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_679": "Data",
                "lc.input_tensor.layernorm_680.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_679",
                "lc.input_tensor.layernorm_680.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_680.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_89 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_89"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_680",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 32923
        },
        "layernorm_680.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_680.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_680.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_680.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_680.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_680.dc.multiply.4",
                "lc.input_tensor.layernorm_680.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_680.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_90 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_90"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_680",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 32929
        },
        "layernorm_694.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_91 (port_0) ublock_order(c)",
                "Data: _fused_op_91 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_91": "Data"
            },
            "input_nodes": [
                "_fused_op_91",
                "_fused_op_91"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_694.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_694.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_694.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_694",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 32959
        },
        "layernorm_694.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_693 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_694.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_693": "Data",
                "lc.input_tensor.layernorm_694.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_693",
                "lc.input_tensor.layernorm_694.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_694.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_91 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_91"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_694",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 32955
        },
        "layernorm_694.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_694.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_694.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_694.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_694.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_694.dc.multiply.4",
                "lc.input_tensor.layernorm_694.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_694.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_92 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_92"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_694",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 32961
        },
        "layernorm_733.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_96 (port_0) ublock_order(c)",
                "Data: _fused_op_96 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_96": "Data"
            },
            "input_nodes": [
                "_fused_op_96",
                "_fused_op_96"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_733.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_733.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_733.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_733",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 33031
        },
        "layernorm_733.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_732 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_733.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_732": "Data",
                "lc.input_tensor.layernorm_733.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_732",
                "lc.input_tensor.layernorm_733.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_733.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_96 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_96"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_733",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 33027
        },
        "layernorm_733.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_733.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_733.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_733.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_733.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_733.dc.multiply.4",
                "lc.input_tensor.layernorm_733.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_733.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_97 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_97"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_733",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 33033
        },
        "layernorm_747.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_98 (port_0) ublock_order(c)",
                "Data: _fused_op_98 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_98": "Data"
            },
            "input_nodes": [
                "_fused_op_98",
                "_fused_op_98"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_747.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_747.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_747.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_747",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 33063
        },
        "layernorm_747.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_746 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_747.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_746": "Data",
                "lc.input_tensor.layernorm_747.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_746",
                "lc.input_tensor.layernorm_747.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_747.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_98 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_98"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_747",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 33059
        },
        "layernorm_747.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_747.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_747.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_747.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_747.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_747.dc.multiply.4",
                "lc.input_tensor.layernorm_747.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_747.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_99 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_99"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_747",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 33065
        },
        "layernorm_786.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_103 (port_0) ublock_order(c)",
                "Data: _fused_op_103 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_103": "Data"
            },
            "input_nodes": [
                "_fused_op_103",
                "_fused_op_103"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_786.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_786.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_786.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_786",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 33135
        },
        "layernorm_786.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_785 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_786.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_785": "Data",
                "lc.input_tensor.layernorm_786.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_785",
                "lc.input_tensor.layernorm_786.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_786.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_103 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_103"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_786",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 33131
        },
        "layernorm_786.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_786.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_786.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_786.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_786.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_786.dc.multiply.4",
                "lc.input_tensor.layernorm_786.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_786.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_104 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_104"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_786",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 33137
        },
        "layernorm_800.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_105 (port_0) ublock_order(c)",
                "Data: _fused_op_105 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_105": "Data"
            },
            "input_nodes": [
                "_fused_op_105",
                "_fused_op_105"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_800.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_800.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_800.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_800",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 33167
        },
        "layernorm_800.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_799 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_800.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_799": "Data",
                "lc.input_tensor.layernorm_800.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_799",
                "lc.input_tensor.layernorm_800.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_800.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_105 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_105"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_800",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 33163
        },
        "layernorm_800.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_800.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_800.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_800.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_800.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_800.dc.multiply.4",
                "lc.input_tensor.layernorm_800.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_800.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_106 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_106"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_800",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 33169
        },
        "layernorm_839.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_110 (port_0) ublock_order(c)",
                "Data: _fused_op_110 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_110": "Data"
            },
            "input_nodes": [
                "_fused_op_110",
                "_fused_op_110"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_839.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_839.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_839.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_839",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 33239
        },
        "layernorm_839.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_838 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_839.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_838": "Data",
                "lc.input_tensor.layernorm_839.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_838",
                "lc.input_tensor.layernorm_839.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_839.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_110 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_110"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_839",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 33235
        },
        "layernorm_839.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_839.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_839.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_839.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_839.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_839.dc.multiply.4",
                "lc.input_tensor.layernorm_839.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_839.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_111 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_111"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_839",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 33241
        },
        "layernorm_853.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_112 (port_0) ublock_order(c)",
                "Data: _fused_op_112 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_112": "Data"
            },
            "input_nodes": [
                "_fused_op_112",
                "_fused_op_112"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_853.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_853.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_853.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_853",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 33271
        },
        "layernorm_853.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_852 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_853.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_852": "Data",
                "lc.input_tensor.layernorm_853.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_852",
                "lc.input_tensor.layernorm_853.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_853.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_112 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_112"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_853",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 33267
        },
        "layernorm_853.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_853.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_853.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_853.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_853.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_853.dc.multiply.4",
                "lc.input_tensor.layernorm_853.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_853.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_113 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_113"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_853",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 33273
        },
        "layernorm_892.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_117 (port_0) ublock_order(c)",
                "Data: _fused_op_117 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_117": "Data"
            },
            "input_nodes": [
                "_fused_op_117",
                "_fused_op_117"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_892.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_892.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_892.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_892",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 33343
        },
        "layernorm_892.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_891 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_892.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_891": "Data",
                "lc.input_tensor.layernorm_892.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_891",
                "lc.input_tensor.layernorm_892.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_892.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_117 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_117"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_892",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 33339
        },
        "layernorm_892.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_892.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_892.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_892.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_892.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_892.dc.multiply.4",
                "lc.input_tensor.layernorm_892.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_892.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_118 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_118"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_892",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 33345
        },
        "layernorm_906.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_119 (port_0) ublock_order(c)",
                "Data: _fused_op_119 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_119": "Data"
            },
            "input_nodes": [
                "_fused_op_119",
                "_fused_op_119"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_906.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_906.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_906.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_906",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 33375
        },
        "layernorm_906.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_905 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_906.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_905": "Data",
                "lc.input_tensor.layernorm_906.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_905",
                "lc.input_tensor.layernorm_906.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_906.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_119 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_119"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_906",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 33371
        },
        "layernorm_906.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_906.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_906.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_906.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_906.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_906.dc.multiply.4",
                "lc.input_tensor.layernorm_906.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_906.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_120 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_120"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_906",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 33377
        },
        "layernorm_945.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_124 (port_0) ublock_order(c)",
                "Data: _fused_op_124 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_124": "Data"
            },
            "input_nodes": [
                "_fused_op_124",
                "_fused_op_124"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_945.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_945.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_945.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_945",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 33447
        },
        "layernorm_945.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_944 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_945.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_944": "Data",
                "lc.input_tensor.layernorm_945.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_944",
                "lc.input_tensor.layernorm_945.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_945.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_124 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_124"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_945",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 33443
        },
        "layernorm_945.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_945.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_945.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_945.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_945.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_945.dc.multiply.4",
                "lc.input_tensor.layernorm_945.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_945.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_125 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_125"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_945",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 33449
        },
        "layernorm_959.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_126 (port_0) ublock_order(c)",
                "Data: _fused_op_126 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_126": "Data"
            },
            "input_nodes": [
                "_fused_op_126",
                "_fused_op_126"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_959.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_959.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_959.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_959",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 33479
        },
        "layernorm_959.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_958 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_959.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_958": "Data",
                "lc.input_tensor.layernorm_959.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_958",
                "lc.input_tensor.layernorm_959.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_959.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_126 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_126"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_959",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 33475
        },
        "layernorm_959.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_959.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_959.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_959.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_959.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_959.dc.multiply.4",
                "lc.input_tensor.layernorm_959.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_959.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_127 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_127"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_959",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 33481
        },
        "layernorm_97.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_12 (port_0) ublock_order(c)",
                "Data: _fused_op_12 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_12": "Data"
            },
            "input_nodes": [
                "_fused_op_12",
                "_fused_op_12"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_97.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_97.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_97.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_97",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 31783
        },
        "layernorm_97.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_96 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_97.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_96": "Data",
                "lc.input_tensor.layernorm_97.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_96",
                "lc.input_tensor.layernorm_97.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_97.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_12 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_12"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_97",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 31779
        },
        "layernorm_97.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_97.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_97.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_97.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_97.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_97.dc.multiply.4",
                "lc.input_tensor.layernorm_97.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_97.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_13 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_13"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_97",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 31785
        },
        "layernorm_998.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_131 (port_0) ublock_order(c)",
                "Data: _fused_op_131 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_131": "Data"
            },
            "input_nodes": [
                "_fused_op_131",
                "_fused_op_131"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_998.dc.multiply.4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_998.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_998.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_998",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 33551
        },
        "layernorm_998.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: add_997 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_998.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_997": "Data",
                "lc.input_tensor.layernorm_998.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_997",
                "lc.input_tensor.layernorm_998.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_998.dc.reduce_sum.0.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_131 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_131"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_998",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 33547
        },
        "layernorm_998.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: layernorm_998.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_998.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_998.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_998.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_998.dc.multiply.4",
                "lc.input_tensor.layernorm_998.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_998.dc.reduce_sum.5.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_132 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_132"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_998",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 33553
        },
        "lc.input_tensor.layernorm_0.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_0.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_0.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_0.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEmbeddings::embeddings/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_0",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 31592
        },
        "lc.input_tensor.layernorm_0.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_0.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_0.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_0.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEmbeddings::embeddings/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_0",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 31599
        },
        "lc.input_tensor.layernorm_1012.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_1012.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_1012.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1012.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1012",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33578
        },
        "lc.input_tensor.layernorm_1012.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_1012.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_1012.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1012.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1012",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33584
        },
        "lc.input_tensor.layernorm_1051.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_1051.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_1051.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1051.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1051",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33650
        },
        "lc.input_tensor.layernorm_1051.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_1051.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_1051.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1051.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1051",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33656
        },
        "lc.input_tensor.layernorm_1065.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_1065.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_1065.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1065.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1065",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33682
        },
        "lc.input_tensor.layernorm_1065.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_1065.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_1065.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1065.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1065",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33688
        },
        "lc.input_tensor.layernorm_1104.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_1104.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_1104.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1104.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1104",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33754
        },
        "lc.input_tensor.layernorm_1104.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_1104.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_1104.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1104.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1104",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33760
        },
        "lc.input_tensor.layernorm_111.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_111.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_111.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_111.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_111",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 31810
        },
        "lc.input_tensor.layernorm_111.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_111.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_111.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_111.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_111",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 31816
        },
        "lc.input_tensor.layernorm_1118.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_1118.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_1118.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1118.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1118",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33786
        },
        "lc.input_tensor.layernorm_1118.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_1118.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_1118.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1118.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1118",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33792
        },
        "lc.input_tensor.layernorm_1157.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_1157.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_1157.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1157.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1157",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33858
        },
        "lc.input_tensor.layernorm_1157.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_1157.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_1157.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1157.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1157",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33864
        },
        "lc.input_tensor.layernorm_1171.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_1171.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_1171.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1171.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1171",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33890
        },
        "lc.input_tensor.layernorm_1171.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_1171.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_1171.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1171.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1171",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33896
        },
        "lc.input_tensor.layernorm_1210.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_1210.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_1210.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1210.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1210",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33962
        },
        "lc.input_tensor.layernorm_1210.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_1210.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_1210.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1210.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1210",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33968
        },
        "lc.input_tensor.layernorm_1224.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_1224.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_1224.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1224.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1224",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33994
        },
        "lc.input_tensor.layernorm_1224.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_1224.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_1224.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1224.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1224",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 34000
        },
        "lc.input_tensor.layernorm_1263.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_1263.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_1263.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1263.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1263",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 34066
        },
        "lc.input_tensor.layernorm_1263.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_1263.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_1263.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1263.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1263",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 34072
        },
        "lc.input_tensor.layernorm_1277.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_1277.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_1277.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1277.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1277",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 34098
        },
        "lc.input_tensor.layernorm_1277.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_1277.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_1277.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_1277.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_1277",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 34104
        },
        "lc.input_tensor.layernorm_150.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_150.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_150.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_150.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_150",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 31882
        },
        "lc.input_tensor.layernorm_150.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_150.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_150.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_150.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_150",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 31888
        },
        "lc.input_tensor.layernorm_164.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_164.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_164.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_164.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_164",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 31914
        },
        "lc.input_tensor.layernorm_164.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_164.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_164.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_164.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_164",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 31920
        },
        "lc.input_tensor.layernorm_203.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_203.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_203.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_203.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_203",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 31986
        },
        "lc.input_tensor.layernorm_203.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_203.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_203.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_203.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_203",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 31992
        },
        "lc.input_tensor.layernorm_217.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_217.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_217.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_217.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_217",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32018
        },
        "lc.input_tensor.layernorm_217.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_217.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_217.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_217.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_217",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32024
        },
        "lc.input_tensor.layernorm_256.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_256.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_256.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_256.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_256",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32090
        },
        "lc.input_tensor.layernorm_256.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_256.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_256.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_256.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_256",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32096
        },
        "lc.input_tensor.layernorm_270.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_270.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_270.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_270.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_270",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32122
        },
        "lc.input_tensor.layernorm_270.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_270.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_270.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_270.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_270",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32128
        },
        "lc.input_tensor.layernorm_309.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_309.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_309.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_309.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_309",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32194
        },
        "lc.input_tensor.layernorm_309.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_309.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_309.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_309.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_309",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32200
        },
        "lc.input_tensor.layernorm_323.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_323.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_323.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_323.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_323",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32226
        },
        "lc.input_tensor.layernorm_323.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_323.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_323.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_323.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_323",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32232
        },
        "lc.input_tensor.layernorm_362.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_362.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_362.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_362.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_362",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32298
        },
        "lc.input_tensor.layernorm_362.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_362.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_362.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_362.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_362",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32304
        },
        "lc.input_tensor.layernorm_376.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_376.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_376.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_376.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_376",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32330
        },
        "lc.input_tensor.layernorm_376.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_376.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_376.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_376.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_376",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32336
        },
        "lc.input_tensor.layernorm_415.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_415.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_415.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_415.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_415",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32402
        },
        "lc.input_tensor.layernorm_415.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_415.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_415.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_415.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_415",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32408
        },
        "lc.input_tensor.layernorm_429.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_429.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_429.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_429.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_429",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32434
        },
        "lc.input_tensor.layernorm_429.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_429.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_429.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_429.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_429",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32440
        },
        "lc.input_tensor.layernorm_44.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_44.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_44.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_44.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_44",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 31674
        },
        "lc.input_tensor.layernorm_44.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_44.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_44.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_44.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_44",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 31680
        },
        "lc.input_tensor.layernorm_468.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_468.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_468.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_468.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_468",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32506
        },
        "lc.input_tensor.layernorm_468.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_468.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_468.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_468.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_468",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32512
        },
        "lc.input_tensor.layernorm_482.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_482.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_482.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_482.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_482",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32538
        },
        "lc.input_tensor.layernorm_482.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_482.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_482.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_482.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_482",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32544
        },
        "lc.input_tensor.layernorm_521.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_521.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_521.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_521.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_521",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32610
        },
        "lc.input_tensor.layernorm_521.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_521.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_521.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_521.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_521",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32616
        },
        "lc.input_tensor.layernorm_535.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_535.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_535.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_535.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_535",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32642
        },
        "lc.input_tensor.layernorm_535.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_535.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_535.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_535.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_535",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32648
        },
        "lc.input_tensor.layernorm_574.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_574.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_574.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_574.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_574",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32714
        },
        "lc.input_tensor.layernorm_574.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_574.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_574.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_574.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_574",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32720
        },
        "lc.input_tensor.layernorm_58.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_58.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_58.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_58.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_58",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 31706
        },
        "lc.input_tensor.layernorm_58.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_58.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_58.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_58.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_58",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 31712
        },
        "lc.input_tensor.layernorm_588.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_588.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_588.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_588.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_588",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32746
        },
        "lc.input_tensor.layernorm_588.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_588.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_588.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_588.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_588",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32752
        },
        "lc.input_tensor.layernorm_627.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_627.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_627.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_627.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_627",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32818
        },
        "lc.input_tensor.layernorm_627.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_627.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_627.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_627.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_627",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32824
        },
        "lc.input_tensor.layernorm_641.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_641.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_641.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_641.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_641",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32850
        },
        "lc.input_tensor.layernorm_641.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_641.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_641.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_641.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_641",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32856
        },
        "lc.input_tensor.layernorm_680.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_680.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_680.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_680.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_680",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32922
        },
        "lc.input_tensor.layernorm_680.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_680.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_680.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_680.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_680",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32928
        },
        "lc.input_tensor.layernorm_694.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_694.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_694.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_694.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_694",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32954
        },
        "lc.input_tensor.layernorm_694.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_694.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_694.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_694.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_694",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32960
        },
        "lc.input_tensor.layernorm_733.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_733.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_733.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_733.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_733",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33026
        },
        "lc.input_tensor.layernorm_733.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_733.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_733.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_733.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_733",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33032
        },
        "lc.input_tensor.layernorm_747.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_747.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_747.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_747.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_747",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33058
        },
        "lc.input_tensor.layernorm_747.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_747.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_747.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_747.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_747",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33064
        },
        "lc.input_tensor.layernorm_786.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_786.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_786.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_786.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_786",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33130
        },
        "lc.input_tensor.layernorm_786.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_786.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_786.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_786.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_786",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33136
        },
        "lc.input_tensor.layernorm_800.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_800.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_800.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_800.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_800",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33162
        },
        "lc.input_tensor.layernorm_800.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_800.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_800.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_800.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_800",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33168
        },
        "lc.input_tensor.layernorm_839.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_839.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_839.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_839.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_839",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33234
        },
        "lc.input_tensor.layernorm_839.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_839.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_839.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_839.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_839",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33240
        },
        "lc.input_tensor.layernorm_853.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_853.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_853.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_853.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_853",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33266
        },
        "lc.input_tensor.layernorm_853.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_853.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_853.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_853.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_853",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33272
        },
        "lc.input_tensor.layernorm_892.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_892.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_892.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_892.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_892",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33338
        },
        "lc.input_tensor.layernorm_892.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_892.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_892.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_892.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_892",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33344
        },
        "lc.input_tensor.layernorm_906.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_906.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_906.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_906.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_906",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33370
        },
        "lc.input_tensor.layernorm_906.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_906.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_906.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_906.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_906",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33376
        },
        "lc.input_tensor.layernorm_945.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_945.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_945.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_945.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_945",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33442
        },
        "lc.input_tensor.layernorm_945.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_945.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_945.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_945.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_945",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33448
        },
        "lc.input_tensor.layernorm_959.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_959.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_959.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_959.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_959",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33474
        },
        "lc.input_tensor.layernorm_959.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_959.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_959.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_959.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_959",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33480
        },
        "lc.input_tensor.layernorm_97.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_97.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_97.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_97.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_97",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 31778
        },
        "lc.input_tensor.layernorm_97.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_97.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_97.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_97.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_97",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 31784
        },
        "lc.input_tensor.layernorm_998.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_998.dc.reduce_sum.0.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_998.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_998.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_998",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33546
        },
        "lc.input_tensor.layernorm_998.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_998.dc.reduce_sum.5.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_998.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_998.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_998",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33552
        },
        "lc.input_tensor.softmax_1031.dc.reduce_sum.3.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.softmax_1031.dc.reduce_sum.3.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: softmax_1031.dc.reduce_sum.3.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_1031.dc.reduce_sum.3.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_1031",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33625
        },
        "lc.input_tensor.softmax_1084.dc.reduce_sum.3.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.softmax_1084.dc.reduce_sum.3.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: softmax_1084.dc.reduce_sum.3.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_1084.dc.reduce_sum.3.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_1084",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33729
        },
        "lc.input_tensor.softmax_1137.dc.reduce_sum.3.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.softmax_1137.dc.reduce_sum.3.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: softmax_1137.dc.reduce_sum.3.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_1137.dc.reduce_sum.3.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_1137",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33833
        },
        "lc.input_tensor.softmax_1190.dc.reduce_sum.3.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.softmax_1190.dc.reduce_sum.3.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: softmax_1190.dc.reduce_sum.3.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_1190.dc.reduce_sum.3.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_1190",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33937
        },
        "lc.input_tensor.softmax_1243.dc.reduce_sum.3.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.softmax_1243.dc.reduce_sum.3.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: softmax_1243.dc.reduce_sum.3.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_1243.dc.reduce_sum.3.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_1243",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 34041
        },
        "lc.input_tensor.softmax_130.dc.reduce_sum.3.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.softmax_130.dc.reduce_sum.3.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: softmax_130.dc.reduce_sum.3.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_130.dc.reduce_sum.3.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_130",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 31857
        },
        "lc.input_tensor.softmax_183.dc.reduce_sum.3.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.softmax_183.dc.reduce_sum.3.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: softmax_183.dc.reduce_sum.3.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_183.dc.reduce_sum.3.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_183",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 31961
        },
        "lc.input_tensor.softmax_236.dc.reduce_sum.3.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.softmax_236.dc.reduce_sum.3.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: softmax_236.dc.reduce_sum.3.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_236.dc.reduce_sum.3.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_236",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32065
        },
        "lc.input_tensor.softmax_24.dc.reduce_sum.3.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.softmax_24.dc.reduce_sum.3.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: softmax_24.dc.reduce_sum.3.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_24.dc.reduce_sum.3.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_24",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 31649
        },
        "lc.input_tensor.softmax_289.dc.reduce_sum.3.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.softmax_289.dc.reduce_sum.3.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: softmax_289.dc.reduce_sum.3.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_289.dc.reduce_sum.3.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_289",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32169
        },
        "lc.input_tensor.softmax_342.dc.reduce_sum.3.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.softmax_342.dc.reduce_sum.3.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: softmax_342.dc.reduce_sum.3.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_342.dc.reduce_sum.3.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_342",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32273
        },
        "lc.input_tensor.softmax_395.dc.reduce_sum.3.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.softmax_395.dc.reduce_sum.3.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: softmax_395.dc.reduce_sum.3.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_395.dc.reduce_sum.3.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_395",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32377
        },
        "lc.input_tensor.softmax_448.dc.reduce_sum.3.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.softmax_448.dc.reduce_sum.3.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: softmax_448.dc.reduce_sum.3.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_448.dc.reduce_sum.3.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_448",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32481
        },
        "lc.input_tensor.softmax_501.dc.reduce_sum.3.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.softmax_501.dc.reduce_sum.3.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: softmax_501.dc.reduce_sum.3.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_501.dc.reduce_sum.3.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_501",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32585
        },
        "lc.input_tensor.softmax_554.dc.reduce_sum.3.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.softmax_554.dc.reduce_sum.3.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: softmax_554.dc.reduce_sum.3.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_554.dc.reduce_sum.3.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_554",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32689
        },
        "lc.input_tensor.softmax_607.dc.reduce_sum.3.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.softmax_607.dc.reduce_sum.3.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: softmax_607.dc.reduce_sum.3.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_607.dc.reduce_sum.3.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_607",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32793
        },
        "lc.input_tensor.softmax_660.dc.reduce_sum.3.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.softmax_660.dc.reduce_sum.3.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: softmax_660.dc.reduce_sum.3.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_660.dc.reduce_sum.3.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_660",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 32897
        },
        "lc.input_tensor.softmax_713.dc.reduce_sum.3.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.softmax_713.dc.reduce_sum.3.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: softmax_713.dc.reduce_sum.3.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_713.dc.reduce_sum.3.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_713",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33001
        },
        "lc.input_tensor.softmax_766.dc.reduce_sum.3.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.softmax_766.dc.reduce_sum.3.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: softmax_766.dc.reduce_sum.3.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_766.dc.reduce_sum.3.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_766",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33105
        },
        "lc.input_tensor.softmax_77.dc.reduce_sum.3.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.softmax_77.dc.reduce_sum.3.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: softmax_77.dc.reduce_sum.3.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_77.dc.reduce_sum.3.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_77",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 31753
        },
        "lc.input_tensor.softmax_819.dc.reduce_sum.3.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.softmax_819.dc.reduce_sum.3.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: softmax_819.dc.reduce_sum.3.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_819.dc.reduce_sum.3.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_819",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33209
        },
        "lc.input_tensor.softmax_872.dc.reduce_sum.3.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.softmax_872.dc.reduce_sum.3.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: softmax_872.dc.reduce_sum.3.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_872.dc.reduce_sum.3.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_872",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33313
        },
        "lc.input_tensor.softmax_925.dc.reduce_sum.3.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.softmax_925.dc.reduce_sum.3.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: softmax_925.dc.reduce_sum.3.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_925.dc.reduce_sum.3.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_925",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33417
        },
        "lc.input_tensor.softmax_978.dc.reduce_sum.3.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.softmax_978.dc.reduce_sum.3.0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: softmax_978.dc.reduce_sum.3.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_978.dc.reduce_sum.3.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_978",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 33521
        },
        "matmul_10": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_1 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.0.attention.self.key.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.0.attention.self.key.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_1": "Data",
                "bert.encoder.layer.0.attention.self.key.bias": "Data",
                "bert.encoder.layer.0.attention.self.key.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_1",
                "bert.encoder.layer.0.attention.self.key.weight",
                "bert.encoder.layer.0.attention.self.key.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_10",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_16 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_16"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key",
                "original_op_name": "matmul_10",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 31622
        },
        "matmul_100": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_13 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.1.intermediate.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.1.intermediate.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_13": "Data",
                "bert.encoder.layer.1.intermediate.dense.bias": "Data",
                "bert.encoder.layer.1.intermediate.dense.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_13",
                "bert.encoder.layer.1.intermediate.dense.weight",
                "bert.encoder.layer.1.intermediate.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_100",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: gelu_103 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "gelu_103"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_100",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 31800
        },
        "matmul_1001": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_132 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.18.intermediate.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.18.intermediate.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_132": "Data",
                "bert.encoder.layer.18.intermediate.dense.bias": "Data",
                "bert.encoder.layer.18.intermediate.dense.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_132",
                "bert.encoder.layer.18.intermediate.dense.weight",
                "bert.encoder.layer.18.intermediate.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1001",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: gelu_1004 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "gelu_1004"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_1001",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33568
        },
        "matmul_1007": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: gelu_1004 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.18.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.18.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.18.output.dense.bias": "Data",
                "bert.encoder.layer.18.output.dense.weight": "Data",
                "gelu_1004": "Data"
            },
            "input_nodes": [
                "gelu_1004",
                "bert.encoder.layer.18.output.dense.weight",
                "bert.encoder.layer.18.output.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1007",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_1011 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_1011"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_1007",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33572
        },
        "matmul_1015": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_134 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.19.attention.self.query.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.19.attention.self.query.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_134": "Data",
                "bert.encoder.layer.19.attention.self.query.bias": "Data",
                "bert.encoder.layer.19.attention.self.query.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_134",
                "bert.encoder.layer.19.attention.self.query.weight",
                "bert.encoder.layer.19.attention.self.query.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1015",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1027 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1027"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query",
                "original_op_name": "matmul_1015",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33600
        },
        "matmul_1021": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_134 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.19.attention.self.key.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.19.attention.self.key.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_134": "Data",
                "bert.encoder.layer.19.attention.self.key.bias": "Data",
                "bert.encoder.layer.19.attention.self.key.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_134",
                "bert.encoder.layer.19.attention.self.key.weight",
                "bert.encoder.layer.19.attention.self.key.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1021",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1027 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1027"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key",
                "original_op_name": "matmul_1021",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33606
        },
        "matmul_1027": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1015 (port_0) ublock_order(c)",
                "Data: matmul_1021 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "matmul_1015": "Data",
                "matmul_1021": "Data"
            },
            "input_nodes": [
                "matmul_1015",
                "matmul_1021"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [],
                            "buda_attrs": {},
                            "named_attrs": {
                                "dim0": -2,
                                "dim1": -1,
                                "z_dim_slice": -1
                            },
                            "type": "transpose"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "vslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1027",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_135 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_135"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_1027",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33613
        },
        "matmul_1035": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_134 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.19.attention.self.value.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.19.attention.self.value.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_134": "Data",
                "bert.encoder.layer.19.attention.self.value.bias": "Data",
                "bert.encoder.layer.19.attention.self.value.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_134",
                "bert.encoder.layer.19.attention.self.value.weight",
                "bert.encoder.layer.19.attention.self.value.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1035",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1042 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1042"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value",
                "original_op_name": "matmul_1035",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33635
        },
        "matmul_1042": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_137 (port_0) ublock_order(c)",
                "Data: matmul_1035 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_137": "Data",
                "matmul_1035": "Data"
            },
            "input_nodes": [
                "_fused_op_137",
                "matmul_1035"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1042",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1046 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1046"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_1042",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33641
        },
        "matmul_1046": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1042 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.19.attention.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.19.attention.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.19.attention.output.dense.bias": "Data",
                "bert.encoder.layer.19.attention.output.dense.weight": "Data",
                "matmul_1042": "Data"
            },
            "input_nodes": [
                "matmul_1042",
                "bert.encoder.layer.19.attention.output.dense.weight",
                "bert.encoder.layer.19.attention.output.dense.bias"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hstack"
                        }
                    }
                ],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1046",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_1050 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_1050"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_1046",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33644
        },
        "matmul_1054": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_139 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.19.intermediate.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.19.intermediate.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_139": "Data",
                "bert.encoder.layer.19.intermediate.dense.bias": "Data",
                "bert.encoder.layer.19.intermediate.dense.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_139",
                "bert.encoder.layer.19.intermediate.dense.weight",
                "bert.encoder.layer.19.intermediate.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1054",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: gelu_1057 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "gelu_1057"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_1054",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33672
        },
        "matmul_106": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: gelu_103 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.1.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.1.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.1.output.dense.bias": "Data",
                "bert.encoder.layer.1.output.dense.weight": "Data",
                "gelu_103": "Data"
            },
            "input_nodes": [
                "gelu_103",
                "bert.encoder.layer.1.output.dense.weight",
                "bert.encoder.layer.1.output.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_106",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_110 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_110"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_106",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 31804
        },
        "matmul_1060": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: gelu_1057 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.19.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.19.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.19.output.dense.bias": "Data",
                "bert.encoder.layer.19.output.dense.weight": "Data",
                "gelu_1057": "Data"
            },
            "input_nodes": [
                "gelu_1057",
                "bert.encoder.layer.19.output.dense.weight",
                "bert.encoder.layer.19.output.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1060",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_1064 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_1064"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_1060",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33676
        },
        "matmul_1068": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_141 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.20.attention.self.query.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.20.attention.self.query.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_141": "Data",
                "bert.encoder.layer.20.attention.self.query.bias": "Data",
                "bert.encoder.layer.20.attention.self.query.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_141",
                "bert.encoder.layer.20.attention.self.query.weight",
                "bert.encoder.layer.20.attention.self.query.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1068",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1080 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1080"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query",
                "original_op_name": "matmul_1068",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33704
        },
        "matmul_1074": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_141 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.20.attention.self.key.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.20.attention.self.key.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_141": "Data",
                "bert.encoder.layer.20.attention.self.key.bias": "Data",
                "bert.encoder.layer.20.attention.self.key.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_141",
                "bert.encoder.layer.20.attention.self.key.weight",
                "bert.encoder.layer.20.attention.self.key.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1074",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1080 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1080"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key",
                "original_op_name": "matmul_1074",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33710
        },
        "matmul_1080": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1068 (port_0) ublock_order(c)",
                "Data: matmul_1074 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "matmul_1068": "Data",
                "matmul_1074": "Data"
            },
            "input_nodes": [
                "matmul_1068",
                "matmul_1074"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [],
                            "buda_attrs": {},
                            "named_attrs": {
                                "dim0": -2,
                                "dim1": -1,
                                "z_dim_slice": -1
                            },
                            "type": "transpose"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "vslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1080",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_142 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_142"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_1080",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33717
        },
        "matmul_1088": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_141 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.20.attention.self.value.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.20.attention.self.value.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_141": "Data",
                "bert.encoder.layer.20.attention.self.value.bias": "Data",
                "bert.encoder.layer.20.attention.self.value.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_141",
                "bert.encoder.layer.20.attention.self.value.weight",
                "bert.encoder.layer.20.attention.self.value.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1088",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1095 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1095"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value",
                "original_op_name": "matmul_1088",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33739
        },
        "matmul_1095": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_144 (port_0) ublock_order(c)",
                "Data: matmul_1088 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_144": "Data",
                "matmul_1088": "Data"
            },
            "input_nodes": [
                "_fused_op_144",
                "matmul_1088"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1095",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1099 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1099"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_1095",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33745
        },
        "matmul_1099": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1095 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.20.attention.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.20.attention.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.20.attention.output.dense.bias": "Data",
                "bert.encoder.layer.20.attention.output.dense.weight": "Data",
                "matmul_1095": "Data"
            },
            "input_nodes": [
                "matmul_1095",
                "bert.encoder.layer.20.attention.output.dense.weight",
                "bert.encoder.layer.20.attention.output.dense.bias"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hstack"
                        }
                    }
                ],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1099",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_1103 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_1103"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_1099",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33748
        },
        "matmul_1107": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_146 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.20.intermediate.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.20.intermediate.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_146": "Data",
                "bert.encoder.layer.20.intermediate.dense.bias": "Data",
                "bert.encoder.layer.20.intermediate.dense.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_146",
                "bert.encoder.layer.20.intermediate.dense.weight",
                "bert.encoder.layer.20.intermediate.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1107",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: gelu_1110 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "gelu_1110"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_1107",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33776
        },
        "matmul_1113": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: gelu_1110 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.20.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.20.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.20.output.dense.bias": "Data",
                "bert.encoder.layer.20.output.dense.weight": "Data",
                "gelu_1110": "Data"
            },
            "input_nodes": [
                "gelu_1110",
                "bert.encoder.layer.20.output.dense.weight",
                "bert.encoder.layer.20.output.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1113",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_1117 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_1117"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_1113",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33780
        },
        "matmul_1121": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_148 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.21.attention.self.query.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.21.attention.self.query.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_148": "Data",
                "bert.encoder.layer.21.attention.self.query.bias": "Data",
                "bert.encoder.layer.21.attention.self.query.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_148",
                "bert.encoder.layer.21.attention.self.query.weight",
                "bert.encoder.layer.21.attention.self.query.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1121",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1133 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1133"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query",
                "original_op_name": "matmul_1121",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33808
        },
        "matmul_1127": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_148 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.21.attention.self.key.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.21.attention.self.key.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_148": "Data",
                "bert.encoder.layer.21.attention.self.key.bias": "Data",
                "bert.encoder.layer.21.attention.self.key.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_148",
                "bert.encoder.layer.21.attention.self.key.weight",
                "bert.encoder.layer.21.attention.self.key.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1127",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1133 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1133"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key",
                "original_op_name": "matmul_1127",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33814
        },
        "matmul_1133": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1121 (port_0) ublock_order(c)",
                "Data: matmul_1127 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "matmul_1121": "Data",
                "matmul_1127": "Data"
            },
            "input_nodes": [
                "matmul_1121",
                "matmul_1127"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [],
                            "buda_attrs": {},
                            "named_attrs": {
                                "dim0": -2,
                                "dim1": -1,
                                "z_dim_slice": -1
                            },
                            "type": "transpose"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "vslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1133",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_149 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_149"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_1133",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33821
        },
        "matmul_114": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_15 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.2.attention.self.query.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.2.attention.self.query.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_15": "Data",
                "bert.encoder.layer.2.attention.self.query.bias": "Data",
                "bert.encoder.layer.2.attention.self.query.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_15",
                "bert.encoder.layer.2.attention.self.query.weight",
                "bert.encoder.layer.2.attention.self.query.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_114",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_126 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_126"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query",
                "original_op_name": "matmul_114",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 31832
        },
        "matmul_1141": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_148 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.21.attention.self.value.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.21.attention.self.value.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_148": "Data",
                "bert.encoder.layer.21.attention.self.value.bias": "Data",
                "bert.encoder.layer.21.attention.self.value.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_148",
                "bert.encoder.layer.21.attention.self.value.weight",
                "bert.encoder.layer.21.attention.self.value.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1141",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1148 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1148"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value",
                "original_op_name": "matmul_1141",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33843
        },
        "matmul_1148": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_151 (port_0) ublock_order(c)",
                "Data: matmul_1141 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_151": "Data",
                "matmul_1141": "Data"
            },
            "input_nodes": [
                "_fused_op_151",
                "matmul_1141"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1148",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1152 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1152"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_1148",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33849
        },
        "matmul_1152": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1148 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.21.attention.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.21.attention.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.21.attention.output.dense.bias": "Data",
                "bert.encoder.layer.21.attention.output.dense.weight": "Data",
                "matmul_1148": "Data"
            },
            "input_nodes": [
                "matmul_1148",
                "bert.encoder.layer.21.attention.output.dense.weight",
                "bert.encoder.layer.21.attention.output.dense.bias"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hstack"
                        }
                    }
                ],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1152",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_1156 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_1156"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_1152",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33852
        },
        "matmul_1160": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_153 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.21.intermediate.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.21.intermediate.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_153": "Data",
                "bert.encoder.layer.21.intermediate.dense.bias": "Data",
                "bert.encoder.layer.21.intermediate.dense.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_153",
                "bert.encoder.layer.21.intermediate.dense.weight",
                "bert.encoder.layer.21.intermediate.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1160",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: gelu_1163 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "gelu_1163"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_1160",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33880
        },
        "matmul_1166": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: gelu_1163 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.21.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.21.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.21.output.dense.bias": "Data",
                "bert.encoder.layer.21.output.dense.weight": "Data",
                "gelu_1163": "Data"
            },
            "input_nodes": [
                "gelu_1163",
                "bert.encoder.layer.21.output.dense.weight",
                "bert.encoder.layer.21.output.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1166",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_1170 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_1170"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_1166",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33884
        },
        "matmul_1174": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_155 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.22.attention.self.query.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.22.attention.self.query.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_155": "Data",
                "bert.encoder.layer.22.attention.self.query.bias": "Data",
                "bert.encoder.layer.22.attention.self.query.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_155",
                "bert.encoder.layer.22.attention.self.query.weight",
                "bert.encoder.layer.22.attention.self.query.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1174",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1186 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1186"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query",
                "original_op_name": "matmul_1174",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33912
        },
        "matmul_1180": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_155 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.22.attention.self.key.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.22.attention.self.key.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_155": "Data",
                "bert.encoder.layer.22.attention.self.key.bias": "Data",
                "bert.encoder.layer.22.attention.self.key.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_155",
                "bert.encoder.layer.22.attention.self.key.weight",
                "bert.encoder.layer.22.attention.self.key.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1180",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1186 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1186"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key",
                "original_op_name": "matmul_1180",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33918
        },
        "matmul_1186": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1174 (port_0) ublock_order(c)",
                "Data: matmul_1180 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "matmul_1174": "Data",
                "matmul_1180": "Data"
            },
            "input_nodes": [
                "matmul_1174",
                "matmul_1180"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [],
                            "buda_attrs": {},
                            "named_attrs": {
                                "dim0": -2,
                                "dim1": -1,
                                "z_dim_slice": -1
                            },
                            "type": "transpose"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "vslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1186",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_156 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_156"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_1186",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33925
        },
        "matmul_1194": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_155 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.22.attention.self.value.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.22.attention.self.value.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_155": "Data",
                "bert.encoder.layer.22.attention.self.value.bias": "Data",
                "bert.encoder.layer.22.attention.self.value.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_155",
                "bert.encoder.layer.22.attention.self.value.weight",
                "bert.encoder.layer.22.attention.self.value.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1194",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1201 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1201"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value",
                "original_op_name": "matmul_1194",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33947
        },
        "matmul_120": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_15 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.2.attention.self.key.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.2.attention.self.key.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_15": "Data",
                "bert.encoder.layer.2.attention.self.key.bias": "Data",
                "bert.encoder.layer.2.attention.self.key.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_15",
                "bert.encoder.layer.2.attention.self.key.weight",
                "bert.encoder.layer.2.attention.self.key.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_120",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_126 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_126"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key",
                "original_op_name": "matmul_120",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 31838
        },
        "matmul_1201": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_158 (port_0) ublock_order(c)",
                "Data: matmul_1194 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_158": "Data",
                "matmul_1194": "Data"
            },
            "input_nodes": [
                "_fused_op_158",
                "matmul_1194"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1201",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1205 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1205"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_1201",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33953
        },
        "matmul_1205": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1201 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.22.attention.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.22.attention.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.22.attention.output.dense.bias": "Data",
                "bert.encoder.layer.22.attention.output.dense.weight": "Data",
                "matmul_1201": "Data"
            },
            "input_nodes": [
                "matmul_1201",
                "bert.encoder.layer.22.attention.output.dense.weight",
                "bert.encoder.layer.22.attention.output.dense.bias"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hstack"
                        }
                    }
                ],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1205",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_1209 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_1209"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_1205",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33956
        },
        "matmul_1213": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_160 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.22.intermediate.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.22.intermediate.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_160": "Data",
                "bert.encoder.layer.22.intermediate.dense.bias": "Data",
                "bert.encoder.layer.22.intermediate.dense.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_160",
                "bert.encoder.layer.22.intermediate.dense.weight",
                "bert.encoder.layer.22.intermediate.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1213",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: gelu_1216 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "gelu_1216"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_1213",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33984
        },
        "matmul_1219": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: gelu_1216 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.22.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.22.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.22.output.dense.bias": "Data",
                "bert.encoder.layer.22.output.dense.weight": "Data",
                "gelu_1216": "Data"
            },
            "input_nodes": [
                "gelu_1216",
                "bert.encoder.layer.22.output.dense.weight",
                "bert.encoder.layer.22.output.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1219",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_1223 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_1223"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_1219",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33988
        },
        "matmul_1227": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_162 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.23.attention.self.query.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.23.attention.self.query.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_162": "Data",
                "bert.encoder.layer.23.attention.self.query.bias": "Data",
                "bert.encoder.layer.23.attention.self.query.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_162",
                "bert.encoder.layer.23.attention.self.query.weight",
                "bert.encoder.layer.23.attention.self.query.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1227",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1239 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1239"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query",
                "original_op_name": "matmul_1227",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 34016
        },
        "matmul_1233": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_162 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.23.attention.self.key.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.23.attention.self.key.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_162": "Data",
                "bert.encoder.layer.23.attention.self.key.bias": "Data",
                "bert.encoder.layer.23.attention.self.key.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_162",
                "bert.encoder.layer.23.attention.self.key.weight",
                "bert.encoder.layer.23.attention.self.key.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1233",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1239 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1239"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key",
                "original_op_name": "matmul_1233",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 34022
        },
        "matmul_1239": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1227 (port_0) ublock_order(c)",
                "Data: matmul_1233 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "matmul_1227": "Data",
                "matmul_1233": "Data"
            },
            "input_nodes": [
                "matmul_1227",
                "matmul_1233"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [],
                            "buda_attrs": {},
                            "named_attrs": {
                                "dim0": -2,
                                "dim1": -1,
                                "z_dim_slice": -1
                            },
                            "type": "transpose"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "vslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1239",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_163 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_163"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_1239",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 34029
        },
        "matmul_1247": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_162 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.23.attention.self.value.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.23.attention.self.value.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_162": "Data",
                "bert.encoder.layer.23.attention.self.value.bias": "Data",
                "bert.encoder.layer.23.attention.self.value.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_162",
                "bert.encoder.layer.23.attention.self.value.weight",
                "bert.encoder.layer.23.attention.self.value.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1247",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1254 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1254"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value",
                "original_op_name": "matmul_1247",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 34051
        },
        "matmul_1254": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_165 (port_0) ublock_order(c)",
                "Data: matmul_1247 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_165": "Data",
                "matmul_1247": "Data"
            },
            "input_nodes": [
                "_fused_op_165",
                "matmul_1247"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1254",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1258 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1258"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_1254",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 34057
        },
        "matmul_1258": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1254 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.23.attention.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.23.attention.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.23.attention.output.dense.bias": "Data",
                "bert.encoder.layer.23.attention.output.dense.weight": "Data",
                "matmul_1254": "Data"
            },
            "input_nodes": [
                "matmul_1254",
                "bert.encoder.layer.23.attention.output.dense.weight",
                "bert.encoder.layer.23.attention.output.dense.bias"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hstack"
                        }
                    }
                ],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1258",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_1262 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_1262"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_1258",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 34060
        },
        "matmul_126": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_114 (port_0) ublock_order(c)",
                "Data: matmul_120 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "matmul_114": "Data",
                "matmul_120": "Data"
            },
            "input_nodes": [
                "matmul_114",
                "matmul_120"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [],
                            "buda_attrs": {},
                            "named_attrs": {
                                "dim0": -2,
                                "dim1": -1,
                                "z_dim_slice": -1
                            },
                            "type": "transpose"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "vslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_126",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_16 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_16"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_126",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 31845
        },
        "matmul_1266": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_167 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.23.intermediate.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.23.intermediate.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_167": "Data",
                "bert.encoder.layer.23.intermediate.dense.bias": "Data",
                "bert.encoder.layer.23.intermediate.dense.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_167",
                "bert.encoder.layer.23.intermediate.dense.weight",
                "bert.encoder.layer.23.intermediate.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1266",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: gelu_1269 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "gelu_1269"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_1266",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 34088
        },
        "matmul_1272": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: gelu_1269 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.23.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.23.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.23.output.dense.bias": "Data",
                "bert.encoder.layer.23.output.dense.weight": "Data",
                "gelu_1269": "Data"
            },
            "input_nodes": [
                "gelu_1269",
                "bert.encoder.layer.23.output.dense.weight",
                "bert.encoder.layer.23.output.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1272",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_1276 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_1276"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_1272",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 34092
        },
        "matmul_1281": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_169 (port_0) ublock_order(c)",
                "Data: qa_outputs.weight (port_1) ublock_order(r)",
                "Data: qa_outputs.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_169": "Data",
                "qa_outputs.bias": "Data",
                "qa_outputs.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_169",
                "qa_outputs.weight",
                "qa_outputs.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1281",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1281_output_nop_0 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1281_output_nop_0"
            ],
            "pybuda": 1,
            "tags": {
                "original_op_name": "matmul_1281",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 34120
        },
        "matmul_1281_output_nop_0": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1281 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "matmul_1281": "Data"
            },
            "input_nodes": [
                "matmul_1281"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1281_output_nop_0",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: bert_large_tt_1.output_reshape_1285 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "bert_large_tt_1.output_reshape_1285"
            ],
            "pybuda": 1,
            "tags": {
                "original_op_name": "matmul_1281",
                "original_op_type": "matmul"
            },
            "type": "nop",
            "unique_id": 34298
        },
        "matmul_1288": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_169 (port_0) ublock_order(c)",
                "Data: qa_outputs.weight_fork_clone19 (port_1) ublock_order(r)",
                "Data: qa_outputs.bias_fork_clone12 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_169": "Data",
                "qa_outputs.bias_fork_clone12": "Data",
                "qa_outputs.weight_fork_clone19": "Data"
            },
            "input_nodes": [
                "_fused_op_169",
                "qa_outputs.weight_fork_clone19",
                "qa_outputs.bias_fork_clone12"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1288",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1288_output_nop_0 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1288_output_nop_0"
            ],
            "pybuda": 1,
            "tags": {
                "original_op_name": "matmul_1288",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 34124
        },
        "matmul_1288_output_nop_0": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_1288 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "matmul_1288": "Data"
            },
            "input_nodes": [
                "matmul_1288"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1288_output_nop_0",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: bert_large_tt_1.output_reshape_1292 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "bert_large_tt_1.output_reshape_1292"
            ],
            "pybuda": 1,
            "tags": {
                "original_op_name": "matmul_1288",
                "original_op_type": "matmul"
            },
            "type": "nop",
            "unique_id": 34299
        },
        "matmul_134": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_15 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.2.attention.self.value.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.2.attention.self.value.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_15": "Data",
                "bert.encoder.layer.2.attention.self.value.bias": "Data",
                "bert.encoder.layer.2.attention.self.value.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_15",
                "bert.encoder.layer.2.attention.self.value.weight",
                "bert.encoder.layer.2.attention.self.value.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_134",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_141 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_141"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value",
                "original_op_name": "matmul_134",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 31867
        },
        "matmul_141": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_18 (port_0) ublock_order(c)",
                "Data: matmul_134 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_18": "Data",
                "matmul_134": "Data"
            },
            "input_nodes": [
                "_fused_op_18",
                "matmul_134"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_141",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_145 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_145"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_141",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 31873
        },
        "matmul_145": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_141 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.2.attention.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.2.attention.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.2.attention.output.dense.bias": "Data",
                "bert.encoder.layer.2.attention.output.dense.weight": "Data",
                "matmul_141": "Data"
            },
            "input_nodes": [
                "matmul_141",
                "bert.encoder.layer.2.attention.output.dense.weight",
                "bert.encoder.layer.2.attention.output.dense.bias"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hstack"
                        }
                    }
                ],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_145",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_149 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_149"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_145",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 31876
        },
        "matmul_153": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_20 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.2.intermediate.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.2.intermediate.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_20": "Data",
                "bert.encoder.layer.2.intermediate.dense.bias": "Data",
                "bert.encoder.layer.2.intermediate.dense.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_20",
                "bert.encoder.layer.2.intermediate.dense.weight",
                "bert.encoder.layer.2.intermediate.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_153",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: gelu_156 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "gelu_156"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_153",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 31904
        },
        "matmul_159": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: gelu_156 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.2.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.2.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.2.output.dense.bias": "Data",
                "bert.encoder.layer.2.output.dense.weight": "Data",
                "gelu_156": "Data"
            },
            "input_nodes": [
                "gelu_156",
                "bert.encoder.layer.2.output.dense.weight",
                "bert.encoder.layer.2.output.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_159",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_163 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_163"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_159",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 31908
        },
        "matmul_16": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_4 (port_0) ublock_order(c)",
                "Data: matmul_10 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "matmul_10": "Data",
                "matmul_4": "Data"
            },
            "input_nodes": [
                "matmul_4",
                "matmul_10"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [],
                            "buda_attrs": {},
                            "named_attrs": {
                                "dim0": -2,
                                "dim1": -1,
                                "z_dim_slice": -1
                            },
                            "type": "transpose"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "vslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_16",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_2 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_2"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_16",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 31629
        },
        "matmul_167": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_22 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.3.attention.self.query.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.3.attention.self.query.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_22": "Data",
                "bert.encoder.layer.3.attention.self.query.bias": "Data",
                "bert.encoder.layer.3.attention.self.query.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_22",
                "bert.encoder.layer.3.attention.self.query.weight",
                "bert.encoder.layer.3.attention.self.query.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_167",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_179 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_179"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query",
                "original_op_name": "matmul_167",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 31936
        },
        "matmul_173": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_22 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.3.attention.self.key.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.3.attention.self.key.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_22": "Data",
                "bert.encoder.layer.3.attention.self.key.bias": "Data",
                "bert.encoder.layer.3.attention.self.key.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_22",
                "bert.encoder.layer.3.attention.self.key.weight",
                "bert.encoder.layer.3.attention.self.key.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_173",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_179 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_179"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key",
                "original_op_name": "matmul_173",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 31942
        },
        "matmul_179": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_167 (port_0) ublock_order(c)",
                "Data: matmul_173 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "matmul_167": "Data",
                "matmul_173": "Data"
            },
            "input_nodes": [
                "matmul_167",
                "matmul_173"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [],
                            "buda_attrs": {},
                            "named_attrs": {
                                "dim0": -2,
                                "dim1": -1,
                                "z_dim_slice": -1
                            },
                            "type": "transpose"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "vslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_179",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_23 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_23"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_179",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 31949
        },
        "matmul_187": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_22 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.3.attention.self.value.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.3.attention.self.value.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_22": "Data",
                "bert.encoder.layer.3.attention.self.value.bias": "Data",
                "bert.encoder.layer.3.attention.self.value.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_22",
                "bert.encoder.layer.3.attention.self.value.weight",
                "bert.encoder.layer.3.attention.self.value.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_187",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_194 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_194"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value",
                "original_op_name": "matmul_187",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 31971
        },
        "matmul_194": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_25 (port_0) ublock_order(c)",
                "Data: matmul_187 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_25": "Data",
                "matmul_187": "Data"
            },
            "input_nodes": [
                "_fused_op_25",
                "matmul_187"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_194",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_198 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_198"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_194",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 31977
        },
        "matmul_198": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_194 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.3.attention.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.3.attention.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.3.attention.output.dense.bias": "Data",
                "bert.encoder.layer.3.attention.output.dense.weight": "Data",
                "matmul_194": "Data"
            },
            "input_nodes": [
                "matmul_194",
                "bert.encoder.layer.3.attention.output.dense.weight",
                "bert.encoder.layer.3.attention.output.dense.bias"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hstack"
                        }
                    }
                ],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_198",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_202 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_202"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_198",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 31980
        },
        "matmul_206": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_27 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.3.intermediate.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.3.intermediate.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_27": "Data",
                "bert.encoder.layer.3.intermediate.dense.bias": "Data",
                "bert.encoder.layer.3.intermediate.dense.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_27",
                "bert.encoder.layer.3.intermediate.dense.weight",
                "bert.encoder.layer.3.intermediate.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_206",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: gelu_209 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "gelu_209"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_206",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32008
        },
        "matmul_212": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: gelu_209 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.3.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.3.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.3.output.dense.bias": "Data",
                "bert.encoder.layer.3.output.dense.weight": "Data",
                "gelu_209": "Data"
            },
            "input_nodes": [
                "gelu_209",
                "bert.encoder.layer.3.output.dense.weight",
                "bert.encoder.layer.3.output.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_212",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_216 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_216"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_212",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32012
        },
        "matmul_220": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_29 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.4.attention.self.query.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.4.attention.self.query.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_29": "Data",
                "bert.encoder.layer.4.attention.self.query.bias": "Data",
                "bert.encoder.layer.4.attention.self.query.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_29",
                "bert.encoder.layer.4.attention.self.query.weight",
                "bert.encoder.layer.4.attention.self.query.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_220",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_232 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_232"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query",
                "original_op_name": "matmul_220",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32040
        },
        "matmul_226": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_29 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.4.attention.self.key.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.4.attention.self.key.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_29": "Data",
                "bert.encoder.layer.4.attention.self.key.bias": "Data",
                "bert.encoder.layer.4.attention.self.key.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_29",
                "bert.encoder.layer.4.attention.self.key.weight",
                "bert.encoder.layer.4.attention.self.key.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_226",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_232 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_232"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key",
                "original_op_name": "matmul_226",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32046
        },
        "matmul_232": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_220 (port_0) ublock_order(c)",
                "Data: matmul_226 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "matmul_220": "Data",
                "matmul_226": "Data"
            },
            "input_nodes": [
                "matmul_220",
                "matmul_226"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [],
                            "buda_attrs": {},
                            "named_attrs": {
                                "dim0": -2,
                                "dim1": -1,
                                "z_dim_slice": -1
                            },
                            "type": "transpose"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "vslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_232",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_30 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_30"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_232",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32053
        },
        "matmul_240": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_29 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.4.attention.self.value.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.4.attention.self.value.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_29": "Data",
                "bert.encoder.layer.4.attention.self.value.bias": "Data",
                "bert.encoder.layer.4.attention.self.value.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_29",
                "bert.encoder.layer.4.attention.self.value.weight",
                "bert.encoder.layer.4.attention.self.value.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_240",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_247 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_247"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value",
                "original_op_name": "matmul_240",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32075
        },
        "matmul_247": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_32 (port_0) ublock_order(c)",
                "Data: matmul_240 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_32": "Data",
                "matmul_240": "Data"
            },
            "input_nodes": [
                "_fused_op_32",
                "matmul_240"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_247",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_251 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_251"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_247",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32081
        },
        "matmul_251": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_247 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.4.attention.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.4.attention.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.4.attention.output.dense.bias": "Data",
                "bert.encoder.layer.4.attention.output.dense.weight": "Data",
                "matmul_247": "Data"
            },
            "input_nodes": [
                "matmul_247",
                "bert.encoder.layer.4.attention.output.dense.weight",
                "bert.encoder.layer.4.attention.output.dense.bias"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hstack"
                        }
                    }
                ],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_251",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_255 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_255"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_251",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32084
        },
        "matmul_259": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_34 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.4.intermediate.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.4.intermediate.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_34": "Data",
                "bert.encoder.layer.4.intermediate.dense.bias": "Data",
                "bert.encoder.layer.4.intermediate.dense.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_34",
                "bert.encoder.layer.4.intermediate.dense.weight",
                "bert.encoder.layer.4.intermediate.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_259",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: gelu_262 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "gelu_262"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_259",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32112
        },
        "matmul_265": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: gelu_262 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.4.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.4.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.4.output.dense.bias": "Data",
                "bert.encoder.layer.4.output.dense.weight": "Data",
                "gelu_262": "Data"
            },
            "input_nodes": [
                "gelu_262",
                "bert.encoder.layer.4.output.dense.weight",
                "bert.encoder.layer.4.output.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_265",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_269 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_269"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_265",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32116
        },
        "matmul_273": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_36 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.5.attention.self.query.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.5.attention.self.query.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_36": "Data",
                "bert.encoder.layer.5.attention.self.query.bias": "Data",
                "bert.encoder.layer.5.attention.self.query.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_36",
                "bert.encoder.layer.5.attention.self.query.weight",
                "bert.encoder.layer.5.attention.self.query.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_273",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_285 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_285"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query",
                "original_op_name": "matmul_273",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32144
        },
        "matmul_279": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_36 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.5.attention.self.key.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.5.attention.self.key.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_36": "Data",
                "bert.encoder.layer.5.attention.self.key.bias": "Data",
                "bert.encoder.layer.5.attention.self.key.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_36",
                "bert.encoder.layer.5.attention.self.key.weight",
                "bert.encoder.layer.5.attention.self.key.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_279",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_285 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_285"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key",
                "original_op_name": "matmul_279",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32150
        },
        "matmul_28": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_1 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.0.attention.self.value.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.0.attention.self.value.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_1": "Data",
                "bert.encoder.layer.0.attention.self.value.bias": "Data",
                "bert.encoder.layer.0.attention.self.value.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_1",
                "bert.encoder.layer.0.attention.self.value.weight",
                "bert.encoder.layer.0.attention.self.value.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_28",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_35 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_35"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value",
                "original_op_name": "matmul_28",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 31659
        },
        "matmul_285": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_273 (port_0) ublock_order(c)",
                "Data: matmul_279 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "matmul_273": "Data",
                "matmul_279": "Data"
            },
            "input_nodes": [
                "matmul_273",
                "matmul_279"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [],
                            "buda_attrs": {},
                            "named_attrs": {
                                "dim0": -2,
                                "dim1": -1,
                                "z_dim_slice": -1
                            },
                            "type": "transpose"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "vslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_285",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_37 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_37"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_285",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32157
        },
        "matmul_293": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_36 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.5.attention.self.value.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.5.attention.self.value.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_36": "Data",
                "bert.encoder.layer.5.attention.self.value.bias": "Data",
                "bert.encoder.layer.5.attention.self.value.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_36",
                "bert.encoder.layer.5.attention.self.value.weight",
                "bert.encoder.layer.5.attention.self.value.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_293",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_300 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_300"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value",
                "original_op_name": "matmul_293",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32179
        },
        "matmul_300": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_39 (port_0) ublock_order(c)",
                "Data: matmul_293 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_39": "Data",
                "matmul_293": "Data"
            },
            "input_nodes": [
                "_fused_op_39",
                "matmul_293"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_300",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_304 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_304"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_300",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32185
        },
        "matmul_304": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_300 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.5.attention.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.5.attention.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.5.attention.output.dense.bias": "Data",
                "bert.encoder.layer.5.attention.output.dense.weight": "Data",
                "matmul_300": "Data"
            },
            "input_nodes": [
                "matmul_300",
                "bert.encoder.layer.5.attention.output.dense.weight",
                "bert.encoder.layer.5.attention.output.dense.bias"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hstack"
                        }
                    }
                ],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_304",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_308 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_308"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_304",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32188
        },
        "matmul_312": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_41 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.5.intermediate.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.5.intermediate.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_41": "Data",
                "bert.encoder.layer.5.intermediate.dense.bias": "Data",
                "bert.encoder.layer.5.intermediate.dense.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_41",
                "bert.encoder.layer.5.intermediate.dense.weight",
                "bert.encoder.layer.5.intermediate.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_312",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: gelu_315 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "gelu_315"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_312",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32216
        },
        "matmul_318": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: gelu_315 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.5.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.5.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.5.output.dense.bias": "Data",
                "bert.encoder.layer.5.output.dense.weight": "Data",
                "gelu_315": "Data"
            },
            "input_nodes": [
                "gelu_315",
                "bert.encoder.layer.5.output.dense.weight",
                "bert.encoder.layer.5.output.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_318",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_322 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_322"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_318",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32220
        },
        "matmul_326": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_43 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.6.attention.self.query.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.6.attention.self.query.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_43": "Data",
                "bert.encoder.layer.6.attention.self.query.bias": "Data",
                "bert.encoder.layer.6.attention.self.query.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_43",
                "bert.encoder.layer.6.attention.self.query.weight",
                "bert.encoder.layer.6.attention.self.query.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_326",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_338 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_338"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query",
                "original_op_name": "matmul_326",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32248
        },
        "matmul_332": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_43 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.6.attention.self.key.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.6.attention.self.key.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_43": "Data",
                "bert.encoder.layer.6.attention.self.key.bias": "Data",
                "bert.encoder.layer.6.attention.self.key.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_43",
                "bert.encoder.layer.6.attention.self.key.weight",
                "bert.encoder.layer.6.attention.self.key.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_332",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_338 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_338"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key",
                "original_op_name": "matmul_332",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32254
        },
        "matmul_338": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_326 (port_0) ublock_order(c)",
                "Data: matmul_332 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "matmul_326": "Data",
                "matmul_332": "Data"
            },
            "input_nodes": [
                "matmul_326",
                "matmul_332"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [],
                            "buda_attrs": {},
                            "named_attrs": {
                                "dim0": -2,
                                "dim1": -1,
                                "z_dim_slice": -1
                            },
                            "type": "transpose"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "vslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_338",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_44 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_44"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_338",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32261
        },
        "matmul_346": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_43 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.6.attention.self.value.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.6.attention.self.value.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_43": "Data",
                "bert.encoder.layer.6.attention.self.value.bias": "Data",
                "bert.encoder.layer.6.attention.self.value.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_43",
                "bert.encoder.layer.6.attention.self.value.weight",
                "bert.encoder.layer.6.attention.self.value.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_346",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_353 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_353"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value",
                "original_op_name": "matmul_346",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32283
        },
        "matmul_35": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_4 (port_0) ublock_order(c)",
                "Data: matmul_28 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_4": "Data",
                "matmul_28": "Data"
            },
            "input_nodes": [
                "_fused_op_4",
                "matmul_28"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_35",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_39 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_39"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_35",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 31665
        },
        "matmul_353": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_46 (port_0) ublock_order(c)",
                "Data: matmul_346 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_46": "Data",
                "matmul_346": "Data"
            },
            "input_nodes": [
                "_fused_op_46",
                "matmul_346"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_353",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_357 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_357"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_353",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32289
        },
        "matmul_357": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_353 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.6.attention.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.6.attention.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.6.attention.output.dense.bias": "Data",
                "bert.encoder.layer.6.attention.output.dense.weight": "Data",
                "matmul_353": "Data"
            },
            "input_nodes": [
                "matmul_353",
                "bert.encoder.layer.6.attention.output.dense.weight",
                "bert.encoder.layer.6.attention.output.dense.bias"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hstack"
                        }
                    }
                ],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_357",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_361 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_361"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_357",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32292
        },
        "matmul_365": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_48 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.6.intermediate.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.6.intermediate.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_48": "Data",
                "bert.encoder.layer.6.intermediate.dense.bias": "Data",
                "bert.encoder.layer.6.intermediate.dense.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_48",
                "bert.encoder.layer.6.intermediate.dense.weight",
                "bert.encoder.layer.6.intermediate.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_365",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: gelu_368 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "gelu_368"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_365",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32320
        },
        "matmul_371": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: gelu_368 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.6.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.6.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.6.output.dense.bias": "Data",
                "bert.encoder.layer.6.output.dense.weight": "Data",
                "gelu_368": "Data"
            },
            "input_nodes": [
                "gelu_368",
                "bert.encoder.layer.6.output.dense.weight",
                "bert.encoder.layer.6.output.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_371",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_375 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_375"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_371",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32324
        },
        "matmul_379": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_50 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.7.attention.self.query.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.7.attention.self.query.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_50": "Data",
                "bert.encoder.layer.7.attention.self.query.bias": "Data",
                "bert.encoder.layer.7.attention.self.query.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_50",
                "bert.encoder.layer.7.attention.self.query.weight",
                "bert.encoder.layer.7.attention.self.query.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_379",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_391 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_391"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query",
                "original_op_name": "matmul_379",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32352
        },
        "matmul_385": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_50 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.7.attention.self.key.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.7.attention.self.key.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_50": "Data",
                "bert.encoder.layer.7.attention.self.key.bias": "Data",
                "bert.encoder.layer.7.attention.self.key.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_50",
                "bert.encoder.layer.7.attention.self.key.weight",
                "bert.encoder.layer.7.attention.self.key.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_385",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_391 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_391"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key",
                "original_op_name": "matmul_385",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32358
        },
        "matmul_39": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_35 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.0.attention.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.0.attention.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.0.attention.output.dense.bias": "Data",
                "bert.encoder.layer.0.attention.output.dense.weight": "Data",
                "matmul_35": "Data"
            },
            "input_nodes": [
                "matmul_35",
                "bert.encoder.layer.0.attention.output.dense.weight",
                "bert.encoder.layer.0.attention.output.dense.bias"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hstack"
                        }
                    }
                ],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_39",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_43 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_43"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_39",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 31668
        },
        "matmul_391": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_379 (port_0) ublock_order(c)",
                "Data: matmul_385 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "matmul_379": "Data",
                "matmul_385": "Data"
            },
            "input_nodes": [
                "matmul_379",
                "matmul_385"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [],
                            "buda_attrs": {},
                            "named_attrs": {
                                "dim0": -2,
                                "dim1": -1,
                                "z_dim_slice": -1
                            },
                            "type": "transpose"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "vslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_391",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_51 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_51"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_391",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32365
        },
        "matmul_399": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_50 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.7.attention.self.value.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.7.attention.self.value.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_50": "Data",
                "bert.encoder.layer.7.attention.self.value.bias": "Data",
                "bert.encoder.layer.7.attention.self.value.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_50",
                "bert.encoder.layer.7.attention.self.value.weight",
                "bert.encoder.layer.7.attention.self.value.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_399",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_406 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_406"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value",
                "original_op_name": "matmul_399",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32387
        },
        "matmul_4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_1 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.0.attention.self.query.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.0.attention.self.query.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_1": "Data",
                "bert.encoder.layer.0.attention.self.query.bias": "Data",
                "bert.encoder.layer.0.attention.self.query.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_1",
                "bert.encoder.layer.0.attention.self.query.weight",
                "bert.encoder.layer.0.attention.self.query.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_4",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_16 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_16"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query",
                "original_op_name": "matmul_4",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 31616
        },
        "matmul_406": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_53 (port_0) ublock_order(c)",
                "Data: matmul_399 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_53": "Data",
                "matmul_399": "Data"
            },
            "input_nodes": [
                "_fused_op_53",
                "matmul_399"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_406",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_410 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_410"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_406",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32393
        },
        "matmul_410": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_406 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.7.attention.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.7.attention.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.7.attention.output.dense.bias": "Data",
                "bert.encoder.layer.7.attention.output.dense.weight": "Data",
                "matmul_406": "Data"
            },
            "input_nodes": [
                "matmul_406",
                "bert.encoder.layer.7.attention.output.dense.weight",
                "bert.encoder.layer.7.attention.output.dense.bias"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hstack"
                        }
                    }
                ],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_410",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_414 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_414"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_410",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32396
        },
        "matmul_418": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_55 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.7.intermediate.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.7.intermediate.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_55": "Data",
                "bert.encoder.layer.7.intermediate.dense.bias": "Data",
                "bert.encoder.layer.7.intermediate.dense.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_55",
                "bert.encoder.layer.7.intermediate.dense.weight",
                "bert.encoder.layer.7.intermediate.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_418",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: gelu_421 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "gelu_421"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_418",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32424
        },
        "matmul_424": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: gelu_421 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.7.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.7.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.7.output.dense.bias": "Data",
                "bert.encoder.layer.7.output.dense.weight": "Data",
                "gelu_421": "Data"
            },
            "input_nodes": [
                "gelu_421",
                "bert.encoder.layer.7.output.dense.weight",
                "bert.encoder.layer.7.output.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_424",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_428 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_428"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_424",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32428
        },
        "matmul_432": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_57 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.8.attention.self.query.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.8.attention.self.query.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_57": "Data",
                "bert.encoder.layer.8.attention.self.query.bias": "Data",
                "bert.encoder.layer.8.attention.self.query.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_57",
                "bert.encoder.layer.8.attention.self.query.weight",
                "bert.encoder.layer.8.attention.self.query.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_432",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_444 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_444"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query",
                "original_op_name": "matmul_432",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32456
        },
        "matmul_438": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_57 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.8.attention.self.key.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.8.attention.self.key.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_57": "Data",
                "bert.encoder.layer.8.attention.self.key.bias": "Data",
                "bert.encoder.layer.8.attention.self.key.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_57",
                "bert.encoder.layer.8.attention.self.key.weight",
                "bert.encoder.layer.8.attention.self.key.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_438",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_444 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_444"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key",
                "original_op_name": "matmul_438",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32462
        },
        "matmul_444": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_432 (port_0) ublock_order(c)",
                "Data: matmul_438 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "matmul_432": "Data",
                "matmul_438": "Data"
            },
            "input_nodes": [
                "matmul_432",
                "matmul_438"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [],
                            "buda_attrs": {},
                            "named_attrs": {
                                "dim0": -2,
                                "dim1": -1,
                                "z_dim_slice": -1
                            },
                            "type": "transpose"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "vslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_444",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_58 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_58"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_444",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32469
        },
        "matmul_452": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_57 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.8.attention.self.value.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.8.attention.self.value.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_57": "Data",
                "bert.encoder.layer.8.attention.self.value.bias": "Data",
                "bert.encoder.layer.8.attention.self.value.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_57",
                "bert.encoder.layer.8.attention.self.value.weight",
                "bert.encoder.layer.8.attention.self.value.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_452",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_459 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_459"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value",
                "original_op_name": "matmul_452",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32491
        },
        "matmul_459": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_60 (port_0) ublock_order(c)",
                "Data: matmul_452 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_60": "Data",
                "matmul_452": "Data"
            },
            "input_nodes": [
                "_fused_op_60",
                "matmul_452"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_459",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_463 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_463"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_459",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32497
        },
        "matmul_463": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_459 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.8.attention.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.8.attention.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.8.attention.output.dense.bias": "Data",
                "bert.encoder.layer.8.attention.output.dense.weight": "Data",
                "matmul_459": "Data"
            },
            "input_nodes": [
                "matmul_459",
                "bert.encoder.layer.8.attention.output.dense.weight",
                "bert.encoder.layer.8.attention.output.dense.bias"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hstack"
                        }
                    }
                ],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_463",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_467 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_467"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_463",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32500
        },
        "matmul_47": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_6 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.0.intermediate.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.0.intermediate.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_6": "Data",
                "bert.encoder.layer.0.intermediate.dense.bias": "Data",
                "bert.encoder.layer.0.intermediate.dense.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_6",
                "bert.encoder.layer.0.intermediate.dense.weight",
                "bert.encoder.layer.0.intermediate.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_47",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: gelu_50 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "gelu_50"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_47",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 31696
        },
        "matmul_471": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_62 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.8.intermediate.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.8.intermediate.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_62": "Data",
                "bert.encoder.layer.8.intermediate.dense.bias": "Data",
                "bert.encoder.layer.8.intermediate.dense.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_62",
                "bert.encoder.layer.8.intermediate.dense.weight",
                "bert.encoder.layer.8.intermediate.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_471",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: gelu_474 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "gelu_474"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_471",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32528
        },
        "matmul_477": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: gelu_474 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.8.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.8.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.8.output.dense.bias": "Data",
                "bert.encoder.layer.8.output.dense.weight": "Data",
                "gelu_474": "Data"
            },
            "input_nodes": [
                "gelu_474",
                "bert.encoder.layer.8.output.dense.weight",
                "bert.encoder.layer.8.output.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_477",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_481 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_481"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_477",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32532
        },
        "matmul_485": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_64 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.9.attention.self.query.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.9.attention.self.query.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_64": "Data",
                "bert.encoder.layer.9.attention.self.query.bias": "Data",
                "bert.encoder.layer.9.attention.self.query.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_64",
                "bert.encoder.layer.9.attention.self.query.weight",
                "bert.encoder.layer.9.attention.self.query.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_485",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_497 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_497"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query",
                "original_op_name": "matmul_485",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32560
        },
        "matmul_491": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_64 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.9.attention.self.key.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.9.attention.self.key.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_64": "Data",
                "bert.encoder.layer.9.attention.self.key.bias": "Data",
                "bert.encoder.layer.9.attention.self.key.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_64",
                "bert.encoder.layer.9.attention.self.key.weight",
                "bert.encoder.layer.9.attention.self.key.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_491",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_497 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_497"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key",
                "original_op_name": "matmul_491",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32566
        },
        "matmul_497": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_485 (port_0) ublock_order(c)",
                "Data: matmul_491 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "matmul_485": "Data",
                "matmul_491": "Data"
            },
            "input_nodes": [
                "matmul_485",
                "matmul_491"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [],
                            "buda_attrs": {},
                            "named_attrs": {
                                "dim0": -2,
                                "dim1": -1,
                                "z_dim_slice": -1
                            },
                            "type": "transpose"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "vslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_497",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_65 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_65"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_497",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32573
        },
        "matmul_505": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_64 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.9.attention.self.value.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.9.attention.self.value.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_64": "Data",
                "bert.encoder.layer.9.attention.self.value.bias": "Data",
                "bert.encoder.layer.9.attention.self.value.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_64",
                "bert.encoder.layer.9.attention.self.value.weight",
                "bert.encoder.layer.9.attention.self.value.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_505",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_512 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_512"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value",
                "original_op_name": "matmul_505",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32595
        },
        "matmul_512": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_67 (port_0) ublock_order(c)",
                "Data: matmul_505 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_67": "Data",
                "matmul_505": "Data"
            },
            "input_nodes": [
                "_fused_op_67",
                "matmul_505"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_512",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_516 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_516"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_512",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32601
        },
        "matmul_516": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_512 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.9.attention.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.9.attention.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.9.attention.output.dense.bias": "Data",
                "bert.encoder.layer.9.attention.output.dense.weight": "Data",
                "matmul_512": "Data"
            },
            "input_nodes": [
                "matmul_512",
                "bert.encoder.layer.9.attention.output.dense.weight",
                "bert.encoder.layer.9.attention.output.dense.bias"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hstack"
                        }
                    }
                ],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_516",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_520 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_520"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_516",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32604
        },
        "matmul_524": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_69 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.9.intermediate.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.9.intermediate.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_69": "Data",
                "bert.encoder.layer.9.intermediate.dense.bias": "Data",
                "bert.encoder.layer.9.intermediate.dense.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_69",
                "bert.encoder.layer.9.intermediate.dense.weight",
                "bert.encoder.layer.9.intermediate.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_524",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: gelu_527 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "gelu_527"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_524",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32632
        },
        "matmul_53": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: gelu_50 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.0.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.0.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.0.output.dense.bias": "Data",
                "bert.encoder.layer.0.output.dense.weight": "Data",
                "gelu_50": "Data"
            },
            "input_nodes": [
                "gelu_50",
                "bert.encoder.layer.0.output.dense.weight",
                "bert.encoder.layer.0.output.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_53",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_57 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_57"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_53",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 31700
        },
        "matmul_530": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: gelu_527 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.9.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.9.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.9.output.dense.bias": "Data",
                "bert.encoder.layer.9.output.dense.weight": "Data",
                "gelu_527": "Data"
            },
            "input_nodes": [
                "gelu_527",
                "bert.encoder.layer.9.output.dense.weight",
                "bert.encoder.layer.9.output.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_530",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_534 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_534"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_530",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32636
        },
        "matmul_538": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_71 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.10.attention.self.query.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.10.attention.self.query.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_71": "Data",
                "bert.encoder.layer.10.attention.self.query.bias": "Data",
                "bert.encoder.layer.10.attention.self.query.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_71",
                "bert.encoder.layer.10.attention.self.query.weight",
                "bert.encoder.layer.10.attention.self.query.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_538",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_550 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_550"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query",
                "original_op_name": "matmul_538",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32664
        },
        "matmul_544": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_71 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.10.attention.self.key.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.10.attention.self.key.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_71": "Data",
                "bert.encoder.layer.10.attention.self.key.bias": "Data",
                "bert.encoder.layer.10.attention.self.key.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_71",
                "bert.encoder.layer.10.attention.self.key.weight",
                "bert.encoder.layer.10.attention.self.key.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_544",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_550 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_550"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key",
                "original_op_name": "matmul_544",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32670
        },
        "matmul_550": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_538 (port_0) ublock_order(c)",
                "Data: matmul_544 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "matmul_538": "Data",
                "matmul_544": "Data"
            },
            "input_nodes": [
                "matmul_538",
                "matmul_544"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [],
                            "buda_attrs": {},
                            "named_attrs": {
                                "dim0": -2,
                                "dim1": -1,
                                "z_dim_slice": -1
                            },
                            "type": "transpose"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "vslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_550",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_72 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_72"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_550",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32677
        },
        "matmul_558": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_71 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.10.attention.self.value.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.10.attention.self.value.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_71": "Data",
                "bert.encoder.layer.10.attention.self.value.bias": "Data",
                "bert.encoder.layer.10.attention.self.value.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_71",
                "bert.encoder.layer.10.attention.self.value.weight",
                "bert.encoder.layer.10.attention.self.value.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_558",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_565 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_565"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value",
                "original_op_name": "matmul_558",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32699
        },
        "matmul_565": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_74 (port_0) ublock_order(c)",
                "Data: matmul_558 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_74": "Data",
                "matmul_558": "Data"
            },
            "input_nodes": [
                "_fused_op_74",
                "matmul_558"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_565",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_569 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_569"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_565",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32705
        },
        "matmul_569": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_565 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.10.attention.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.10.attention.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.10.attention.output.dense.bias": "Data",
                "bert.encoder.layer.10.attention.output.dense.weight": "Data",
                "matmul_565": "Data"
            },
            "input_nodes": [
                "matmul_565",
                "bert.encoder.layer.10.attention.output.dense.weight",
                "bert.encoder.layer.10.attention.output.dense.bias"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hstack"
                        }
                    }
                ],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_569",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_573 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_573"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_569",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32708
        },
        "matmul_577": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_76 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.10.intermediate.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.10.intermediate.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_76": "Data",
                "bert.encoder.layer.10.intermediate.dense.bias": "Data",
                "bert.encoder.layer.10.intermediate.dense.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_76",
                "bert.encoder.layer.10.intermediate.dense.weight",
                "bert.encoder.layer.10.intermediate.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_577",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: gelu_580 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "gelu_580"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_577",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32736
        },
        "matmul_583": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: gelu_580 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.10.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.10.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.10.output.dense.bias": "Data",
                "bert.encoder.layer.10.output.dense.weight": "Data",
                "gelu_580": "Data"
            },
            "input_nodes": [
                "gelu_580",
                "bert.encoder.layer.10.output.dense.weight",
                "bert.encoder.layer.10.output.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_583",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_587 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_587"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_583",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32740
        },
        "matmul_591": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_78 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.11.attention.self.query.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.11.attention.self.query.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_78": "Data",
                "bert.encoder.layer.11.attention.self.query.bias": "Data",
                "bert.encoder.layer.11.attention.self.query.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_78",
                "bert.encoder.layer.11.attention.self.query.weight",
                "bert.encoder.layer.11.attention.self.query.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_591",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_603 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_603"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query",
                "original_op_name": "matmul_591",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32768
        },
        "matmul_597": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_78 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.11.attention.self.key.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.11.attention.self.key.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_78": "Data",
                "bert.encoder.layer.11.attention.self.key.bias": "Data",
                "bert.encoder.layer.11.attention.self.key.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_78",
                "bert.encoder.layer.11.attention.self.key.weight",
                "bert.encoder.layer.11.attention.self.key.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_597",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_603 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_603"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key",
                "original_op_name": "matmul_597",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32774
        },
        "matmul_603": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_591 (port_0) ublock_order(c)",
                "Data: matmul_597 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "matmul_591": "Data",
                "matmul_597": "Data"
            },
            "input_nodes": [
                "matmul_591",
                "matmul_597"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [],
                            "buda_attrs": {},
                            "named_attrs": {
                                "dim0": -2,
                                "dim1": -1,
                                "z_dim_slice": -1
                            },
                            "type": "transpose"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "vslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_603",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_79 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_79"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_603",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32781
        },
        "matmul_61": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_8 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.1.attention.self.query.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.1.attention.self.query.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_8": "Data",
                "bert.encoder.layer.1.attention.self.query.bias": "Data",
                "bert.encoder.layer.1.attention.self.query.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_8",
                "bert.encoder.layer.1.attention.self.query.weight",
                "bert.encoder.layer.1.attention.self.query.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_61",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_73 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_73"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query",
                "original_op_name": "matmul_61",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 31728
        },
        "matmul_611": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_78 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.11.attention.self.value.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.11.attention.self.value.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_78": "Data",
                "bert.encoder.layer.11.attention.self.value.bias": "Data",
                "bert.encoder.layer.11.attention.self.value.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_78",
                "bert.encoder.layer.11.attention.self.value.weight",
                "bert.encoder.layer.11.attention.self.value.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_611",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_618 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_618"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value",
                "original_op_name": "matmul_611",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32803
        },
        "matmul_618": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_81 (port_0) ublock_order(c)",
                "Data: matmul_611 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_81": "Data",
                "matmul_611": "Data"
            },
            "input_nodes": [
                "_fused_op_81",
                "matmul_611"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_618",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_622 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_622"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_618",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32809
        },
        "matmul_622": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_618 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.11.attention.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.11.attention.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.11.attention.output.dense.bias": "Data",
                "bert.encoder.layer.11.attention.output.dense.weight": "Data",
                "matmul_618": "Data"
            },
            "input_nodes": [
                "matmul_618",
                "bert.encoder.layer.11.attention.output.dense.weight",
                "bert.encoder.layer.11.attention.output.dense.bias"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hstack"
                        }
                    }
                ],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_622",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_626 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_626"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_622",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32812
        },
        "matmul_630": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_83 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.11.intermediate.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.11.intermediate.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_83": "Data",
                "bert.encoder.layer.11.intermediate.dense.bias": "Data",
                "bert.encoder.layer.11.intermediate.dense.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_83",
                "bert.encoder.layer.11.intermediate.dense.weight",
                "bert.encoder.layer.11.intermediate.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_630",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: gelu_633 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "gelu_633"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_630",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32840
        },
        "matmul_636": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: gelu_633 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.11.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.11.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.11.output.dense.bias": "Data",
                "bert.encoder.layer.11.output.dense.weight": "Data",
                "gelu_633": "Data"
            },
            "input_nodes": [
                "gelu_633",
                "bert.encoder.layer.11.output.dense.weight",
                "bert.encoder.layer.11.output.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_636",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_640 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_640"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_636",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32844
        },
        "matmul_644": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_85 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.12.attention.self.query.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.12.attention.self.query.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_85": "Data",
                "bert.encoder.layer.12.attention.self.query.bias": "Data",
                "bert.encoder.layer.12.attention.self.query.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_85",
                "bert.encoder.layer.12.attention.self.query.weight",
                "bert.encoder.layer.12.attention.self.query.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_644",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_656 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_656"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query",
                "original_op_name": "matmul_644",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32872
        },
        "matmul_650": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_85 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.12.attention.self.key.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.12.attention.self.key.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_85": "Data",
                "bert.encoder.layer.12.attention.self.key.bias": "Data",
                "bert.encoder.layer.12.attention.self.key.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_85",
                "bert.encoder.layer.12.attention.self.key.weight",
                "bert.encoder.layer.12.attention.self.key.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_650",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_656 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_656"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key",
                "original_op_name": "matmul_650",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32878
        },
        "matmul_656": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_644 (port_0) ublock_order(c)",
                "Data: matmul_650 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "matmul_644": "Data",
                "matmul_650": "Data"
            },
            "input_nodes": [
                "matmul_644",
                "matmul_650"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [],
                            "buda_attrs": {},
                            "named_attrs": {
                                "dim0": -2,
                                "dim1": -1,
                                "z_dim_slice": -1
                            },
                            "type": "transpose"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "vslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_656",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_86 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_86"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_656",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32885
        },
        "matmul_664": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_85 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.12.attention.self.value.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.12.attention.self.value.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_85": "Data",
                "bert.encoder.layer.12.attention.self.value.bias": "Data",
                "bert.encoder.layer.12.attention.self.value.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_85",
                "bert.encoder.layer.12.attention.self.value.weight",
                "bert.encoder.layer.12.attention.self.value.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_664",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_671 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_671"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value",
                "original_op_name": "matmul_664",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32907
        },
        "matmul_67": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_8 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.1.attention.self.key.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.1.attention.self.key.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_8": "Data",
                "bert.encoder.layer.1.attention.self.key.bias": "Data",
                "bert.encoder.layer.1.attention.self.key.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_8",
                "bert.encoder.layer.1.attention.self.key.weight",
                "bert.encoder.layer.1.attention.self.key.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_67",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_73 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_73"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key",
                "original_op_name": "matmul_67",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 31734
        },
        "matmul_671": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_88 (port_0) ublock_order(c)",
                "Data: matmul_664 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_88": "Data",
                "matmul_664": "Data"
            },
            "input_nodes": [
                "_fused_op_88",
                "matmul_664"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_671",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_675 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_675"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_671",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32913
        },
        "matmul_675": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_671 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.12.attention.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.12.attention.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.12.attention.output.dense.bias": "Data",
                "bert.encoder.layer.12.attention.output.dense.weight": "Data",
                "matmul_671": "Data"
            },
            "input_nodes": [
                "matmul_671",
                "bert.encoder.layer.12.attention.output.dense.weight",
                "bert.encoder.layer.12.attention.output.dense.bias"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hstack"
                        }
                    }
                ],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_675",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_679 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_679"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_675",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32916
        },
        "matmul_683": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_90 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.12.intermediate.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.12.intermediate.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_90": "Data",
                "bert.encoder.layer.12.intermediate.dense.bias": "Data",
                "bert.encoder.layer.12.intermediate.dense.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_90",
                "bert.encoder.layer.12.intermediate.dense.weight",
                "bert.encoder.layer.12.intermediate.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_683",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: gelu_686 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "gelu_686"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_683",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32944
        },
        "matmul_689": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: gelu_686 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.12.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.12.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.12.output.dense.bias": "Data",
                "bert.encoder.layer.12.output.dense.weight": "Data",
                "gelu_686": "Data"
            },
            "input_nodes": [
                "gelu_686",
                "bert.encoder.layer.12.output.dense.weight",
                "bert.encoder.layer.12.output.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_689",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_693 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_693"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_689",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32948
        },
        "matmul_697": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_92 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.13.attention.self.query.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.13.attention.self.query.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_92": "Data",
                "bert.encoder.layer.13.attention.self.query.bias": "Data",
                "bert.encoder.layer.13.attention.self.query.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_92",
                "bert.encoder.layer.13.attention.self.query.weight",
                "bert.encoder.layer.13.attention.self.query.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_697",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_709 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_709"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query",
                "original_op_name": "matmul_697",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32976
        },
        "matmul_703": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_92 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.13.attention.self.key.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.13.attention.self.key.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_92": "Data",
                "bert.encoder.layer.13.attention.self.key.bias": "Data",
                "bert.encoder.layer.13.attention.self.key.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_92",
                "bert.encoder.layer.13.attention.self.key.weight",
                "bert.encoder.layer.13.attention.self.key.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_703",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_709 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_709"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key",
                "original_op_name": "matmul_703",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32982
        },
        "matmul_709": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_697 (port_0) ublock_order(c)",
                "Data: matmul_703 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "matmul_697": "Data",
                "matmul_703": "Data"
            },
            "input_nodes": [
                "matmul_697",
                "matmul_703"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [],
                            "buda_attrs": {},
                            "named_attrs": {
                                "dim0": -2,
                                "dim1": -1,
                                "z_dim_slice": -1
                            },
                            "type": "transpose"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "vslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_709",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_93 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_93"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_709",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 32989
        },
        "matmul_717": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_92 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.13.attention.self.value.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.13.attention.self.value.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_92": "Data",
                "bert.encoder.layer.13.attention.self.value.bias": "Data",
                "bert.encoder.layer.13.attention.self.value.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_92",
                "bert.encoder.layer.13.attention.self.value.weight",
                "bert.encoder.layer.13.attention.self.value.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_717",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_724 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_724"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value",
                "original_op_name": "matmul_717",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33011
        },
        "matmul_724": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_95 (port_0) ublock_order(c)",
                "Data: matmul_717 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_95": "Data",
                "matmul_717": "Data"
            },
            "input_nodes": [
                "_fused_op_95",
                "matmul_717"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_724",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_728 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_728"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_724",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33017
        },
        "matmul_728": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_724 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.13.attention.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.13.attention.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.13.attention.output.dense.bias": "Data",
                "bert.encoder.layer.13.attention.output.dense.weight": "Data",
                "matmul_724": "Data"
            },
            "input_nodes": [
                "matmul_724",
                "bert.encoder.layer.13.attention.output.dense.weight",
                "bert.encoder.layer.13.attention.output.dense.bias"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hstack"
                        }
                    }
                ],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_728",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_732 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_732"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_728",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33020
        },
        "matmul_73": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_61 (port_0) ublock_order(c)",
                "Data: matmul_67 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "matmul_61": "Data",
                "matmul_67": "Data"
            },
            "input_nodes": [
                "matmul_61",
                "matmul_67"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [],
                            "buda_attrs": {},
                            "named_attrs": {
                                "dim0": -2,
                                "dim1": -1,
                                "z_dim_slice": -1
                            },
                            "type": "transpose"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "vslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_73",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_9 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_9"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_73",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 31741
        },
        "matmul_736": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_97 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.13.intermediate.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.13.intermediate.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_97": "Data",
                "bert.encoder.layer.13.intermediate.dense.bias": "Data",
                "bert.encoder.layer.13.intermediate.dense.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_97",
                "bert.encoder.layer.13.intermediate.dense.weight",
                "bert.encoder.layer.13.intermediate.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_736",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: gelu_739 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "gelu_739"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_736",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33048
        },
        "matmul_742": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: gelu_739 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.13.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.13.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.13.output.dense.bias": "Data",
                "bert.encoder.layer.13.output.dense.weight": "Data",
                "gelu_739": "Data"
            },
            "input_nodes": [
                "gelu_739",
                "bert.encoder.layer.13.output.dense.weight",
                "bert.encoder.layer.13.output.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_742",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_746 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_746"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_742",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33052
        },
        "matmul_750": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_99 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.14.attention.self.query.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.14.attention.self.query.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_99": "Data",
                "bert.encoder.layer.14.attention.self.query.bias": "Data",
                "bert.encoder.layer.14.attention.self.query.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_99",
                "bert.encoder.layer.14.attention.self.query.weight",
                "bert.encoder.layer.14.attention.self.query.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_750",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_762 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_762"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query",
                "original_op_name": "matmul_750",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33080
        },
        "matmul_756": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_99 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.14.attention.self.key.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.14.attention.self.key.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_99": "Data",
                "bert.encoder.layer.14.attention.self.key.bias": "Data",
                "bert.encoder.layer.14.attention.self.key.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_99",
                "bert.encoder.layer.14.attention.self.key.weight",
                "bert.encoder.layer.14.attention.self.key.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_756",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_762 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_762"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key",
                "original_op_name": "matmul_756",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33086
        },
        "matmul_762": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_750 (port_0) ublock_order(c)",
                "Data: matmul_756 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "matmul_750": "Data",
                "matmul_756": "Data"
            },
            "input_nodes": [
                "matmul_750",
                "matmul_756"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [],
                            "buda_attrs": {},
                            "named_attrs": {
                                "dim0": -2,
                                "dim1": -1,
                                "z_dim_slice": -1
                            },
                            "type": "transpose"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "vslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_762",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_100 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_100"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_762",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33093
        },
        "matmul_770": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_99 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.14.attention.self.value.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.14.attention.self.value.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_99": "Data",
                "bert.encoder.layer.14.attention.self.value.bias": "Data",
                "bert.encoder.layer.14.attention.self.value.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_99",
                "bert.encoder.layer.14.attention.self.value.weight",
                "bert.encoder.layer.14.attention.self.value.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_770",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_777 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_777"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value",
                "original_op_name": "matmul_770",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33115
        },
        "matmul_777": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_102 (port_0) ublock_order(c)",
                "Data: matmul_770 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_102": "Data",
                "matmul_770": "Data"
            },
            "input_nodes": [
                "_fused_op_102",
                "matmul_770"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_777",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_781 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_781"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_777",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33121
        },
        "matmul_781": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_777 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.14.attention.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.14.attention.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.14.attention.output.dense.bias": "Data",
                "bert.encoder.layer.14.attention.output.dense.weight": "Data",
                "matmul_777": "Data"
            },
            "input_nodes": [
                "matmul_777",
                "bert.encoder.layer.14.attention.output.dense.weight",
                "bert.encoder.layer.14.attention.output.dense.bias"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hstack"
                        }
                    }
                ],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_781",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_785 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_785"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_781",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33124
        },
        "matmul_789": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_104 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.14.intermediate.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.14.intermediate.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_104": "Data",
                "bert.encoder.layer.14.intermediate.dense.bias": "Data",
                "bert.encoder.layer.14.intermediate.dense.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_104",
                "bert.encoder.layer.14.intermediate.dense.weight",
                "bert.encoder.layer.14.intermediate.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_789",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: gelu_792 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "gelu_792"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_789",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33152
        },
        "matmul_795": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: gelu_792 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.14.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.14.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.14.output.dense.bias": "Data",
                "bert.encoder.layer.14.output.dense.weight": "Data",
                "gelu_792": "Data"
            },
            "input_nodes": [
                "gelu_792",
                "bert.encoder.layer.14.output.dense.weight",
                "bert.encoder.layer.14.output.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_795",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_799 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_799"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_795",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33156
        },
        "matmul_803": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_106 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.15.attention.self.query.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.15.attention.self.query.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_106": "Data",
                "bert.encoder.layer.15.attention.self.query.bias": "Data",
                "bert.encoder.layer.15.attention.self.query.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_106",
                "bert.encoder.layer.15.attention.self.query.weight",
                "bert.encoder.layer.15.attention.self.query.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_803",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_815 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_815"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query",
                "original_op_name": "matmul_803",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33184
        },
        "matmul_809": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_106 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.15.attention.self.key.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.15.attention.self.key.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_106": "Data",
                "bert.encoder.layer.15.attention.self.key.bias": "Data",
                "bert.encoder.layer.15.attention.self.key.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_106",
                "bert.encoder.layer.15.attention.self.key.weight",
                "bert.encoder.layer.15.attention.self.key.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_809",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_815 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_815"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key",
                "original_op_name": "matmul_809",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33190
        },
        "matmul_81": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_8 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.1.attention.self.value.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.1.attention.self.value.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_8": "Data",
                "bert.encoder.layer.1.attention.self.value.bias": "Data",
                "bert.encoder.layer.1.attention.self.value.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_8",
                "bert.encoder.layer.1.attention.self.value.weight",
                "bert.encoder.layer.1.attention.self.value.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_81",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_88 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_88"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value",
                "original_op_name": "matmul_81",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 31763
        },
        "matmul_815": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_803 (port_0) ublock_order(c)",
                "Data: matmul_809 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "matmul_803": "Data",
                "matmul_809": "Data"
            },
            "input_nodes": [
                "matmul_803",
                "matmul_809"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [],
                            "buda_attrs": {},
                            "named_attrs": {
                                "dim0": -2,
                                "dim1": -1,
                                "z_dim_slice": -1
                            },
                            "type": "transpose"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "vslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_815",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_107 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_107"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_815",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33197
        },
        "matmul_823": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_106 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.15.attention.self.value.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.15.attention.self.value.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_106": "Data",
                "bert.encoder.layer.15.attention.self.value.bias": "Data",
                "bert.encoder.layer.15.attention.self.value.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_106",
                "bert.encoder.layer.15.attention.self.value.weight",
                "bert.encoder.layer.15.attention.self.value.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_823",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_830 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_830"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value",
                "original_op_name": "matmul_823",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33219
        },
        "matmul_830": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_109 (port_0) ublock_order(c)",
                "Data: matmul_823 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_109": "Data",
                "matmul_823": "Data"
            },
            "input_nodes": [
                "_fused_op_109",
                "matmul_823"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_830",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_834 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_834"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_830",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33225
        },
        "matmul_834": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_830 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.15.attention.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.15.attention.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.15.attention.output.dense.bias": "Data",
                "bert.encoder.layer.15.attention.output.dense.weight": "Data",
                "matmul_830": "Data"
            },
            "input_nodes": [
                "matmul_830",
                "bert.encoder.layer.15.attention.output.dense.weight",
                "bert.encoder.layer.15.attention.output.dense.bias"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hstack"
                        }
                    }
                ],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_834",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_838 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_838"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_834",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33228
        },
        "matmul_842": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_111 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.15.intermediate.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.15.intermediate.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_111": "Data",
                "bert.encoder.layer.15.intermediate.dense.bias": "Data",
                "bert.encoder.layer.15.intermediate.dense.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_111",
                "bert.encoder.layer.15.intermediate.dense.weight",
                "bert.encoder.layer.15.intermediate.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_842",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: gelu_845 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "gelu_845"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_842",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33256
        },
        "matmul_848": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: gelu_845 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.15.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.15.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.15.output.dense.bias": "Data",
                "bert.encoder.layer.15.output.dense.weight": "Data",
                "gelu_845": "Data"
            },
            "input_nodes": [
                "gelu_845",
                "bert.encoder.layer.15.output.dense.weight",
                "bert.encoder.layer.15.output.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_848",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_852 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_852"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_848",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33260
        },
        "matmul_856": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_113 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.16.attention.self.query.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.16.attention.self.query.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_113": "Data",
                "bert.encoder.layer.16.attention.self.query.bias": "Data",
                "bert.encoder.layer.16.attention.self.query.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_113",
                "bert.encoder.layer.16.attention.self.query.weight",
                "bert.encoder.layer.16.attention.self.query.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_856",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_868 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_868"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query",
                "original_op_name": "matmul_856",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33288
        },
        "matmul_862": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_113 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.16.attention.self.key.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.16.attention.self.key.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_113": "Data",
                "bert.encoder.layer.16.attention.self.key.bias": "Data",
                "bert.encoder.layer.16.attention.self.key.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_113",
                "bert.encoder.layer.16.attention.self.key.weight",
                "bert.encoder.layer.16.attention.self.key.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_862",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_868 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_868"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key",
                "original_op_name": "matmul_862",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33294
        },
        "matmul_868": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_856 (port_0) ublock_order(c)",
                "Data: matmul_862 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "matmul_856": "Data",
                "matmul_862": "Data"
            },
            "input_nodes": [
                "matmul_856",
                "matmul_862"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [],
                            "buda_attrs": {},
                            "named_attrs": {
                                "dim0": -2,
                                "dim1": -1,
                                "z_dim_slice": -1
                            },
                            "type": "transpose"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "vslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_868",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_114 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_114"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_868",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33301
        },
        "matmul_876": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_113 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.16.attention.self.value.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.16.attention.self.value.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_113": "Data",
                "bert.encoder.layer.16.attention.self.value.bias": "Data",
                "bert.encoder.layer.16.attention.self.value.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_113",
                "bert.encoder.layer.16.attention.self.value.weight",
                "bert.encoder.layer.16.attention.self.value.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_876",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_883 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_883"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value",
                "original_op_name": "matmul_876",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33323
        },
        "matmul_88": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_11 (port_0) ublock_order(c)",
                "Data: matmul_81 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_11": "Data",
                "matmul_81": "Data"
            },
            "input_nodes": [
                "_fused_op_11",
                "matmul_81"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_88",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_92 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_92"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_88",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 31769
        },
        "matmul_883": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_116 (port_0) ublock_order(c)",
                "Data: matmul_876 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_116": "Data",
                "matmul_876": "Data"
            },
            "input_nodes": [
                "_fused_op_116",
                "matmul_876"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_883",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_887 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_887"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_883",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33329
        },
        "matmul_887": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_883 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.16.attention.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.16.attention.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.16.attention.output.dense.bias": "Data",
                "bert.encoder.layer.16.attention.output.dense.weight": "Data",
                "matmul_883": "Data"
            },
            "input_nodes": [
                "matmul_883",
                "bert.encoder.layer.16.attention.output.dense.weight",
                "bert.encoder.layer.16.attention.output.dense.bias"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hstack"
                        }
                    }
                ],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_887",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_891 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_891"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_887",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33332
        },
        "matmul_895": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_118 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.16.intermediate.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.16.intermediate.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_118": "Data",
                "bert.encoder.layer.16.intermediate.dense.bias": "Data",
                "bert.encoder.layer.16.intermediate.dense.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_118",
                "bert.encoder.layer.16.intermediate.dense.weight",
                "bert.encoder.layer.16.intermediate.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_895",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: gelu_898 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "gelu_898"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_895",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33360
        },
        "matmul_901": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: gelu_898 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.16.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.16.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.16.output.dense.bias": "Data",
                "bert.encoder.layer.16.output.dense.weight": "Data",
                "gelu_898": "Data"
            },
            "input_nodes": [
                "gelu_898",
                "bert.encoder.layer.16.output.dense.weight",
                "bert.encoder.layer.16.output.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_901",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_905 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_905"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_901",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33364
        },
        "matmul_909": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_120 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.17.attention.self.query.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.17.attention.self.query.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_120": "Data",
                "bert.encoder.layer.17.attention.self.query.bias": "Data",
                "bert.encoder.layer.17.attention.self.query.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_120",
                "bert.encoder.layer.17.attention.self.query.weight",
                "bert.encoder.layer.17.attention.self.query.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_909",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_921 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_921"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query",
                "original_op_name": "matmul_909",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33392
        },
        "matmul_915": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_120 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.17.attention.self.key.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.17.attention.self.key.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_120": "Data",
                "bert.encoder.layer.17.attention.self.key.bias": "Data",
                "bert.encoder.layer.17.attention.self.key.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_120",
                "bert.encoder.layer.17.attention.self.key.weight",
                "bert.encoder.layer.17.attention.self.key.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_915",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_921 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_921"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key",
                "original_op_name": "matmul_915",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33398
        },
        "matmul_92": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_88 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.1.attention.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.1.attention.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.1.attention.output.dense.bias": "Data",
                "bert.encoder.layer.1.attention.output.dense.weight": "Data",
                "matmul_88": "Data"
            },
            "input_nodes": [
                "matmul_88",
                "bert.encoder.layer.1.attention.output.dense.weight",
                "bert.encoder.layer.1.attention.output.dense.bias"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hstack"
                        }
                    }
                ],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_92",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_96 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_96"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_92",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 31772
        },
        "matmul_921": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_909 (port_0) ublock_order(c)",
                "Data: matmul_915 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "matmul_909": "Data",
                "matmul_915": "Data"
            },
            "input_nodes": [
                "matmul_909",
                "matmul_915"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [],
                            "buda_attrs": {},
                            "named_attrs": {
                                "dim0": -2,
                                "dim1": -1,
                                "z_dim_slice": -1
                            },
                            "type": "transpose"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "vslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_921",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_121 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_121"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_921",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33405
        },
        "matmul_929": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_120 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.17.attention.self.value.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.17.attention.self.value.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_120": "Data",
                "bert.encoder.layer.17.attention.self.value.bias": "Data",
                "bert.encoder.layer.17.attention.self.value.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_120",
                "bert.encoder.layer.17.attention.self.value.weight",
                "bert.encoder.layer.17.attention.self.value.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_929",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_936 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_936"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value",
                "original_op_name": "matmul_929",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33427
        },
        "matmul_936": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_123 (port_0) ublock_order(c)",
                "Data: matmul_929 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_123": "Data",
                "matmul_929": "Data"
            },
            "input_nodes": [
                "_fused_op_123",
                "matmul_929"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_936",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_940 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_940"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_936",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33433
        },
        "matmul_940": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_936 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.17.attention.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.17.attention.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.17.attention.output.dense.bias": "Data",
                "bert.encoder.layer.17.attention.output.dense.weight": "Data",
                "matmul_936": "Data"
            },
            "input_nodes": [
                "matmul_936",
                "bert.encoder.layer.17.attention.output.dense.weight",
                "bert.encoder.layer.17.attention.output.dense.bias"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hstack"
                        }
                    }
                ],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_940",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_944 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_944"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_940",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33436
        },
        "matmul_948": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    4096
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_125 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.17.intermediate.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.17.intermediate.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_125": "Data",
                "bert.encoder.layer.17.intermediate.dense.bias": "Data",
                "bert.encoder.layer.17.intermediate.dense.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_125",
                "bert.encoder.layer.17.intermediate.dense.weight",
                "bert.encoder.layer.17.intermediate.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_948",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: gelu_951 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "gelu_951"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_948",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33464
        },
        "matmul_954": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: gelu_951 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.17.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.17.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.17.output.dense.bias": "Data",
                "bert.encoder.layer.17.output.dense.weight": "Data",
                "gelu_951": "Data"
            },
            "input_nodes": [
                "gelu_951",
                "bert.encoder.layer.17.output.dense.weight",
                "bert.encoder.layer.17.output.dense.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_954",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_958 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_958"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_954",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33468
        },
        "matmul_962": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_127 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.18.attention.self.query.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.18.attention.self.query.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_127": "Data",
                "bert.encoder.layer.18.attention.self.query.bias": "Data",
                "bert.encoder.layer.18.attention.self.query.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_127",
                "bert.encoder.layer.18.attention.self.query.weight",
                "bert.encoder.layer.18.attention.self.query.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_962",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_974 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_974"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query",
                "original_op_name": "matmul_962",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33496
        },
        "matmul_968": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_127 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.18.attention.self.key.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.18.attention.self.key.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_127": "Data",
                "bert.encoder.layer.18.attention.self.key.bias": "Data",
                "bert.encoder.layer.18.attention.self.key.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_127",
                "bert.encoder.layer.18.attention.self.key.weight",
                "bert.encoder.layer.18.attention.self.key.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_968",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_974 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_974"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key",
                "original_op_name": "matmul_968",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33502
        },
        "matmul_974": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_962 (port_0) ublock_order(c)",
                "Data: matmul_968 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "matmul_962": "Data",
                "matmul_968": "Data"
            },
            "input_nodes": [
                "matmul_962",
                "matmul_968"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [],
                            "buda_attrs": {},
                            "named_attrs": {
                                "dim0": -2,
                                "dim1": -1,
                                "z_dim_slice": -1
                            },
                            "type": "transpose"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "vslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_974",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_128 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_128"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_974",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33509
        },
        "matmul_982": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_127 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.18.attention.self.value.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.18.attention.self.value.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_127": "Data",
                "bert.encoder.layer.18.attention.self.value.bias": "Data",
                "bert.encoder.layer.18.attention.self.value.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_127",
                "bert.encoder.layer.18.attention.self.value.weight",
                "bert.encoder.layer.18.attention.self.value.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_982",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_989 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_989"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value",
                "original_op_name": "matmul_982",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33531
        },
        "matmul_989": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_130 (port_0) ublock_order(c)",
                "Data: matmul_982 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_130": "Data",
                "matmul_982": "Data"
            },
            "input_nodes": [
                "_fused_op_130",
                "matmul_982"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_989",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_993 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_993"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_989",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33537
        },
        "matmul_993": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: matmul_989 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.18.attention.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.18.attention.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.18.attention.output.dense.bias": "Data",
                "bert.encoder.layer.18.attention.output.dense.weight": "Data",
                "matmul_989": "Data"
            },
            "input_nodes": [
                "matmul_989",
                "bert.encoder.layer.18.attention.output.dense.weight",
                "bert.encoder.layer.18.attention.output.dense.bias"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hstack"
                        }
                    }
                ],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_993",
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_997 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_997"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_993",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 33540
        },
        "multiply_22": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    384
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: subtract_21 (port_0) ublock_order(r)",
                "Data: input_1_multiply_22 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "input_1_multiply_22": "Data",
                "subtract_21": "Data"
            },
            "input_nodes": [
                "subtract_21",
                "input_1_multiply_22"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "multiply_22",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: multiply_22_attempt_1_input_op_fork_nop0 (port_0)",
                "Data: multiply_22_attempt_1_input_op_fork_nop1 (port_0)",
                "Data: multiply_22_attempt_1_input_op_fork_nop2 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "multiply_22_attempt_1_input_op_fork_nop0",
                "multiply_22_attempt_1_input_op_fork_nop1",
                "multiply_22_attempt_1_input_op_fork_nop2"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert",
                "original_op_name": "multiply_22",
                "original_op_type": "multiply"
            },
            "type": "multiply",
            "unique_id": 31639
        },
        "multiply_22_attempt_1_input_op_fork_nop0": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    384
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: multiply_22 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "multiply_22": "Data"
            },
            "input_nodes": [
                "multiply_22"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "multiply_22_attempt_1_input_op_fork_nop0",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_2 (port_0)",
                "Data: _fused_op_9 (port_0)",
                "Data: _fused_op_16 (port_0)",
                "Data: _fused_op_23 (port_0)",
                "Data: _fused_op_30 (port_0)",
                "Data: _fused_op_37 (port_0)",
                "Data: _fused_op_44 (port_0)",
                "Data: _fused_op_51 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_2",
                "_fused_op_9",
                "_fused_op_16",
                "_fused_op_23",
                "_fused_op_30",
                "_fused_op_37",
                "_fused_op_44",
                "_fused_op_51"
            ],
            "pybuda": 1,
            "tags": {},
            "type": "nop",
            "unique_id": 34300
        },
        "multiply_22_attempt_1_input_op_fork_nop1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    384
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: multiply_22 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "multiply_22": "Data"
            },
            "input_nodes": [
                "multiply_22"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "multiply_22_attempt_1_input_op_fork_nop1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_58 (port_0)",
                "Data: _fused_op_65 (port_0)",
                "Data: _fused_op_72 (port_0)",
                "Data: _fused_op_79 (port_0)",
                "Data: _fused_op_86 (port_0)",
                "Data: _fused_op_93 (port_0)",
                "Data: _fused_op_100 (port_0)",
                "Data: _fused_op_107 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_58",
                "_fused_op_65",
                "_fused_op_72",
                "_fused_op_79",
                "_fused_op_86",
                "_fused_op_93",
                "_fused_op_100",
                "_fused_op_107"
            ],
            "pybuda": 1,
            "tags": {},
            "type": "nop",
            "unique_id": 34301
        },
        "multiply_22_attempt_1_input_op_fork_nop2": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    384
                ]
            },
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: multiply_22 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "multiply_22": "Data"
            },
            "input_nodes": [
                "multiply_22"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "multiply_22_attempt_1_input_op_fork_nop2",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_114 (port_0)",
                "Data: _fused_op_121 (port_0)",
                "Data: _fused_op_128 (port_0)",
                "Data: _fused_op_135 (port_0)",
                "Data: _fused_op_142 (port_0)",
                "Data: _fused_op_149 (port_0)",
                "Data: _fused_op_156 (port_0)",
                "Data: _fused_op_163 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_114",
                "_fused_op_121",
                "_fused_op_128",
                "_fused_op_135",
                "_fused_op_142",
                "_fused_op_149",
                "_fused_op_156",
                "_fused_op_163"
            ],
            "pybuda": 1,
            "tags": {},
            "type": "nop",
            "unique_id": 34302
        },
        "pybuda_6_i0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "pybuda_6_i0",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_0.dc.reduce_sum.0.lc1 (port_0)",
                "Data: _fused_op_0 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_0.dc.reduce_sum.0.lc1",
                "_fused_op_0"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "pybuda_6_i0"
            },
            "tile_broadcast": [],
            "type": "Input::input",
            "unique_id": 31594
        },
        "qa_outputs.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "qa_outputs.bias",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1281 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1281"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "qa_outputs.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 34122
        },
        "qa_outputs.bias_fork_clone12": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "qa_outputs.bias_fork_clone12",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1288 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1288"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "qa_outputs.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 34126
        },
        "qa_outputs.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    32
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "qa_outputs.weight",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1281 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1281"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "qa_outputs.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 34121
        },
        "qa_outputs.weight_fork_clone19": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    32
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "qa_outputs.weight_fork_clone19",
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1288 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1288"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "qa_outputs.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 34125
        },
        "softmax_1031.dc.reduce_max.0": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "reduce(3,max,16,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_135 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_135": "Data"
            },
            "input_nodes": [
                "_fused_op_135"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_1031.dc.reduce_max.0",
            "op_type": {
                "attrs": [
                    3,
                    "max",
                    16
                ],
                "buda_attrs": {
                    "dim": "c",
                    "type": "max"
                },
                "named_attrs": {},
                "type": "reduce"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_136 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_136"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_1031",
                "original_op_type": "softmax"
            },
            "type": "reduce",
            "unique_id": 33620
        },
        "softmax_1031.dc.reduce_sum.3.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_136 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.softmax_1031.dc.reduce_sum.3.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_136": "Data",
                "lc.input_tensor.softmax_1031.dc.reduce_sum.3.0": "Data"
            },
            "input_nodes": [
                "_fused_op_136",
                "lc.input_tensor.softmax_1031.dc.reduce_sum.3.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_1031.dc.reduce_sum.3.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_137 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_137"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_1031",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 33626
        },
        "softmax_1084.dc.reduce_max.0": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "reduce(3,max,16,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_142 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_142": "Data"
            },
            "input_nodes": [
                "_fused_op_142"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_1084.dc.reduce_max.0",
            "op_type": {
                "attrs": [
                    3,
                    "max",
                    16
                ],
                "buda_attrs": {
                    "dim": "c",
                    "type": "max"
                },
                "named_attrs": {},
                "type": "reduce"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_143 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_143"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_1084",
                "original_op_type": "softmax"
            },
            "type": "reduce",
            "unique_id": 33724
        },
        "softmax_1084.dc.reduce_sum.3.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_143 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.softmax_1084.dc.reduce_sum.3.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_143": "Data",
                "lc.input_tensor.softmax_1084.dc.reduce_sum.3.0": "Data"
            },
            "input_nodes": [
                "_fused_op_143",
                "lc.input_tensor.softmax_1084.dc.reduce_sum.3.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_1084.dc.reduce_sum.3.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_144 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_144"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_1084",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 33730
        },
        "softmax_1137.dc.reduce_max.0": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "reduce(3,max,16,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_149 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_149": "Data"
            },
            "input_nodes": [
                "_fused_op_149"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_1137.dc.reduce_max.0",
            "op_type": {
                "attrs": [
                    3,
                    "max",
                    16
                ],
                "buda_attrs": {
                    "dim": "c",
                    "type": "max"
                },
                "named_attrs": {},
                "type": "reduce"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_150 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_150"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_1137",
                "original_op_type": "softmax"
            },
            "type": "reduce",
            "unique_id": 33828
        },
        "softmax_1137.dc.reduce_sum.3.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_150 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.softmax_1137.dc.reduce_sum.3.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_150": "Data",
                "lc.input_tensor.softmax_1137.dc.reduce_sum.3.0": "Data"
            },
            "input_nodes": [
                "_fused_op_150",
                "lc.input_tensor.softmax_1137.dc.reduce_sum.3.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_1137.dc.reduce_sum.3.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_151 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_151"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_1137",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 33834
        },
        "softmax_1190.dc.reduce_max.0": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "reduce(3,max,16,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_156 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_156": "Data"
            },
            "input_nodes": [
                "_fused_op_156"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_1190.dc.reduce_max.0",
            "op_type": {
                "attrs": [
                    3,
                    "max",
                    16
                ],
                "buda_attrs": {
                    "dim": "c",
                    "type": "max"
                },
                "named_attrs": {},
                "type": "reduce"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_157 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_157"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_1190",
                "original_op_type": "softmax"
            },
            "type": "reduce",
            "unique_id": 33932
        },
        "softmax_1190.dc.reduce_sum.3.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_157 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.softmax_1190.dc.reduce_sum.3.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_157": "Data",
                "lc.input_tensor.softmax_1190.dc.reduce_sum.3.0": "Data"
            },
            "input_nodes": [
                "_fused_op_157",
                "lc.input_tensor.softmax_1190.dc.reduce_sum.3.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_1190.dc.reduce_sum.3.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_158 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_158"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_1190",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 33938
        },
        "softmax_1243.dc.reduce_max.0": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "reduce(3,max,16,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_163 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_163": "Data"
            },
            "input_nodes": [
                "_fused_op_163"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_1243.dc.reduce_max.0",
            "op_type": {
                "attrs": [
                    3,
                    "max",
                    16
                ],
                "buda_attrs": {
                    "dim": "c",
                    "type": "max"
                },
                "named_attrs": {},
                "type": "reduce"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_164 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_164"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_1243",
                "original_op_type": "softmax"
            },
            "type": "reduce",
            "unique_id": 34036
        },
        "softmax_1243.dc.reduce_sum.3.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_164 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.softmax_1243.dc.reduce_sum.3.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_164": "Data",
                "lc.input_tensor.softmax_1243.dc.reduce_sum.3.0": "Data"
            },
            "input_nodes": [
                "_fused_op_164",
                "lc.input_tensor.softmax_1243.dc.reduce_sum.3.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_1243.dc.reduce_sum.3.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_165 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_165"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_1243",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 34042
        },
        "softmax_130.dc.reduce_max.0": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "reduce(3,max,16,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_16 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_16": "Data"
            },
            "input_nodes": [
                "_fused_op_16"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_130.dc.reduce_max.0",
            "op_type": {
                "attrs": [
                    3,
                    "max",
                    16
                ],
                "buda_attrs": {
                    "dim": "c",
                    "type": "max"
                },
                "named_attrs": {},
                "type": "reduce"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_17 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_17"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_130",
                "original_op_type": "softmax"
            },
            "type": "reduce",
            "unique_id": 31852
        },
        "softmax_130.dc.reduce_sum.3.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_17 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.softmax_130.dc.reduce_sum.3.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_17": "Data",
                "lc.input_tensor.softmax_130.dc.reduce_sum.3.0": "Data"
            },
            "input_nodes": [
                "_fused_op_17",
                "lc.input_tensor.softmax_130.dc.reduce_sum.3.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_130.dc.reduce_sum.3.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_18 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_18"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_130",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 31858
        },
        "softmax_183.dc.reduce_max.0": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "reduce(3,max,16,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_23 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_23": "Data"
            },
            "input_nodes": [
                "_fused_op_23"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_183.dc.reduce_max.0",
            "op_type": {
                "attrs": [
                    3,
                    "max",
                    16
                ],
                "buda_attrs": {
                    "dim": "c",
                    "type": "max"
                },
                "named_attrs": {},
                "type": "reduce"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_24 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_24"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_183",
                "original_op_type": "softmax"
            },
            "type": "reduce",
            "unique_id": 31956
        },
        "softmax_183.dc.reduce_sum.3.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_24 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.softmax_183.dc.reduce_sum.3.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_24": "Data",
                "lc.input_tensor.softmax_183.dc.reduce_sum.3.0": "Data"
            },
            "input_nodes": [
                "_fused_op_24",
                "lc.input_tensor.softmax_183.dc.reduce_sum.3.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_183.dc.reduce_sum.3.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_25 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_25"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_183",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 31962
        },
        "softmax_236.dc.reduce_max.0": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "reduce(3,max,16,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_30 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_30": "Data"
            },
            "input_nodes": [
                "_fused_op_30"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_236.dc.reduce_max.0",
            "op_type": {
                "attrs": [
                    3,
                    "max",
                    16
                ],
                "buda_attrs": {
                    "dim": "c",
                    "type": "max"
                },
                "named_attrs": {},
                "type": "reduce"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_31 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_31"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_236",
                "original_op_type": "softmax"
            },
            "type": "reduce",
            "unique_id": 32060
        },
        "softmax_236.dc.reduce_sum.3.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_31 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.softmax_236.dc.reduce_sum.3.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_31": "Data",
                "lc.input_tensor.softmax_236.dc.reduce_sum.3.0": "Data"
            },
            "input_nodes": [
                "_fused_op_31",
                "lc.input_tensor.softmax_236.dc.reduce_sum.3.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_236.dc.reduce_sum.3.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_32 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_32"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_236",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 32066
        },
        "softmax_24.dc.reduce_max.0": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "reduce(3,max,16,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_2 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_2": "Data"
            },
            "input_nodes": [
                "_fused_op_2"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_24.dc.reduce_max.0",
            "op_type": {
                "attrs": [
                    3,
                    "max",
                    16
                ],
                "buda_attrs": {
                    "dim": "c",
                    "type": "max"
                },
                "named_attrs": {},
                "type": "reduce"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_3 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_3"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_24",
                "original_op_type": "softmax"
            },
            "type": "reduce",
            "unique_id": 31644
        },
        "softmax_24.dc.reduce_sum.3.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_3 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.softmax_24.dc.reduce_sum.3.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_3": "Data",
                "lc.input_tensor.softmax_24.dc.reduce_sum.3.0": "Data"
            },
            "input_nodes": [
                "_fused_op_3",
                "lc.input_tensor.softmax_24.dc.reduce_sum.3.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_24.dc.reduce_sum.3.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_4 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_4"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_24",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 31650
        },
        "softmax_289.dc.reduce_max.0": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "reduce(3,max,16,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_37 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_37": "Data"
            },
            "input_nodes": [
                "_fused_op_37"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_289.dc.reduce_max.0",
            "op_type": {
                "attrs": [
                    3,
                    "max",
                    16
                ],
                "buda_attrs": {
                    "dim": "c",
                    "type": "max"
                },
                "named_attrs": {},
                "type": "reduce"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_38 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_38"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_289",
                "original_op_type": "softmax"
            },
            "type": "reduce",
            "unique_id": 32164
        },
        "softmax_289.dc.reduce_sum.3.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_38 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.softmax_289.dc.reduce_sum.3.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_38": "Data",
                "lc.input_tensor.softmax_289.dc.reduce_sum.3.0": "Data"
            },
            "input_nodes": [
                "_fused_op_38",
                "lc.input_tensor.softmax_289.dc.reduce_sum.3.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_289.dc.reduce_sum.3.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_39 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_39"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_289",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 32170
        },
        "softmax_342.dc.reduce_max.0": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "reduce(3,max,16,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_44 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_44": "Data"
            },
            "input_nodes": [
                "_fused_op_44"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_342.dc.reduce_max.0",
            "op_type": {
                "attrs": [
                    3,
                    "max",
                    16
                ],
                "buda_attrs": {
                    "dim": "c",
                    "type": "max"
                },
                "named_attrs": {},
                "type": "reduce"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_45 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_45"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_342",
                "original_op_type": "softmax"
            },
            "type": "reduce",
            "unique_id": 32268
        },
        "softmax_342.dc.reduce_sum.3.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_45 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.softmax_342.dc.reduce_sum.3.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_45": "Data",
                "lc.input_tensor.softmax_342.dc.reduce_sum.3.0": "Data"
            },
            "input_nodes": [
                "_fused_op_45",
                "lc.input_tensor.softmax_342.dc.reduce_sum.3.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_342.dc.reduce_sum.3.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_46 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_46"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_342",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 32274
        },
        "softmax_395.dc.reduce_max.0": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "reduce(3,max,16,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_51 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_51": "Data"
            },
            "input_nodes": [
                "_fused_op_51"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_395.dc.reduce_max.0",
            "op_type": {
                "attrs": [
                    3,
                    "max",
                    16
                ],
                "buda_attrs": {
                    "dim": "c",
                    "type": "max"
                },
                "named_attrs": {},
                "type": "reduce"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_52 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_52"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_395",
                "original_op_type": "softmax"
            },
            "type": "reduce",
            "unique_id": 32372
        },
        "softmax_395.dc.reduce_sum.3.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_52 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.softmax_395.dc.reduce_sum.3.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_52": "Data",
                "lc.input_tensor.softmax_395.dc.reduce_sum.3.0": "Data"
            },
            "input_nodes": [
                "_fused_op_52",
                "lc.input_tensor.softmax_395.dc.reduce_sum.3.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_395.dc.reduce_sum.3.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_53 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_53"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_395",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 32378
        },
        "softmax_448.dc.reduce_max.0": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "reduce(3,max,16,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_58 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_58": "Data"
            },
            "input_nodes": [
                "_fused_op_58"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_448.dc.reduce_max.0",
            "op_type": {
                "attrs": [
                    3,
                    "max",
                    16
                ],
                "buda_attrs": {
                    "dim": "c",
                    "type": "max"
                },
                "named_attrs": {},
                "type": "reduce"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_59 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_59"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_448",
                "original_op_type": "softmax"
            },
            "type": "reduce",
            "unique_id": 32476
        },
        "softmax_448.dc.reduce_sum.3.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_59 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.softmax_448.dc.reduce_sum.3.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_59": "Data",
                "lc.input_tensor.softmax_448.dc.reduce_sum.3.0": "Data"
            },
            "input_nodes": [
                "_fused_op_59",
                "lc.input_tensor.softmax_448.dc.reduce_sum.3.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_448.dc.reduce_sum.3.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_60 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_60"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_448",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 32482
        },
        "softmax_501.dc.reduce_max.0": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "reduce(3,max,16,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_65 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_65": "Data"
            },
            "input_nodes": [
                "_fused_op_65"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_501.dc.reduce_max.0",
            "op_type": {
                "attrs": [
                    3,
                    "max",
                    16
                ],
                "buda_attrs": {
                    "dim": "c",
                    "type": "max"
                },
                "named_attrs": {},
                "type": "reduce"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_66 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_66"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_501",
                "original_op_type": "softmax"
            },
            "type": "reduce",
            "unique_id": 32580
        },
        "softmax_501.dc.reduce_sum.3.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_66 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.softmax_501.dc.reduce_sum.3.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_66": "Data",
                "lc.input_tensor.softmax_501.dc.reduce_sum.3.0": "Data"
            },
            "input_nodes": [
                "_fused_op_66",
                "lc.input_tensor.softmax_501.dc.reduce_sum.3.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_501.dc.reduce_sum.3.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_67 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_67"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_501",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 32586
        },
        "softmax_554.dc.reduce_max.0": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "reduce(3,max,16,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_72 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_72": "Data"
            },
            "input_nodes": [
                "_fused_op_72"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_554.dc.reduce_max.0",
            "op_type": {
                "attrs": [
                    3,
                    "max",
                    16
                ],
                "buda_attrs": {
                    "dim": "c",
                    "type": "max"
                },
                "named_attrs": {},
                "type": "reduce"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_73 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_73"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_554",
                "original_op_type": "softmax"
            },
            "type": "reduce",
            "unique_id": 32684
        },
        "softmax_554.dc.reduce_sum.3.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_73 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.softmax_554.dc.reduce_sum.3.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_73": "Data",
                "lc.input_tensor.softmax_554.dc.reduce_sum.3.0": "Data"
            },
            "input_nodes": [
                "_fused_op_73",
                "lc.input_tensor.softmax_554.dc.reduce_sum.3.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_554.dc.reduce_sum.3.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_74 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_74"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_554",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 32690
        },
        "softmax_607.dc.reduce_max.0": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "reduce(3,max,16,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_79 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_79": "Data"
            },
            "input_nodes": [
                "_fused_op_79"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_607.dc.reduce_max.0",
            "op_type": {
                "attrs": [
                    3,
                    "max",
                    16
                ],
                "buda_attrs": {
                    "dim": "c",
                    "type": "max"
                },
                "named_attrs": {},
                "type": "reduce"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_80 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_80"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_607",
                "original_op_type": "softmax"
            },
            "type": "reduce",
            "unique_id": 32788
        },
        "softmax_607.dc.reduce_sum.3.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_80 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.softmax_607.dc.reduce_sum.3.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_80": "Data",
                "lc.input_tensor.softmax_607.dc.reduce_sum.3.0": "Data"
            },
            "input_nodes": [
                "_fused_op_80",
                "lc.input_tensor.softmax_607.dc.reduce_sum.3.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_607.dc.reduce_sum.3.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_81 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_81"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_607",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 32794
        },
        "softmax_660.dc.reduce_max.0": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "reduce(3,max,16,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_86 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_86": "Data"
            },
            "input_nodes": [
                "_fused_op_86"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_660.dc.reduce_max.0",
            "op_type": {
                "attrs": [
                    3,
                    "max",
                    16
                ],
                "buda_attrs": {
                    "dim": "c",
                    "type": "max"
                },
                "named_attrs": {},
                "type": "reduce"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_87 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_87"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_660",
                "original_op_type": "softmax"
            },
            "type": "reduce",
            "unique_id": 32892
        },
        "softmax_660.dc.reduce_sum.3.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_87 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.softmax_660.dc.reduce_sum.3.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_87": "Data",
                "lc.input_tensor.softmax_660.dc.reduce_sum.3.0": "Data"
            },
            "input_nodes": [
                "_fused_op_87",
                "lc.input_tensor.softmax_660.dc.reduce_sum.3.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_660.dc.reduce_sum.3.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_88 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_88"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_660",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 32898
        },
        "softmax_713.dc.reduce_max.0": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "reduce(3,max,16,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_93 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_93": "Data"
            },
            "input_nodes": [
                "_fused_op_93"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_713.dc.reduce_max.0",
            "op_type": {
                "attrs": [
                    3,
                    "max",
                    16
                ],
                "buda_attrs": {
                    "dim": "c",
                    "type": "max"
                },
                "named_attrs": {},
                "type": "reduce"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_94 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_94"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_713",
                "original_op_type": "softmax"
            },
            "type": "reduce",
            "unique_id": 32996
        },
        "softmax_713.dc.reduce_sum.3.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_94 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.softmax_713.dc.reduce_sum.3.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_94": "Data",
                "lc.input_tensor.softmax_713.dc.reduce_sum.3.0": "Data"
            },
            "input_nodes": [
                "_fused_op_94",
                "lc.input_tensor.softmax_713.dc.reduce_sum.3.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_713.dc.reduce_sum.3.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_95 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_95"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_713",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 33002
        },
        "softmax_766.dc.reduce_max.0": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "reduce(3,max,16,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_100 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_100": "Data"
            },
            "input_nodes": [
                "_fused_op_100"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_766.dc.reduce_max.0",
            "op_type": {
                "attrs": [
                    3,
                    "max",
                    16
                ],
                "buda_attrs": {
                    "dim": "c",
                    "type": "max"
                },
                "named_attrs": {},
                "type": "reduce"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_101 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_101"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_766",
                "original_op_type": "softmax"
            },
            "type": "reduce",
            "unique_id": 33100
        },
        "softmax_766.dc.reduce_sum.3.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_101 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.softmax_766.dc.reduce_sum.3.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_101": "Data",
                "lc.input_tensor.softmax_766.dc.reduce_sum.3.0": "Data"
            },
            "input_nodes": [
                "_fused_op_101",
                "lc.input_tensor.softmax_766.dc.reduce_sum.3.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_766.dc.reduce_sum.3.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_102 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_102"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_766",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 33106
        },
        "softmax_77.dc.reduce_max.0": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "reduce(3,max,16,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_9 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_9": "Data"
            },
            "input_nodes": [
                "_fused_op_9"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_77.dc.reduce_max.0",
            "op_type": {
                "attrs": [
                    3,
                    "max",
                    16
                ],
                "buda_attrs": {
                    "dim": "c",
                    "type": "max"
                },
                "named_attrs": {},
                "type": "reduce"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_10 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_10"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_77",
                "original_op_type": "softmax"
            },
            "type": "reduce",
            "unique_id": 31748
        },
        "softmax_77.dc.reduce_sum.3.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_10 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.softmax_77.dc.reduce_sum.3.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_10": "Data",
                "lc.input_tensor.softmax_77.dc.reduce_sum.3.0": "Data"
            },
            "input_nodes": [
                "_fused_op_10",
                "lc.input_tensor.softmax_77.dc.reduce_sum.3.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_77.dc.reduce_sum.3.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_11 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_11"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_77",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 31754
        },
        "softmax_819.dc.reduce_max.0": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "reduce(3,max,16,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_107 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_107": "Data"
            },
            "input_nodes": [
                "_fused_op_107"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_819.dc.reduce_max.0",
            "op_type": {
                "attrs": [
                    3,
                    "max",
                    16
                ],
                "buda_attrs": {
                    "dim": "c",
                    "type": "max"
                },
                "named_attrs": {},
                "type": "reduce"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_108 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_108"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_819",
                "original_op_type": "softmax"
            },
            "type": "reduce",
            "unique_id": 33204
        },
        "softmax_819.dc.reduce_sum.3.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_108 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.softmax_819.dc.reduce_sum.3.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_108": "Data",
                "lc.input_tensor.softmax_819.dc.reduce_sum.3.0": "Data"
            },
            "input_nodes": [
                "_fused_op_108",
                "lc.input_tensor.softmax_819.dc.reduce_sum.3.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_819.dc.reduce_sum.3.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_109 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_109"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_819",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 33210
        },
        "softmax_872.dc.reduce_max.0": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "reduce(3,max,16,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_114 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_114": "Data"
            },
            "input_nodes": [
                "_fused_op_114"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_872.dc.reduce_max.0",
            "op_type": {
                "attrs": [
                    3,
                    "max",
                    16
                ],
                "buda_attrs": {
                    "dim": "c",
                    "type": "max"
                },
                "named_attrs": {},
                "type": "reduce"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_115 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_115"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_872",
                "original_op_type": "softmax"
            },
            "type": "reduce",
            "unique_id": 33308
        },
        "softmax_872.dc.reduce_sum.3.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_115 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.softmax_872.dc.reduce_sum.3.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_115": "Data",
                "lc.input_tensor.softmax_872.dc.reduce_sum.3.0": "Data"
            },
            "input_nodes": [
                "_fused_op_115",
                "lc.input_tensor.softmax_872.dc.reduce_sum.3.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_872.dc.reduce_sum.3.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_116 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_116"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_872",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 33314
        },
        "softmax_925.dc.reduce_max.0": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "reduce(3,max,16,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_121 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_121": "Data"
            },
            "input_nodes": [
                "_fused_op_121"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_925.dc.reduce_max.0",
            "op_type": {
                "attrs": [
                    3,
                    "max",
                    16
                ],
                "buda_attrs": {
                    "dim": "c",
                    "type": "max"
                },
                "named_attrs": {},
                "type": "reduce"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_122 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_122"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_925",
                "original_op_type": "softmax"
            },
            "type": "reduce",
            "unique_id": 33412
        },
        "softmax_925.dc.reduce_sum.3.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_122 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.softmax_925.dc.reduce_sum.3.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_122": "Data",
                "lc.input_tensor.softmax_925.dc.reduce_sum.3.0": "Data"
            },
            "input_nodes": [
                "_fused_op_122",
                "lc.input_tensor.softmax_925.dc.reduce_sum.3.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_925.dc.reduce_sum.3.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_123 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_123"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_925",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 33418
        },
        "softmax_978.dc.reduce_max.0": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "reduce(3,max,16,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_128 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_128": "Data"
            },
            "input_nodes": [
                "_fused_op_128"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_978.dc.reduce_max.0",
            "op_type": {
                "attrs": [
                    3,
                    "max",
                    16
                ],
                "buda_attrs": {
                    "dim": "c",
                    "type": "max"
                },
                "named_attrs": {},
                "type": "reduce"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_129 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_129"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_978",
                "original_op_type": "softmax"
            },
            "type": "reduce",
            "unique_id": 33516
        },
        "softmax_978.dc.reduce_sum.3.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: _fused_op_129 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.softmax_978.dc.reduce_sum.3.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_129": "Data",
                "lc.input_tensor.softmax_978.dc.reduce_sum.3.0": "Data"
            },
            "input_nodes": [
                "_fused_op_129",
                "lc.input_tensor.softmax_978.dc.reduce_sum.3.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_978.dc.reduce_sum.3.lc1",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_130 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_130"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_978",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 33522
        },
        "subtract_21": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    384
                ]
            },
            "class": "subtract",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "incoming_edge_port_info": [
                "Data: input_0_subtract_21 (port_0) ublock_order(r)",
                "Data: attention_mask_1 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "attention_mask_1": "Data",
                "input_0_subtract_21": "Data"
            },
            "input_nodes": [
                "input_0_subtract_21",
                "attention_mask_1"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "subtract_21",
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "subtract"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: multiply_22 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "multiply_22"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert",
                "original_op_name": "subtract_21",
                "original_op_type": "subtract"
            },
            "type": "subtract",
            "unique_id": 31637
        }
    },
    "topological_sorted_nodes": [
        "lc.input_tensor.layernorm_0.dc.reduce_sum.0.0",
        "pybuda_6_i0",
        "layernorm_0.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_0.1",
        "_fused_op_0",
        "layernorm_0.dc.multiply.4",
        "lc.input_tensor.layernorm_0.dc.reduce_sum.5.0",
        "layernorm_0.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_0.6",
        "dc.input_tensor.layernorm_0.8",
        "bert.embeddings.LayerNorm.weight",
        "bert.embeddings.LayerNorm.bias",
        "_fused_op_1",
        "bert.encoder.layer.0.attention.self.query.weight",
        "bert.encoder.layer.0.attention.self.query.bias",
        "matmul_4",
        "bert.encoder.layer.0.attention.self.key.weight",
        "bert.encoder.layer.0.attention.self.key.bias",
        "matmul_10",
        "matmul_16",
        "input_1_multiply_18",
        "attention_mask_1",
        "input_0_subtract_21",
        "subtract_21",
        "input_1_multiply_22",
        "multiply_22",
        "multiply_22_attempt_1_input_op_fork_nop0",
        "_fused_op_2",
        "softmax_24.dc.reduce_max.0",
        "lc.input_tensor.softmax_24.dc.reduce_sum.3.0",
        "_fused_op_3",
        "softmax_24.dc.reduce_sum.3.lc1",
        "dc.input_tensor.softmax_24.4",
        "bert.encoder.layer.0.attention.self.value.weight",
        "bert.encoder.layer.0.attention.self.value.bias",
        "matmul_28",
        "_fused_op_4",
        "matmul_35",
        "bert.encoder.layer.0.attention.output.dense.weight",
        "bert.encoder.layer.0.attention.output.dense.bias",
        "matmul_39",
        "add_43",
        "lc.input_tensor.layernorm_44.dc.reduce_sum.0.0",
        "layernorm_44.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_44.1",
        "_fused_op_5",
        "layernorm_44.dc.multiply.4",
        "lc.input_tensor.layernorm_44.dc.reduce_sum.5.0",
        "layernorm_44.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_44.6",
        "dc.input_tensor.layernorm_44.8",
        "bert.encoder.layer.0.attention.output.LayerNorm.weight",
        "bert.encoder.layer.0.attention.output.LayerNorm.bias",
        "_fused_op_6",
        "bert.encoder.layer.0.intermediate.dense.weight",
        "bert.encoder.layer.0.intermediate.dense.bias",
        "matmul_47",
        "gelu_50",
        "bert.encoder.layer.0.output.dense.weight",
        "bert.encoder.layer.0.output.dense.bias",
        "matmul_53",
        "add_57",
        "lc.input_tensor.layernorm_58.dc.reduce_sum.0.0",
        "layernorm_58.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_58.1",
        "_fused_op_7",
        "layernorm_58.dc.multiply.4",
        "lc.input_tensor.layernorm_58.dc.reduce_sum.5.0",
        "layernorm_58.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_58.6",
        "dc.input_tensor.layernorm_58.8",
        "bert.encoder.layer.0.output.LayerNorm.weight",
        "bert.encoder.layer.0.output.LayerNorm.bias",
        "_fused_op_8",
        "bert.encoder.layer.1.attention.self.query.weight",
        "bert.encoder.layer.1.attention.self.query.bias",
        "matmul_61",
        "bert.encoder.layer.1.attention.self.key.weight",
        "bert.encoder.layer.1.attention.self.key.bias",
        "matmul_67",
        "matmul_73",
        "input_1_multiply_75",
        "_fused_op_9",
        "softmax_77.dc.reduce_max.0",
        "lc.input_tensor.softmax_77.dc.reduce_sum.3.0",
        "_fused_op_10",
        "softmax_77.dc.reduce_sum.3.lc1",
        "dc.input_tensor.softmax_77.4",
        "bert.encoder.layer.1.attention.self.value.weight",
        "bert.encoder.layer.1.attention.self.value.bias",
        "matmul_81",
        "_fused_op_11",
        "matmul_88",
        "bert.encoder.layer.1.attention.output.dense.weight",
        "bert.encoder.layer.1.attention.output.dense.bias",
        "matmul_92",
        "add_96",
        "lc.input_tensor.layernorm_97.dc.reduce_sum.0.0",
        "layernorm_97.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_97.1",
        "_fused_op_12",
        "layernorm_97.dc.multiply.4",
        "lc.input_tensor.layernorm_97.dc.reduce_sum.5.0",
        "layernorm_97.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_97.6",
        "dc.input_tensor.layernorm_97.8",
        "bert.encoder.layer.1.attention.output.LayerNorm.weight",
        "bert.encoder.layer.1.attention.output.LayerNorm.bias",
        "_fused_op_13",
        "bert.encoder.layer.1.intermediate.dense.weight",
        "bert.encoder.layer.1.intermediate.dense.bias",
        "matmul_100",
        "gelu_103",
        "bert.encoder.layer.1.output.dense.weight",
        "bert.encoder.layer.1.output.dense.bias",
        "matmul_106",
        "add_110",
        "lc.input_tensor.layernorm_111.dc.reduce_sum.0.0",
        "layernorm_111.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_111.1",
        "_fused_op_14",
        "layernorm_111.dc.multiply.4",
        "lc.input_tensor.layernorm_111.dc.reduce_sum.5.0",
        "layernorm_111.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_111.6",
        "dc.input_tensor.layernorm_111.8",
        "bert.encoder.layer.1.output.LayerNorm.weight",
        "bert.encoder.layer.1.output.LayerNorm.bias",
        "_fused_op_15",
        "bert.encoder.layer.2.attention.self.query.weight",
        "bert.encoder.layer.2.attention.self.query.bias",
        "matmul_114",
        "bert.encoder.layer.2.attention.self.key.weight",
        "bert.encoder.layer.2.attention.self.key.bias",
        "matmul_120",
        "matmul_126",
        "input_1_multiply_128",
        "_fused_op_16",
        "softmax_130.dc.reduce_max.0",
        "lc.input_tensor.softmax_130.dc.reduce_sum.3.0",
        "_fused_op_17",
        "softmax_130.dc.reduce_sum.3.lc1",
        "dc.input_tensor.softmax_130.4",
        "bert.encoder.layer.2.attention.self.value.weight",
        "bert.encoder.layer.2.attention.self.value.bias",
        "matmul_134",
        "_fused_op_18",
        "matmul_141",
        "bert.encoder.layer.2.attention.output.dense.weight",
        "bert.encoder.layer.2.attention.output.dense.bias",
        "matmul_145",
        "add_149",
        "lc.input_tensor.layernorm_150.dc.reduce_sum.0.0",
        "layernorm_150.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_150.1",
        "_fused_op_19",
        "layernorm_150.dc.multiply.4",
        "lc.input_tensor.layernorm_150.dc.reduce_sum.5.0",
        "layernorm_150.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_150.6",
        "dc.input_tensor.layernorm_150.8",
        "bert.encoder.layer.2.attention.output.LayerNorm.weight",
        "bert.encoder.layer.2.attention.output.LayerNorm.bias",
        "_fused_op_20",
        "bert.encoder.layer.2.intermediate.dense.weight",
        "bert.encoder.layer.2.intermediate.dense.bias",
        "matmul_153",
        "gelu_156",
        "bert.encoder.layer.2.output.dense.weight",
        "bert.encoder.layer.2.output.dense.bias",
        "matmul_159",
        "add_163",
        "lc.input_tensor.layernorm_164.dc.reduce_sum.0.0",
        "layernorm_164.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_164.1",
        "_fused_op_21",
        "layernorm_164.dc.multiply.4",
        "lc.input_tensor.layernorm_164.dc.reduce_sum.5.0",
        "layernorm_164.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_164.6",
        "dc.input_tensor.layernorm_164.8",
        "bert.encoder.layer.2.output.LayerNorm.weight",
        "bert.encoder.layer.2.output.LayerNorm.bias",
        "_fused_op_22",
        "bert.encoder.layer.3.attention.self.query.weight",
        "bert.encoder.layer.3.attention.self.query.bias",
        "matmul_167",
        "bert.encoder.layer.3.attention.self.key.weight",
        "bert.encoder.layer.3.attention.self.key.bias",
        "matmul_173",
        "matmul_179",
        "input_1_multiply_181",
        "_fused_op_23",
        "softmax_183.dc.reduce_max.0",
        "lc.input_tensor.softmax_183.dc.reduce_sum.3.0",
        "_fused_op_24",
        "softmax_183.dc.reduce_sum.3.lc1",
        "dc.input_tensor.softmax_183.4",
        "bert.encoder.layer.3.attention.self.value.weight",
        "bert.encoder.layer.3.attention.self.value.bias",
        "matmul_187",
        "_fused_op_25",
        "matmul_194",
        "bert.encoder.layer.3.attention.output.dense.weight",
        "bert.encoder.layer.3.attention.output.dense.bias",
        "matmul_198",
        "add_202",
        "lc.input_tensor.layernorm_203.dc.reduce_sum.0.0",
        "layernorm_203.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_203.1",
        "_fused_op_26",
        "layernorm_203.dc.multiply.4",
        "lc.input_tensor.layernorm_203.dc.reduce_sum.5.0",
        "layernorm_203.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_203.6",
        "dc.input_tensor.layernorm_203.8",
        "bert.encoder.layer.3.attention.output.LayerNorm.weight",
        "bert.encoder.layer.3.attention.output.LayerNorm.bias",
        "_fused_op_27",
        "bert.encoder.layer.3.intermediate.dense.weight",
        "bert.encoder.layer.3.intermediate.dense.bias",
        "matmul_206",
        "gelu_209",
        "bert.encoder.layer.3.output.dense.weight",
        "bert.encoder.layer.3.output.dense.bias",
        "matmul_212",
        "add_216",
        "lc.input_tensor.layernorm_217.dc.reduce_sum.0.0",
        "layernorm_217.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_217.1",
        "_fused_op_28",
        "layernorm_217.dc.multiply.4",
        "lc.input_tensor.layernorm_217.dc.reduce_sum.5.0",
        "layernorm_217.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_217.6",
        "dc.input_tensor.layernorm_217.8",
        "bert.encoder.layer.3.output.LayerNorm.weight",
        "bert.encoder.layer.3.output.LayerNorm.bias",
        "_fused_op_29",
        "bert.encoder.layer.4.attention.self.query.weight",
        "bert.encoder.layer.4.attention.self.query.bias",
        "matmul_220",
        "bert.encoder.layer.4.attention.self.key.weight",
        "bert.encoder.layer.4.attention.self.key.bias",
        "matmul_226",
        "matmul_232",
        "input_1_multiply_234",
        "_fused_op_30",
        "softmax_236.dc.reduce_max.0",
        "lc.input_tensor.softmax_236.dc.reduce_sum.3.0",
        "_fused_op_31",
        "softmax_236.dc.reduce_sum.3.lc1",
        "dc.input_tensor.softmax_236.4",
        "bert.encoder.layer.4.attention.self.value.weight",
        "bert.encoder.layer.4.attention.self.value.bias",
        "matmul_240",
        "_fused_op_32",
        "matmul_247",
        "bert.encoder.layer.4.attention.output.dense.weight",
        "bert.encoder.layer.4.attention.output.dense.bias",
        "matmul_251",
        "add_255",
        "lc.input_tensor.layernorm_256.dc.reduce_sum.0.0",
        "layernorm_256.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_256.1",
        "_fused_op_33",
        "layernorm_256.dc.multiply.4",
        "lc.input_tensor.layernorm_256.dc.reduce_sum.5.0",
        "layernorm_256.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_256.6",
        "dc.input_tensor.layernorm_256.8",
        "bert.encoder.layer.4.attention.output.LayerNorm.weight",
        "bert.encoder.layer.4.attention.output.LayerNorm.bias",
        "_fused_op_34",
        "bert.encoder.layer.4.intermediate.dense.weight",
        "bert.encoder.layer.4.intermediate.dense.bias",
        "matmul_259",
        "gelu_262",
        "bert.encoder.layer.4.output.dense.weight",
        "bert.encoder.layer.4.output.dense.bias",
        "matmul_265",
        "add_269",
        "lc.input_tensor.layernorm_270.dc.reduce_sum.0.0",
        "layernorm_270.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_270.1",
        "_fused_op_35",
        "layernorm_270.dc.multiply.4",
        "lc.input_tensor.layernorm_270.dc.reduce_sum.5.0",
        "layernorm_270.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_270.6",
        "dc.input_tensor.layernorm_270.8",
        "bert.encoder.layer.4.output.LayerNorm.weight",
        "bert.encoder.layer.4.output.LayerNorm.bias",
        "_fused_op_36",
        "bert.encoder.layer.5.attention.self.query.weight",
        "bert.encoder.layer.5.attention.self.query.bias",
        "matmul_273",
        "bert.encoder.layer.5.attention.self.key.weight",
        "bert.encoder.layer.5.attention.self.key.bias",
        "matmul_279",
        "matmul_285",
        "input_1_multiply_287",
        "_fused_op_37",
        "softmax_289.dc.reduce_max.0",
        "lc.input_tensor.softmax_289.dc.reduce_sum.3.0",
        "_fused_op_38",
        "softmax_289.dc.reduce_sum.3.lc1",
        "dc.input_tensor.softmax_289.4",
        "bert.encoder.layer.5.attention.self.value.weight",
        "bert.encoder.layer.5.attention.self.value.bias",
        "matmul_293",
        "_fused_op_39",
        "matmul_300",
        "bert.encoder.layer.5.attention.output.dense.weight",
        "bert.encoder.layer.5.attention.output.dense.bias",
        "matmul_304",
        "add_308",
        "lc.input_tensor.layernorm_309.dc.reduce_sum.0.0",
        "layernorm_309.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_309.1",
        "_fused_op_40",
        "layernorm_309.dc.multiply.4",
        "lc.input_tensor.layernorm_309.dc.reduce_sum.5.0",
        "layernorm_309.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_309.6",
        "dc.input_tensor.layernorm_309.8",
        "bert.encoder.layer.5.attention.output.LayerNorm.weight",
        "bert.encoder.layer.5.attention.output.LayerNorm.bias",
        "_fused_op_41",
        "bert.encoder.layer.5.intermediate.dense.weight",
        "bert.encoder.layer.5.intermediate.dense.bias",
        "matmul_312",
        "gelu_315",
        "bert.encoder.layer.5.output.dense.weight",
        "bert.encoder.layer.5.output.dense.bias",
        "matmul_318",
        "add_322",
        "lc.input_tensor.layernorm_323.dc.reduce_sum.0.0",
        "layernorm_323.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_323.1",
        "_fused_op_42",
        "layernorm_323.dc.multiply.4",
        "lc.input_tensor.layernorm_323.dc.reduce_sum.5.0",
        "layernorm_323.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_323.6",
        "dc.input_tensor.layernorm_323.8",
        "bert.encoder.layer.5.output.LayerNorm.weight",
        "bert.encoder.layer.5.output.LayerNorm.bias",
        "_fused_op_43",
        "bert.encoder.layer.6.attention.self.query.weight",
        "bert.encoder.layer.6.attention.self.query.bias",
        "matmul_326",
        "bert.encoder.layer.6.attention.self.key.weight",
        "bert.encoder.layer.6.attention.self.key.bias",
        "matmul_332",
        "matmul_338",
        "input_1_multiply_340",
        "_fused_op_44",
        "softmax_342.dc.reduce_max.0",
        "lc.input_tensor.softmax_342.dc.reduce_sum.3.0",
        "_fused_op_45",
        "softmax_342.dc.reduce_sum.3.lc1",
        "dc.input_tensor.softmax_342.4",
        "bert.encoder.layer.6.attention.self.value.weight",
        "bert.encoder.layer.6.attention.self.value.bias",
        "matmul_346",
        "_fused_op_46",
        "matmul_353",
        "bert.encoder.layer.6.attention.output.dense.weight",
        "bert.encoder.layer.6.attention.output.dense.bias",
        "matmul_357",
        "add_361",
        "lc.input_tensor.layernorm_362.dc.reduce_sum.0.0",
        "layernorm_362.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_362.1",
        "_fused_op_47",
        "layernorm_362.dc.multiply.4",
        "lc.input_tensor.layernorm_362.dc.reduce_sum.5.0",
        "layernorm_362.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_362.6",
        "dc.input_tensor.layernorm_362.8",
        "bert.encoder.layer.6.attention.output.LayerNorm.weight",
        "bert.encoder.layer.6.attention.output.LayerNorm.bias",
        "_fused_op_48",
        "bert.encoder.layer.6.intermediate.dense.weight",
        "bert.encoder.layer.6.intermediate.dense.bias",
        "matmul_365",
        "gelu_368",
        "bert.encoder.layer.6.output.dense.weight",
        "bert.encoder.layer.6.output.dense.bias",
        "matmul_371",
        "add_375",
        "lc.input_tensor.layernorm_376.dc.reduce_sum.0.0",
        "layernorm_376.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_376.1",
        "_fused_op_49",
        "layernorm_376.dc.multiply.4",
        "lc.input_tensor.layernorm_376.dc.reduce_sum.5.0",
        "layernorm_376.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_376.6",
        "dc.input_tensor.layernorm_376.8",
        "bert.encoder.layer.6.output.LayerNorm.weight",
        "bert.encoder.layer.6.output.LayerNorm.bias",
        "_fused_op_50",
        "bert.encoder.layer.7.attention.self.query.weight",
        "bert.encoder.layer.7.attention.self.query.bias",
        "matmul_379",
        "bert.encoder.layer.7.attention.self.key.weight",
        "bert.encoder.layer.7.attention.self.key.bias",
        "matmul_385",
        "matmul_391",
        "input_1_multiply_393",
        "_fused_op_51",
        "softmax_395.dc.reduce_max.0",
        "lc.input_tensor.softmax_395.dc.reduce_sum.3.0",
        "_fused_op_52",
        "softmax_395.dc.reduce_sum.3.lc1",
        "dc.input_tensor.softmax_395.4",
        "bert.encoder.layer.7.attention.self.value.weight",
        "bert.encoder.layer.7.attention.self.value.bias",
        "matmul_399",
        "_fused_op_53",
        "matmul_406",
        "bert.encoder.layer.7.attention.output.dense.weight",
        "bert.encoder.layer.7.attention.output.dense.bias",
        "matmul_410",
        "add_414",
        "lc.input_tensor.layernorm_415.dc.reduce_sum.0.0",
        "layernorm_415.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_415.1",
        "_fused_op_54",
        "layernorm_415.dc.multiply.4",
        "lc.input_tensor.layernorm_415.dc.reduce_sum.5.0",
        "layernorm_415.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_415.6",
        "dc.input_tensor.layernorm_415.8",
        "bert.encoder.layer.7.attention.output.LayerNorm.weight",
        "bert.encoder.layer.7.attention.output.LayerNorm.bias",
        "_fused_op_55",
        "bert.encoder.layer.7.intermediate.dense.weight",
        "bert.encoder.layer.7.intermediate.dense.bias",
        "matmul_418",
        "gelu_421",
        "bert.encoder.layer.7.output.dense.weight",
        "bert.encoder.layer.7.output.dense.bias",
        "matmul_424",
        "add_428",
        "lc.input_tensor.layernorm_429.dc.reduce_sum.0.0",
        "layernorm_429.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_429.1",
        "_fused_op_56",
        "layernorm_429.dc.multiply.4",
        "lc.input_tensor.layernorm_429.dc.reduce_sum.5.0",
        "layernorm_429.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_429.6",
        "dc.input_tensor.layernorm_429.8",
        "bert.encoder.layer.7.output.LayerNorm.weight",
        "bert.encoder.layer.7.output.LayerNorm.bias",
        "_fused_op_57",
        "bert.encoder.layer.8.attention.self.query.weight",
        "bert.encoder.layer.8.attention.self.query.bias",
        "matmul_432",
        "bert.encoder.layer.8.attention.self.key.weight",
        "bert.encoder.layer.8.attention.self.key.bias",
        "matmul_438",
        "matmul_444",
        "input_1_multiply_446",
        "multiply_22_attempt_1_input_op_fork_nop1",
        "_fused_op_58",
        "softmax_448.dc.reduce_max.0",
        "lc.input_tensor.softmax_448.dc.reduce_sum.3.0",
        "_fused_op_59",
        "softmax_448.dc.reduce_sum.3.lc1",
        "dc.input_tensor.softmax_448.4",
        "bert.encoder.layer.8.attention.self.value.weight",
        "bert.encoder.layer.8.attention.self.value.bias",
        "matmul_452",
        "_fused_op_60",
        "matmul_459",
        "bert.encoder.layer.8.attention.output.dense.weight",
        "bert.encoder.layer.8.attention.output.dense.bias",
        "matmul_463",
        "add_467",
        "lc.input_tensor.layernorm_468.dc.reduce_sum.0.0",
        "layernorm_468.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_468.1",
        "_fused_op_61",
        "layernorm_468.dc.multiply.4",
        "lc.input_tensor.layernorm_468.dc.reduce_sum.5.0",
        "layernorm_468.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_468.6",
        "dc.input_tensor.layernorm_468.8",
        "bert.encoder.layer.8.attention.output.LayerNorm.weight",
        "bert.encoder.layer.8.attention.output.LayerNorm.bias",
        "_fused_op_62",
        "bert.encoder.layer.8.intermediate.dense.weight",
        "bert.encoder.layer.8.intermediate.dense.bias",
        "matmul_471",
        "gelu_474",
        "bert.encoder.layer.8.output.dense.weight",
        "bert.encoder.layer.8.output.dense.bias",
        "matmul_477",
        "add_481",
        "lc.input_tensor.layernorm_482.dc.reduce_sum.0.0",
        "layernorm_482.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_482.1",
        "_fused_op_63",
        "layernorm_482.dc.multiply.4",
        "lc.input_tensor.layernorm_482.dc.reduce_sum.5.0",
        "layernorm_482.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_482.6",
        "dc.input_tensor.layernorm_482.8",
        "bert.encoder.layer.8.output.LayerNorm.weight",
        "bert.encoder.layer.8.output.LayerNorm.bias",
        "_fused_op_64",
        "bert.encoder.layer.9.attention.self.query.weight",
        "bert.encoder.layer.9.attention.self.query.bias",
        "matmul_485",
        "bert.encoder.layer.9.attention.self.key.weight",
        "bert.encoder.layer.9.attention.self.key.bias",
        "matmul_491",
        "matmul_497",
        "input_1_multiply_499",
        "_fused_op_65",
        "softmax_501.dc.reduce_max.0",
        "lc.input_tensor.softmax_501.dc.reduce_sum.3.0",
        "_fused_op_66",
        "softmax_501.dc.reduce_sum.3.lc1",
        "dc.input_tensor.softmax_501.4",
        "bert.encoder.layer.9.attention.self.value.weight",
        "bert.encoder.layer.9.attention.self.value.bias",
        "matmul_505",
        "_fused_op_67",
        "matmul_512",
        "bert.encoder.layer.9.attention.output.dense.weight",
        "bert.encoder.layer.9.attention.output.dense.bias",
        "matmul_516",
        "add_520",
        "lc.input_tensor.layernorm_521.dc.reduce_sum.0.0",
        "layernorm_521.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_521.1",
        "_fused_op_68",
        "layernorm_521.dc.multiply.4",
        "lc.input_tensor.layernorm_521.dc.reduce_sum.5.0",
        "layernorm_521.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_521.6",
        "dc.input_tensor.layernorm_521.8",
        "bert.encoder.layer.9.attention.output.LayerNorm.weight",
        "bert.encoder.layer.9.attention.output.LayerNorm.bias",
        "_fused_op_69",
        "bert.encoder.layer.9.intermediate.dense.weight",
        "bert.encoder.layer.9.intermediate.dense.bias",
        "matmul_524",
        "gelu_527",
        "bert.encoder.layer.9.output.dense.weight",
        "bert.encoder.layer.9.output.dense.bias",
        "matmul_530",
        "add_534",
        "lc.input_tensor.layernorm_535.dc.reduce_sum.0.0",
        "layernorm_535.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_535.1",
        "_fused_op_70",
        "layernorm_535.dc.multiply.4",
        "lc.input_tensor.layernorm_535.dc.reduce_sum.5.0",
        "layernorm_535.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_535.6",
        "dc.input_tensor.layernorm_535.8",
        "bert.encoder.layer.9.output.LayerNorm.weight",
        "bert.encoder.layer.9.output.LayerNorm.bias",
        "_fused_op_71",
        "bert.encoder.layer.10.attention.self.query.weight",
        "bert.encoder.layer.10.attention.self.query.bias",
        "matmul_538",
        "bert.encoder.layer.10.attention.self.key.weight",
        "bert.encoder.layer.10.attention.self.key.bias",
        "matmul_544",
        "matmul_550",
        "input_1_multiply_552",
        "_fused_op_72",
        "softmax_554.dc.reduce_max.0",
        "lc.input_tensor.softmax_554.dc.reduce_sum.3.0",
        "_fused_op_73",
        "softmax_554.dc.reduce_sum.3.lc1",
        "dc.input_tensor.softmax_554.4",
        "bert.encoder.layer.10.attention.self.value.weight",
        "bert.encoder.layer.10.attention.self.value.bias",
        "matmul_558",
        "_fused_op_74",
        "matmul_565",
        "bert.encoder.layer.10.attention.output.dense.weight",
        "bert.encoder.layer.10.attention.output.dense.bias",
        "matmul_569",
        "add_573",
        "lc.input_tensor.layernorm_574.dc.reduce_sum.0.0",
        "layernorm_574.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_574.1",
        "_fused_op_75",
        "layernorm_574.dc.multiply.4",
        "lc.input_tensor.layernorm_574.dc.reduce_sum.5.0",
        "layernorm_574.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_574.6",
        "dc.input_tensor.layernorm_574.8",
        "bert.encoder.layer.10.attention.output.LayerNorm.weight",
        "bert.encoder.layer.10.attention.output.LayerNorm.bias",
        "_fused_op_76",
        "bert.encoder.layer.10.intermediate.dense.weight",
        "bert.encoder.layer.10.intermediate.dense.bias",
        "matmul_577",
        "gelu_580",
        "bert.encoder.layer.10.output.dense.weight",
        "bert.encoder.layer.10.output.dense.bias",
        "matmul_583",
        "add_587",
        "lc.input_tensor.layernorm_588.dc.reduce_sum.0.0",
        "layernorm_588.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_588.1",
        "_fused_op_77",
        "layernorm_588.dc.multiply.4",
        "lc.input_tensor.layernorm_588.dc.reduce_sum.5.0",
        "layernorm_588.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_588.6",
        "dc.input_tensor.layernorm_588.8",
        "bert.encoder.layer.10.output.LayerNorm.weight",
        "bert.encoder.layer.10.output.LayerNorm.bias",
        "_fused_op_78",
        "bert.encoder.layer.11.attention.self.query.weight",
        "bert.encoder.layer.11.attention.self.query.bias",
        "matmul_591",
        "bert.encoder.layer.11.attention.self.key.weight",
        "bert.encoder.layer.11.attention.self.key.bias",
        "matmul_597",
        "matmul_603",
        "input_1_multiply_605",
        "_fused_op_79",
        "softmax_607.dc.reduce_max.0",
        "lc.input_tensor.softmax_607.dc.reduce_sum.3.0",
        "_fused_op_80",
        "softmax_607.dc.reduce_sum.3.lc1",
        "dc.input_tensor.softmax_607.4",
        "bert.encoder.layer.11.attention.self.value.weight",
        "bert.encoder.layer.11.attention.self.value.bias",
        "matmul_611",
        "_fused_op_81",
        "matmul_618",
        "bert.encoder.layer.11.attention.output.dense.weight",
        "bert.encoder.layer.11.attention.output.dense.bias",
        "matmul_622",
        "add_626",
        "lc.input_tensor.layernorm_627.dc.reduce_sum.0.0",
        "layernorm_627.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_627.1",
        "_fused_op_82",
        "layernorm_627.dc.multiply.4",
        "lc.input_tensor.layernorm_627.dc.reduce_sum.5.0",
        "layernorm_627.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_627.6",
        "dc.input_tensor.layernorm_627.8",
        "bert.encoder.layer.11.attention.output.LayerNorm.weight",
        "bert.encoder.layer.11.attention.output.LayerNorm.bias",
        "_fused_op_83",
        "bert.encoder.layer.11.intermediate.dense.weight",
        "bert.encoder.layer.11.intermediate.dense.bias",
        "matmul_630",
        "gelu_633",
        "bert.encoder.layer.11.output.dense.weight",
        "bert.encoder.layer.11.output.dense.bias",
        "matmul_636",
        "add_640",
        "lc.input_tensor.layernorm_641.dc.reduce_sum.0.0",
        "layernorm_641.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_641.1",
        "_fused_op_84",
        "layernorm_641.dc.multiply.4",
        "lc.input_tensor.layernorm_641.dc.reduce_sum.5.0",
        "layernorm_641.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_641.6",
        "dc.input_tensor.layernorm_641.8",
        "bert.encoder.layer.11.output.LayerNorm.weight",
        "bert.encoder.layer.11.output.LayerNorm.bias",
        "_fused_op_85",
        "bert.encoder.layer.12.attention.self.query.weight",
        "bert.encoder.layer.12.attention.self.query.bias",
        "matmul_644",
        "bert.encoder.layer.12.attention.self.key.weight",
        "bert.encoder.layer.12.attention.self.key.bias",
        "matmul_650",
        "matmul_656",
        "input_1_multiply_658",
        "_fused_op_86",
        "softmax_660.dc.reduce_max.0",
        "lc.input_tensor.softmax_660.dc.reduce_sum.3.0",
        "_fused_op_87",
        "softmax_660.dc.reduce_sum.3.lc1",
        "dc.input_tensor.softmax_660.4",
        "bert.encoder.layer.12.attention.self.value.weight",
        "bert.encoder.layer.12.attention.self.value.bias",
        "matmul_664",
        "_fused_op_88",
        "matmul_671",
        "bert.encoder.layer.12.attention.output.dense.weight",
        "bert.encoder.layer.12.attention.output.dense.bias",
        "matmul_675",
        "add_679",
        "lc.input_tensor.layernorm_680.dc.reduce_sum.0.0",
        "layernorm_680.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_680.1",
        "_fused_op_89",
        "layernorm_680.dc.multiply.4",
        "lc.input_tensor.layernorm_680.dc.reduce_sum.5.0",
        "layernorm_680.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_680.6",
        "dc.input_tensor.layernorm_680.8",
        "bert.encoder.layer.12.attention.output.LayerNorm.weight",
        "bert.encoder.layer.12.attention.output.LayerNorm.bias",
        "_fused_op_90",
        "bert.encoder.layer.12.intermediate.dense.weight",
        "bert.encoder.layer.12.intermediate.dense.bias",
        "matmul_683",
        "gelu_686",
        "bert.encoder.layer.12.output.dense.weight",
        "bert.encoder.layer.12.output.dense.bias",
        "matmul_689",
        "add_693",
        "lc.input_tensor.layernorm_694.dc.reduce_sum.0.0",
        "layernorm_694.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_694.1",
        "_fused_op_91",
        "layernorm_694.dc.multiply.4",
        "lc.input_tensor.layernorm_694.dc.reduce_sum.5.0",
        "layernorm_694.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_694.6",
        "dc.input_tensor.layernorm_694.8",
        "bert.encoder.layer.12.output.LayerNorm.weight",
        "bert.encoder.layer.12.output.LayerNorm.bias",
        "_fused_op_92",
        "bert.encoder.layer.13.attention.self.query.weight",
        "bert.encoder.layer.13.attention.self.query.bias",
        "matmul_697",
        "bert.encoder.layer.13.attention.self.key.weight",
        "bert.encoder.layer.13.attention.self.key.bias",
        "matmul_703",
        "matmul_709",
        "input_1_multiply_711",
        "_fused_op_93",
        "softmax_713.dc.reduce_max.0",
        "lc.input_tensor.softmax_713.dc.reduce_sum.3.0",
        "_fused_op_94",
        "softmax_713.dc.reduce_sum.3.lc1",
        "dc.input_tensor.softmax_713.4",
        "bert.encoder.layer.13.attention.self.value.weight",
        "bert.encoder.layer.13.attention.self.value.bias",
        "matmul_717",
        "_fused_op_95",
        "matmul_724",
        "bert.encoder.layer.13.attention.output.dense.weight",
        "bert.encoder.layer.13.attention.output.dense.bias",
        "matmul_728",
        "add_732",
        "lc.input_tensor.layernorm_733.dc.reduce_sum.0.0",
        "layernorm_733.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_733.1",
        "_fused_op_96",
        "layernorm_733.dc.multiply.4",
        "lc.input_tensor.layernorm_733.dc.reduce_sum.5.0",
        "layernorm_733.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_733.6",
        "dc.input_tensor.layernorm_733.8",
        "bert.encoder.layer.13.attention.output.LayerNorm.weight",
        "bert.encoder.layer.13.attention.output.LayerNorm.bias",
        "_fused_op_97",
        "bert.encoder.layer.13.intermediate.dense.weight",
        "bert.encoder.layer.13.intermediate.dense.bias",
        "matmul_736",
        "gelu_739",
        "bert.encoder.layer.13.output.dense.weight",
        "bert.encoder.layer.13.output.dense.bias",
        "matmul_742",
        "add_746",
        "lc.input_tensor.layernorm_747.dc.reduce_sum.0.0",
        "layernorm_747.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_747.1",
        "_fused_op_98",
        "layernorm_747.dc.multiply.4",
        "lc.input_tensor.layernorm_747.dc.reduce_sum.5.0",
        "layernorm_747.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_747.6",
        "dc.input_tensor.layernorm_747.8",
        "bert.encoder.layer.13.output.LayerNorm.weight",
        "bert.encoder.layer.13.output.LayerNorm.bias",
        "_fused_op_99",
        "bert.encoder.layer.14.attention.self.query.weight",
        "bert.encoder.layer.14.attention.self.query.bias",
        "matmul_750",
        "bert.encoder.layer.14.attention.self.key.weight",
        "bert.encoder.layer.14.attention.self.key.bias",
        "matmul_756",
        "matmul_762",
        "input_1_multiply_764",
        "_fused_op_100",
        "softmax_766.dc.reduce_max.0",
        "lc.input_tensor.softmax_766.dc.reduce_sum.3.0",
        "_fused_op_101",
        "softmax_766.dc.reduce_sum.3.lc1",
        "dc.input_tensor.softmax_766.4",
        "bert.encoder.layer.14.attention.self.value.weight",
        "bert.encoder.layer.14.attention.self.value.bias",
        "matmul_770",
        "_fused_op_102",
        "matmul_777",
        "bert.encoder.layer.14.attention.output.dense.weight",
        "bert.encoder.layer.14.attention.output.dense.bias",
        "matmul_781",
        "add_785",
        "lc.input_tensor.layernorm_786.dc.reduce_sum.0.0",
        "layernorm_786.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_786.1",
        "_fused_op_103",
        "layernorm_786.dc.multiply.4",
        "lc.input_tensor.layernorm_786.dc.reduce_sum.5.0",
        "layernorm_786.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_786.6",
        "dc.input_tensor.layernorm_786.8",
        "bert.encoder.layer.14.attention.output.LayerNorm.weight",
        "bert.encoder.layer.14.attention.output.LayerNorm.bias",
        "_fused_op_104",
        "bert.encoder.layer.14.intermediate.dense.weight",
        "bert.encoder.layer.14.intermediate.dense.bias",
        "matmul_789",
        "gelu_792",
        "bert.encoder.layer.14.output.dense.weight",
        "bert.encoder.layer.14.output.dense.bias",
        "matmul_795",
        "add_799",
        "lc.input_tensor.layernorm_800.dc.reduce_sum.0.0",
        "layernorm_800.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_800.1",
        "_fused_op_105",
        "layernorm_800.dc.multiply.4",
        "lc.input_tensor.layernorm_800.dc.reduce_sum.5.0",
        "layernorm_800.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_800.6",
        "dc.input_tensor.layernorm_800.8",
        "bert.encoder.layer.14.output.LayerNorm.weight",
        "bert.encoder.layer.14.output.LayerNorm.bias",
        "_fused_op_106",
        "bert.encoder.layer.15.attention.self.query.weight",
        "bert.encoder.layer.15.attention.self.query.bias",
        "matmul_803",
        "bert.encoder.layer.15.attention.self.key.weight",
        "bert.encoder.layer.15.attention.self.key.bias",
        "matmul_809",
        "matmul_815",
        "input_1_multiply_817",
        "_fused_op_107",
        "softmax_819.dc.reduce_max.0",
        "lc.input_tensor.softmax_819.dc.reduce_sum.3.0",
        "_fused_op_108",
        "softmax_819.dc.reduce_sum.3.lc1",
        "dc.input_tensor.softmax_819.4",
        "bert.encoder.layer.15.attention.self.value.weight",
        "bert.encoder.layer.15.attention.self.value.bias",
        "matmul_823",
        "_fused_op_109",
        "matmul_830",
        "bert.encoder.layer.15.attention.output.dense.weight",
        "bert.encoder.layer.15.attention.output.dense.bias",
        "matmul_834",
        "add_838",
        "lc.input_tensor.layernorm_839.dc.reduce_sum.0.0",
        "layernorm_839.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_839.1",
        "_fused_op_110",
        "layernorm_839.dc.multiply.4",
        "lc.input_tensor.layernorm_839.dc.reduce_sum.5.0",
        "layernorm_839.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_839.6",
        "dc.input_tensor.layernorm_839.8",
        "bert.encoder.layer.15.attention.output.LayerNorm.weight",
        "bert.encoder.layer.15.attention.output.LayerNorm.bias",
        "_fused_op_111",
        "bert.encoder.layer.15.intermediate.dense.weight",
        "bert.encoder.layer.15.intermediate.dense.bias",
        "matmul_842",
        "gelu_845",
        "bert.encoder.layer.15.output.dense.weight",
        "bert.encoder.layer.15.output.dense.bias",
        "matmul_848",
        "add_852",
        "lc.input_tensor.layernorm_853.dc.reduce_sum.0.0",
        "layernorm_853.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_853.1",
        "_fused_op_112",
        "layernorm_853.dc.multiply.4",
        "lc.input_tensor.layernorm_853.dc.reduce_sum.5.0",
        "layernorm_853.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_853.6",
        "dc.input_tensor.layernorm_853.8",
        "bert.encoder.layer.15.output.LayerNorm.weight",
        "bert.encoder.layer.15.output.LayerNorm.bias",
        "_fused_op_113",
        "bert.encoder.layer.16.attention.self.query.weight",
        "bert.encoder.layer.16.attention.self.query.bias",
        "matmul_856",
        "bert.encoder.layer.16.attention.self.key.weight",
        "bert.encoder.layer.16.attention.self.key.bias",
        "matmul_862",
        "matmul_868",
        "input_1_multiply_870",
        "multiply_22_attempt_1_input_op_fork_nop2",
        "_fused_op_114",
        "softmax_872.dc.reduce_max.0",
        "lc.input_tensor.softmax_872.dc.reduce_sum.3.0",
        "_fused_op_115",
        "softmax_872.dc.reduce_sum.3.lc1",
        "dc.input_tensor.softmax_872.4",
        "bert.encoder.layer.16.attention.self.value.weight",
        "bert.encoder.layer.16.attention.self.value.bias",
        "matmul_876",
        "_fused_op_116",
        "matmul_883",
        "bert.encoder.layer.16.attention.output.dense.weight",
        "bert.encoder.layer.16.attention.output.dense.bias",
        "matmul_887",
        "add_891",
        "lc.input_tensor.layernorm_892.dc.reduce_sum.0.0",
        "layernorm_892.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_892.1",
        "_fused_op_117",
        "layernorm_892.dc.multiply.4",
        "lc.input_tensor.layernorm_892.dc.reduce_sum.5.0",
        "layernorm_892.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_892.6",
        "dc.input_tensor.layernorm_892.8",
        "bert.encoder.layer.16.attention.output.LayerNorm.weight",
        "bert.encoder.layer.16.attention.output.LayerNorm.bias",
        "_fused_op_118",
        "bert.encoder.layer.16.intermediate.dense.weight",
        "bert.encoder.layer.16.intermediate.dense.bias",
        "matmul_895",
        "gelu_898",
        "bert.encoder.layer.16.output.dense.weight",
        "bert.encoder.layer.16.output.dense.bias",
        "matmul_901",
        "add_905",
        "lc.input_tensor.layernorm_906.dc.reduce_sum.0.0",
        "layernorm_906.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_906.1",
        "_fused_op_119",
        "layernorm_906.dc.multiply.4",
        "lc.input_tensor.layernorm_906.dc.reduce_sum.5.0",
        "layernorm_906.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_906.6",
        "dc.input_tensor.layernorm_906.8",
        "bert.encoder.layer.16.output.LayerNorm.weight",
        "bert.encoder.layer.16.output.LayerNorm.bias",
        "_fused_op_120",
        "bert.encoder.layer.17.attention.self.query.weight",
        "bert.encoder.layer.17.attention.self.query.bias",
        "matmul_909",
        "bert.encoder.layer.17.attention.self.key.weight",
        "bert.encoder.layer.17.attention.self.key.bias",
        "matmul_915",
        "matmul_921",
        "input_1_multiply_923",
        "_fused_op_121",
        "softmax_925.dc.reduce_max.0",
        "lc.input_tensor.softmax_925.dc.reduce_sum.3.0",
        "_fused_op_122",
        "softmax_925.dc.reduce_sum.3.lc1",
        "dc.input_tensor.softmax_925.4",
        "bert.encoder.layer.17.attention.self.value.weight",
        "bert.encoder.layer.17.attention.self.value.bias",
        "matmul_929",
        "_fused_op_123",
        "matmul_936",
        "bert.encoder.layer.17.attention.output.dense.weight",
        "bert.encoder.layer.17.attention.output.dense.bias",
        "matmul_940",
        "add_944",
        "lc.input_tensor.layernorm_945.dc.reduce_sum.0.0",
        "layernorm_945.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_945.1",
        "_fused_op_124",
        "layernorm_945.dc.multiply.4",
        "lc.input_tensor.layernorm_945.dc.reduce_sum.5.0",
        "layernorm_945.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_945.6",
        "dc.input_tensor.layernorm_945.8",
        "bert.encoder.layer.17.attention.output.LayerNorm.weight",
        "bert.encoder.layer.17.attention.output.LayerNorm.bias",
        "_fused_op_125",
        "bert.encoder.layer.17.intermediate.dense.weight",
        "bert.encoder.layer.17.intermediate.dense.bias",
        "matmul_948",
        "gelu_951",
        "bert.encoder.layer.17.output.dense.weight",
        "bert.encoder.layer.17.output.dense.bias",
        "matmul_954",
        "add_958",
        "lc.input_tensor.layernorm_959.dc.reduce_sum.0.0",
        "layernorm_959.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_959.1",
        "_fused_op_126",
        "layernorm_959.dc.multiply.4",
        "lc.input_tensor.layernorm_959.dc.reduce_sum.5.0",
        "layernorm_959.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_959.6",
        "dc.input_tensor.layernorm_959.8",
        "bert.encoder.layer.17.output.LayerNorm.weight",
        "bert.encoder.layer.17.output.LayerNorm.bias",
        "_fused_op_127",
        "bert.encoder.layer.18.attention.self.query.weight",
        "bert.encoder.layer.18.attention.self.query.bias",
        "matmul_962",
        "bert.encoder.layer.18.attention.self.key.weight",
        "bert.encoder.layer.18.attention.self.key.bias",
        "matmul_968",
        "matmul_974",
        "input_1_multiply_976",
        "_fused_op_128",
        "softmax_978.dc.reduce_max.0",
        "lc.input_tensor.softmax_978.dc.reduce_sum.3.0",
        "_fused_op_129",
        "softmax_978.dc.reduce_sum.3.lc1",
        "dc.input_tensor.softmax_978.4",
        "bert.encoder.layer.18.attention.self.value.weight",
        "bert.encoder.layer.18.attention.self.value.bias",
        "matmul_982",
        "_fused_op_130",
        "matmul_989",
        "bert.encoder.layer.18.attention.output.dense.weight",
        "bert.encoder.layer.18.attention.output.dense.bias",
        "matmul_993",
        "add_997",
        "lc.input_tensor.layernorm_998.dc.reduce_sum.0.0",
        "layernorm_998.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_998.1",
        "_fused_op_131",
        "layernorm_998.dc.multiply.4",
        "lc.input_tensor.layernorm_998.dc.reduce_sum.5.0",
        "layernorm_998.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_998.6",
        "dc.input_tensor.layernorm_998.8",
        "bert.encoder.layer.18.attention.output.LayerNorm.weight",
        "bert.encoder.layer.18.attention.output.LayerNorm.bias",
        "_fused_op_132",
        "bert.encoder.layer.18.intermediate.dense.weight",
        "bert.encoder.layer.18.intermediate.dense.bias",
        "matmul_1001",
        "gelu_1004",
        "bert.encoder.layer.18.output.dense.weight",
        "bert.encoder.layer.18.output.dense.bias",
        "matmul_1007",
        "add_1011",
        "lc.input_tensor.layernorm_1012.dc.reduce_sum.0.0",
        "layernorm_1012.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_1012.1",
        "_fused_op_133",
        "layernorm_1012.dc.multiply.4",
        "lc.input_tensor.layernorm_1012.dc.reduce_sum.5.0",
        "layernorm_1012.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_1012.6",
        "dc.input_tensor.layernorm_1012.8",
        "bert.encoder.layer.18.output.LayerNorm.weight",
        "bert.encoder.layer.18.output.LayerNorm.bias",
        "_fused_op_134",
        "bert.encoder.layer.19.attention.self.query.weight",
        "bert.encoder.layer.19.attention.self.query.bias",
        "matmul_1015",
        "bert.encoder.layer.19.attention.self.key.weight",
        "bert.encoder.layer.19.attention.self.key.bias",
        "matmul_1021",
        "matmul_1027",
        "input_1_multiply_1029",
        "_fused_op_135",
        "softmax_1031.dc.reduce_max.0",
        "lc.input_tensor.softmax_1031.dc.reduce_sum.3.0",
        "_fused_op_136",
        "softmax_1031.dc.reduce_sum.3.lc1",
        "dc.input_tensor.softmax_1031.4",
        "bert.encoder.layer.19.attention.self.value.weight",
        "bert.encoder.layer.19.attention.self.value.bias",
        "matmul_1035",
        "_fused_op_137",
        "matmul_1042",
        "bert.encoder.layer.19.attention.output.dense.weight",
        "bert.encoder.layer.19.attention.output.dense.bias",
        "matmul_1046",
        "add_1050",
        "lc.input_tensor.layernorm_1051.dc.reduce_sum.0.0",
        "layernorm_1051.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_1051.1",
        "_fused_op_138",
        "layernorm_1051.dc.multiply.4",
        "lc.input_tensor.layernorm_1051.dc.reduce_sum.5.0",
        "layernorm_1051.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_1051.6",
        "dc.input_tensor.layernorm_1051.8",
        "bert.encoder.layer.19.attention.output.LayerNorm.weight",
        "bert.encoder.layer.19.attention.output.LayerNorm.bias",
        "_fused_op_139",
        "bert.encoder.layer.19.intermediate.dense.weight",
        "bert.encoder.layer.19.intermediate.dense.bias",
        "matmul_1054",
        "gelu_1057",
        "bert.encoder.layer.19.output.dense.weight",
        "bert.encoder.layer.19.output.dense.bias",
        "matmul_1060",
        "add_1064",
        "lc.input_tensor.layernorm_1065.dc.reduce_sum.0.0",
        "layernorm_1065.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_1065.1",
        "_fused_op_140",
        "layernorm_1065.dc.multiply.4",
        "lc.input_tensor.layernorm_1065.dc.reduce_sum.5.0",
        "layernorm_1065.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_1065.6",
        "dc.input_tensor.layernorm_1065.8",
        "bert.encoder.layer.19.output.LayerNorm.weight",
        "bert.encoder.layer.19.output.LayerNorm.bias",
        "_fused_op_141",
        "bert.encoder.layer.20.attention.self.query.weight",
        "bert.encoder.layer.20.attention.self.query.bias",
        "matmul_1068",
        "bert.encoder.layer.20.attention.self.key.weight",
        "bert.encoder.layer.20.attention.self.key.bias",
        "matmul_1074",
        "matmul_1080",
        "input_1_multiply_1082",
        "_fused_op_142",
        "softmax_1084.dc.reduce_max.0",
        "lc.input_tensor.softmax_1084.dc.reduce_sum.3.0",
        "_fused_op_143",
        "softmax_1084.dc.reduce_sum.3.lc1",
        "dc.input_tensor.softmax_1084.4",
        "bert.encoder.layer.20.attention.self.value.weight",
        "bert.encoder.layer.20.attention.self.value.bias",
        "matmul_1088",
        "_fused_op_144",
        "matmul_1095",
        "bert.encoder.layer.20.attention.output.dense.weight",
        "bert.encoder.layer.20.attention.output.dense.bias",
        "matmul_1099",
        "add_1103",
        "lc.input_tensor.layernorm_1104.dc.reduce_sum.0.0",
        "layernorm_1104.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_1104.1",
        "_fused_op_145",
        "layernorm_1104.dc.multiply.4",
        "lc.input_tensor.layernorm_1104.dc.reduce_sum.5.0",
        "layernorm_1104.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_1104.6",
        "dc.input_tensor.layernorm_1104.8",
        "bert.encoder.layer.20.attention.output.LayerNorm.weight",
        "bert.encoder.layer.20.attention.output.LayerNorm.bias",
        "_fused_op_146",
        "bert.encoder.layer.20.intermediate.dense.weight",
        "bert.encoder.layer.20.intermediate.dense.bias",
        "matmul_1107",
        "gelu_1110",
        "bert.encoder.layer.20.output.dense.weight",
        "bert.encoder.layer.20.output.dense.bias",
        "matmul_1113",
        "add_1117",
        "lc.input_tensor.layernorm_1118.dc.reduce_sum.0.0",
        "layernorm_1118.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_1118.1",
        "_fused_op_147",
        "layernorm_1118.dc.multiply.4",
        "lc.input_tensor.layernorm_1118.dc.reduce_sum.5.0",
        "layernorm_1118.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_1118.6",
        "dc.input_tensor.layernorm_1118.8",
        "bert.encoder.layer.20.output.LayerNorm.weight",
        "bert.encoder.layer.20.output.LayerNorm.bias",
        "_fused_op_148",
        "bert.encoder.layer.21.attention.self.query.weight",
        "bert.encoder.layer.21.attention.self.query.bias",
        "matmul_1121",
        "bert.encoder.layer.21.attention.self.key.weight",
        "bert.encoder.layer.21.attention.self.key.bias",
        "matmul_1127",
        "matmul_1133",
        "input_1_multiply_1135",
        "_fused_op_149",
        "softmax_1137.dc.reduce_max.0",
        "lc.input_tensor.softmax_1137.dc.reduce_sum.3.0",
        "_fused_op_150",
        "softmax_1137.dc.reduce_sum.3.lc1",
        "dc.input_tensor.softmax_1137.4",
        "bert.encoder.layer.21.attention.self.value.weight",
        "bert.encoder.layer.21.attention.self.value.bias",
        "matmul_1141",
        "_fused_op_151",
        "matmul_1148",
        "bert.encoder.layer.21.attention.output.dense.weight",
        "bert.encoder.layer.21.attention.output.dense.bias",
        "matmul_1152",
        "add_1156",
        "lc.input_tensor.layernorm_1157.dc.reduce_sum.0.0",
        "layernorm_1157.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_1157.1",
        "_fused_op_152",
        "layernorm_1157.dc.multiply.4",
        "lc.input_tensor.layernorm_1157.dc.reduce_sum.5.0",
        "layernorm_1157.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_1157.6",
        "dc.input_tensor.layernorm_1157.8",
        "bert.encoder.layer.21.attention.output.LayerNorm.weight",
        "bert.encoder.layer.21.attention.output.LayerNorm.bias",
        "_fused_op_153",
        "bert.encoder.layer.21.intermediate.dense.weight",
        "bert.encoder.layer.21.intermediate.dense.bias",
        "matmul_1160",
        "gelu_1163",
        "bert.encoder.layer.21.output.dense.weight",
        "bert.encoder.layer.21.output.dense.bias",
        "matmul_1166",
        "add_1170",
        "lc.input_tensor.layernorm_1171.dc.reduce_sum.0.0",
        "layernorm_1171.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_1171.1",
        "_fused_op_154",
        "layernorm_1171.dc.multiply.4",
        "lc.input_tensor.layernorm_1171.dc.reduce_sum.5.0",
        "layernorm_1171.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_1171.6",
        "dc.input_tensor.layernorm_1171.8",
        "bert.encoder.layer.21.output.LayerNorm.weight",
        "bert.encoder.layer.21.output.LayerNorm.bias",
        "_fused_op_155",
        "bert.encoder.layer.22.attention.self.query.weight",
        "bert.encoder.layer.22.attention.self.query.bias",
        "matmul_1174",
        "bert.encoder.layer.22.attention.self.key.weight",
        "bert.encoder.layer.22.attention.self.key.bias",
        "matmul_1180",
        "matmul_1186",
        "input_1_multiply_1188",
        "_fused_op_156",
        "softmax_1190.dc.reduce_max.0",
        "lc.input_tensor.softmax_1190.dc.reduce_sum.3.0",
        "_fused_op_157",
        "softmax_1190.dc.reduce_sum.3.lc1",
        "dc.input_tensor.softmax_1190.4",
        "bert.encoder.layer.22.attention.self.value.weight",
        "bert.encoder.layer.22.attention.self.value.bias",
        "matmul_1194",
        "_fused_op_158",
        "matmul_1201",
        "bert.encoder.layer.22.attention.output.dense.weight",
        "bert.encoder.layer.22.attention.output.dense.bias",
        "matmul_1205",
        "add_1209",
        "lc.input_tensor.layernorm_1210.dc.reduce_sum.0.0",
        "layernorm_1210.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_1210.1",
        "_fused_op_159",
        "layernorm_1210.dc.multiply.4",
        "lc.input_tensor.layernorm_1210.dc.reduce_sum.5.0",
        "layernorm_1210.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_1210.6",
        "dc.input_tensor.layernorm_1210.8",
        "bert.encoder.layer.22.attention.output.LayerNorm.weight",
        "bert.encoder.layer.22.attention.output.LayerNorm.bias",
        "_fused_op_160",
        "bert.encoder.layer.22.intermediate.dense.weight",
        "bert.encoder.layer.22.intermediate.dense.bias",
        "matmul_1213",
        "gelu_1216",
        "bert.encoder.layer.22.output.dense.weight",
        "bert.encoder.layer.22.output.dense.bias",
        "matmul_1219",
        "add_1223",
        "lc.input_tensor.layernorm_1224.dc.reduce_sum.0.0",
        "layernorm_1224.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_1224.1",
        "_fused_op_161",
        "layernorm_1224.dc.multiply.4",
        "lc.input_tensor.layernorm_1224.dc.reduce_sum.5.0",
        "layernorm_1224.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_1224.6",
        "dc.input_tensor.layernorm_1224.8",
        "bert.encoder.layer.22.output.LayerNorm.weight",
        "bert.encoder.layer.22.output.LayerNorm.bias",
        "_fused_op_162",
        "bert.encoder.layer.23.attention.self.query.weight",
        "bert.encoder.layer.23.attention.self.query.bias",
        "matmul_1227",
        "bert.encoder.layer.23.attention.self.key.weight",
        "bert.encoder.layer.23.attention.self.key.bias",
        "matmul_1233",
        "matmul_1239",
        "input_1_multiply_1241",
        "_fused_op_163",
        "softmax_1243.dc.reduce_max.0",
        "lc.input_tensor.softmax_1243.dc.reduce_sum.3.0",
        "_fused_op_164",
        "softmax_1243.dc.reduce_sum.3.lc1",
        "dc.input_tensor.softmax_1243.4",
        "bert.encoder.layer.23.attention.self.value.weight",
        "bert.encoder.layer.23.attention.self.value.bias",
        "matmul_1247",
        "_fused_op_165",
        "matmul_1254",
        "bert.encoder.layer.23.attention.output.dense.weight",
        "bert.encoder.layer.23.attention.output.dense.bias",
        "matmul_1258",
        "add_1262",
        "lc.input_tensor.layernorm_1263.dc.reduce_sum.0.0",
        "layernorm_1263.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_1263.1",
        "_fused_op_166",
        "layernorm_1263.dc.multiply.4",
        "lc.input_tensor.layernorm_1263.dc.reduce_sum.5.0",
        "layernorm_1263.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_1263.6",
        "dc.input_tensor.layernorm_1263.8",
        "bert.encoder.layer.23.attention.output.LayerNorm.weight",
        "bert.encoder.layer.23.attention.output.LayerNorm.bias",
        "_fused_op_167",
        "bert.encoder.layer.23.intermediate.dense.weight",
        "bert.encoder.layer.23.intermediate.dense.bias",
        "matmul_1266",
        "gelu_1269",
        "bert.encoder.layer.23.output.dense.weight",
        "bert.encoder.layer.23.output.dense.bias",
        "matmul_1272",
        "add_1276",
        "lc.input_tensor.layernorm_1277.dc.reduce_sum.0.0",
        "layernorm_1277.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_1277.1",
        "_fused_op_168",
        "layernorm_1277.dc.multiply.4",
        "lc.input_tensor.layernorm_1277.dc.reduce_sum.5.0",
        "layernorm_1277.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_1277.6",
        "dc.input_tensor.layernorm_1277.8",
        "bert.encoder.layer.23.output.LayerNorm.weight",
        "bert.encoder.layer.23.output.LayerNorm.bias",
        "_fused_op_169",
        "qa_outputs.weight",
        "qa_outputs.bias",
        "matmul_1281",
        "matmul_1281_output_nop_0",
        "bert_large_tt_1.output_reshape_1285",
        "qa_outputs.weight_fork_clone19",
        "qa_outputs.bias_fork_clone12",
        "matmul_1288",
        "matmul_1288_output_nop_0",
        "bert_large_tt_1.output_reshape_1292"
    ]
}