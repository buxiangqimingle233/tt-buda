{
    "graph": {},
    "nodes": {
        "_fused_op_169": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "chip_id": 0,
            "class": "fused_op(0,1,)",
            "epoch": 73,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "grid_end": [
                6,
                1
            ],
            "grid_start": [
                0,
                0
            ],
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_1277.6 (port_0) ublock_order(r)",
                "Data: e2e_layernorm_1277.dc.reduce_sum.5.lc1_0 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_1277.8 (port_2) ublock_order(r)",
                "Data: e2e__fused_op_168_0 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.23.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.23.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.23.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.23.output.LayerNorm.weight": "Data",
                "dc.input_tensor.layernorm_1277.6": "Data",
                "dc.input_tensor.layernorm_1277.8": "Data",
                "e2e__fused_op_168_0": "Data",
                "e2e_layernorm_1277.dc.reduce_sum.5.lc1_0": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_1277.6",
                "e2e_layernorm_1277.dc.reduce_sum.5.lc1_0",
                "dc.input_tensor.layernorm_1277.8",
                "e2e__fused_op_168_0",
                "bert.encoder.layer.23.output.LayerNorm.weight",
                "bert.encoder.layer.23.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_169",
            "op_model": {
                "execution_cycles": 20748,
                "grid_shape": [
                    6,
                    1
                ],
                "input_shapes": [
                    [
                        1,
                        1,
                        12,
                        1
                    ],
                    [
                        1,
                        1,
                        12,
                        1
                    ],
                    [
                        1,
                        1,
                        12,
                        1
                    ],
                    [
                        1,
                        1,
                        12,
                        32
                    ],
                    [
                        1,
                        1,
                        12,
                        32
                    ],
                    [
                        1,
                        1,
                        12,
                        32
                    ]
                ],
                "inputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 2
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 0
                    },
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 2
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 4
                    },
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 2
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 0
                    },
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 32,
                            "ublock_ct": 1,
                            "ublock_rt": 2
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 4
                    },
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 32,
                            "ublock_ct": 1,
                            "ublock_rt": 2
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 64,
                        "l1_size_tiles": 64
                    },
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 32,
                            "ublock_ct": 1,
                            "ublock_rt": 2
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 64,
                        "l1_size_tiles": 64
                    }
                ],
                "op_model_id": 364793,
                "op_type": "fused_op",
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 32,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 2
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 128
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {
                    "kernel_broadcast": {
                        "input_4": 64,
                        "input_5": 64
                    }
                },
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1281 (port_0)",
                "Data: matmul_1288 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1281",
                "matmul_1288"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_1277.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_1277.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_1277.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_1277.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_1277.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_1277.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_1277.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 6965
        },
        "bert.encoder.layer.23.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "chip_id": 0,
            "class": "Input::",
            "epoch": 73,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.23.output.LayerNorm.bias",
            "op_model": {
                "execution_cycles": 0,
                "grid_shape": [
                    1,
                    1
                ],
                "input_shapes": [],
                "inputs": [],
                "op_model_id": 365501,
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 32,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 1,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 32
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_169 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_169"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.23.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 6786
        },
        "bert.encoder.layer.23.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "chip_id": 0,
            "class": "Input::",
            "epoch": 73,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.23.output.LayerNorm.weight",
            "op_model": {
                "execution_cycles": 0,
                "grid_shape": [
                    1,
                    1
                ],
                "input_shapes": [],
                "inputs": [],
                "op_model_id": 365500,
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 32,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 1,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 32
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_169 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_169"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.23.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 6784
        },
        "bert_large_tt_1.output_reshape_1285": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "chip_id": 0,
            "class": "Output",
            "epoch": 73,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [
                "Data: matmul_1281_output_nop_0 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "matmul_1281_output_nop_0": "Data"
            },
            "input_nodes": [
                "matmul_1281_output_nop_0"
            ],
            "input_tms": [
                []
            ],
            "is_cross_epoch_type": false,
            "is_saved_intermediate": false,
            "memory_access": "FIFO",
            "name": "bert_large_tt_1.output_reshape_1285",
            "opcode": "Output",
            "outgoing_edge_port_info": [],
            "output_df": "Float16_b",
            "output_nodes": [],
            "pybuda": 1,
            "queue_type": "output",
            "tags": {},
            "type": "Output",
            "unique_id": 6791
        },
        "bert_large_tt_1.output_reshape_1292": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "chip_id": 0,
            "class": "Output",
            "epoch": 73,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [
                "Data: matmul_1288_output_nop_0 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "matmul_1288_output_nop_0": "Data"
            },
            "input_nodes": [
                "matmul_1288_output_nop_0"
            ],
            "input_tms": [
                []
            ],
            "is_cross_epoch_type": false,
            "is_saved_intermediate": false,
            "memory_access": "FIFO",
            "name": "bert_large_tt_1.output_reshape_1292",
            "opcode": "Output",
            "outgoing_edge_port_info": [],
            "output_df": "Float16_b",
            "output_nodes": [],
            "pybuda": 1,
            "queue_type": "output",
            "tags": {},
            "type": "Output",
            "unique_id": 6795
        },
        "dc.input_tensor.layernorm_1277.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "chip_id": 0,
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 73,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1277.6",
            "op_model": {
                "execution_cycles": 0,
                "grid_shape": [
                    6,
                    1
                ],
                "input_shapes": [],
                "inputs": [],
                "op_model_id": 365498,
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 2
                        },
                        "buffer_factor": 1,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 2
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_169 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_169"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 6775
        },
        "dc.input_tensor.layernorm_1277.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "chip_id": 0,
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 73,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_1277.8",
            "op_model": {
                "execution_cycles": 0,
                "grid_shape": [
                    6,
                    1
                ],
                "input_shapes": [],
                "inputs": [],
                "op_model_id": 365499,
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 2
                        },
                        "buffer_factor": 1,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 2
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_169 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_169"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 6777
        },
        "e2e__fused_op_168_0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "BudaDramQueue::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [
                "Data: _fused_op_168 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_168": "Data"
            },
            "input_nodes": [
                "_fused_op_168"
            ],
            "input_tms": [
                []
            ],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "e2e__fused_op_168_0",
            "op_model": {
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "opcode": "Queue",
            "outgoing_edge_port_info": [
                "Data: _fused_op_169 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_169"
            ],
            "pybuda": 1,
            "queue_type": "epoch_to_epoch",
            "tags": {},
            "type": "Queue",
            "unique_id": 7894
        },
        "e2e_layernorm_1277.dc.reduce_sum.5.lc1_0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "class": "BudaDramQueue::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [
                "Data: layernorm_1277.dc.reduce_sum.5.lc1 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_1277.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "layernorm_1277.dc.reduce_sum.5.lc1"
            ],
            "input_tms": [
                []
            ],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "e2e_layernorm_1277.dc.reduce_sum.5.lc1_0",
            "op_model": {
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "opcode": "Queue",
            "outgoing_edge_port_info": [
                "Data: _fused_op_169 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_169"
            ],
            "pybuda": 1,
            "queue_type": "epoch_to_epoch",
            "tags": {},
            "type": "Queue",
            "unique_id": 7895
        },
        "matmul_1281": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "chip_id": 0,
            "class": "matmul",
            "epoch": 73,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "grid_end": [
                6,
                2
            ],
            "grid_start": [
                0,
                1
            ],
            "incoming_edge_port_info": [
                "Data: _fused_op_169 (port_0) ublock_order(c)",
                "Data: qa_outputs.weight (port_1) ublock_order(r)",
                "Data: qa_outputs.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_169": "Data",
                "qa_outputs.bias": "Data",
                "qa_outputs.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_169",
                "qa_outputs.weight",
                "qa_outputs.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1281",
            "op_model": {
                "execution_cycles": 4819,
                "grid_shape": [
                    6,
                    1
                ],
                "input_shapes": [
                    [
                        1,
                        1,
                        12,
                        32
                    ],
                    [
                        1,
                        1,
                        32,
                        1
                    ],
                    [
                        1,
                        1,
                        12,
                        1
                    ]
                ],
                "inputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 8,
                            "ublock_ct": 4,
                            "ublock_rt": 2
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 16
                    },
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 8,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 4
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 0
                    },
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 6,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 2
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 1,
                        "l1_size_tiles": 1
                    }
                ],
                "op_model_id": 223278,
                "op_type": "matmul",
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 2
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 4
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true,
                    "kernel_broadcast": {
                        "input_2": 1
                    },
                    "l1_acc": true,
                    "m_k": 8,
                    "u_kt": 4
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1281_output_nop_0 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1281_output_nop_0"
            ],
            "pybuda": 1,
            "tags": {
                "original_op_name": "matmul_1281",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 6788
        },
        "matmul_1281_output_nop_0": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "chip_id": 0,
            "class": "nop",
            "epoch": 73,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "grid_end": [
                6,
                4
            ],
            "grid_start": [
                0,
                3
            ],
            "incoming_edge_port_info": [
                "Data: matmul_1281 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "matmul_1281": "Data"
            },
            "input_nodes": [
                "matmul_1281"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1281_output_nop_0",
            "op_model": {
                "execution_cycles": 417,
                "grid_shape": [
                    6,
                    1
                ],
                "input_shapes": [
                    [
                        1,
                        1,
                        12,
                        1
                    ]
                ],
                "inputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 2
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 4
                    }
                ],
                "op_model_id": 223302,
                "op_type": "nop",
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 2
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 4
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: bert_large_tt_1.output_reshape_1285 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "bert_large_tt_1.output_reshape_1285"
            ],
            "pybuda": 1,
            "tags": {
                "original_op_name": "matmul_1281",
                "original_op_type": "matmul"
            },
            "type": "nop",
            "unique_id": 6966
        },
        "matmul_1288": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "chip_id": 0,
            "class": "matmul",
            "epoch": 73,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "grid_end": [
                6,
                3
            ],
            "grid_start": [
                0,
                2
            ],
            "incoming_edge_port_info": [
                "Data: _fused_op_169 (port_0) ublock_order(c)",
                "Data: qa_outputs.weight_fork_clone19 (port_1) ublock_order(r)",
                "Data: qa_outputs.bias_fork_clone12 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_169": "Data",
                "qa_outputs.bias_fork_clone12": "Data",
                "qa_outputs.weight_fork_clone19": "Data"
            },
            "input_nodes": [
                "_fused_op_169",
                "qa_outputs.weight_fork_clone19",
                "qa_outputs.bias_fork_clone12"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1288",
            "op_model": {
                "execution_cycles": 4819,
                "grid_shape": [
                    6,
                    1
                ],
                "input_shapes": [
                    [
                        1,
                        1,
                        12,
                        32
                    ],
                    [
                        1,
                        1,
                        32,
                        1
                    ],
                    [
                        1,
                        1,
                        12,
                        1
                    ]
                ],
                "inputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 8,
                            "ublock_ct": 4,
                            "ublock_rt": 2
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 16
                    },
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 8,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 4
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 0
                    },
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 6,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 2
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 1,
                        "l1_size_tiles": 1
                    }
                ],
                "op_model_id": 223394,
                "op_type": "matmul",
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 2
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 4
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true,
                    "kernel_broadcast": {
                        "input_2": 1
                    },
                    "l1_acc": true,
                    "m_k": 8,
                    "u_kt": 4
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_1288_output_nop_0 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1288_output_nop_0"
            ],
            "pybuda": 1,
            "tags": {
                "original_op_name": "matmul_1288",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 6792
        },
        "matmul_1288_output_nop_0": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "chip_id": 0,
            "class": "nop",
            "epoch": 73,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "grid_end": [
                6,
                5
            ],
            "grid_start": [
                0,
                4
            ],
            "incoming_edge_port_info": [
                "Data: matmul_1288 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "matmul_1288": "Data"
            },
            "input_nodes": [
                "matmul_1288"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_1288_output_nop_0",
            "op_model": {
                "execution_cycles": 417,
                "grid_shape": [
                    6,
                    1
                ],
                "input_shapes": [
                    [
                        1,
                        1,
                        12,
                        1
                    ]
                ],
                "inputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 2
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 4
                    }
                ],
                "op_model_id": 223418,
                "op_type": "nop",
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 2
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 4
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: bert_large_tt_1.output_reshape_1292 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "bert_large_tt_1.output_reshape_1292"
            ],
            "pybuda": 1,
            "tags": {
                "original_op_name": "matmul_1288",
                "original_op_type": "matmul"
            },
            "type": "nop",
            "unique_id": 6967
        },
        "qa_outputs.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "chip_id": 0,
            "class": "Input::",
            "epoch": 73,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "qa_outputs.bias",
            "op_model": {
                "execution_cycles": 0,
                "grid_shape": [
                    1,
                    1
                ],
                "input_shapes": [],
                "inputs": [],
                "op_model_id": 365503,
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 1,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 1
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1281 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1281"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "qa_outputs.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 6790
        },
        "qa_outputs.bias_fork_clone12": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "chip_id": 0,
            "class": "Input::",
            "epoch": 73,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "qa_outputs.bias_fork_clone12",
            "op_model": {
                "execution_cycles": 0,
                "grid_shape": [
                    1,
                    1
                ],
                "input_shapes": [],
                "inputs": [],
                "op_model_id": 365505,
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 1,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 1
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1288 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1288"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "qa_outputs.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 6794
        },
        "qa_outputs.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    32
                ]
            },
            "chip_id": 0,
            "class": "Input::",
            "epoch": 73,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "qa_outputs.weight",
            "op_model": {
                "execution_cycles": 0,
                "grid_shape": [
                    4,
                    1
                ],
                "input_shapes": [],
                "inputs": [],
                "op_model_id": 365502,
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 2,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 4
                        },
                        "buffer_factor": 1,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 8
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1281 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1281"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "qa_outputs.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 6789
        },
        "qa_outputs.weight_fork_clone19": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    32
                ]
            },
            "chip_id": 0,
            "class": "Input::",
            "epoch": 73,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "qa_outputs.weight_fork_clone19",
            "op_model": {
                "execution_cycles": 0,
                "grid_shape": [
                    4,
                    1
                ],
                "input_shapes": [],
                "inputs": [],
                "op_model_id": 365504,
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 2,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 4
                        },
                        "buffer_factor": 1,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 8
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_1288 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_1288"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "qa_outputs.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 6793
        }
    },
    "topological_sorted_nodes": [
        "dc.input_tensor.layernorm_1277.6",
        "dc.input_tensor.layernorm_1277.8",
        "bert.encoder.layer.23.output.LayerNorm.weight",
        "bert.encoder.layer.23.output.LayerNorm.bias",
        "e2e_layernorm_1277.dc.reduce_sum.5.lc1_0",
        "e2e__fused_op_168_0",
        "_fused_op_169",
        "qa_outputs.weight",
        "qa_outputs.bias",
        "matmul_1281",
        "matmul_1281_output_nop_0",
        "bert_large_tt_1.output_reshape_1285",
        "qa_outputs.weight_fork_clone19",
        "qa_outputs.bias_fork_clone12",
        "matmul_1288",
        "matmul_1288_output_nop_0",
        "bert_large_tt_1.output_reshape_1292"
    ]
}