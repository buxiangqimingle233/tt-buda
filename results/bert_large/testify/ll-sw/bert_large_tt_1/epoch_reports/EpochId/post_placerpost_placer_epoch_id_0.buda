{
    "graph": {},
    "nodes": {
        "_fused_op_0": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "chip_id": 0,
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "grid_end": [
                4,
                2
            ],
            "grid_start": [
                0,
                1
            ],
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_0.1 (port_0) ublock_order(c)",
                "Data: layernorm_0.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: pybuda_6_i0 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "dc.input_tensor.layernorm_0.1": "Data",
                "layernorm_0.dc.reduce_sum.0.lc1": "Data",
                "pybuda_6_i0": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_0.1",
                "layernorm_0.dc.reduce_sum.0.lc1",
                "pybuda_6_i0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_0",
            "op_model": {
                "execution_cycles": 12747,
                "grid_shape": [
                    4,
                    1
                ],
                "input_shapes": [
                    [
                        1,
                        1,
                        12,
                        32
                    ],
                    [
                        1,
                        1,
                        12,
                        32
                    ],
                    [
                        1,
                        1,
                        12,
                        32
                    ]
                ],
                "inputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 3,
                            "tblock_n": 4,
                            "ublock_ct": 8,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 0
                    },
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 3,
                            "tblock_n": 4,
                            "ublock_ct": 8,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 16
                    },
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 3,
                            "tblock_n": 4,
                            "ublock_ct": 8,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 16
                    }
                ],
                "op_model_id": 2636941,
                "op_type": "fused_op",
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 3,
                            "mblock_n": 4,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 8,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 192
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_0.dc.multiply.4 (port_0)",
                "Data: buffer_1_29655_29656 (port_0)",
                "Data: layernorm_0.dc.multiply.4 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_0.dc.multiply.4",
                "buffer_1_29655_29656",
                "layernorm_0.dc.multiply.4"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_0.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_0.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29655
        },
        "_fused_op_1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "chip_id": 0,
            "class": "fused_op(0,1,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "grid_end": [
                5,
                8
            ],
            "grid_start": [
                1,
                7
            ],
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_0.6 (port_0) ublock_order(r)",
                "Data: layernorm_0.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_0.8 (port_2) ublock_order(r)",
                "Data: buffer_0_29655_29656 (port_3) ublock_order(r)",
                "Data: bert.embeddings.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.embeddings.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.embeddings.LayerNorm.bias": "Data",
                "bert.embeddings.LayerNorm.weight": "Data",
                "buffer_0_29655_29656": "Data",
                "dc.input_tensor.layernorm_0.6": "Data",
                "dc.input_tensor.layernorm_0.8": "Data",
                "layernorm_0.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_0.6",
                "layernorm_0.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_0.8",
                "buffer_0_29655_29656",
                "bert.embeddings.LayerNorm.weight",
                "bert.embeddings.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_1",
            "op_model": {
                "execution_cycles": 26676,
                "grid_shape": [
                    4,
                    1
                ],
                "input_shapes": [
                    [
                        1,
                        1,
                        12,
                        1
                    ],
                    [
                        1,
                        1,
                        12,
                        1
                    ],
                    [
                        1,
                        1,
                        12,
                        1
                    ],
                    [
                        1,
                        1,
                        12,
                        32
                    ],
                    [
                        1,
                        1,
                        12,
                        32
                    ],
                    [
                        1,
                        1,
                        12,
                        32
                    ]
                ],
                "inputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 3
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 0
                    },
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 3
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 6
                    },
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 3
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 0
                    },
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 32,
                            "ublock_ct": 1,
                            "ublock_rt": 3
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 36
                    },
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 32,
                            "ublock_ct": 1,
                            "ublock_rt": 3
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 96,
                        "l1_size_tiles": 96
                    },
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 32,
                            "ublock_ct": 1,
                            "ublock_rt": 3
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 96,
                        "l1_size_tiles": 96
                    }
                ],
                "op_model_id": 2637284,
                "op_type": "fused_op",
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 32,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 3
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 192
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {
                    "kernel_broadcast": {
                        "input_4": 96,
                        "input_5": 96
                    }
                },
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_4 (port_0)",
                "Data: matmul_10 (port_0)",
                "Data: e2e__fused_op_1_0 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_4",
                "matmul_10",
                "e2e__fused_op_1_0"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_0.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_0.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_0.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_0.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_0.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_0.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_0.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29656
        },
        "_fused_op_2": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "chip_id": 0,
            "class": "fused_op",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "grid_end": [
                9,
                8
            ],
            "grid_start": [
                5,
                6
            ],
            "incoming_edge_port_info": [
                "Data: matmul_16 (port_0) ublock_order(r)",
                "Data: input_1_multiply_18 (port_1) ublock_order(r)",
                "Data: multiply_22_attempt_1_input_op_fork_nop0 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "input_1_multiply_18": "Data",
                "matmul_16": "Data",
                "multiply_22_attempt_1_input_op_fork_nop0": "Data"
            },
            "input_nodes": [
                "matmul_16",
                "input_1_multiply_18",
                "multiply_22_attempt_1_input_op_fork_nop0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_2",
            "op_model": {
                "execution_cycles": 40959,
                "grid_shape": [
                    4,
                    2
                ],
                "input_shapes": [
                    [
                        1,
                        16,
                        12,
                        12
                    ],
                    [
                        1,
                        16,
                        12,
                        12
                    ],
                    [
                        1,
                        16,
                        12,
                        12
                    ]
                ],
                "inputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 16,
                            "tblock_m": 3,
                            "tblock_n": 1,
                            "ublock_ct": 6,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 12
                    },
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 16,
                            "tblock_m": 3,
                            "tblock_n": 1,
                            "ublock_ct": 6,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 1,
                        "l1_size_tiles": 1
                    },
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 16,
                            "tblock_m": 3,
                            "tblock_n": 1,
                            "ublock_ct": 6,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 12
                    }
                ],
                "op_model_id": 2526549,
                "op_type": "fused_op",
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 3,
                            "mblock_n": 1,
                            "t": 16,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 6,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 36
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "kernel_broadcast": {
                        "input_1": 1
                    }
                },
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_24.dc.reduce_max.0 (port_0)",
                "Data: e2e__fused_op_2_0 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_24.dc.reduce_max.0",
                "e2e__fused_op_2_0"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "multiply_18: multiply (1,16,12,12), out: 0",
                    "add_23: add (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "add"
            },
            "type": "fused_op",
            "unique_id": 29657
        },
        "attention_mask_1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    384
                ]
            },
            "chip_id": 0,
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "attention_mask_1",
            "op_model": {
                "execution_cycles": 0,
                "grid_shape": [
                    1,
                    1
                ],
                "input_shapes": [],
                "inputs": [],
                "op_model_id": 2936844,
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 2,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 6,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 1,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 12
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: subtract_21 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "subtract_21"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_name": "attention_mask_1"
            },
            "tile_broadcast": [],
            "type": "Input::input",
            "unique_id": 27161
        },
        "bert.embeddings.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "chip_id": 0,
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.embeddings.LayerNorm.bias",
            "op_model": {
                "execution_cycles": 0,
                "grid_shape": [
                    1,
                    1
                ],
                "input_shapes": [],
                "inputs": [],
                "op_model_id": 2936838,
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 32,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 1,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 32
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.embeddings.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27140
        },
        "bert.embeddings.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "chip_id": 0,
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.embeddings.LayerNorm.weight",
            "op_model": {
                "execution_cycles": 0,
                "grid_shape": [
                    1,
                    1
                ],
                "input_shapes": [],
                "inputs": [],
                "op_model_id": 2936837,
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 32,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 1,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 32
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.embeddings.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27138
        },
        "bert.encoder.layer.0.attention.self.key.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "chip_id": 0,
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.0.attention.self.key.bias",
            "op_model": {
                "execution_cycles": 0,
                "grid_shape": [
                    1,
                    2
                ],
                "input_shapes": [],
                "inputs": [],
                "op_model_id": 2936842,
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 2,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 8,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 1,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 16
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_10 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_10"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.0.attention.self.key.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27151
        },
        "bert.encoder.layer.0.attention.self.key.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "chip_id": 0,
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.0.attention.self.key.weight",
            "op_model": {
                "execution_cycles": 0,
                "grid_shape": [
                    4,
                    2
                ],
                "input_shapes": [],
                "inputs": [],
                "op_model_id": 2936841,
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 2,
                            "mblock_n": 2,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 8,
                            "ublock_rt": 4
                        },
                        "buffer_factor": 1,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 128
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_10 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_10"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.0.attention.self.key.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27150
        },
        "bert.encoder.layer.0.attention.self.query.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "chip_id": 0,
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.0.attention.self.query.bias",
            "op_model": {
                "execution_cycles": 0,
                "grid_shape": [
                    1,
                    2
                ],
                "input_shapes": [],
                "inputs": [],
                "op_model_id": 2936840,
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 2,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 8,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 1,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 16
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_4 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_4"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.0.attention.self.query.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27145
        },
        "bert.encoder.layer.0.attention.self.query.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "chip_id": 0,
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.0.attention.self.query.weight",
            "op_model": {
                "execution_cycles": 0,
                "grid_shape": [
                    4,
                    2
                ],
                "input_shapes": [],
                "inputs": [],
                "op_model_id": 2936839,
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 2,
                            "mblock_n": 2,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 8,
                            "ublock_rt": 4
                        },
                        "buffer_factor": 1,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 128
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_4 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_4"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.0.attention.self.query.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 27144
        },
        "buffer_0_29655_29656": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "chip_id": 0,
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "grid_end": [
                5,
                7
            ],
            "grid_start": [
                1,
                6
            ],
            "incoming_edge_port_info": [
                "Data: buffer_1_29655_29656 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29655_29656": "Data"
            },
            "input_nodes": [
                "buffer_1_29655_29656"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29655_29656",
            "op_model": {
                "execution_cycles": 9036,
                "grid_shape": [
                    4,
                    1
                ],
                "input_shapes": [
                    [
                        1,
                        1,
                        12,
                        32
                    ]
                ],
                "inputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 3,
                            "tblock_n": 4,
                            "ublock_ct": 8,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 240
                    }
                ],
                "op_model_id": 2637223,
                "op_type": "nop",
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 3,
                            "mblock_n": 4,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 8,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 192
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_1"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 29830
        },
        "buffer_1_29655_29656": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "chip_id": 0,
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "grid_end": [
                5,
                5
            ],
            "grid_start": [
                1,
                4
            ],
            "incoming_edge_port_info": [
                "Data: _fused_op_0 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_0": "Data"
            },
            "input_nodes": [
                "_fused_op_0"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29655_29656",
            "op_model": {
                "execution_cycles": 9036,
                "grid_shape": [
                    4,
                    1
                ],
                "input_shapes": [
                    [
                        1,
                        1,
                        12,
                        32
                    ]
                ],
                "inputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 3,
                            "tblock_n": 4,
                            "ublock_ct": 8,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 240
                    }
                ],
                "op_model_id": 2637082,
                "op_type": "nop",
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 3,
                            "mblock_n": 4,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 8,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 192
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29655_29656 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29655_29656"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 29831
        },
        "dc.input_tensor.layernorm_0.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "chip_id": 0,
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_0.1",
            "op_model": {
                "execution_cycles": 0,
                "grid_shape": [
                    4,
                    1
                ],
                "input_shapes": [],
                "inputs": [],
                "op_model_id": 2936833,
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 3,
                            "mblock_n": 4,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 8,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 1,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 96
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_0 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_0"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27123
        },
        "dc.input_tensor.layernorm_0.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "chip_id": 0,
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_0.6",
            "op_model": {
                "execution_cycles": 0,
                "grid_shape": [
                    4,
                    1
                ],
                "input_shapes": [],
                "inputs": [],
                "op_model_id": 2936835,
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 3
                        },
                        "buffer_factor": 1,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 3
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27129
        },
        "dc.input_tensor.layernorm_0.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "chip_id": 0,
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_0.8",
            "op_model": {
                "execution_cycles": 0,
                "grid_shape": [
                    4,
                    1
                ],
                "input_shapes": [],
                "inputs": [],
                "op_model_id": 2936836,
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 3
                        },
                        "buffer_factor": 1,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 3
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27131
        },
        "e2e__fused_op_1_0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "BudaDramQueue::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [
                "Data: _fused_op_1 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_1": "Data"
            },
            "input_nodes": [
                "_fused_op_1"
            ],
            "input_tms": [
                []
            ],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "e2e__fused_op_1_0",
            "op_model": {
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "opcode": "Queue",
            "outgoing_edge_port_info": [
                "Data: matmul_28 (port_0)",
                "Data: add_43 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_28",
                "add_43"
            ],
            "pybuda": 1,
            "queue_type": "epoch_to_epoch",
            "tags": {},
            "type": "Queue",
            "unique_id": 31471
        },
        "e2e__fused_op_2_0": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "BudaDramQueue::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [
                "Data: _fused_op_2 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_2": "Data"
            },
            "input_nodes": [
                "_fused_op_2"
            ],
            "input_tms": [
                []
            ],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "e2e__fused_op_2_0",
            "op_model": {
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "opcode": "Queue",
            "outgoing_edge_port_info": [
                "Data: _fused_op_3 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_3"
            ],
            "pybuda": 1,
            "queue_type": "epoch_to_epoch",
            "tags": {},
            "type": "Queue",
            "unique_id": 31473
        },
        "e2e_multiply_22_attempt_1_input_op_fork_nop0_0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    384
                ]
            },
            "class": "BudaDramQueue::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [
                "Data: multiply_22_attempt_1_input_op_fork_nop0 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "multiply_22_attempt_1_input_op_fork_nop0": "Data"
            },
            "input_nodes": [
                "multiply_22_attempt_1_input_op_fork_nop0"
            ],
            "input_tms": [
                []
            ],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "e2e_multiply_22_attempt_1_input_op_fork_nop0_0",
            "op_model": {
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "opcode": "Queue",
            "outgoing_edge_port_info": [
                "Data: _fused_op_9 (port_0)",
                "Data: _fused_op_16 (port_0)",
                "Data: _fused_op_23 (port_0)",
                "Data: _fused_op_30 (port_0)",
                "Data: _fused_op_37 (port_0)",
                "Data: _fused_op_44 (port_0)",
                "Data: _fused_op_51 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_9",
                "_fused_op_16",
                "_fused_op_23",
                "_fused_op_30",
                "_fused_op_37",
                "_fused_op_44",
                "_fused_op_51"
            ],
            "pybuda": 1,
            "queue_type": "epoch_to_epoch",
            "tags": {},
            "type": "Queue",
            "unique_id": 31472
        },
        "e2e_multiply_22_attempt_1_input_op_fork_nop1_0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    384
                ]
            },
            "class": "BudaDramQueue::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [
                "Data: multiply_22_attempt_1_input_op_fork_nop1 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "multiply_22_attempt_1_input_op_fork_nop1": "Data"
            },
            "input_nodes": [
                "multiply_22_attempt_1_input_op_fork_nop1"
            ],
            "input_tms": [
                []
            ],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "e2e_multiply_22_attempt_1_input_op_fork_nop1_0",
            "op_model": {
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "opcode": "Queue",
            "outgoing_edge_port_info": [
                "Data: _fused_op_58 (port_0)",
                "Data: _fused_op_65 (port_0)",
                "Data: _fused_op_72 (port_0)",
                "Data: _fused_op_79 (port_0)",
                "Data: _fused_op_86 (port_0)",
                "Data: _fused_op_93 (port_0)",
                "Data: _fused_op_100 (port_0)",
                "Data: _fused_op_107 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_58",
                "_fused_op_65",
                "_fused_op_72",
                "_fused_op_79",
                "_fused_op_86",
                "_fused_op_93",
                "_fused_op_100",
                "_fused_op_107"
            ],
            "pybuda": 1,
            "queue_type": "epoch_to_epoch",
            "tags": {},
            "type": "Queue",
            "unique_id": 31513
        },
        "e2e_multiply_22_attempt_1_input_op_fork_nop2_0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    384
                ]
            },
            "class": "BudaDramQueue::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [
                "Data: multiply_22_attempt_1_input_op_fork_nop2 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "multiply_22_attempt_1_input_op_fork_nop2": "Data"
            },
            "input_nodes": [
                "multiply_22_attempt_1_input_op_fork_nop2"
            ],
            "input_tms": [
                []
            ],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "e2e_multiply_22_attempt_1_input_op_fork_nop2_0",
            "op_model": {
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "opcode": "Queue",
            "outgoing_edge_port_info": [
                "Data: _fused_op_114 (port_0)",
                "Data: _fused_op_121 (port_0)",
                "Data: _fused_op_128 (port_0)",
                "Data: _fused_op_135 (port_0)",
                "Data: _fused_op_142 (port_0)",
                "Data: _fused_op_149 (port_0)",
                "Data: _fused_op_156 (port_0)",
                "Data: _fused_op_163 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_114",
                "_fused_op_121",
                "_fused_op_128",
                "_fused_op_135",
                "_fused_op_142",
                "_fused_op_149",
                "_fused_op_156",
                "_fused_op_163"
            ],
            "pybuda": 1,
            "queue_type": "epoch_to_epoch",
            "tags": {},
            "type": "Queue",
            "unique_id": 31554
        },
        "e2e_softmax_24.dc.reduce_max.0_0": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "BudaDramQueue::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [
                "Data: softmax_24.dc.reduce_max.0 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "softmax_24.dc.reduce_max.0": "Data"
            },
            "input_nodes": [
                "softmax_24.dc.reduce_max.0"
            ],
            "input_tms": [
                []
            ],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "e2e_softmax_24.dc.reduce_max.0_0",
            "op_model": {
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "opcode": "Queue",
            "outgoing_edge_port_info": [
                "Data: _fused_op_3 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_3"
            ],
            "pybuda": 1,
            "queue_type": "epoch_to_epoch",
            "tags": {},
            "type": "Queue",
            "unique_id": 31474
        },
        "input_0_subtract_21": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "chip_id": 0,
            "class": "constant",
            "constant_dims": [
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "input_0_subtract_21",
            "op_model": {
                "execution_cycles": 0,
                "grid_shape": [
                    1,
                    1
                ],
                "input_shapes": [],
                "inputs": [],
                "op_model_id": 2936845,
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 1,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 1
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: subtract_21 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "subtract_21"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert",
                "original_op_name": "subtract_21",
                "original_op_type": "subtract"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27165
        },
        "input_1_multiply_18": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "chip_id": 0,
            "class": "constant",
            "constant_dims": [
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "input_1_multiply_18",
            "op_model": {
                "execution_cycles": 0,
                "grid_shape": [
                    1,
                    1
                ],
                "input_shapes": [],
                "inputs": [],
                "op_model_id": 2936843,
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 1,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 1
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_2 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_2"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "add"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27159
        },
        "input_1_multiply_22": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "chip_id": 0,
            "class": "constant",
            "constant_dims": [
                1
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "input_1_multiply_22",
            "op_model": {
                "execution_cycles": 0,
                "grid_shape": [
                    1,
                    1
                ],
                "input_shapes": [],
                "inputs": [],
                "op_model_id": 2936846,
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 1,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 1
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: multiply_22 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "multiply_22"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert",
                "original_op_name": "multiply_22",
                "original_op_type": "multiply"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27167
        },
        "layernorm_0.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "chip_id": 0,
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "grid_end": [
                4,
                4
            ],
            "grid_start": [
                0,
                3
            ],
            "incoming_edge_port_info": [
                "Data: _fused_op_0 (port_0) ublock_order(c)",
                "Data: _fused_op_0 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_0": "Data"
            },
            "input_nodes": [
                "_fused_op_0",
                "_fused_op_0"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_0.dc.multiply.4",
            "op_model": {
                "execution_cycles": 13147,
                "grid_shape": [
                    4,
                    1
                ],
                "input_shapes": [
                    [
                        1,
                        1,
                        12,
                        32
                    ],
                    [
                        1,
                        1,
                        12,
                        32
                    ]
                ],
                "inputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 3,
                            "tblock_n": 4,
                            "ublock_ct": 8,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 16
                    },
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 3,
                            "tblock_n": 4,
                            "ublock_ct": 8,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 16
                    }
                ],
                "op_model_id": 2525387,
                "op_type": "multiply",
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 3,
                            "mblock_n": 4,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 8,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 192
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_0.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_0.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEmbeddings::embeddings/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_0",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 27125
        },
        "layernorm_0.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "chip_id": 0,
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "grid_end": [
                4,
                1
            ],
            "grid_start": [
                0,
                0
            ],
            "incoming_edge_port_info": [
                "Data: pybuda_6_i0 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_0.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "lc.input_tensor.layernorm_0.dc.reduce_sum.0.0": "Data",
                "pybuda_6_i0": "Data"
            },
            "input_nodes": [
                "pybuda_6_i0",
                "lc.input_tensor.layernorm_0.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_0.dc.reduce_sum.0.lc1",
            "op_model": {
                "execution_cycles": 6855,
                "grid_shape": [
                    4,
                    1
                ],
                "input_shapes": [
                    [
                        1,
                        1,
                        12,
                        32
                    ],
                    [
                        1,
                        1,
                        32,
                        1
                    ]
                ],
                "inputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 8,
                            "ublock_ct": 4,
                            "ublock_rt": 3
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 24
                    },
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 8,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 4
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 1,
                        "l1_size_tiles": 1
                    }
                ],
                "op_model_id": 2525138,
                "op_type": "matmul",
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 3
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 6
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "kernel_broadcast": {
                        "input_1": 1
                    },
                    "l1_acc": true,
                    "m_k": 8,
                    "u_kt": 4
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_0 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_0"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEmbeddings::embeddings/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_0",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 27120
        },
        "layernorm_0.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "chip_id": 0,
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "grid_end": [
                4,
                6
            ],
            "grid_start": [
                0,
                5
            ],
            "incoming_edge_port_info": [
                "Data: layernorm_0.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_0.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_0.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_0.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_0.dc.multiply.4",
                "lc.input_tensor.layernorm_0.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_0.dc.reduce_sum.5.lc1",
            "op_model": {
                "execution_cycles": 6855,
                "grid_shape": [
                    4,
                    1
                ],
                "input_shapes": [
                    [
                        1,
                        1,
                        12,
                        32
                    ],
                    [
                        1,
                        1,
                        32,
                        1
                    ]
                ],
                "inputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 8,
                            "ublock_ct": 4,
                            "ublock_rt": 3
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 24
                    },
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 8,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 4
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 1,
                        "l1_size_tiles": 1
                    }
                ],
                "op_model_id": 2525509,
                "op_type": "matmul",
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 3
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 6
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "kernel_broadcast": {
                        "input_1": 1
                    },
                    "l1_acc": true,
                    "m_k": 8,
                    "u_kt": 4
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEmbeddings::embeddings/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_0",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 27127
        },
        "lc.input_tensor.layernorm_0.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "chip_id": 0,
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_0.dc.reduce_sum.0.0",
            "op_model": {
                "execution_cycles": 0,
                "grid_shape": [
                    1,
                    1
                ],
                "input_shapes": [],
                "inputs": [],
                "op_model_id": 2936831,
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 1,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 1
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_0.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_0.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEmbeddings::embeddings/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_0",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27119
        },
        "lc.input_tensor.layernorm_0.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "chip_id": 0,
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_0.dc.reduce_sum.5.0",
            "op_model": {
                "execution_cycles": 0,
                "grid_shape": [
                    1,
                    1
                ],
                "input_shapes": [],
                "inputs": [],
                "op_model_id": 2936834,
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 1,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 1
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_0.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_0.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEmbeddings::embeddings/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_0",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 27126
        },
        "matmul_10": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "chip_id": 0,
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "grid_end": [
                8,
                4
            ],
            "grid_start": [
                4,
                2
            ],
            "incoming_edge_port_info": [
                "Data: _fused_op_1 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.0.attention.self.key.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.0.attention.self.key.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_1": "Data",
                "bert.encoder.layer.0.attention.self.key.bias": "Data",
                "bert.encoder.layer.0.attention.self.key.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_1",
                "bert.encoder.layer.0.attention.self.key.weight",
                "bert.encoder.layer.0.attention.self.key.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_10",
            "op_model": {
                "execution_cycles": 97758,
                "grid_shape": [
                    4,
                    2
                ],
                "input_shapes": [
                    [
                        1,
                        1,
                        12,
                        32
                    ],
                    [
                        1,
                        1,
                        32,
                        32
                    ],
                    [
                        1,
                        1,
                        12,
                        32
                    ]
                ],
                "inputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 3,
                            "tblock_n": 8,
                            "ublock_ct": 4,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 8
                    },
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 2,
                            "t": 1,
                            "tblock_m": 8,
                            "tblock_n": 1,
                            "ublock_ct": 8,
                            "ublock_rt": 4
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 128
                    },
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 12,
                            "tblock_n": 2,
                            "ublock_ct": 8,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 16,
                        "l1_size_tiles": 16
                    }
                ],
                "op_model_id": 2525870,
                "op_type": "matmul",
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 3,
                            "mblock_n": 2,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 8,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 96
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true,
                    "kernel_broadcast": {
                        "input_2": 16
                    },
                    "l1_acc": true,
                    "m_k": 8,
                    "u_kt": 4
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_16 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_16"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key",
                "original_op_name": "matmul_10",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27149
        },
        "matmul_16": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "chip_id": 0,
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "grid_end": [
                8,
                6
            ],
            "grid_start": [
                4,
                5
            ],
            "incoming_edge_port_info": [
                "Data: matmul_4 (port_0) ublock_order(c)",
                "Data: matmul_10 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "matmul_10": "Data",
                "matmul_4": "Data"
            },
            "input_nodes": [
                "matmul_4",
                "matmul_10"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [],
                            "buda_attrs": {},
                            "named_attrs": {
                                "dim0": -2,
                                "dim1": -1,
                                "z_dim_slice": -1
                            },
                            "type": "transpose"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "vslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_16",
            "op_model": {
                "execution_cycles": 103472,
                "grid_shape": [
                    4,
                    1
                ],
                "input_shapes": [
                    [
                        1,
                        16,
                        12,
                        2
                    ],
                    [
                        1,
                        16,
                        2,
                        12
                    ]
                ],
                "inputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 16,
                            "tblock_m": 3,
                            "tblock_n": 2,
                            "ublock_ct": 1,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 339
                    },
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 2,
                            "t": 16,
                            "tblock_m": 2,
                            "tblock_n": 1,
                            "ublock_ct": 6,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 24
                    }
                ],
                "op_model_id": 2526232,
                "op_type": "matmul",
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 3,
                            "mblock_n": 2,
                            "t": 16,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 6,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 72
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "l1_acc": true,
                    "m_k": 2,
                    "u_kt": 1
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_2 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_2"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_16",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27156
        },
        "matmul_4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "chip_id": 0,
            "class": "matmul",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "grid_end": [
                8,
                2
            ],
            "grid_start": [
                4,
                0
            ],
            "incoming_edge_port_info": [
                "Data: _fused_op_1 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.0.attention.self.query.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.0.attention.self.query.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_1": "Data",
                "bert.encoder.layer.0.attention.self.query.bias": "Data",
                "bert.encoder.layer.0.attention.self.query.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_1",
                "bert.encoder.layer.0.attention.self.query.weight",
                "bert.encoder.layer.0.attention.self.query.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_4",
            "op_model": {
                "execution_cycles": 97758,
                "grid_shape": [
                    4,
                    2
                ],
                "input_shapes": [
                    [
                        1,
                        1,
                        12,
                        32
                    ],
                    [
                        1,
                        1,
                        32,
                        32
                    ],
                    [
                        1,
                        1,
                        12,
                        32
                    ]
                ],
                "inputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 3,
                            "tblock_n": 8,
                            "ublock_ct": 4,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 64
                    },
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 2,
                            "t": 1,
                            "tblock_m": 8,
                            "tblock_n": 1,
                            "ublock_ct": 8,
                            "ublock_rt": 4
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 128
                    },
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 12,
                            "tblock_n": 2,
                            "ublock_ct": 8,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 16,
                        "l1_size_tiles": 16
                    }
                ],
                "op_model_id": 2525681,
                "op_type": "matmul",
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 3,
                            "mblock_n": 2,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 8,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 96
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true,
                    "kernel_broadcast": {
                        "input_2": 16
                    },
                    "l1_acc": true,
                    "m_k": 8,
                    "u_kt": 4
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_16 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_16"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query",
                "original_op_name": "matmul_4",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 27143
        },
        "multiply_22": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    384
                ]
            },
            "chip_id": 0,
            "class": "multiply",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "grid_end": [
                1,
                5
            ],
            "grid_start": [
                0,
                4
            ],
            "incoming_edge_port_info": [
                "Data: subtract_21 (port_0) ublock_order(r)",
                "Data: input_1_multiply_22 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "input_1_multiply_22": "Data",
                "subtract_21": "Data"
            },
            "input_nodes": [
                "subtract_21",
                "input_1_multiply_22"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "multiply_22",
            "op_model": {
                "execution_cycles": 1754,
                "grid_shape": [
                    1,
                    1
                ],
                "input_shapes": [
                    [
                        1,
                        1,
                        1,
                        12
                    ],
                    [
                        1,
                        1,
                        1,
                        12
                    ]
                ],
                "inputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 2,
                            "ublock_ct": 6,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 12
                    },
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 2,
                            "ublock_ct": 6,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 1,
                        "l1_size_tiles": 1
                    }
                ],
                "op_model_id": 2526356,
                "op_type": "multiply",
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 2,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 6,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 24
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "kernel_broadcast": {
                        "input_1": 1
                    }
                },
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: multiply_22_attempt_1_input_op_fork_nop0 (port_0)",
                "Data: multiply_22_attempt_1_input_op_fork_nop1 (port_0)",
                "Data: multiply_22_attempt_1_input_op_fork_nop2 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "multiply_22_attempt_1_input_op_fork_nop0",
                "multiply_22_attempt_1_input_op_fork_nop1",
                "multiply_22_attempt_1_input_op_fork_nop2"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert",
                "original_op_name": "multiply_22",
                "original_op_type": "multiply"
            },
            "type": "multiply",
            "unique_id": 27166
        },
        "multiply_22_attempt_1_input_op_fork_nop0": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    384
                ]
            },
            "chip_id": 0,
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "grid_end": [
                1,
                7
            ],
            "grid_start": [
                0,
                6
            ],
            "incoming_edge_port_info": [
                "Data: multiply_22 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "multiply_22": "Data"
            },
            "input_nodes": [
                "multiply_22"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "multiply_22_attempt_1_input_op_fork_nop0",
            "op_model": {
                "execution_cycles": 1282,
                "grid_shape": [
                    1,
                    1
                ],
                "input_shapes": [
                    [
                        1,
                        1,
                        1,
                        12
                    ]
                ],
                "inputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 2,
                            "ublock_ct": 6,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 12
                    }
                ],
                "op_model_id": 2526373,
                "op_type": "nop",
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 2,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 6,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 24
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: e2e_multiply_22_attempt_1_input_op_fork_nop0_0 (port_0)",
                "Data: _fused_op_2 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "e2e_multiply_22_attempt_1_input_op_fork_nop0_0",
                "_fused_op_2"
            ],
            "pybuda": 1,
            "tags": {},
            "type": "nop",
            "unique_id": 29827
        },
        "multiply_22_attempt_1_input_op_fork_nop1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    384
                ]
            },
            "chip_id": 0,
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "grid_end": [
                1,
                8
            ],
            "grid_start": [
                0,
                7
            ],
            "incoming_edge_port_info": [
                "Data: multiply_22 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "multiply_22": "Data"
            },
            "input_nodes": [
                "multiply_22"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "multiply_22_attempt_1_input_op_fork_nop1",
            "op_model": {
                "execution_cycles": 1282,
                "grid_shape": [
                    1,
                    1
                ],
                "input_shapes": [
                    [
                        1,
                        1,
                        1,
                        12
                    ]
                ],
                "inputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 2,
                            "ublock_ct": 6,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 12
                    }
                ],
                "op_model_id": 2563382,
                "op_type": "nop",
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 2,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 6,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 24
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: e2e_multiply_22_attempt_1_input_op_fork_nop1_0 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "e2e_multiply_22_attempt_1_input_op_fork_nop1_0"
            ],
            "pybuda": 1,
            "tags": {},
            "type": "nop",
            "unique_id": 29828
        },
        "multiply_22_attempt_1_input_op_fork_nop2": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    384
                ]
            },
            "chip_id": 0,
            "class": "nop",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "grid_end": [
                2,
                3
            ],
            "grid_start": [
                1,
                2
            ],
            "incoming_edge_port_info": [
                "Data: multiply_22 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "multiply_22": "Data"
            },
            "input_nodes": [
                "multiply_22"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "multiply_22_attempt_1_input_op_fork_nop2",
            "op_model": {
                "execution_cycles": 1282,
                "grid_shape": [
                    1,
                    1
                ],
                "input_shapes": [
                    [
                        1,
                        1,
                        1,
                        12
                    ]
                ],
                "inputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 2,
                            "ublock_ct": 6,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 12
                    }
                ],
                "op_model_id": 2600391,
                "op_type": "nop",
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 2,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 6,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 24
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: e2e_multiply_22_attempt_1_input_op_fork_nop2_0 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "e2e_multiply_22_attempt_1_input_op_fork_nop2_0"
            ],
            "pybuda": 1,
            "tags": {},
            "type": "nop",
            "unique_id": 29829
        },
        "pybuda_6_i0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "chip_id": 0,
            "class": "Input::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "pybuda_6_i0",
            "op_model": {
                "execution_cycles": 0,
                "grid_shape": [
                    1,
                    1
                ],
                "input_shapes": [],
                "inputs": [],
                "op_model_id": 2936832,
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 12,
                            "mblock_n": 32,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 1,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 384
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_0.dc.reduce_sum.0.lc1 (port_0)",
                "Data: _fused_op_0 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_0.dc.reduce_sum.0.lc1",
                "_fused_op_0"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "pybuda_6_i0"
            },
            "tile_broadcast": [],
            "type": "Input::input",
            "unique_id": 27121
        },
        "softmax_24.dc.reduce_max.0": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "chip_id": 0,
            "class": "reduce(3,max,16,)",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "grid_end": [
                9,
                5
            ],
            "grid_start": [
                5,
                4
            ],
            "incoming_edge_port_info": [
                "Data: _fused_op_2 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_2": "Data"
            },
            "input_nodes": [
                "_fused_op_2"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_24.dc.reduce_max.0",
            "op_model": {
                "execution_cycles": 4368,
                "grid_shape": [
                    4,
                    1
                ],
                "input_shapes": [
                    [
                        1,
                        16,
                        12,
                        12
                    ]
                ],
                "inputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 16,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 12,
                            "ublock_rt": 3
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 72
                    }
                ],
                "op_model_id": 2526618,
                "op_type": "reduce",
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 16,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 3
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 6
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "op_type": {
                "attrs": [
                    3,
                    "max",
                    16
                ],
                "buda_attrs": {
                    "dim": "c",
                    "m_k": 1,
                    "type": "max",
                    "u_kt": 12
                },
                "named_attrs": {},
                "type": "reduce"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: e2e_softmax_24.dc.reduce_max.0_0 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "e2e_softmax_24.dc.reduce_max.0_0"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_24",
                "original_op_type": "softmax"
            },
            "type": "reduce",
            "unique_id": 27171
        },
        "subtract_21": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    384
                ]
            },
            "chip_id": 0,
            "class": "subtract",
            "epoch": 0,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "grid_end": [
                1,
                3
            ],
            "grid_start": [
                0,
                2
            ],
            "incoming_edge_port_info": [
                "Data: input_0_subtract_21 (port_0) ublock_order(r)",
                "Data: attention_mask_1 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "attention_mask_1": "Data",
                "input_0_subtract_21": "Data"
            },
            "input_nodes": [
                "input_0_subtract_21",
                "attention_mask_1"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "subtract_21",
            "op_model": {
                "execution_cycles": 1660,
                "grid_shape": [
                    1,
                    1
                ],
                "input_shapes": [
                    [
                        1,
                        1,
                        1,
                        12
                    ],
                    [
                        1,
                        1,
                        1,
                        12
                    ]
                ],
                "inputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 2,
                            "ublock_ct": 6,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 1,
                        "l1_size_tiles": 1
                    },
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 2,
                            "ublock_ct": 6,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 12
                    }
                ],
                "op_model_id": 2526339,
                "op_type": "subtract",
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 2,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 6,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 24
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "kernel_broadcast": {
                        "input_0": 1
                    }
                },
                "named_attrs": {},
                "type": "subtract"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: multiply_22 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "multiply_22"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert",
                "original_op_name": "subtract_21",
                "original_op_type": "subtract"
            },
            "type": "subtract",
            "unique_id": 27164
        }
    },
    "topological_sorted_nodes": [
        "lc.input_tensor.layernorm_0.dc.reduce_sum.0.0",
        "pybuda_6_i0",
        "layernorm_0.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_0.1",
        "_fused_op_0",
        "layernorm_0.dc.multiply.4",
        "lc.input_tensor.layernorm_0.dc.reduce_sum.5.0",
        "layernorm_0.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_0.6",
        "dc.input_tensor.layernorm_0.8",
        "bert.embeddings.LayerNorm.weight",
        "bert.embeddings.LayerNorm.bias",
        "buffer_1_29655_29656",
        "buffer_0_29655_29656",
        "_fused_op_1",
        "bert.encoder.layer.0.attention.self.query.weight",
        "bert.encoder.layer.0.attention.self.query.bias",
        "matmul_4",
        "bert.encoder.layer.0.attention.self.key.weight",
        "bert.encoder.layer.0.attention.self.key.bias",
        "matmul_10",
        "matmul_16",
        "input_1_multiply_18",
        "attention_mask_1",
        "input_0_subtract_21",
        "subtract_21",
        "input_1_multiply_22",
        "multiply_22",
        "multiply_22_attempt_1_input_op_fork_nop0",
        "_fused_op_2",
        "softmax_24.dc.reduce_max.0",
        "e2e__fused_op_2_0",
        "e2e_softmax_24.dc.reduce_max.0_0",
        "e2e__fused_op_1_0",
        "e2e_multiply_22_attempt_1_input_op_fork_nop0_0",
        "multiply_22_attempt_1_input_op_fork_nop1",
        "e2e_multiply_22_attempt_1_input_op_fork_nop1_0",
        "multiply_22_attempt_1_input_op_fork_nop2",
        "e2e_multiply_22_attempt_1_input_op_fork_nop2_0"
    ]
}