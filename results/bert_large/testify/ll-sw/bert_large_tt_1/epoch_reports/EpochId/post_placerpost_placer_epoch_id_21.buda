{
    "graph": {},
    "nodes": {
        "_fused_op_59": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "chip_id": 0,
            "class": "fused_op",
            "epoch": 21,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "grid_end": [
                2,
                6
            ],
            "grid_start": [
                0,
                0
            ],
            "incoming_edge_port_info": [
                "Data: e2e__fused_op_58_0 (port_0) ublock_order(c)",
                "Data: e2e_softmax_448.dc.reduce_max.0_0 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "e2e__fused_op_58_0": "Data",
                "e2e_softmax_448.dc.reduce_max.0_0": "Data"
            },
            "input_nodes": [
                "e2e__fused_op_58_0",
                "e2e_softmax_448.dc.reduce_max.0_0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "tile_broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_59",
            "op_model": {
                "execution_cycles": 353604,
                "grid_shape": [
                    2,
                    6
                ],
                "input_shapes": [
                    [
                        1,
                        16,
                        12,
                        12
                    ],
                    [
                        1,
                        16,
                        12,
                        12
                    ]
                ],
                "inputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 16,
                            "tblock_m": 2,
                            "tblock_n": 1,
                            "ublock_ct": 2,
                            "ublock_rt": 3
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 12
                    },
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 16,
                            "tblock_m": 2,
                            "tblock_n": 1,
                            "ublock_ct": 2,
                            "ublock_rt": 3
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 12
                    }
                ],
                "op_model_id": 2741860,
                "op_type": "fused_op",
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 2,
                            "mblock_n": 1,
                            "t": 16,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 2,
                            "ublock_rt": 3
                        },
                        "buffer_factor": 32,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 384
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: softmax_448.dc.reduce_sum.3.lc1 (port_0)",
                "Data: buffer_0_29714_29715 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_448.dc.reduce_sum.3.lc1",
                "buffer_0_29714_29715"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_448.dc.subtract.1: subtract (1,16,12,12), out: 0",
                    "softmax_448.dc.exp.2: exp (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 29714
        },
        "_fused_op_60": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "chip_id": 0,
            "class": "fused_op(0,1,)",
            "epoch": 21,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "grid_end": [
                4,
                1
            ],
            "grid_start": [
                2,
                0
            ],
            "incoming_edge_port_info": [
                "Data: softmax_448.dc.reduce_sum.3.lc1 (port_0) ublock_order(r)",
                "Data: dc.input_tensor.softmax_448.4 (port_1) ublock_order(r)",
                "Data: buffer_0_29714_29715 (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_29714_29715": "Data",
                "dc.input_tensor.softmax_448.4": "Data",
                "softmax_448.dc.reduce_sum.3.lc1": "Data"
            },
            "input_nodes": [
                "softmax_448.dc.reduce_sum.3.lc1",
                "dc.input_tensor.softmax_448.4",
                "buffer_0_29714_29715"
            ],
            "input_tms": [
                [],
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_60",
            "op_model": {
                "execution_cycles": 262553,
                "grid_shape": [
                    2,
                    1
                ],
                "input_shapes": [
                    [
                        1,
                        16,
                        12,
                        1
                    ],
                    [
                        1,
                        16,
                        12,
                        1
                    ],
                    [
                        1,
                        16,
                        12,
                        12
                    ]
                ],
                "inputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 16,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 6
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 12
                    },
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 16,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 6
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 0
                    },
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 16,
                            "tblock_m": 1,
                            "tblock_n": 12,
                            "ublock_ct": 1,
                            "ublock_rt": 6
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 174
                    }
                ],
                "op_model_id": 2742175,
                "op_type": "fused_op",
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 12,
                            "t": 16,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 6
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 144
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_459 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_459"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "softmax_448.dc.add.5: add (1,16,12,1), out: 0",
                    "softmax_448.dc.reciprocal.6: reciprocal (1,16,12,1), out: 0",
                    "softmax_448.dc.multiply.7: multiply (1,16,12,12), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "softmax"
            },
            "type": "fused_op",
            "unique_id": 29715
        },
        "_fused_op_61": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "chip_id": 0,
            "class": "fused_op",
            "epoch": 21,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "grid_end": [
                6,
                7
            ],
            "grid_start": [
                4,
                6
            ],
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_468.1 (port_0) ublock_order(c)",
                "Data: layernorm_468.dc.reduce_sum.0.lc1 (port_1) ublock_order(c)",
                "Data: buffer_0_28032_29716 (port_2) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_0_28032_29716": "Data",
                "dc.input_tensor.layernorm_468.1": "Data",
                "layernorm_468.dc.reduce_sum.0.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_468.1",
                "layernorm_468.dc.reduce_sum.0.lc1",
                "buffer_0_28032_29716"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                3,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_61",
            "op_model": {
                "execution_cycles": 25495,
                "grid_shape": [
                    2,
                    1
                ],
                "input_shapes": [
                    [
                        1,
                        1,
                        12,
                        32
                    ],
                    [
                        1,
                        1,
                        12,
                        32
                    ],
                    [
                        1,
                        1,
                        12,
                        32
                    ]
                ],
                "inputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 6,
                            "tblock_n": 4,
                            "ublock_ct": 8,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 16
                    },
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 6,
                            "tblock_n": 4,
                            "ublock_ct": 8,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 16
                    },
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 6,
                            "tblock_n": 4,
                            "ublock_ct": 8,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 16
                    }
                ],
                "op_model_id": 2742657,
                "op_type": "fused_op",
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 6,
                            "mblock_n": 4,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 8,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 384
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_468.dc.multiply.4 (port_0)",
                "Data: buffer_2_29716_29717 (port_0)",
                "Data: layernorm_468.dc.multiply.4 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_468.dc.multiply.4",
                "buffer_2_29716_29717",
                "layernorm_468.dc.multiply.4"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_468.dc.multiply.2: multiply (1,1,12,32), out: 0",
                    "layernorm_468.dc.subtract.3: subtract (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29716
        },
        "_fused_op_62": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "chip_id": 0,
            "class": "fused_op(0,1,)",
            "epoch": 21,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "grid_end": [
                8,
                5
            ],
            "grid_start": [
                6,
                4
            ],
            "incoming_edge_port_info": [
                "Data: dc.input_tensor.layernorm_468.6 (port_0) ublock_order(r)",
                "Data: layernorm_468.dc.reduce_sum.5.lc1 (port_1) ublock_order(r)",
                "Data: dc.input_tensor.layernorm_468.8 (port_2) ublock_order(r)",
                "Data: buffer_0_29716_29717 (port_3) ublock_order(r)",
                "Data: bert.encoder.layer.8.attention.output.LayerNorm.weight (port_4) ublock_order(r)",
                "Data: bert.encoder.layer.8.attention.output.LayerNorm.bias (port_5) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.8.attention.output.LayerNorm.bias": "Data",
                "bert.encoder.layer.8.attention.output.LayerNorm.weight": "Data",
                "buffer_0_29716_29717": "Data",
                "dc.input_tensor.layernorm_468.6": "Data",
                "dc.input_tensor.layernorm_468.8": "Data",
                "layernorm_468.dc.reduce_sum.5.lc1": "Data"
            },
            "input_nodes": [
                "dc.input_tensor.layernorm_468.6",
                "layernorm_468.dc.reduce_sum.5.lc1",
                "dc.input_tensor.layernorm_468.8",
                "buffer_0_29716_29717",
                "bert.encoder.layer.8.attention.output.LayerNorm.weight",
                "bert.encoder.layer.8.attention.output.LayerNorm.bias"
            ],
            "input_tms": [
                [],
                [],
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "_fused_op_62",
            "op_model": {
                "execution_cycles": 44459,
                "grid_shape": [
                    2,
                    1
                ],
                "input_shapes": [
                    [
                        1,
                        1,
                        12,
                        1
                    ],
                    [
                        1,
                        1,
                        12,
                        1
                    ],
                    [
                        1,
                        1,
                        12,
                        1
                    ],
                    [
                        1,
                        1,
                        12,
                        32
                    ],
                    [
                        1,
                        1,
                        12,
                        32
                    ],
                    [
                        1,
                        1,
                        12,
                        32
                    ]
                ],
                "inputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 6
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 0
                    },
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 6
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 12
                    },
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 6
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 0
                    },
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 32,
                            "ublock_ct": 1,
                            "ublock_rt": 6
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 12
                    },
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 32,
                            "ublock_ct": 1,
                            "ublock_rt": 6
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 12
                    },
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 32,
                            "ublock_ct": 1,
                            "ublock_rt": 6
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 12
                    }
                ],
                "op_model_id": 2743190,
                "op_type": "fused_op",
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 32,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 6
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 384
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "op_type": {
                "attrs": [
                    0,
                    true
                ],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "fused_op"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_471 (port_0)",
                "Data: e2e__fused_op_62_0 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_471",
                "e2e__fused_op_62_0"
            ],
            "pybuda": 1,
            "schedules": [
                [
                    "layernorm_468.dc.multiply.7: multiply (1,1,12,1), out: 0",
                    "layernorm_468.dc.add.9: add (1,1,12,1), out: 0",
                    "layernorm_468.dc.sqrt.10: sqrt (1,1,12,1), out: 0",
                    "layernorm_468.dc.reciprocal.11: reciprocal (1,1,12,1), out: 0",
                    "layernorm_468.dc.multiply.12: multiply (1,1,12,32), out: 0",
                    "layernorm_468.dc.multiply.13: multiply (1,1,12,32), out: 0",
                    "layernorm_468.dc.add.14: add (1,1,12,32), out: 0"
                ]
            ],
            "tags": {
                "original_op_type": "layernorm"
            },
            "type": "fused_op",
            "unique_id": 29717
        },
        "add_467": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "chip_id": 0,
            "class": "add",
            "epoch": 21,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "grid_end": [
                4,
                7
            ],
            "grid_start": [
                2,
                6
            ],
            "incoming_edge_port_info": [
                "Data: matmul_463 (port_0) ublock_order(c)",
                "Data: e2e__fused_op_57_0 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "e2e__fused_op_57_0": "Data",
                "matmul_463": "Data"
            },
            "input_nodes": [
                "matmul_463",
                "e2e__fused_op_57_0"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "add_467",
            "op_model": {
                "execution_cycles": 24669,
                "grid_shape": [
                    2,
                    1
                ],
                "input_shapes": [
                    [
                        1,
                        1,
                        12,
                        32
                    ],
                    [
                        1,
                        1,
                        12,
                        32
                    ]
                ],
                "inputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 6,
                            "tblock_n": 4,
                            "ublock_ct": 8,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 16
                    },
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 6,
                            "tblock_n": 4,
                            "ublock_ct": 8,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 16
                    }
                ],
                "op_model_id": 2742234,
                "op_type": "add",
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 6,
                            "mblock_n": 4,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 8,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 384
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "add"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_468.dc.reduce_sum.0.lc1 (port_0)",
                "Data: buffer_1_28032_29716 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_468.dc.reduce_sum.0.lc1",
                "buffer_1_28032_29716"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output",
                "original_op_name": "add_467",
                "original_op_type": "add"
            },
            "type": "add",
            "unique_id": 28032
        },
        "bert.encoder.layer.8.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "chip_id": 0,
            "class": "Input::",
            "epoch": 21,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.8.attention.output.LayerNorm.bias",
            "op_model": {
                "execution_cycles": 0,
                "grid_shape": [
                    1,
                    1
                ],
                "input_shapes": [],
                "inputs": [],
                "op_model_id": 2937091,
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 32,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 1,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 32
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_62 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_62"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.8.attention.output.LayerNorm.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28053
        },
        "bert.encoder.layer.8.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "chip_id": 0,
            "class": "Input::",
            "epoch": 21,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.8.attention.output.LayerNorm.weight",
            "op_model": {
                "execution_cycles": 0,
                "grid_shape": [
                    1,
                    1
                ],
                "input_shapes": [],
                "inputs": [],
                "op_model_id": 2937090,
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 32,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 1,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 32
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_62 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_62"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.8.attention.output.LayerNorm.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28051
        },
        "bert.encoder.layer.8.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "chip_id": 0,
            "class": "Input::",
            "epoch": 21,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.8.attention.output.dense.bias",
            "op_model": {
                "execution_cycles": 0,
                "grid_shape": [
                    1,
                    4
                ],
                "input_shapes": [],
                "inputs": [],
                "op_model_id": 2937084,
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 8,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 1,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 8
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_463 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_463"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.8.attention.output.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28029
        },
        "bert.encoder.layer.8.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "chip_id": 0,
            "class": "Input::",
            "epoch": 21,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.8.attention.output.dense.weight",
            "op_model": {
                "execution_cycles": 0,
                "grid_shape": [
                    2,
                    4
                ],
                "input_shapes": [],
                "inputs": [],
                "op_model_id": 2937083,
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 8,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 8,
                            "ublock_rt": 2
                        },
                        "buffer_factor": 1,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 128
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_463 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_463"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.8.attention.output.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28028
        },
        "bert.encoder.layer.8.attention.self.value.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    1024
                ]
            },
            "chip_id": 0,
            "class": "Input::",
            "epoch": 21,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.8.attention.self.value.bias",
            "op_model": {
                "execution_cycles": 0,
                "grid_shape": [
                    1,
                    4
                ],
                "input_shapes": [],
                "inputs": [],
                "op_model_id": 2937082,
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 8,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 1,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 8
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_452 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_452"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.8.attention.self.value.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28020
        },
        "bert.encoder.layer.8.attention.self.value.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    1024
                ]
            },
            "chip_id": 0,
            "class": "Input::",
            "epoch": 21,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.8.attention.self.value.weight",
            "op_model": {
                "execution_cycles": 0,
                "grid_shape": [
                    2,
                    4
                ],
                "input_shapes": [],
                "inputs": [],
                "op_model_id": 2937081,
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 2,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 8,
                            "ublock_rt": 8
                        },
                        "buffer_factor": 1,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 128
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_452 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_452"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.8.attention.self.value.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28019
        },
        "bert.encoder.layer.8.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    4096
                ]
            },
            "chip_id": 0,
            "class": "Input::",
            "epoch": 21,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.8.intermediate.dense.bias",
            "op_model": {
                "execution_cycles": 0,
                "grid_shape": [
                    1,
                    8
                ],
                "input_shapes": [],
                "inputs": [],
                "op_model_id": 2937093,
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 2,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 8,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 1,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 16
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_471 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_471"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.8.intermediate.dense.bias"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28057
        },
        "bert.encoder.layer.8.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1024,
                    4096
                ]
            },
            "chip_id": 0,
            "class": "Input::",
            "epoch": 21,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "RAM",
            "name": "bert.encoder.layer.8.intermediate.dense.weight",
            "op_model": {
                "execution_cycles": 0,
                "grid_shape": [
                    2,
                    8
                ],
                "input_shapes": [],
                "inputs": [],
                "op_model_id": 2937092,
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 4,
                            "mblock_n": 2,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 8,
                            "ublock_rt": 4
                        },
                        "buffer_factor": 1,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 256
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: matmul_471 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_471"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": true,
            "tags": {
                "original_op_name": "bert.encoder.layer.8.intermediate.dense.weight"
            },
            "tile_broadcast": [],
            "type": "Input::parameter",
            "unique_id": 28056
        },
        "buffer_0_28032_29716": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "chip_id": 0,
            "class": "nop",
            "epoch": 21,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "grid_end": [
                6,
                6
            ],
            "grid_start": [
                4,
                5
            ],
            "incoming_edge_port_info": [
                "Data: buffer_1_28032_29716 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_28032_29716": "Data"
            },
            "input_nodes": [
                "buffer_1_28032_29716"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_28032_29716",
            "op_model": {
                "execution_cycles": 18072,
                "grid_shape": [
                    2,
                    1
                ],
                "input_shapes": [
                    [
                        1,
                        1,
                        12,
                        32
                    ]
                ],
                "inputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 6,
                            "tblock_n": 4,
                            "ublock_ct": 8,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 16
                    }
                ],
                "op_model_id": 2742516,
                "op_type": "nop",
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 6,
                            "mblock_n": 4,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 8,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 384
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_61 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_61"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30404
        },
        "buffer_0_29714_29715": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "chip_id": 0,
            "class": "nop",
            "epoch": 21,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "grid_end": [
                2,
                8
            ],
            "grid_start": [
                0,
                7
            ],
            "incoming_edge_port_info": [
                "Data: _fused_op_59 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_59": "Data"
            },
            "input_nodes": [
                "_fused_op_59"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29714_29715",
            "op_model": {
                "execution_cycles": 123072,
                "grid_shape": [
                    2,
                    1
                ],
                "input_shapes": [
                    [
                        1,
                        16,
                        12,
                        12
                    ]
                ],
                "inputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 16,
                            "tblock_m": 6,
                            "tblock_n": 2,
                            "ublock_ct": 6,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 288
                    }
                ],
                "op_model_id": 2742026,
                "op_type": "nop",
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 6,
                            "mblock_n": 2,
                            "t": 16,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 6,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 144
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_60 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_60"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30403
        },
        "buffer_0_29716_29717": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "chip_id": 0,
            "class": "nop",
            "epoch": 21,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "grid_end": [
                8,
                4
            ],
            "grid_start": [
                6,
                3
            ],
            "incoming_edge_port_info": [
                "Data: buffer_1_29716_29717 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_1_29716_29717": "Data"
            },
            "input_nodes": [
                "buffer_1_29716_29717"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_0_29716_29717",
            "op_model": {
                "execution_cycles": 18072,
                "grid_shape": [
                    2,
                    1
                ],
                "input_shapes": [
                    [
                        1,
                        1,
                        12,
                        32
                    ]
                ],
                "inputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 6,
                            "tblock_n": 4,
                            "ublock_ct": 8,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 16
                    }
                ],
                "op_model_id": 2743080,
                "op_type": "nop",
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 6,
                            "mblock_n": 4,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 8,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 384
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_62 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_62"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30406
        },
        "buffer_1_28032_29716": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "chip_id": 0,
            "class": "nop",
            "epoch": 21,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "grid_end": [
                6,
                5
            ],
            "grid_start": [
                4,
                4
            ],
            "incoming_edge_port_info": [
                "Data: add_467 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "add_467": "Data"
            },
            "input_nodes": [
                "add_467"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_28032_29716",
            "op_model": {
                "execution_cycles": 18072,
                "grid_shape": [
                    2,
                    1
                ],
                "input_shapes": [
                    [
                        1,
                        1,
                        12,
                        32
                    ]
                ],
                "inputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 6,
                            "tblock_n": 4,
                            "ublock_ct": 8,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 16
                    }
                ],
                "op_model_id": 2742375,
                "op_type": "nop",
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 6,
                            "mblock_n": 4,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 8,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 384
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_28032_29716 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_28032_29716"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30405
        },
        "buffer_1_29716_29717": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "chip_id": 0,
            "class": "nop",
            "epoch": 21,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "grid_end": [
                8,
                3
            ],
            "grid_start": [
                6,
                2
            ],
            "incoming_edge_port_info": [
                "Data: buffer_2_29716_29717 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "buffer_2_29716_29717": "Data"
            },
            "input_nodes": [
                "buffer_2_29716_29717"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_1_29716_29717",
            "op_model": {
                "execution_cycles": 18072,
                "grid_shape": [
                    2,
                    1
                ],
                "input_shapes": [
                    [
                        1,
                        1,
                        12,
                        32
                    ]
                ],
                "inputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 6,
                            "tblock_n": 4,
                            "ublock_ct": 8,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 16
                    }
                ],
                "op_model_id": 2742939,
                "op_type": "nop",
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 6,
                            "mblock_n": 4,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 8,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 384
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_0_29716_29717 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_0_29716_29717"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30407
        },
        "buffer_2_29716_29717": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "chip_id": 0,
            "class": "nop",
            "epoch": 21,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "grid_end": [
                8,
                2
            ],
            "grid_start": [
                6,
                1
            ],
            "incoming_edge_port_info": [
                "Data: _fused_op_61 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_61": "Data"
            },
            "input_nodes": [
                "_fused_op_61"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "buffer_2_29716_29717",
            "op_model": {
                "execution_cycles": 18072,
                "grid_shape": [
                    2,
                    1
                ],
                "input_shapes": [
                    [
                        1,
                        1,
                        12,
                        32
                    ]
                ],
                "inputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 6,
                            "tblock_n": 4,
                            "ublock_ct": 8,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 16
                    }
                ],
                "op_model_id": 2742798,
                "op_type": "nop",
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 6,
                            "mblock_n": 4,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 8,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 384
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "nop"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: buffer_1_29716_29717 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "buffer_1_29716_29717"
            ],
            "pybuda": 1,
            "tags": {
                "fj_buffering_nop": true
            },
            "type": "nop",
            "unique_id": 30408
        },
        "dc.input_tensor.layernorm_468.1": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "chip_id": 0,
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1024
            ],
            "epoch": 21,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_468.1",
            "op_model": {
                "execution_cycles": 0,
                "grid_shape": [
                    2,
                    1
                ],
                "input_shapes": [],
                "inputs": [],
                "op_model_id": 2937086,
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 6,
                            "mblock_n": 4,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 8,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 1,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 192
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_61 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_61"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28036
        },
        "dc.input_tensor.layernorm_468.6": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "chip_id": 0,
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 21,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_468.6",
            "op_model": {
                "execution_cycles": 0,
                "grid_shape": [
                    2,
                    1
                ],
                "input_shapes": [],
                "inputs": [],
                "op_model_id": 2937088,
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 6
                        },
                        "buffer_factor": 1,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 6
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_62 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_62"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28042
        },
        "dc.input_tensor.layernorm_468.8": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "chip_id": 0,
            "class": "constant",
            "constant_dims": [
                1,
                384,
                1
            ],
            "epoch": 21,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.layernorm_468.8",
            "op_model": {
                "execution_cycles": 0,
                "grid_shape": [
                    2,
                    1
                ],
                "input_shapes": [],
                "inputs": [],
                "op_model_id": 2937089,
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 6
                        },
                        "buffer_factor": 1,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 6
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_62 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_62"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "layernorm"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28044
        },
        "dc.input_tensor.softmax_448.4": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "chip_id": 0,
            "class": "constant",
            "constant_dims": [
                1,
                16,
                384,
                1
            ],
            "epoch": 21,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "dc.input_tensor.softmax_448.4",
            "op_model": {
                "execution_cycles": 0,
                "grid_shape": [
                    2,
                    1
                ],
                "input_shapes": [],
                "inputs": [],
                "op_model_id": 2937080,
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 16,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 6
                        },
                        "buffer_factor": 1,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 96
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: _fused_op_60 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_60"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "original_op_type": "softmax"
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28011
        },
        "e2e__fused_op_57_0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "BudaDramQueue::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [
                "Data: _fused_op_57 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_57": "Data"
            },
            "input_nodes": [
                "_fused_op_57"
            ],
            "input_tms": [
                []
            ],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "e2e__fused_op_57_0",
            "op_model": {
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "opcode": "Queue",
            "outgoing_edge_port_info": [
                "Data: matmul_452 (port_0)",
                "Data: add_467 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_452",
                "add_467"
            ],
            "pybuda": 1,
            "queue_type": "epoch_to_epoch",
            "tags": {},
            "type": "Queue",
            "unique_id": 31512
        },
        "e2e__fused_op_58_0": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "BudaDramQueue::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [
                "Data: _fused_op_58 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_58": "Data"
            },
            "input_nodes": [
                "_fused_op_58"
            ],
            "input_tms": [
                []
            ],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "e2e__fused_op_58_0",
            "op_model": {
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "opcode": "Queue",
            "outgoing_edge_port_info": [
                "Data: _fused_op_59 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_59"
            ],
            "pybuda": 1,
            "queue_type": "epoch_to_epoch",
            "tags": {},
            "type": "Queue",
            "unique_id": 31514
        },
        "e2e__fused_op_62_0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "class": "BudaDramQueue::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [
                "Data: _fused_op_62 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_62": "Data"
            },
            "input_nodes": [
                "_fused_op_62"
            ],
            "input_tms": [
                []
            ],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "e2e__fused_op_62_0",
            "op_model": {
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "opcode": "Queue",
            "outgoing_edge_port_info": [
                "Data: add_481 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_481"
            ],
            "pybuda": 1,
            "queue_type": "epoch_to_epoch",
            "tags": {},
            "type": "Queue",
            "unique_id": 31516
        },
        "e2e_gelu_474_0": {
            "cache": {
                "shape": [
                    1,
                    2,
                    384,
                    2048
                ]
            },
            "class": "BudaDramQueue::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [
                "Data: gelu_474 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "gelu_474": "Data"
            },
            "input_nodes": [
                "gelu_474"
            ],
            "input_tms": [
                []
            ],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "e2e_gelu_474_0",
            "op_model": {
                "t_stream_factor": {
                    "dir": "C",
                    "factor": [
                        1,
                        2
                    ]
                }
            },
            "opcode": "Queue",
            "outgoing_edge_port_info": [
                "Data: matmul_477 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_477"
            ],
            "pybuda": 1,
            "queue_type": "epoch_to_epoch",
            "tags": {},
            "type": "Queue",
            "unique_id": 31517
        },
        "e2e_softmax_448.dc.reduce_max.0_0": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "class": "BudaDramQueue::",
            "epoch": 0,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [
                "Data: softmax_448.dc.reduce_max.0 (port_0) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "softmax_448.dc.reduce_max.0": "Data"
            },
            "input_nodes": [
                "softmax_448.dc.reduce_max.0"
            ],
            "input_tms": [
                []
            ],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "e2e_softmax_448.dc.reduce_max.0_0",
            "op_model": {
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "opcode": "Queue",
            "outgoing_edge_port_info": [
                "Data: _fused_op_59 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_59"
            ],
            "pybuda": 1,
            "queue_type": "epoch_to_epoch",
            "tags": {},
            "type": "Queue",
            "unique_id": 31515
        },
        "gelu_474": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    2,
                    384,
                    2048
                ]
            },
            "chip_id": 0,
            "class": "gelu(none,)",
            "epoch": 21,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "grid_end": [
                8,
                7
            ],
            "grid_start": [
                6,
                5
            ],
            "incoming_edge_port_info": [
                "Data: matmul_471 (port_0) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "matmul_471": "Data"
            },
            "input_nodes": [
                "matmul_471"
            ],
            "input_tms": [
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "gelu_474",
            "op_model": {
                "execution_cycles": 104223,
                "grid_shape": [
                    2,
                    2
                ],
                "input_shapes": [
                    [
                        1,
                        2,
                        12,
                        64
                    ]
                ],
                "inputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 2,
                            "tblock_m": 6,
                            "tblock_n": 4,
                            "ublock_ct": 8,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 16
                    }
                ],
                "op_model_id": 2565880,
                "op_type": "gelu",
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 6,
                            "mblock_n": 4,
                            "t": 2,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 8,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 384
                    }
                ],
                "t_stream_factor": {
                    "dir": "C",
                    "factor": [
                        1,
                        2
                    ]
                }
            },
            "op_type": {
                "attrs": [
                    "none"
                ],
                "buda_attrs": {
                    "approximate_mode": "false"
                },
                "named_attrs": {},
                "type": "gelu"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: e2e_gelu_474_0 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "e2e_gelu_474_0"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn",
                "original_op_name": "gelu_474",
                "original_op_type": "gelu"
            },
            "type": "gelu",
            "unique_id": 28058
        },
        "layernorm_468.dc.multiply.4": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "chip_id": 0,
            "class": "multiply",
            "epoch": 21,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "grid_end": [
                6,
                8
            ],
            "grid_start": [
                4,
                7
            ],
            "incoming_edge_port_info": [
                "Data: _fused_op_61 (port_0) ublock_order(c)",
                "Data: _fused_op_61 (port_1) ublock_order(c)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_61": "Data"
            },
            "input_nodes": [
                "_fused_op_61",
                "_fused_op_61"
            ],
            "input_tms": [
                [],
                []
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_468.dc.multiply.4",
            "op_model": {
                "execution_cycles": 26294,
                "grid_shape": [
                    2,
                    1
                ],
                "input_shapes": [
                    [
                        1,
                        1,
                        12,
                        32
                    ],
                    [
                        1,
                        1,
                        12,
                        32
                    ]
                ],
                "inputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 6,
                            "tblock_n": 4,
                            "ublock_ct": 8,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 16
                    },
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 6,
                            "tblock_n": 4,
                            "ublock_ct": 8,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 16
                    }
                ],
                "op_model_id": 2564885,
                "op_type": "multiply",
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 6,
                            "mblock_n": 4,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 8,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 384
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "op_type": {
                "attrs": [],
                "buda_attrs": {},
                "named_attrs": {},
                "type": "multiply"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: layernorm_468.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_468.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_468",
                "original_op_type": "layernorm"
            },
            "type": "multiply",
            "unique_id": 28038
        },
        "layernorm_468.dc.reduce_sum.0.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "chip_id": 0,
            "class": "matmul",
            "epoch": 21,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "grid_end": [
                4,
                8
            ],
            "grid_start": [
                2,
                7
            ],
            "incoming_edge_port_info": [
                "Data: add_467 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_468.dc.reduce_sum.0.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "add_467": "Data",
                "lc.input_tensor.layernorm_468.dc.reduce_sum.0.0": "Data"
            },
            "input_nodes": [
                "add_467",
                "lc.input_tensor.layernorm_468.dc.reduce_sum.0.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_468.dc.reduce_sum.0.lc1",
            "op_model": {
                "execution_cycles": 12966,
                "grid_shape": [
                    2,
                    1
                ],
                "input_shapes": [
                    [
                        1,
                        1,
                        12,
                        32
                    ],
                    [
                        1,
                        1,
                        32,
                        1
                    ]
                ],
                "inputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 8,
                            "ublock_ct": 4,
                            "ublock_rt": 6
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 48
                    },
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 8,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 4
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 1,
                        "l1_size_tiles": 1
                    }
                ],
                "op_model_id": 2564676,
                "op_type": "matmul",
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 6
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 12
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "kernel_broadcast": {
                        "input_1": 1
                    },
                    "l1_acc": true,
                    "m_k": 8,
                    "u_kt": 4
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_61 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_61"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_468",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 28034
        },
        "layernorm_468.dc.reduce_sum.5.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    32
                ]
            },
            "chip_id": 0,
            "class": "matmul",
            "epoch": 21,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "grid_end": [
                8,
                1
            ],
            "grid_start": [
                6,
                0
            ],
            "incoming_edge_port_info": [
                "Data: layernorm_468.dc.multiply.4 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.layernorm_468.dc.reduce_sum.5.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "layernorm_468.dc.multiply.4": "Data",
                "lc.input_tensor.layernorm_468.dc.reduce_sum.5.0": "Data"
            },
            "input_nodes": [
                "layernorm_468.dc.multiply.4",
                "lc.input_tensor.layernorm_468.dc.reduce_sum.5.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                32,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "layernorm_468.dc.reduce_sum.5.lc1",
            "op_model": {
                "execution_cycles": 12966,
                "grid_shape": [
                    2,
                    1
                ],
                "input_shapes": [
                    [
                        1,
                        1,
                        12,
                        32
                    ],
                    [
                        1,
                        1,
                        32,
                        1
                    ]
                ],
                "inputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 8,
                            "ublock_ct": 4,
                            "ublock_rt": 6
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 48
                    },
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 8,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 4
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 1,
                        "l1_size_tiles": 1
                    }
                ],
                "op_model_id": 2565022,
                "op_type": "matmul",
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 6
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 12
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "kernel_broadcast": {
                        "input_1": 1
                    },
                    "l1_acc": true,
                    "m_k": 8,
                    "u_kt": 4
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_62 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_62"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_468",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 28040
        },
        "lc.input_tensor.layernorm_468.dc.reduce_sum.0.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "chip_id": 0,
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 21,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_468.dc.reduce_sum.0.0",
            "op_model": {
                "execution_cycles": 0,
                "grid_shape": [
                    1,
                    1
                ],
                "input_shapes": [],
                "inputs": [],
                "op_model_id": 2937085,
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 1,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 1
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_468.dc.reduce_sum.0.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_468.dc.reduce_sum.0.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_468",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28033
        },
        "lc.input_tensor.layernorm_468.dc.reduce_sum.5.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "chip_id": 0,
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 21,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.layernorm_468.dc.reduce_sum.5.0",
            "op_model": {
                "execution_cycles": 0,
                "grid_shape": [
                    1,
                    1
                ],
                "input_shapes": [],
                "inputs": [],
                "op_model_id": 2937087,
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 1,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 1
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: layernorm_468.dc.reduce_sum.5.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "layernorm_468.dc.reduce_sum.5.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm",
                "original_op_name": "layernorm_468",
                "original_op_type": "layernorm",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28039
        },
        "lc.input_tensor.softmax_448.dc.reduce_sum.3.0": {
            "cache": {
                "shape": [
                    1,
                    1,
                    32,
                    32
                ]
            },
            "chip_id": 0,
            "class": "constant",
            "constant_dims": [
                1,
                1,
                32,
                32
            ],
            "epoch": 21,
            "epoch_type": "Forward",
            "incoming_edge_port_info": [],
            "input_node_to_edge_type": {},
            "input_nodes": [],
            "is_cross_epoch_type": false,
            "memory_access": "FIFO",
            "name": "lc.input_tensor.softmax_448.dc.reduce_sum.3.0",
            "op_model": {
                "execution_cycles": 0,
                "grid_shape": [
                    1,
                    1
                ],
                "input_shapes": [],
                "inputs": [],
                "op_model_id": 2937079,
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 1,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 1
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "opcode": "Input",
            "outgoing_edge_port_info": [
                "Data: softmax_448.dc.reduce_sum.3.lc1 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "softmax_448.dc.reduce_sum.3.lc1"
            ],
            "pybuda": 1,
            "queue_type": "input",
            "requires_grad": false,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_448",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "tile_broadcast": [],
            "type": "Constant",
            "unique_id": 28008
        },
        "matmul_452": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "chip_id": 0,
            "class": "matmul",
            "epoch": 21,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "grid_end": [
                4,
                5
            ],
            "grid_start": [
                2,
                1
            ],
            "incoming_edge_port_info": [
                "Data: e2e__fused_op_57_0 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.8.attention.self.value.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.8.attention.self.value.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.8.attention.self.value.bias": "Data",
                "bert.encoder.layer.8.attention.self.value.weight": "Data",
                "e2e__fused_op_57_0": "Data"
            },
            "input_nodes": [
                "e2e__fused_op_57_0",
                "bert.encoder.layer.8.attention.self.value.weight",
                "bert.encoder.layer.8.attention.self.value.bias"
            ],
            "input_tms": [
                [],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_452",
            "op_model": {
                "execution_cycles": 86363,
                "grid_shape": [
                    2,
                    4
                ],
                "input_shapes": [
                    [
                        1,
                        1,
                        12,
                        32
                    ],
                    [
                        1,
                        1,
                        32,
                        32
                    ],
                    [
                        1,
                        1,
                        12,
                        32
                    ]
                ],
                "inputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 6,
                            "tblock_n": 4,
                            "ublock_ct": 8,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 16
                    },
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 4,
                            "tblock_n": 1,
                            "ublock_ct": 8,
                            "ublock_rt": 8
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 0
                    },
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 12,
                            "tblock_n": 1,
                            "ublock_ct": 8,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 8,
                        "l1_size_tiles": 8
                    }
                ],
                "op_model_id": 2741492,
                "op_type": "matmul",
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 6,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 8,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 96
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true,
                    "kernel_broadcast": {
                        "input_2": 8
                    },
                    "l1_acc": true,
                    "m_k": 4,
                    "u_kt": 8
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_459 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_459"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value",
                "original_op_name": "matmul_452",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28018
        },
        "matmul_459": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "chip_id": 0,
            "class": "matmul",
            "epoch": 21,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "grid_end": [
                4,
                6
            ],
            "grid_start": [
                2,
                5
            ],
            "incoming_edge_port_info": [
                "Data: _fused_op_60 (port_0) ublock_order(c)",
                "Data: matmul_452 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_60": "Data",
                "matmul_452": "Data"
            },
            "input_nodes": [
                "_fused_op_60",
                "matmul_452"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_459",
            "op_model": {
                "execution_cycles": 133889,
                "grid_shape": [
                    2,
                    1
                ],
                "input_shapes": [
                    [
                        1,
                        16,
                        12,
                        12
                    ],
                    [
                        1,
                        16,
                        12,
                        2
                    ]
                ],
                "inputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 16,
                            "tblock_m": 2,
                            "tblock_n": 2,
                            "ublock_ct": 6,
                            "ublock_rt": 3
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 36
                    },
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 16,
                            "tblock_m": 2,
                            "tblock_n": 1,
                            "ublock_ct": 2,
                            "ublock_rt": 6
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 24
                    }
                ],
                "op_model_id": 2564258,
                "op_type": "matmul",
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 2,
                            "mblock_n": 1,
                            "t": 16,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 2,
                            "ublock_rt": 3
                        },
                        "buffer_factor": 32,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 384
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "l1_acc": true,
                    "m_k": 2,
                    "u_kt": 6
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: matmul_463 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "matmul_463"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "matmul_459",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28024
        },
        "matmul_463": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    1,
                    384,
                    1024
                ]
            },
            "chip_id": 0,
            "class": "matmul",
            "epoch": 21,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "grid_end": [
                6,
                4
            ],
            "grid_start": [
                4,
                0
            ],
            "incoming_edge_port_info": [
                "Data: matmul_459 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.8.attention.output.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.8.attention.output.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "bert.encoder.layer.8.attention.output.dense.bias": "Data",
                "bert.encoder.layer.8.attention.output.dense.weight": "Data",
                "matmul_459": "Data"
            },
            "input_nodes": [
                "matmul_459",
                "bert.encoder.layer.8.attention.output.dense.weight",
                "bert.encoder.layer.8.attention.output.dense.bias"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                16
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hstack"
                        }
                    }
                ],
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_463",
            "op_model": {
                "execution_cycles": 120549,
                "grid_shape": [
                    2,
                    4
                ],
                "input_shapes": [
                    [
                        1,
                        1,
                        12,
                        32
                    ],
                    [
                        1,
                        1,
                        32,
                        32
                    ],
                    [
                        1,
                        1,
                        12,
                        32
                    ]
                ],
                "inputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 6,
                            "tblock_n": 16,
                            "ublock_ct": 2,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 4
                    },
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 16,
                            "tblock_n": 1,
                            "ublock_ct": 8,
                            "ublock_rt": 2
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 0
                    },
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 12,
                            "tblock_n": 1,
                            "ublock_ct": 8,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 8,
                        "l1_size_tiles": 8
                    }
                ],
                "op_model_id": 2564424,
                "op_type": "matmul",
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 6,
                            "mblock_n": 1,
                            "t": 1,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 8,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 96
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true,
                    "kernel_broadcast": {
                        "input_2": 8
                    },
                    "l1_acc": true,
                    "m_k": 16,
                    "u_kt": 2
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: add_467 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "add_467"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_463",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28027
        },
        "matmul_471": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    2,
                    384,
                    2048
                ]
            },
            "chip_id": 0,
            "class": "matmul",
            "epoch": 21,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "grid_end": [
                10,
                8
            ],
            "grid_start": [
                8,
                0
            ],
            "incoming_edge_port_info": [
                "Data: _fused_op_62 (port_0) ublock_order(c)",
                "Data: bert.encoder.layer.8.intermediate.dense.weight (port_1) ublock_order(r)",
                "Data: bert.encoder.layer.8.intermediate.dense.bias (port_2) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_62": "Data",
                "bert.encoder.layer.8.intermediate.dense.bias": "Data",
                "bert.encoder.layer.8.intermediate.dense.weight": "Data"
            },
            "input_nodes": [
                "_fused_op_62",
                "bert.encoder.layer.8.intermediate.dense.weight",
                "bert.encoder.layer.8.intermediate.dense.bias"
            ],
            "input_tms": [
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                2
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "vslice"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                2
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "hslice"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "matmul_471",
            "op_model": {
                "execution_cycles": 195516,
                "grid_shape": [
                    2,
                    8
                ],
                "input_shapes": [
                    [
                        1,
                        2,
                        12,
                        32
                    ],
                    [
                        1,
                        2,
                        32,
                        64
                    ],
                    [
                        1,
                        2,
                        12,
                        64
                    ]
                ],
                "inputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 2,
                            "tblock_m": 6,
                            "tblock_n": 8,
                            "ublock_ct": 4,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 8
                    },
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 2,
                            "tblock_m": 8,
                            "tblock_n": 1,
                            "ublock_ct": 8,
                            "ublock_rt": 4
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 64
                    },
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 2,
                            "tblock_m": 12,
                            "tblock_n": 1,
                            "ublock_ct": 8,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 16
                    }
                ],
                "op_model_id": 2565398,
                "op_type": "matmul",
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 6,
                            "mblock_n": 1,
                            "t": 2,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 8,
                            "ublock_rt": 1
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 96
                    }
                ],
                "t_stream_factor": {
                    "dir": "C",
                    "factor": [
                        1,
                        2
                    ]
                }
            },
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "bias": true,
                    "l1_acc": true,
                    "m_k": 8,
                    "u_kt": 4
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: gelu_474 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "gelu_474"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense",
                "original_op_name": "matmul_471",
                "original_op_type": "matmul"
            },
            "type": "matmul",
            "unique_id": 28055
        },
        "softmax_448.dc.reduce_sum.3.lc1": {
            "accumulate_df": "Float16_b",
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    32
                ]
            },
            "chip_id": 0,
            "class": "matmul",
            "epoch": 21,
            "epoch_type": "Forward",
            "fidelity": "HiFi3",
            "gradient_op": false,
            "grid_end": [
                2,
                7
            ],
            "grid_start": [
                0,
                6
            ],
            "incoming_edge_port_info": [
                "Data: _fused_op_59 (port_0) ublock_order(c)",
                "Data: lc.input_tensor.softmax_448.dc.reduce_sum.3.0 (port_1) ublock_order(r)"
            ],
            "input_node_to_edge_type": {
                "_fused_op_59": "Data",
                "lc.input_tensor.softmax_448.dc.reduce_sum.3.0": "Data"
            },
            "input_nodes": [
                "_fused_op_59",
                "lc.input_tensor.softmax_448.dc.reduce_sum.3.0"
            ],
            "input_tms": [
                [],
                [
                    {
                        "op_type": {
                            "attrs": [
                                2,
                                12,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    },
                    {
                        "op_type": {
                            "attrs": [
                                1,
                                16,
                                false
                            ],
                            "buda_attrs": {},
                            "named_attrs": {},
                            "type": "broadcast"
                        }
                    }
                ]
            ],
            "intermediate_df": "Float16_b",
            "ir": "buda",
            "name": "softmax_448.dc.reduce_sum.3.lc1",
            "op_model": {
                "execution_cycles": 74934,
                "grid_shape": [
                    2,
                    1
                ],
                "input_shapes": [
                    [
                        1,
                        16,
                        12,
                        12
                    ],
                    [
                        1,
                        16,
                        12,
                        1
                    ]
                ],
                "inputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 16,
                            "tblock_m": 1,
                            "tblock_n": 3,
                            "ublock_ct": 4,
                            "ublock_rt": 6
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 48
                    },
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 16,
                            "tblock_m": 3,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 4
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 1,
                        "l1_size_tiles": 1
                    }
                ],
                "op_model_id": 2563908,
                "op_type": "matmul",
                "outputs": [
                    {
                        "block_shape": {
                            "mblock_m": 1,
                            "mblock_n": 1,
                            "t": 16,
                            "tblock_m": 1,
                            "tblock_n": 1,
                            "ublock_ct": 1,
                            "ublock_rt": 6
                        },
                        "buffer_factor": 2,
                        "data_format": "Float16_b",
                        "kernel_broadcast_tiles": 0,
                        "l1_size_tiles": 12
                    }
                ],
                "t_stream_factor": {
                    "dir": "None",
                    "factor": [
                        1,
                        1
                    ]
                }
            },
            "op_type": {
                "attrs": [],
                "buda_attrs": {
                    "kernel_broadcast": {
                        "input_1": 1
                    },
                    "l1_acc": true,
                    "m_k": 3,
                    "u_kt": 4
                },
                "named_attrs": {},
                "type": "matmul"
            },
            "opcode": "BudaOp",
            "outgoing_edge_port_info": [
                "Data: _fused_op_60 (port_0)"
            ],
            "output_df": "Float16_b",
            "output_nodes": [
                "_fused_op_60"
            ],
            "pybuda": 1,
            "tags": {
                "layer": "transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self",
                "original_op_name": "softmax_448",
                "original_op_type": "softmax",
                "reduce_c": true
            },
            "type": "matmul",
            "unique_id": 28009
        }
    },
    "topological_sorted_nodes": [
        "lc.input_tensor.softmax_448.dc.reduce_sum.3.0",
        "e2e__fused_op_58_0",
        "e2e_softmax_448.dc.reduce_max.0_0",
        "_fused_op_59",
        "softmax_448.dc.reduce_sum.3.lc1",
        "dc.input_tensor.softmax_448.4",
        "e2e__fused_op_57_0",
        "bert.encoder.layer.8.attention.self.value.weight",
        "bert.encoder.layer.8.attention.self.value.bias",
        "matmul_452",
        "buffer_0_29714_29715",
        "_fused_op_60",
        "matmul_459",
        "bert.encoder.layer.8.attention.output.dense.weight",
        "bert.encoder.layer.8.attention.output.dense.bias",
        "matmul_463",
        "add_467",
        "lc.input_tensor.layernorm_468.dc.reduce_sum.0.0",
        "layernorm_468.dc.reduce_sum.0.lc1",
        "dc.input_tensor.layernorm_468.1",
        "buffer_1_28032_29716",
        "buffer_0_28032_29716",
        "_fused_op_61",
        "layernorm_468.dc.multiply.4",
        "lc.input_tensor.layernorm_468.dc.reduce_sum.5.0",
        "layernorm_468.dc.reduce_sum.5.lc1",
        "dc.input_tensor.layernorm_468.6",
        "dc.input_tensor.layernorm_468.8",
        "bert.encoder.layer.8.attention.output.LayerNorm.weight",
        "bert.encoder.layer.8.attention.output.LayerNorm.bias",
        "buffer_2_29716_29717",
        "buffer_1_29716_29717",
        "buffer_0_29716_29717",
        "_fused_op_62",
        "bert.encoder.layer.8.intermediate.dense.weight",
        "bert.encoder.layer.8.intermediate.dense.bias",
        "matmul_471",
        "gelu_474",
        "e2e_gelu_474_0",
        "e2e__fused_op_62_0"
    ]
}