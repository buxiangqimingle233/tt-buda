{
    "netlist": {
        "devices": {
            "arch": "wormhole_b0"
        },
        "queues": {
            "pybuda_6_i0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    12,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "host",
                "host": [
                    [
                        0,
                        32
                    ]
                ]
            },
            "attention_mask_1": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    2
                ],
                "ublock": [
                    1,
                    6
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "host",
                "host": [
                    [
                        0,
                        798816
                    ]
                ]
            },
            "bert_large_tt_1.output_reshape_1285": {
                "input": "matmul_1281_output_nop_0",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    2,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "host",
                "host": [
                    [
                        0,
                        823840
                    ]
                ]
            },
            "bert_large_tt_1.output_reshape_1292": {
                "input": "matmul_1288_output_nop_0",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    2,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "host",
                "host": [
                    [
                        0,
                        848480
                    ]
                ]
            },
            "bert.embeddings.LayerNorm.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1005112096
                    ]
                ]
            },
            "bert.embeddings.LayerNorm.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1004812576
                    ]
                ]
            },
            "bert.encoder.layer.0.attention.self.query.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    4,
                    2
                ],
                "t": 1,
                "mblock": [
                    2,
                    2
                ],
                "ublock": [
                    4,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1023618944
                    ],
                    [
                        3,
                        2097360768
                    ],
                    [
                        4,
                        1023618944
                    ],
                    [
                        4,
                        2097360768
                    ],
                    [
                        5,
                        1023618944
                    ],
                    [
                        5,
                        2097360768
                    ],
                    [
                        0,
                        754517856
                    ],
                    [
                        0,
                        2096695136
                    ]
                ]
            },
            "bert.encoder.layer.0.attention.self.query.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    2
                ],
                "t": 1,
                "mblock": [
                    1,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1004379296
                    ],
                    [
                        3,
                        2078121120
                    ]
                ]
            },
            "bert.encoder.layer.0.attention.self.key.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    4,
                    2
                ],
                "t": 1,
                "mblock": [
                    2,
                    2
                ],
                "ublock": [
                    4,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1023885216
                    ],
                    [
                        5,
                        2097627040
                    ],
                    [
                        0,
                        754784128
                    ],
                    [
                        0,
                        2096961408
                    ],
                    [
                        1,
                        1023419264
                    ],
                    [
                        1,
                        2097161088
                    ],
                    [
                        2,
                        1023419264
                    ],
                    [
                        2,
                        2097161088
                    ]
                ]
            },
            "bert.encoder.layer.0.attention.self.key.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    2
                ],
                "t": 1,
                "mblock": [
                    1,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        735611200
                    ],
                    [
                        0,
                        2077788480
                    ]
                ]
            },
            "bert.encoder.layer.0.attention.self.value.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    2,
                    1
                ],
                "ublock": [
                    8,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1018892640
                    ],
                    [
                        2,
                        2092634464
                    ],
                    [
                        3,
                        1019092320
                    ],
                    [
                        3,
                        2092834144
                    ],
                    [
                        4,
                        1019092320
                    ],
                    [
                        4,
                        2092834144
                    ],
                    [
                        5,
                        1019092320
                    ],
                    [
                        5,
                        2092834144
                    ]
                ]
            },
            "bert.encoder.layer.0.attention.self.value.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        735202944
                    ],
                    [
                        0,
                        2077380224
                    ],
                    [
                        1,
                        1003871360
                    ],
                    [
                        1,
                        2077613184
                    ]
                ]
            },
            "bert.encoder.layer.0.attention.output.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    8,
                    1
                ],
                "ublock": [
                    2,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        750523776
                    ],
                    [
                        0,
                        2092701056
                    ],
                    [
                        1,
                        1019158912
                    ],
                    [
                        1,
                        2092900736
                    ],
                    [
                        2,
                        1019158912
                    ],
                    [
                        2,
                        2092900736
                    ],
                    [
                        3,
                        1019358592
                    ],
                    [
                        3,
                        2093100416
                    ]
                ]
            },
            "bert.encoder.layer.0.attention.output.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        735352992
                    ],
                    [
                        0,
                        2077530272
                    ],
                    [
                        1,
                        1004021408
                    ],
                    [
                        1,
                        2077763232
                    ]
                ]
            },
            "bert.encoder.layer.0.attention.output.LayerNorm.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        2078687584
                    ]
                ]
            },
            "bert.encoder.layer.0.attention.output.LayerNorm.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1005212128
                    ]
                ]
            },
            "bert.encoder.layer.0.intermediate.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    8
                ],
                "t": 1,
                "mblock": [
                    4,
                    2
                ],
                "ublock": [
                    4,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1043055968
                    ],
                    [
                        5,
                        2116797792
                    ],
                    [
                        0,
                        773821760
                    ],
                    [
                        0,
                        2115999040
                    ],
                    [
                        1,
                        1042323776
                    ],
                    [
                        1,
                        2116065600
                    ],
                    [
                        2,
                        1042323776
                    ],
                    [
                        2,
                        2116065600
                    ],
                    [
                        3,
                        1042523456
                    ],
                    [
                        3,
                        2116265280
                    ],
                    [
                        4,
                        1042523456
                    ],
                    [
                        4,
                        2116265280
                    ],
                    [
                        5,
                        1042523456
                    ],
                    [
                        5,
                        2116265280
                    ],
                    [
                        0,
                        773289248
                    ],
                    [
                        0,
                        2115466528
                    ]
                ]
            },
            "bert.encoder.layer.0.intermediate.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    8
                ],
                "t": 1,
                "mblock": [
                    1,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1004545792
                    ],
                    [
                        5,
                        2078287616
                    ],
                    [
                        0,
                        735511264
                    ],
                    [
                        0,
                        2077688544
                    ],
                    [
                        1,
                        1004179680
                    ],
                    [
                        1,
                        2077921504
                    ],
                    [
                        2,
                        1004212960
                    ],
                    [
                        2,
                        2077954784
                    ]
                ]
            },
            "bert.encoder.layer.0.output.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    8
                ],
                "t": 1,
                "mblock": [
                    8,
                    1
                ],
                "ublock": [
                    8,
                    4
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1041458432
                    ],
                    [
                        3,
                        2115200256
                    ],
                    [
                        4,
                        1041458432
                    ],
                    [
                        4,
                        2115200256
                    ],
                    [
                        5,
                        1041458432
                    ],
                    [
                        5,
                        2115200256
                    ],
                    [
                        0,
                        772224224
                    ],
                    [
                        0,
                        2114401504
                    ],
                    [
                        1,
                        1040726240
                    ],
                    [
                        1,
                        2114468064
                    ],
                    [
                        2,
                        1040726240
                    ],
                    [
                        2,
                        2114468064
                    ],
                    [
                        3,
                        1040925920
                    ],
                    [
                        3,
                        2114667744
                    ],
                    [
                        4,
                        1040925920
                    ],
                    [
                        4,
                        2114667744
                    ]
                ]
            },
            "bert.encoder.layer.0.output.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    8
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    4
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        2077271296
                    ],
                    [
                        2,
                        1003571072
                    ],
                    [
                        2,
                        2077312896
                    ],
                    [
                        3,
                        1003804032
                    ],
                    [
                        3,
                        2077545856
                    ],
                    [
                        4,
                        1003887232
                    ],
                    [
                        4,
                        2077629056
                    ],
                    [
                        5,
                        1003887232
                    ]
                ]
            },
            "bert.encoder.layer.0.output.LayerNorm.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1005212128
                    ]
                ]
            },
            "bert.encoder.layer.0.output.LayerNorm.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        2078720992
                    ]
                ]
            },
            "bert.encoder.layer.1.attention.self.query.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    2,
                    1
                ],
                "ublock": [
                    8,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        2101155168
                    ],
                    [
                        2,
                        1027413344
                    ],
                    [
                        2,
                        2101155168
                    ],
                    [
                        3,
                        1027613024
                    ],
                    [
                        3,
                        2101354848
                    ],
                    [
                        4,
                        1027613024
                    ],
                    [
                        4,
                        2101354848
                    ],
                    [
                        5,
                        1027613024
                    ]
                ]
            },
            "bert.encoder.layer.1.attention.self.query.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1004337504
                    ],
                    [
                        4,
                        2078079328
                    ],
                    [
                        5,
                        1004337504
                    ],
                    [
                        5,
                        2078079328
                    ]
                ]
            },
            "bert.encoder.layer.1.attention.self.key.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    2,
                    1
                ],
                "ublock": [
                    8,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1025749120
                    ],
                    [
                        4,
                        2099490944
                    ],
                    [
                        5,
                        1025749120
                    ],
                    [
                        5,
                        2099490944
                    ],
                    [
                        0,
                        756648032
                    ],
                    [
                        0,
                        2098825312
                    ],
                    [
                        1,
                        1025283168
                    ],
                    [
                        1,
                        2099024992
                    ]
                ]
            },
            "bert.encoder.layer.1.attention.self.key.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1004054080
                    ],
                    [
                        4,
                        2077795904
                    ],
                    [
                        5,
                        1004054080
                    ],
                    [
                        5,
                        2077795904
                    ]
                ]
            },
            "bert.encoder.layer.1.attention.self.value.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    2,
                    1
                ],
                "ublock": [
                    8,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1012435520
                    ],
                    [
                        3,
                        2086177344
                    ],
                    [
                        4,
                        1012435520
                    ],
                    [
                        4,
                        2086177344
                    ],
                    [
                        5,
                        1012435520
                    ],
                    [
                        5,
                        2086177344
                    ],
                    [
                        0,
                        743334432
                    ],
                    [
                        0,
                        2085511712
                    ]
                ]
            },
            "bert.encoder.layer.1.attention.self.value.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1003896288
                    ],
                    [
                        2,
                        2077638112
                    ],
                    [
                        3,
                        1004129248
                    ],
                    [
                        3,
                        2077871072
                    ]
                ]
            },
            "bert.encoder.layer.1.attention.output.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    8,
                    1
                ],
                "ublock": [
                    2,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        2087575296
                    ],
                    [
                        2,
                        1013833472
                    ],
                    [
                        2,
                        2087575296
                    ],
                    [
                        3,
                        1014033152
                    ],
                    [
                        3,
                        2087774976
                    ],
                    [
                        4,
                        1014033152
                    ],
                    [
                        4,
                        2087774976
                    ],
                    [
                        5,
                        1014033152
                    ]
                ]
            },
            "bert.encoder.layer.1.attention.output.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1003862944
                    ],
                    [
                        2,
                        2077604768
                    ],
                    [
                        3,
                        1004095904
                    ],
                    [
                        3,
                        2077837728
                    ]
                ]
            },
            "bert.encoder.layer.1.attention.output.LayerNorm.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1005445056
                    ]
                ]
            },
            "bert.encoder.layer.1.attention.output.LayerNorm.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        736410528
                    ]
                ]
            },
            "bert.encoder.layer.1.intermediate.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    8
                ],
                "t": 1,
                "mblock": [
                    4,
                    2
                ],
                "ublock": [
                    4,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1056701600
                    ],
                    [
                        1,
                        2130443424
                    ],
                    [
                        2,
                        1056701600
                    ],
                    [
                        2,
                        2130443424
                    ],
                    [
                        3,
                        1056901280
                    ],
                    [
                        3,
                        2130643104
                    ],
                    [
                        4,
                        1056901280
                    ],
                    [
                        4,
                        2130643104
                    ],
                    [
                        5,
                        1056901280
                    ],
                    [
                        5,
                        2130643104
                    ],
                    [
                        0,
                        787667072
                    ],
                    [
                        0,
                        2129844352
                    ],
                    [
                        1,
                        1056169088
                    ],
                    [
                        1,
                        2129910912
                    ],
                    [
                        2,
                        1056169088
                    ],
                    [
                        2,
                        2129910912
                    ]
                ]
            },
            "bert.encoder.layer.1.intermediate.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    8
                ],
                "t": 1,
                "mblock": [
                    1,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1004512544
                    ],
                    [
                        3,
                        2078254368
                    ],
                    [
                        4,
                        1004579104
                    ],
                    [
                        4,
                        2078320928
                    ],
                    [
                        5,
                        1004579104
                    ],
                    [
                        5,
                        2078320928
                    ],
                    [
                        0,
                        735544576
                    ],
                    [
                        0,
                        2077721856
                    ]
                ]
            },
            "bert.encoder.layer.1.output.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    8
                ],
                "t": 1,
                "mblock": [
                    8,
                    1
                ],
                "ublock": [
                    8,
                    4
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1055836256
                    ],
                    [
                        5,
                        2129578080
                    ],
                    [
                        0,
                        786602048
                    ],
                    [
                        0,
                        2128779328
                    ],
                    [
                        1,
                        1055104064
                    ],
                    [
                        1,
                        2128845888
                    ],
                    [
                        2,
                        1055104064
                    ],
                    [
                        2,
                        2128845888
                    ],
                    [
                        3,
                        1055303744
                    ],
                    [
                        3,
                        2129045568
                    ],
                    [
                        4,
                        1055303744
                    ],
                    [
                        4,
                        2129045568
                    ],
                    [
                        5,
                        1055303744
                    ],
                    [
                        5,
                        2129045568
                    ],
                    [
                        0,
                        786069536
                    ],
                    [
                        0,
                        2128246816
                    ]
                ]
            },
            "bert.encoder.layer.1.output.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    8
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    4
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        2077304544
                    ],
                    [
                        3,
                        1003795680
                    ],
                    [
                        3,
                        2077537504
                    ],
                    [
                        4,
                        1003878880
                    ],
                    [
                        4,
                        2077620704
                    ],
                    [
                        5,
                        1003878880
                    ],
                    [
                        5,
                        2077620704
                    ],
                    [
                        0,
                        734844352
                    ]
                ]
            },
            "bert.encoder.layer.1.output.LayerNorm.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1005012352
                    ]
                ]
            },
            "bert.encoder.layer.1.output.LayerNorm.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        2078754176
                    ]
                ]
            },
            "bert.encoder.layer.2.attention.self.query.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    4,
                    2
                ],
                "t": 1,
                "mblock": [
                    2,
                    2
                ],
                "ublock": [
                    4,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        2090437696
                    ],
                    [
                        4,
                        1016695872
                    ],
                    [
                        4,
                        2090437696
                    ],
                    [
                        5,
                        1016695872
                    ],
                    [
                        5,
                        2090437696
                    ],
                    [
                        0,
                        747594784
                    ],
                    [
                        0,
                        2089772064
                    ],
                    [
                        1,
                        1016229920
                    ]
                ]
            },
            "bert.encoder.layer.2.attention.self.query.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    2
                ],
                "t": 1,
                "mblock": [
                    1,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1004712672
                    ],
                    [
                        1,
                        2078454496
                    ]
                ]
            },
            "bert.encoder.layer.2.attention.self.key.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    4,
                    2
                ],
                "t": 1,
                "mblock": [
                    2,
                    2
                ],
                "ublock": [
                    4,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        748127328
                    ],
                    [
                        0,
                        2090304608
                    ],
                    [
                        1,
                        1016762464
                    ],
                    [
                        1,
                        2090504288
                    ],
                    [
                        2,
                        1016762464
                    ],
                    [
                        2,
                        2090504288
                    ],
                    [
                        3,
                        1016962144
                    ],
                    [
                        3,
                        2090703968
                    ]
                ]
            },
            "bert.encoder.layer.2.attention.self.key.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    2
                ],
                "t": 1,
                "mblock": [
                    1,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1004945600
                    ],
                    [
                        3,
                        2078687424
                    ]
                ]
            },
            "bert.encoder.layer.2.attention.self.value.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    2,
                    1
                ],
                "ublock": [
                    8,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        2091635968
                    ],
                    [
                        1,
                        1018093824
                    ],
                    [
                        1,
                        2091835648
                    ],
                    [
                        2,
                        1018093824
                    ],
                    [
                        2,
                        2091835648
                    ],
                    [
                        3,
                        1018293504
                    ],
                    [
                        3,
                        2092035328
                    ],
                    [
                        4,
                        1018293504
                    ]
                ]
            },
            "bert.encoder.layer.2.attention.self.value.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1003796256
                    ],
                    [
                        2,
                        2077538080
                    ],
                    [
                        3,
                        1004029216
                    ],
                    [
                        3,
                        2077771040
                    ]
                ]
            },
            "bert.encoder.layer.2.attention.output.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    8,
                    1
                ],
                "ublock": [
                    2,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        2091502784
                    ],
                    [
                        5,
                        1017760960
                    ],
                    [
                        5,
                        2091502784
                    ],
                    [
                        0,
                        748659872
                    ],
                    [
                        0,
                        2090837152
                    ],
                    [
                        1,
                        1017295008
                    ],
                    [
                        1,
                        2091036832
                    ],
                    [
                        2,
                        1017295008
                    ]
                ]
            },
            "bert.encoder.layer.2.attention.output.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1004137440
                    ],
                    [
                        4,
                        2077879264
                    ],
                    [
                        5,
                        1004137440
                    ],
                    [
                        5,
                        2077879264
                    ]
                ]
            },
            "bert.encoder.layer.2.attention.output.LayerNorm.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        2078587808
                    ]
                ]
            },
            "bert.encoder.layer.2.attention.output.LayerNorm.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        2079186880
                    ]
                ]
            },
            "bert.encoder.layer.2.intermediate.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    8
                ],
                "t": 1,
                "mblock": [
                    4,
                    2
                ],
                "ublock": [
                    4,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1053706208
                    ],
                    [
                        5,
                        2127448032
                    ],
                    [
                        0,
                        784472000
                    ],
                    [
                        0,
                        2126649280
                    ],
                    [
                        1,
                        1052974016
                    ],
                    [
                        1,
                        2126715840
                    ],
                    [
                        2,
                        1052974016
                    ],
                    [
                        2,
                        2126715840
                    ],
                    [
                        3,
                        1053173696
                    ],
                    [
                        3,
                        2126915520
                    ],
                    [
                        4,
                        1053173696
                    ],
                    [
                        4,
                        2126915520
                    ],
                    [
                        5,
                        1053173696
                    ],
                    [
                        5,
                        2126915520
                    ],
                    [
                        0,
                        783939488
                    ],
                    [
                        0,
                        2126116768
                    ]
                ]
            },
            "bert.encoder.layer.2.intermediate.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    8
                ],
                "t": 1,
                "mblock": [
                    1,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1005012224
                    ],
                    [
                        3,
                        2078754048
                    ],
                    [
                        4,
                        1005078784
                    ],
                    [
                        4,
                        2078820608
                    ],
                    [
                        5,
                        1005078784
                    ],
                    [
                        5,
                        2078820608
                    ],
                    [
                        0,
                        736044256
                    ],
                    [
                        0,
                        2078221536
                    ]
                ]
            },
            "bert.encoder.layer.2.output.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    8
                ],
                "t": 1,
                "mblock": [
                    8,
                    1
                ],
                "ublock": [
                    8,
                    4
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1057966304
                    ],
                    [
                        5,
                        2131708128
                    ],
                    [
                        0,
                        788732096
                    ],
                    [
                        0,
                        2130909376
                    ],
                    [
                        1,
                        1057234112
                    ],
                    [
                        1,
                        2130975936
                    ],
                    [
                        2,
                        1057234112
                    ],
                    [
                        2,
                        2130975936
                    ],
                    [
                        3,
                        1057433792
                    ],
                    [
                        3,
                        2131175616
                    ],
                    [
                        4,
                        1057433792
                    ],
                    [
                        4,
                        2131175616
                    ],
                    [
                        5,
                        1057433792
                    ],
                    [
                        5,
                        2131175616
                    ],
                    [
                        0,
                        788199584
                    ],
                    [
                        0,
                        2130376864
                    ]
                ]
            },
            "bert.encoder.layer.2.output.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    8
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    4
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        2076979872
                    ],
                    [
                        1,
                        1003471008
                    ],
                    [
                        1,
                        2077212832
                    ],
                    [
                        2,
                        1003512608
                    ],
                    [
                        2,
                        2077254432
                    ],
                    [
                        3,
                        1003745568
                    ],
                    [
                        3,
                        2077487392
                    ],
                    [
                        4,
                        1003828768
                    ]
                ]
            },
            "bert.encoder.layer.2.output.LayerNorm.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        2079320064
                    ]
                ]
            },
            "bert.encoder.layer.2.output.LayerNorm.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        2079153728
                    ]
                ]
            },
            "bert.encoder.layer.3.attention.self.query.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    2,
                    1
                ],
                "ublock": [
                    8,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        2088573792
                    ],
                    [
                        5,
                        1014831968
                    ],
                    [
                        5,
                        2088573792
                    ],
                    [
                        0,
                        745730880
                    ],
                    [
                        0,
                        2087908160
                    ],
                    [
                        1,
                        1014366016
                    ],
                    [
                        1,
                        2088107840
                    ],
                    [
                        2,
                        1014366016
                    ]
                ]
            },
            "bert.encoder.layer.3.attention.self.query.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1004187456
                    ],
                    [
                        4,
                        2077929280
                    ],
                    [
                        5,
                        1004187456
                    ],
                    [
                        5,
                        2077929280
                    ]
                ]
            },
            "bert.encoder.layer.3.attention.self.key.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    2,
                    1
                ],
                "ublock": [
                    8,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1015098240
                    ],
                    [
                        5,
                        2088840064
                    ],
                    [
                        0,
                        745997152
                    ],
                    [
                        0,
                        2088174432
                    ],
                    [
                        1,
                        1014632288
                    ],
                    [
                        1,
                        2088374112
                    ],
                    [
                        2,
                        1014632288
                    ],
                    [
                        2,
                        2088374112
                    ]
                ]
            },
            "bert.encoder.layer.3.attention.self.key.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1003879616
                    ],
                    [
                        2,
                        2077621440
                    ],
                    [
                        3,
                        1004112576
                    ],
                    [
                        3,
                        2077854400
                    ]
                ]
            },
            "bert.encoder.layer.3.attention.self.value.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    2,
                    1
                ],
                "ublock": [
                    8,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1015897056
                    ],
                    [
                        3,
                        2089638880
                    ],
                    [
                        4,
                        1015897056
                    ],
                    [
                        4,
                        2089638880
                    ],
                    [
                        5,
                        1015897056
                    ],
                    [
                        5,
                        2089638880
                    ],
                    [
                        0,
                        746795968
                    ],
                    [
                        0,
                        2088973248
                    ]
                ]
            },
            "bert.encoder.layer.3.attention.self.value.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1003696224
                    ],
                    [
                        2,
                        2077438048
                    ],
                    [
                        3,
                        1003929184
                    ],
                    [
                        3,
                        2077671008
                    ]
                ]
            },
            "bert.encoder.layer.3.attention.output.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    8,
                    1
                ],
                "ublock": [
                    2,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1015963648
                    ],
                    [
                        1,
                        2089705472
                    ],
                    [
                        2,
                        1015963648
                    ],
                    [
                        2,
                        2089705472
                    ],
                    [
                        3,
                        1016163328
                    ],
                    [
                        3,
                        2089905152
                    ],
                    [
                        4,
                        1016163328
                    ],
                    [
                        4,
                        2089905152
                    ]
                ]
            },
            "bert.encoder.layer.3.attention.output.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        734986208
                    ],
                    [
                        0,
                        2077163488
                    ],
                    [
                        1,
                        1003654624
                    ],
                    [
                        1,
                        2077396448
                    ]
                ]
            },
            "bert.encoder.layer.3.attention.output.LayerNorm.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1005511680
                    ]
                ]
            },
            "bert.encoder.layer.3.attention.output.LayerNorm.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        2079253504
                    ]
                ]
            },
            "bert.encoder.layer.3.intermediate.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    8
                ],
                "t": 1,
                "mblock": [
                    4,
                    2
                ],
                "ublock": [
                    4,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1064356448
                    ],
                    [
                        5,
                        2138098272
                    ],
                    [
                        0,
                        795122240
                    ],
                    [
                        0,
                        2137299520
                    ],
                    [
                        1,
                        1063624256
                    ],
                    [
                        1,
                        2137366080
                    ],
                    [
                        2,
                        1063624256
                    ],
                    [
                        2,
                        2137366080
                    ],
                    [
                        3,
                        1063823936
                    ],
                    [
                        3,
                        2137565760
                    ],
                    [
                        4,
                        1063823936
                    ],
                    [
                        4,
                        2137565760
                    ],
                    [
                        5,
                        1063823936
                    ],
                    [
                        5,
                        2137565760
                    ],
                    [
                        0,
                        794589728
                    ],
                    [
                        0,
                        2136767008
                    ]
                ]
            },
            "bert.encoder.layer.3.intermediate.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    8
                ],
                "t": 1,
                "mblock": [
                    1,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        735811072
                    ],
                    [
                        0,
                        2077988352
                    ],
                    [
                        1,
                        1004479488
                    ],
                    [
                        1,
                        2078221312
                    ],
                    [
                        2,
                        1004512768
                    ],
                    [
                        2,
                        2078254592
                    ],
                    [
                        3,
                        1004745728
                    ],
                    [
                        3,
                        2078487552
                    ]
                ]
            },
            "bert.encoder.layer.3.output.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    8
                ],
                "t": 1,
                "mblock": [
                    8,
                    1
                ],
                "ublock": [
                    8,
                    4
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1051576160
                    ],
                    [
                        5,
                        2125317984
                    ],
                    [
                        0,
                        782341952
                    ],
                    [
                        0,
                        2124519232
                    ],
                    [
                        1,
                        1050843968
                    ],
                    [
                        1,
                        2124585792
                    ],
                    [
                        2,
                        1050843968
                    ],
                    [
                        2,
                        2124585792
                    ],
                    [
                        3,
                        1051043648
                    ],
                    [
                        3,
                        2124785472
                    ],
                    [
                        4,
                        1051043648
                    ],
                    [
                        4,
                        2124785472
                    ],
                    [
                        5,
                        1051043648
                    ],
                    [
                        5,
                        2124785472
                    ],
                    [
                        0,
                        781809440
                    ],
                    [
                        0,
                        2123986720
                    ]
                ]
            },
            "bert.encoder.layer.3.output.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    8
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    4
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1003903936
                    ],
                    [
                        5,
                        2077645760
                    ],
                    [
                        0,
                        734869408
                    ],
                    [
                        0,
                        2077046688
                    ],
                    [
                        1,
                        1003537824
                    ],
                    [
                        1,
                        2077279648
                    ],
                    [
                        2,
                        1003579424
                    ],
                    [
                        2,
                        2077321248
                    ]
                ]
            },
            "bert.encoder.layer.3.output.LayerNorm.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        2078953952
                    ]
                ]
            },
            "bert.encoder.layer.3.output.LayerNorm.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        2078953952
                    ]
                ]
            },
            "bert.encoder.layer.4.attention.self.query.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    4,
                    2
                ],
                "t": 1,
                "mblock": [
                    2,
                    2
                ],
                "ublock": [
                    4,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        2084646304
                    ],
                    [
                        3,
                        1011104160
                    ],
                    [
                        3,
                        2084845984
                    ],
                    [
                        4,
                        1011104160
                    ],
                    [
                        4,
                        2084845984
                    ],
                    [
                        5,
                        1011104160
                    ],
                    [
                        5,
                        2084845984
                    ],
                    [
                        0,
                        742003072
                    ]
                ]
            },
            "bert.encoder.layer.4.attention.self.query.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    2
                ],
                "t": 1,
                "mblock": [
                    1,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1004546112
                    ],
                    [
                        1,
                        2078287936
                    ]
                ]
            },
            "bert.encoder.layer.4.attention.self.key.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    4,
                    2
                ],
                "t": 1,
                "mblock": [
                    2,
                    2
                ],
                "ublock": [
                    4,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1012701792
                    ],
                    [
                        5,
                        2086443616
                    ],
                    [
                        0,
                        743600704
                    ],
                    [
                        0,
                        2085777984
                    ],
                    [
                        1,
                        1012235840
                    ],
                    [
                        1,
                        2085977664
                    ],
                    [
                        2,
                        1012235840
                    ],
                    [
                        2,
                        2085977664
                    ]
                ]
            },
            "bert.encoder.layer.4.attention.self.key.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    2
                ],
                "t": 1,
                "mblock": [
                    1,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1004612704
                    ],
                    [
                        2,
                        2078354528
                    ]
                ]
            },
            "bert.encoder.layer.4.attention.self.value.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    2,
                    1
                ],
                "ublock": [
                    8,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1009573120
                    ],
                    [
                        2,
                        2083314944
                    ],
                    [
                        3,
                        1009772800
                    ],
                    [
                        3,
                        2083514624
                    ],
                    [
                        4,
                        1009772800
                    ],
                    [
                        4,
                        2083514624
                    ],
                    [
                        5,
                        1009772800
                    ],
                    [
                        5,
                        2083514624
                    ]
                ]
            },
            "bert.encoder.layer.4.attention.self.value.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        735319648
                    ],
                    [
                        0,
                        2077496928
                    ],
                    [
                        1,
                        1003988064
                    ],
                    [
                        1,
                        2077729888
                    ]
                ]
            },
            "bert.encoder.layer.4.attention.output.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    8,
                    1
                ],
                "ublock": [
                    2,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1009506528
                    ],
                    [
                        4,
                        2083248352
                    ],
                    [
                        5,
                        1009506528
                    ],
                    [
                        5,
                        2083248352
                    ],
                    [
                        0,
                        740405440
                    ],
                    [
                        0,
                        2082582720
                    ],
                    [
                        1,
                        1009040576
                    ],
                    [
                        1,
                        2082782400
                    ]
                ]
            },
            "bert.encoder.layer.4.attention.output.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1004387520
                    ],
                    [
                        4,
                        2078129344
                    ],
                    [
                        5,
                        1004387520
                    ],
                    [
                        5,
                        2078129344
                    ]
                ]
            },
            "bert.encoder.layer.4.attention.output.LayerNorm.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1004812576
                    ]
                ]
            },
            "bert.encoder.layer.4.attention.output.LayerNorm.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        736144160
                    ]
                ]
            },
            "bert.encoder.layer.4.intermediate.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    8
                ],
                "t": 1,
                "mblock": [
                    4,
                    2
                ],
                "ublock": [
                    4,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1054571552
                    ],
                    [
                        1,
                        2128313376
                    ],
                    [
                        2,
                        1054571552
                    ],
                    [
                        2,
                        2128313376
                    ],
                    [
                        3,
                        1054771232
                    ],
                    [
                        3,
                        2128513056
                    ],
                    [
                        4,
                        1054771232
                    ],
                    [
                        4,
                        2128513056
                    ],
                    [
                        5,
                        1054771232
                    ],
                    [
                        5,
                        2128513056
                    ],
                    [
                        0,
                        785537024
                    ],
                    [
                        0,
                        2127714304
                    ],
                    [
                        1,
                        1054039040
                    ],
                    [
                        1,
                        2127780864
                    ],
                    [
                        2,
                        1054039040
                    ],
                    [
                        2,
                        2127780864
                    ]
                ]
            },
            "bert.encoder.layer.4.intermediate.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    8
                ],
                "t": 1,
                "mblock": [
                    1,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1004778976
                    ],
                    [
                        4,
                        2078520800
                    ],
                    [
                        5,
                        1004778976
                    ],
                    [
                        5,
                        2078520800
                    ],
                    [
                        0,
                        735744448
                    ],
                    [
                        0,
                        2077921728
                    ],
                    [
                        1,
                        1004412864
                    ],
                    [
                        1,
                        2078154688
                    ]
                ]
            },
            "bert.encoder.layer.4.output.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    8
                ],
                "t": 1,
                "mblock": [
                    8,
                    1
                ],
                "ublock": [
                    8,
                    4
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1060961696
                    ],
                    [
                        1,
                        2134703520
                    ],
                    [
                        2,
                        1060961696
                    ],
                    [
                        2,
                        2134703520
                    ],
                    [
                        3,
                        1061161376
                    ],
                    [
                        3,
                        2134903200
                    ],
                    [
                        4,
                        1061161376
                    ],
                    [
                        4,
                        2134903200
                    ],
                    [
                        5,
                        1061161376
                    ],
                    [
                        5,
                        2134903200
                    ],
                    [
                        0,
                        791927168
                    ],
                    [
                        0,
                        2134104448
                    ],
                    [
                        1,
                        1060429184
                    ],
                    [
                        1,
                        2134171008
                    ],
                    [
                        2,
                        1060429184
                    ],
                    [
                        2,
                        2134171008
                    ]
                ]
            },
            "bert.encoder.layer.4.output.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    8
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    4
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        2077403872
                    ],
                    [
                        4,
                        1003745248
                    ],
                    [
                        4,
                        2077487072
                    ],
                    [
                        5,
                        1003745248
                    ],
                    [
                        5,
                        2077487072
                    ],
                    [
                        0,
                        734710720
                    ],
                    [
                        0,
                        2076888000
                    ],
                    [
                        1,
                        1003379136
                    ]
                ]
            },
            "bert.encoder.layer.4.output.LayerNorm.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1004945760
                    ]
                ]
            },
            "bert.encoder.layer.4.output.LayerNorm.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        2078987136
                    ]
                ]
            },
            "bert.encoder.layer.5.attention.self.query.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    2,
                    1
                ],
                "ublock": [
                    8,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1011969568
                    ],
                    [
                        1,
                        2085711392
                    ],
                    [
                        2,
                        1011969568
                    ],
                    [
                        2,
                        2085711392
                    ],
                    [
                        3,
                        1012169248
                    ],
                    [
                        3,
                        2085911072
                    ],
                    [
                        4,
                        1012169248
                    ],
                    [
                        4,
                        2085911072
                    ]
                ]
            },
            "bert.encoder.layer.5.attention.self.query.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        735252960
                    ],
                    [
                        0,
                        2077430240
                    ],
                    [
                        1,
                        1003921376
                    ],
                    [
                        1,
                        2077663200
                    ]
                ]
            },
            "bert.encoder.layer.5.attention.self.key.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    2,
                    1
                ],
                "ublock": [
                    8,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        2085245440
                    ],
                    [
                        1,
                        1011703296
                    ],
                    [
                        1,
                        2085445120
                    ],
                    [
                        2,
                        1011703296
                    ],
                    [
                        2,
                        2085445120
                    ],
                    [
                        3,
                        1011902976
                    ],
                    [
                        3,
                        2085644800
                    ],
                    [
                        4,
                        1011902976
                    ]
                ]
            },
            "bert.encoder.layer.5.attention.self.key.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1004287488
                    ],
                    [
                        4,
                        2078029312
                    ],
                    [
                        5,
                        1004287488
                    ],
                    [
                        5,
                        2078029312
                    ]
                ]
            },
            "bert.encoder.layer.5.attention.self.value.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    2,
                    1
                ],
                "ublock": [
                    8,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        2098226176
                    ],
                    [
                        2,
                        1024484352
                    ],
                    [
                        2,
                        2098226176
                    ],
                    [
                        3,
                        1024684032
                    ],
                    [
                        3,
                        2098425856
                    ],
                    [
                        4,
                        1024684032
                    ],
                    [
                        4,
                        2098425856
                    ],
                    [
                        5,
                        1024684032
                    ]
                ]
            },
            "bert.encoder.layer.5.attention.self.value.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1003996320
                    ],
                    [
                        2,
                        2077738144
                    ],
                    [
                        3,
                        1004229280
                    ],
                    [
                        3,
                        2077971104
                    ]
                ]
            },
            "bert.encoder.layer.5.attention.output.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    8,
                    1
                ],
                "ublock": [
                    2,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        2098958400
                    ],
                    [
                        0,
                        756115488
                    ],
                    [
                        0,
                        2098292768
                    ],
                    [
                        1,
                        1024750624
                    ],
                    [
                        1,
                        2098492448
                    ],
                    [
                        2,
                        1024750624
                    ],
                    [
                        2,
                        2098492448
                    ],
                    [
                        3,
                        1024950304
                    ]
                ]
            },
            "bert.encoder.layer.5.attention.output.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1004320832
                    ],
                    [
                        4,
                        2078062656
                    ],
                    [
                        5,
                        1004320832
                    ],
                    [
                        5,
                        2078062656
                    ]
                ]
            },
            "bert.encoder.layer.5.attention.output.LayerNorm.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        2078554400
                    ]
                ]
            },
            "bert.encoder.layer.5.attention.output.LayerNorm.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1005045536
                    ]
                ]
            },
            "bert.encoder.layer.5.intermediate.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    8
                ],
                "t": 1,
                "mblock": [
                    4,
                    2
                ],
                "ublock": [
                    4,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1036665824
                    ],
                    [
                        5,
                        2110407648
                    ],
                    [
                        0,
                        767431616
                    ],
                    [
                        0,
                        2109608896
                    ],
                    [
                        1,
                        1035933632
                    ],
                    [
                        1,
                        2109675456
                    ],
                    [
                        2,
                        1035933632
                    ],
                    [
                        2,
                        2109675456
                    ],
                    [
                        3,
                        1036133312
                    ],
                    [
                        3,
                        2109875136
                    ],
                    [
                        4,
                        1036133312
                    ],
                    [
                        4,
                        2109875136
                    ],
                    [
                        5,
                        1036133312
                    ],
                    [
                        5,
                        2109875136
                    ],
                    [
                        0,
                        766899104
                    ],
                    [
                        0,
                        2109076384
                    ]
                ]
            },
            "bert.encoder.layer.5.intermediate.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    8
                ],
                "t": 1,
                "mblock": [
                    1,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        735944320
                    ],
                    [
                        0,
                        2078121600
                    ],
                    [
                        1,
                        1004612736
                    ],
                    [
                        1,
                        2078354560
                    ],
                    [
                        2,
                        1004646016
                    ],
                    [
                        2,
                        2078387840
                    ],
                    [
                        3,
                        1004878976
                    ],
                    [
                        3,
                        2078620800
                    ]
                ]
            },
            "bert.encoder.layer.5.output.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    8
                ],
                "t": 1,
                "mblock": [
                    8,
                    1
                ],
                "ublock": [
                    8,
                    4
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1038795872
                    ],
                    [
                        5,
                        2112537696
                    ],
                    [
                        0,
                        769561664
                    ],
                    [
                        0,
                        2111738944
                    ],
                    [
                        1,
                        1038063680
                    ],
                    [
                        1,
                        2111805504
                    ],
                    [
                        2,
                        1038063680
                    ],
                    [
                        2,
                        2111805504
                    ],
                    [
                        3,
                        1038263360
                    ],
                    [
                        3,
                        2112005184
                    ],
                    [
                        4,
                        1038263360
                    ],
                    [
                        4,
                        2112005184
                    ],
                    [
                        5,
                        1038263360
                    ],
                    [
                        5,
                        2112005184
                    ],
                    [
                        0,
                        769029152
                    ],
                    [
                        0,
                        2111206432
                    ]
                ]
            },
            "bert.encoder.layer.5.output.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    8
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    4
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        2077137664
                    ],
                    [
                        2,
                        1003437440
                    ],
                    [
                        2,
                        2077179264
                    ],
                    [
                        3,
                        1003670400
                    ],
                    [
                        3,
                        2077412224
                    ],
                    [
                        4,
                        1003753600
                    ],
                    [
                        4,
                        2077495424
                    ],
                    [
                        5,
                        1003753600
                    ]
                ]
            },
            "bert.encoder.layer.5.output.LayerNorm.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        2078687584
                    ]
                ]
            },
            "bert.encoder.layer.5.output.LayerNorm.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1004945760
                    ]
                ]
            },
            "bert.encoder.layer.6.attention.self.query.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    4,
                    2
                ],
                "t": 1,
                "mblock": [
                    2,
                    2
                ],
                "ublock": [
                    4,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1021289088
                    ],
                    [
                        1,
                        2095030912
                    ],
                    [
                        2,
                        1021289088
                    ],
                    [
                        2,
                        2095030912
                    ],
                    [
                        3,
                        1021488768
                    ],
                    [
                        3,
                        2095230592
                    ],
                    [
                        4,
                        1021488768
                    ],
                    [
                        4,
                        2095230592
                    ]
                ]
            },
            "bert.encoder.layer.6.attention.self.query.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    2
                ],
                "t": 1,
                "mblock": [
                    1,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1004978912
                    ],
                    [
                        3,
                        2078720736
                    ]
                ]
            },
            "bert.encoder.layer.6.attention.self.key.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    4,
                    2
                ],
                "t": 1,
                "mblock": [
                    2,
                    2
                ],
                "ublock": [
                    4,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        2094564960
                    ],
                    [
                        1,
                        1021022816
                    ],
                    [
                        1,
                        2094764640
                    ],
                    [
                        2,
                        1021022816
                    ],
                    [
                        2,
                        2094764640
                    ],
                    [
                        3,
                        1021222496
                    ],
                    [
                        3,
                        2094964320
                    ],
                    [
                        4,
                        1021222496
                    ]
                ]
            },
            "bert.encoder.layer.6.attention.self.key.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    2
                ],
                "t": 1,
                "mblock": [
                    1,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1004745952
                    ],
                    [
                        2,
                        2078487776
                    ]
                ]
            },
            "bert.encoder.layer.6.attention.self.value.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    2,
                    1
                ],
                "ublock": [
                    8,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1021755040
                    ],
                    [
                        3,
                        2095496864
                    ],
                    [
                        4,
                        1021755040
                    ],
                    [
                        4,
                        2095496864
                    ],
                    [
                        5,
                        1021755040
                    ],
                    [
                        5,
                        2095496864
                    ],
                    [
                        0,
                        752653952
                    ],
                    [
                        0,
                        2094831232
                    ]
                ]
            },
            "bert.encoder.layer.6.attention.self.value.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1003929632
                    ],
                    [
                        2,
                        2077671456
                    ],
                    [
                        3,
                        1004162592
                    ],
                    [
                        3,
                        2077904416
                    ]
                ]
            },
            "bert.encoder.layer.6.attention.output.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    8,
                    1
                ],
                "ublock": [
                    2,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        751056320
                    ],
                    [
                        0,
                        2093233600
                    ],
                    [
                        1,
                        1019691456
                    ],
                    [
                        1,
                        2093433280
                    ],
                    [
                        2,
                        1019691456
                    ],
                    [
                        2,
                        2093433280
                    ],
                    [
                        3,
                        1019891136
                    ],
                    [
                        3,
                        2093632960
                    ]
                ]
            },
            "bert.encoder.layer.6.attention.output.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1004237472
                    ],
                    [
                        4,
                        2077979296
                    ],
                    [
                        5,
                        1004237472
                    ],
                    [
                        5,
                        2077979296
                    ]
                ]
            },
            "bert.encoder.layer.6.attention.output.LayerNorm.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        2078787360
                    ]
                ]
            },
            "bert.encoder.layer.6.attention.output.LayerNorm.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        2078853920
                    ]
                ]
            },
            "bert.encoder.layer.6.intermediate.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    8
                ],
                "t": 1,
                "mblock": [
                    4,
                    2
                ],
                "ublock": [
                    4,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1041791264
                    ],
                    [
                        1,
                        2115533088
                    ],
                    [
                        2,
                        1041791264
                    ],
                    [
                        2,
                        2115533088
                    ],
                    [
                        3,
                        1041990944
                    ],
                    [
                        3,
                        2115732768
                    ],
                    [
                        4,
                        1041990944
                    ],
                    [
                        4,
                        2115732768
                    ],
                    [
                        5,
                        1041990944
                    ],
                    [
                        5,
                        2115732768
                    ],
                    [
                        0,
                        772756736
                    ],
                    [
                        0,
                        2114934016
                    ],
                    [
                        1,
                        1041258752
                    ],
                    [
                        1,
                        2115000576
                    ],
                    [
                        2,
                        1041258752
                    ],
                    [
                        2,
                        2115000576
                    ]
                ]
            },
            "bert.encoder.layer.6.intermediate.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    8
                ],
                "t": 1,
                "mblock": [
                    1,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1004579392
                    ],
                    [
                        2,
                        2078321216
                    ],
                    [
                        3,
                        1004812352
                    ],
                    [
                        3,
                        2078554176
                    ],
                    [
                        4,
                        1004878912
                    ],
                    [
                        4,
                        2078620736
                    ],
                    [
                        5,
                        1004878912
                    ],
                    [
                        5,
                        2078620736
                    ]
                ]
            },
            "bert.encoder.layer.6.output.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    8
                ],
                "t": 1,
                "mblock": [
                    8,
                    1
                ],
                "ublock": [
                    8,
                    4
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1039661216
                    ],
                    [
                        1,
                        2113403040
                    ],
                    [
                        2,
                        1039661216
                    ],
                    [
                        2,
                        2113403040
                    ],
                    [
                        3,
                        1039860896
                    ],
                    [
                        3,
                        2113602720
                    ],
                    [
                        4,
                        1039860896
                    ],
                    [
                        4,
                        2113602720
                    ],
                    [
                        5,
                        1039860896
                    ],
                    [
                        5,
                        2113602720
                    ],
                    [
                        0,
                        770626688
                    ],
                    [
                        0,
                        2112803968
                    ],
                    [
                        1,
                        1039128704
                    ],
                    [
                        1,
                        2112870528
                    ],
                    [
                        2,
                        1039128704
                    ],
                    [
                        2,
                        2112870528
                    ]
                ]
            },
            "bert.encoder.layer.6.output.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    8
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    4
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        2077495424
                    ],
                    [
                        0,
                        734719072
                    ],
                    [
                        0,
                        2076896352
                    ],
                    [
                        1,
                        1003387488
                    ],
                    [
                        1,
                        2077129312
                    ],
                    [
                        2,
                        1003429088
                    ],
                    [
                        2,
                        2077170912
                    ],
                    [
                        3,
                        1003662048
                    ]
                ]
            },
            "bert.encoder.layer.6.output.LayerNorm.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        2079320064
                    ]
                ]
            },
            "bert.encoder.layer.6.output.LayerNorm.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1005578240
                    ]
                ]
            },
            "bert.encoder.layer.7.attention.self.query.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    2,
                    1
                ],
                "ublock": [
                    8,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1022354176
                    ],
                    [
                        2,
                        2096096000
                    ],
                    [
                        3,
                        1022553856
                    ],
                    [
                        3,
                        2096295680
                    ],
                    [
                        4,
                        1022553856
                    ],
                    [
                        4,
                        2096295680
                    ],
                    [
                        5,
                        1022553856
                    ],
                    [
                        5,
                        2096295680
                    ]
                ]
            },
            "bert.encoder.layer.7.attention.self.query.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1004020736
                    ],
                    [
                        4,
                        2077762560
                    ],
                    [
                        5,
                        1004020736
                    ],
                    [
                        5,
                        2077762560
                    ]
                ]
            },
            "bert.encoder.layer.7.attention.self.key.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    2,
                    1
                ],
                "ublock": [
                    8,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        2096029408
                    ],
                    [
                        0,
                        753186496
                    ],
                    [
                        0,
                        2095363776
                    ],
                    [
                        1,
                        1021821632
                    ],
                    [
                        1,
                        2095563456
                    ],
                    [
                        2,
                        1021821632
                    ],
                    [
                        2,
                        2095563456
                    ],
                    [
                        3,
                        1022021312
                    ]
                ]
            },
            "bert.encoder.layer.7.attention.self.key.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1004046336
                    ],
                    [
                        2,
                        2077788160
                    ],
                    [
                        3,
                        1004279296
                    ],
                    [
                        3,
                        2078021120
                    ]
                ]
            },
            "bert.encoder.layer.7.attention.self.value.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    2,
                    1
                ],
                "ublock": [
                    8,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        2095763136
                    ],
                    [
                        4,
                        1022021312
                    ],
                    [
                        4,
                        2095763136
                    ],
                    [
                        5,
                        1022021312
                    ],
                    [
                        5,
                        2095763136
                    ],
                    [
                        0,
                        752920224
                    ],
                    [
                        0,
                        2095097504
                    ],
                    [
                        1,
                        1021555360
                    ]
                ]
            },
            "bert.encoder.layer.7.attention.self.value.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1004070752
                    ],
                    [
                        4,
                        2077812576
                    ],
                    [
                        5,
                        1004070752
                    ],
                    [
                        5,
                        2077812576
                    ]
                ]
            },
            "bert.encoder.layer.7.attention.output.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    8,
                    1
                ],
                "ublock": [
                    2,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        2098159584
                    ],
                    [
                        4,
                        1024417760
                    ],
                    [
                        4,
                        2098159584
                    ],
                    [
                        5,
                        1024417760
                    ],
                    [
                        5,
                        2098159584
                    ],
                    [
                        0,
                        755316672
                    ],
                    [
                        0,
                        2097493952
                    ],
                    [
                        1,
                        1023951808
                    ]
                ]
            },
            "bert.encoder.layer.7.attention.output.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        735019552
                    ],
                    [
                        0,
                        2077196832
                    ],
                    [
                        1,
                        1003687968
                    ],
                    [
                        1,
                        2077429792
                    ]
                ]
            },
            "bert.encoder.layer.7.attention.output.LayerNorm.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        2079153728
                    ]
                ]
            },
            "bert.encoder.layer.7.attention.output.LayerNorm.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1005411904
                    ]
                ]
            },
            "bert.encoder.layer.7.intermediate.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    8
                ],
                "t": 1,
                "mblock": [
                    4,
                    2
                ],
                "ublock": [
                    4,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1043921312
                    ],
                    [
                        1,
                        2117663136
                    ],
                    [
                        2,
                        1043921312
                    ],
                    [
                        2,
                        2117663136
                    ],
                    [
                        3,
                        1044120992
                    ],
                    [
                        3,
                        2117862816
                    ],
                    [
                        4,
                        1044120992
                    ],
                    [
                        4,
                        2117862816
                    ],
                    [
                        5,
                        1044120992
                    ],
                    [
                        5,
                        2117862816
                    ],
                    [
                        0,
                        774886784
                    ],
                    [
                        0,
                        2117064064
                    ],
                    [
                        1,
                        1043388800
                    ],
                    [
                        1,
                        2117130624
                    ],
                    [
                        2,
                        1043388800
                    ],
                    [
                        2,
                        2117130624
                    ]
                ]
            },
            "bert.encoder.layer.7.intermediate.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    8
                ],
                "t": 1,
                "mblock": [
                    1,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1004679104
                    ],
                    [
                        3,
                        2078420928
                    ],
                    [
                        4,
                        1004745664
                    ],
                    [
                        4,
                        2078487488
                    ],
                    [
                        5,
                        1004745664
                    ],
                    [
                        5,
                        2078487488
                    ],
                    [
                        0,
                        735711136
                    ],
                    [
                        0,
                        2077888416
                    ]
                ]
            },
            "bert.encoder.layer.7.output.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    8
                ],
                "t": 1,
                "mblock": [
                    8,
                    1
                ],
                "ublock": [
                    8,
                    4
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1043588480
                    ],
                    [
                        3,
                        2117330304
                    ],
                    [
                        4,
                        1043588480
                    ],
                    [
                        4,
                        2117330304
                    ],
                    [
                        5,
                        1043588480
                    ],
                    [
                        5,
                        2117330304
                    ],
                    [
                        0,
                        774354272
                    ],
                    [
                        0,
                        2116531552
                    ],
                    [
                        1,
                        1042856288
                    ],
                    [
                        1,
                        2116598112
                    ],
                    [
                        2,
                        1042856288
                    ],
                    [
                        2,
                        2116598112
                    ],
                    [
                        3,
                        1043055968
                    ],
                    [
                        3,
                        2116797792
                    ],
                    [
                        4,
                        1043055968
                    ],
                    [
                        4,
                        2116797792
                    ]
                ]
            },
            "bert.encoder.layer.7.output.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    8
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    4
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        2077204480
                    ],
                    [
                        2,
                        1003504256
                    ],
                    [
                        2,
                        2077246080
                    ],
                    [
                        3,
                        1003737216
                    ],
                    [
                        3,
                        2077479040
                    ],
                    [
                        4,
                        1003820416
                    ],
                    [
                        4,
                        2077562240
                    ],
                    [
                        5,
                        1003820416
                    ]
                ]
            },
            "bert.encoder.layer.7.output.LayerNorm.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1005378496
                    ]
                ]
            },
            "bert.encoder.layer.7.output.LayerNorm.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        2079120320
                    ]
                ]
            },
            "bert.encoder.layer.8.attention.self.query.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    4,
                    2
                ],
                "t": 1,
                "mblock": [
                    2,
                    2
                ],
                "ublock": [
                    4,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        2099224672
                    ],
                    [
                        4,
                        1025482848
                    ],
                    [
                        4,
                        2099224672
                    ],
                    [
                        5,
                        1025482848
                    ],
                    [
                        5,
                        2099224672
                    ],
                    [
                        0,
                        756381760
                    ],
                    [
                        0,
                        2098559040
                    ],
                    [
                        1,
                        1025016896
                    ]
                ]
            },
            "bert.encoder.layer.8.attention.self.query.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    2
                ],
                "t": 1,
                "mblock": [
                    1,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        735844384
                    ],
                    [
                        0,
                        2078021664
                    ]
                ]
            },
            "bert.encoder.layer.8.attention.self.key.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    4,
                    2
                ],
                "t": 1,
                "mblock": [
                    2,
                    2
                ],
                "ublock": [
                    4,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1026281664
                    ],
                    [
                        5,
                        2100023488
                    ],
                    [
                        0,
                        757180576
                    ],
                    [
                        0,
                        2099357856
                    ],
                    [
                        1,
                        1025815712
                    ],
                    [
                        1,
                        2099557536
                    ],
                    [
                        2,
                        1025815712
                    ],
                    [
                        2,
                        2099557536
                    ]
                ]
            },
            "bert.encoder.layer.8.attention.self.key.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    2
                ],
                "t": 1,
                "mblock": [
                    1,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1005045472
                    ],
                    [
                        4,
                        2078787296
                    ]
                ]
            },
            "bert.encoder.layer.8.attention.self.value.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    2,
                    1
                ],
                "ublock": [
                    8,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        2086976160
                    ],
                    [
                        4,
                        1013234336
                    ],
                    [
                        4,
                        2086976160
                    ],
                    [
                        5,
                        1013234336
                    ],
                    [
                        5,
                        2086976160
                    ],
                    [
                        0,
                        744133248
                    ],
                    [
                        0,
                        2086310528
                    ],
                    [
                        1,
                        1012768384
                    ]
                ]
            },
            "bert.encoder.layer.8.attention.self.value.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        735102912
                    ],
                    [
                        0,
                        2077280192
                    ],
                    [
                        1,
                        1003771328
                    ],
                    [
                        1,
                        2077513152
                    ]
                ]
            },
            "bert.encoder.layer.8.attention.output.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    8,
                    1
                ],
                "ublock": [
                    2,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        2087508704
                    ],
                    [
                        4,
                        1013766880
                    ],
                    [
                        4,
                        2087508704
                    ],
                    [
                        5,
                        1013766880
                    ],
                    [
                        5,
                        2087508704
                    ],
                    [
                        0,
                        744665792
                    ],
                    [
                        0,
                        2086843072
                    ],
                    [
                        1,
                        1013300928
                    ]
                ]
            },
            "bert.encoder.layer.8.attention.output.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1004120768
                    ],
                    [
                        4,
                        2077862592
                    ],
                    [
                        5,
                        1004120768
                    ],
                    [
                        5,
                        2077862592
                    ]
                ]
            },
            "bert.encoder.layer.8.attention.output.LayerNorm.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1005012352
                    ]
                ]
            },
            "bert.encoder.layer.8.attention.output.LayerNorm.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        2078754176
                    ]
                ]
            },
            "bert.encoder.layer.8.intermediate.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    8
                ],
                "t": 1,
                "mblock": [
                    4,
                    2
                ],
                "ublock": [
                    4,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1047848576
                    ],
                    [
                        3,
                        2121590400
                    ],
                    [
                        4,
                        1047848576
                    ],
                    [
                        4,
                        2121590400
                    ],
                    [
                        5,
                        1047848576
                    ],
                    [
                        5,
                        2121590400
                    ],
                    [
                        0,
                        778614368
                    ],
                    [
                        0,
                        2120791648
                    ],
                    [
                        1,
                        1047116384
                    ],
                    [
                        1,
                        2120858208
                    ],
                    [
                        2,
                        1047116384
                    ],
                    [
                        2,
                        2120858208
                    ],
                    [
                        3,
                        1047316064
                    ],
                    [
                        3,
                        2121057888
                    ],
                    [
                        4,
                        1047316064
                    ],
                    [
                        4,
                        2121057888
                    ]
                ]
            },
            "bert.encoder.layer.8.intermediate.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    8
                ],
                "t": 1,
                "mblock": [
                    1,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1004379520
                    ],
                    [
                        2,
                        2078121344
                    ],
                    [
                        3,
                        1004612480
                    ],
                    [
                        3,
                        2078354304
                    ],
                    [
                        4,
                        1004679040
                    ],
                    [
                        4,
                        2078420864
                    ],
                    [
                        5,
                        1004679040
                    ],
                    [
                        5,
                        2078420864
                    ]
                ]
            },
            "bert.encoder.layer.8.output.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    8
                ],
                "t": 1,
                "mblock": [
                    8,
                    1
                ],
                "ublock": [
                    8,
                    4
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1065221792
                    ],
                    [
                        1,
                        2138963616
                    ],
                    [
                        2,
                        1065221792
                    ],
                    [
                        2,
                        2138963616
                    ],
                    [
                        3,
                        1065421472
                    ],
                    [
                        3,
                        2139163296
                    ],
                    [
                        4,
                        1065421472
                    ],
                    [
                        4,
                        2139163296
                    ],
                    [
                        5,
                        1065421472
                    ],
                    [
                        5,
                        2139163296
                    ],
                    [
                        0,
                        796187264
                    ],
                    [
                        0,
                        2138364544
                    ],
                    [
                        1,
                        1064689280
                    ],
                    [
                        1,
                        2138431104
                    ],
                    [
                        2,
                        1064689280
                    ],
                    [
                        2,
                        2138431104
                    ]
                ]
            },
            "bert.encoder.layer.8.output.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    8
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    4
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        2077021632
                    ],
                    [
                        1,
                        1003512768
                    ],
                    [
                        1,
                        2077254592
                    ],
                    [
                        2,
                        1003554368
                    ],
                    [
                        2,
                        2077296192
                    ],
                    [
                        3,
                        1003787328
                    ],
                    [
                        3,
                        2077529152
                    ],
                    [
                        4,
                        1003870528
                    ]
                ]
            },
            "bert.encoder.layer.8.output.LayerNorm.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        2079186880
                    ]
                ]
            },
            "bert.encoder.layer.8.output.LayerNorm.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1005445056
                    ]
                ]
            },
            "bert.encoder.layer.9.attention.self.query.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    2,
                    1
                ],
                "ublock": [
                    8,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1014898560
                    ],
                    [
                        1,
                        2088640384
                    ],
                    [
                        2,
                        1014898560
                    ],
                    [
                        2,
                        2088640384
                    ],
                    [
                        3,
                        1015098240
                    ],
                    [
                        3,
                        2088840064
                    ],
                    [
                        4,
                        1015098240
                    ],
                    [
                        4,
                        2088840064
                    ]
                ]
            },
            "bert.encoder.layer.9.attention.self.query.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        735186272
                    ],
                    [
                        0,
                        2077363552
                    ],
                    [
                        1,
                        1003854688
                    ],
                    [
                        1,
                        2077596512
                    ]
                ]
            },
            "bert.encoder.layer.9.attention.self.key.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    2,
                    1
                ],
                "ublock": [
                    8,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        2098425856
                    ],
                    [
                        0,
                        755582944
                    ],
                    [
                        0,
                        2097760224
                    ],
                    [
                        1,
                        1024218080
                    ],
                    [
                        1,
                        2097959904
                    ],
                    [
                        2,
                        1024218080
                    ],
                    [
                        2,
                        2097959904
                    ],
                    [
                        3,
                        1024417760
                    ]
                ]
            },
            "bert.encoder.layer.9.attention.self.key.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1003846272
                    ],
                    [
                        2,
                        2077588096
                    ],
                    [
                        3,
                        1004079232
                    ],
                    [
                        3,
                        2077821056
                    ]
                ]
            },
            "bert.encoder.layer.9.attention.self.value.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    2,
                    1
                ],
                "ublock": [
                    8,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        2092035328
                    ],
                    [
                        5,
                        1018293504
                    ],
                    [
                        5,
                        2092035328
                    ],
                    [
                        0,
                        749192416
                    ],
                    [
                        0,
                        2091369696
                    ],
                    [
                        1,
                        1017827552
                    ],
                    [
                        1,
                        2091569376
                    ],
                    [
                        2,
                        1017827552
                    ]
                ]
            },
            "bert.encoder.layer.9.attention.self.value.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        735152928
                    ],
                    [
                        0,
                        2077330208
                    ],
                    [
                        1,
                        1003821344
                    ],
                    [
                        1,
                        2077563168
                    ]
                ]
            },
            "bert.encoder.layer.9.attention.output.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    8,
                    1
                ],
                "ublock": [
                    2,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        2091569376
                    ],
                    [
                        3,
                        1018027232
                    ],
                    [
                        3,
                        2091769056
                    ],
                    [
                        4,
                        1018027232
                    ],
                    [
                        4,
                        2091769056
                    ],
                    [
                        5,
                        1018027232
                    ],
                    [
                        5,
                        2091769056
                    ],
                    [
                        0,
                        748926144
                    ]
                ]
            },
            "bert.encoder.layer.9.attention.output.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        735169600
                    ],
                    [
                        0,
                        2077346880
                    ],
                    [
                        1,
                        1003838016
                    ],
                    [
                        1,
                        2077579840
                    ]
                ]
            },
            "bert.encoder.layer.9.attention.output.LayerNorm.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1005578240
                    ]
                ]
            },
            "bert.encoder.layer.9.attention.output.LayerNorm.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        736543712
                    ]
                ]
            },
            "bert.encoder.layer.9.intermediate.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    8
                ],
                "t": 1,
                "mblock": [
                    4,
                    2
                ],
                "ublock": [
                    4,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1060096352
                    ],
                    [
                        5,
                        2133838176
                    ],
                    [
                        0,
                        790862144
                    ],
                    [
                        0,
                        2133039424
                    ],
                    [
                        1,
                        1059364160
                    ],
                    [
                        1,
                        2133105984
                    ],
                    [
                        2,
                        1059364160
                    ],
                    [
                        2,
                        2133105984
                    ],
                    [
                        3,
                        1059563840
                    ],
                    [
                        3,
                        2133305664
                    ],
                    [
                        4,
                        1059563840
                    ],
                    [
                        4,
                        2133305664
                    ],
                    [
                        5,
                        1059563840
                    ],
                    [
                        5,
                        2133305664
                    ],
                    [
                        0,
                        790329632
                    ],
                    [
                        0,
                        2132506912
                    ]
                ]
            },
            "bert.encoder.layer.9.intermediate.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    8
                ],
                "t": 1,
                "mblock": [
                    1,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1004479168
                    ],
                    [
                        5,
                        2078220992
                    ],
                    [
                        0,
                        735444640
                    ],
                    [
                        0,
                        2077621920
                    ],
                    [
                        1,
                        1004113056
                    ],
                    [
                        1,
                        2077854880
                    ],
                    [
                        2,
                        1004146336
                    ],
                    [
                        2,
                        2077888160
                    ]
                ]
            },
            "bert.encoder.layer.9.output.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    8
                ],
                "t": 1,
                "mblock": [
                    8,
                    1
                ],
                "ublock": [
                    8,
                    4
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1062226400
                    ],
                    [
                        5,
                        2135968224
                    ],
                    [
                        0,
                        792992192
                    ],
                    [
                        0,
                        2135169472
                    ],
                    [
                        1,
                        1061494208
                    ],
                    [
                        1,
                        2135236032
                    ],
                    [
                        2,
                        1061494208
                    ],
                    [
                        2,
                        2135236032
                    ],
                    [
                        3,
                        1061693888
                    ],
                    [
                        3,
                        2135435712
                    ],
                    [
                        4,
                        1061693888
                    ],
                    [
                        4,
                        2135435712
                    ],
                    [
                        5,
                        1061693888
                    ],
                    [
                        5,
                        2135435712
                    ],
                    [
                        0,
                        792459680
                    ],
                    [
                        0,
                        2134636960
                    ]
                ]
            },
            "bert.encoder.layer.9.output.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    8
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    4
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        2077212672
                    ],
                    [
                        3,
                        1003703808
                    ],
                    [
                        3,
                        2077445632
                    ],
                    [
                        4,
                        1003787008
                    ],
                    [
                        4,
                        2077528832
                    ],
                    [
                        5,
                        1003787008
                    ],
                    [
                        5,
                        2077528832
                    ],
                    [
                        0,
                        734752480
                    ]
                ]
            },
            "bert.encoder.layer.9.output.LayerNorm.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        2078554400
                    ]
                ]
            },
            "bert.encoder.layer.9.output.LayerNorm.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        2078321440
                    ]
                ]
            },
            "bert.encoder.layer.10.attention.self.query.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    4,
                    2
                ],
                "t": 1,
                "mblock": [
                    2,
                    2
                ],
                "ublock": [
                    4,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        2100622624
                    ],
                    [
                        2,
                        1026880800
                    ],
                    [
                        2,
                        2100622624
                    ],
                    [
                        3,
                        1027080480
                    ],
                    [
                        3,
                        2100822304
                    ],
                    [
                        4,
                        1027080480
                    ],
                    [
                        4,
                        2100822304
                    ],
                    [
                        5,
                        1027080480
                    ]
                ]
            },
            "bert.encoder.layer.10.attention.self.query.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    2
                ],
                "t": 1,
                "mblock": [
                    1,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1004579168
                    ],
                    [
                        3,
                        2078320992
                    ]
                ]
            },
            "bert.encoder.layer.10.attention.self.key.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    4,
                    2
                ],
                "t": 1,
                "mblock": [
                    2,
                    2
                ],
                "ublock": [
                    4,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        2100090080
                    ],
                    [
                        2,
                        1026348256
                    ],
                    [
                        2,
                        2100090080
                    ],
                    [
                        3,
                        1026547936
                    ],
                    [
                        3,
                        2100289760
                    ],
                    [
                        4,
                        1026547936
                    ],
                    [
                        4,
                        2100289760
                    ],
                    [
                        5,
                        1026547936
                    ]
                ]
            },
            "bert.encoder.layer.10.attention.self.key.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    2
                ],
                "t": 1,
                "mblock": [
                    1,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1004645728
                    ],
                    [
                        4,
                        2078387552
                    ]
                ]
            },
            "bert.encoder.layer.10.attention.self.value.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    2,
                    1
                ],
                "ublock": [
                    8,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        2097693632
                    ],
                    [
                        2,
                        1023951808
                    ],
                    [
                        2,
                        2097693632
                    ],
                    [
                        3,
                        1024151488
                    ],
                    [
                        3,
                        2097893312
                    ],
                    [
                        4,
                        1024151488
                    ],
                    [
                        4,
                        2097893312
                    ],
                    [
                        5,
                        1024151488
                    ]
                ]
            },
            "bert.encoder.layer.10.attention.self.value.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        735236288
                    ],
                    [
                        0,
                        2077413568
                    ],
                    [
                        1,
                        1003904704
                    ],
                    [
                        1,
                        2077646528
                    ]
                ]
            },
            "bert.encoder.layer.10.attention.output.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    8,
                    1
                ],
                "ublock": [
                    2,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        2097893312
                    ],
                    [
                        0,
                        755050400
                    ],
                    [
                        0,
                        2097227680
                    ],
                    [
                        1,
                        1023685536
                    ],
                    [
                        1,
                        2097427360
                    ],
                    [
                        2,
                        1023685536
                    ],
                    [
                        2,
                        2097427360
                    ],
                    [
                        3,
                        1023885216
                    ]
                ]
            },
            "bert.encoder.layer.10.attention.output.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        735269632
                    ],
                    [
                        0,
                        2077446912
                    ],
                    [
                        1,
                        1003938048
                    ],
                    [
                        1,
                        2077679872
                    ]
                ]
            },
            "bert.encoder.layer.10.attention.output.LayerNorm.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1005245312
                    ]
                ]
            },
            "bert.encoder.layer.10.attention.output.LayerNorm.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        2080019424
                    ]
                ]
            },
            "bert.encoder.layer.10.intermediate.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    8
                ],
                "t": 1,
                "mblock": [
                    4,
                    2
                ],
                "ublock": [
                    4,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1048181408
                    ],
                    [
                        1,
                        2121923232
                    ],
                    [
                        2,
                        1048181408
                    ],
                    [
                        2,
                        2121923232
                    ],
                    [
                        3,
                        1048381088
                    ],
                    [
                        3,
                        2122122912
                    ],
                    [
                        4,
                        1048381088
                    ],
                    [
                        4,
                        2122122912
                    ],
                    [
                        5,
                        1048381088
                    ],
                    [
                        5,
                        2122122912
                    ],
                    [
                        0,
                        779146880
                    ],
                    [
                        0,
                        2121324160
                    ],
                    [
                        1,
                        1047648896
                    ],
                    [
                        1,
                        2121390720
                    ],
                    [
                        2,
                        1047648896
                    ],
                    [
                        2,
                        2121390720
                    ]
                ]
            },
            "bert.encoder.layer.10.intermediate.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    8
                ],
                "t": 1,
                "mblock": [
                    1,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1004146368
                    ],
                    [
                        1,
                        2077888192
                    ],
                    [
                        2,
                        1004179648
                    ],
                    [
                        2,
                        2077921472
                    ],
                    [
                        3,
                        1004412608
                    ],
                    [
                        3,
                        2078154432
                    ],
                    [
                        4,
                        1004479168
                    ],
                    [
                        4,
                        2078220992
                    ]
                ]
            },
            "bert.encoder.layer.10.output.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    8
                ],
                "t": 1,
                "mblock": [
                    8,
                    1
                ],
                "ublock": [
                    8,
                    4
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1032405728
                    ],
                    [
                        5,
                        2106147552
                    ],
                    [
                        0,
                        763171520
                    ],
                    [
                        0,
                        2105348800
                    ],
                    [
                        1,
                        1031673536
                    ],
                    [
                        1,
                        2105415360
                    ],
                    [
                        2,
                        1031673536
                    ],
                    [
                        2,
                        2105415360
                    ],
                    [
                        3,
                        1031873216
                    ],
                    [
                        3,
                        2105615040
                    ],
                    [
                        4,
                        1031873216
                    ],
                    [
                        4,
                        2105615040
                    ],
                    [
                        5,
                        1031873216
                    ],
                    [
                        5,
                        2105615040
                    ],
                    [
                        0,
                        762639008
                    ],
                    [
                        0,
                        2104816288
                    ]
                ]
            },
            "bert.encoder.layer.10.output.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    8
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    4
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        2077120960
                    ],
                    [
                        2,
                        1003420736
                    ],
                    [
                        2,
                        2077162560
                    ],
                    [
                        3,
                        1003653696
                    ],
                    [
                        3,
                        2077395520
                    ],
                    [
                        4,
                        1003736896
                    ],
                    [
                        4,
                        2077478720
                    ],
                    [
                        5,
                        1003736896
                    ]
                ]
            },
            "bert.encoder.layer.10.output.LayerNorm.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        2079719872
                    ]
                ]
            },
            "bert.encoder.layer.10.output.LayerNorm.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1006211008
                    ]
                ]
            },
            "bert.encoder.layer.11.attention.self.query.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    2,
                    1
                ],
                "ublock": [
                    8,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        2096828224
                    ],
                    [
                        5,
                        1023086400
                    ],
                    [
                        5,
                        2096828224
                    ],
                    [
                        0,
                        753985312
                    ],
                    [
                        0,
                        2096162592
                    ],
                    [
                        1,
                        1022620448
                    ],
                    [
                        1,
                        2096362272
                    ],
                    [
                        2,
                        1022620448
                    ]
                ]
            },
            "bert.encoder.layer.11.attention.self.query.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1003946304
                    ],
                    [
                        2,
                        2077688128
                    ],
                    [
                        3,
                        1004179264
                    ],
                    [
                        3,
                        2077921088
                    ]
                ]
            },
            "bert.encoder.layer.11.attention.self.key.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    2,
                    1
                ],
                "ublock": [
                    8,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        2094032416
                    ],
                    [
                        1,
                        1020490272
                    ],
                    [
                        1,
                        2094232096
                    ],
                    [
                        2,
                        1020490272
                    ],
                    [
                        2,
                        2094232096
                    ],
                    [
                        3,
                        1020689952
                    ],
                    [
                        3,
                        2094431776
                    ],
                    [
                        4,
                        1020689952
                    ]
                ]
            },
            "bert.encoder.layer.11.attention.self.key.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        735219616
                    ],
                    [
                        0,
                        2077396896
                    ],
                    [
                        1,
                        1003888032
                    ],
                    [
                        1,
                        2077629856
                    ]
                ]
            },
            "bert.encoder.layer.11.attention.self.value.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    2,
                    1
                ],
                "ublock": [
                    8,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1026081984
                    ],
                    [
                        1,
                        2099823808
                    ],
                    [
                        2,
                        1026081984
                    ],
                    [
                        2,
                        2099823808
                    ],
                    [
                        3,
                        1026281664
                    ],
                    [
                        3,
                        2100023488
                    ],
                    [
                        4,
                        1026281664
                    ],
                    [
                        4,
                        2100023488
                    ]
                ]
            },
            "bert.encoder.layer.11.attention.self.value.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1004220800
                    ],
                    [
                        4,
                        2077962624
                    ],
                    [
                        5,
                        1004220800
                    ],
                    [
                        5,
                        2077962624
                    ]
                ]
            },
            "bert.encoder.layer.11.attention.output.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    8,
                    1
                ],
                "ublock": [
                    2,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        2085644800
                    ],
                    [
                        5,
                        1011902976
                    ],
                    [
                        5,
                        2085644800
                    ],
                    [
                        0,
                        742801888
                    ],
                    [
                        0,
                        2084979168
                    ],
                    [
                        1,
                        1011437024
                    ],
                    [
                        1,
                        2085178848
                    ],
                    [
                        2,
                        1011437024
                    ]
                ]
            },
            "bert.encoder.layer.11.attention.output.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1004270816
                    ],
                    [
                        4,
                        2078012640
                    ],
                    [
                        5,
                        1004270816
                    ],
                    [
                        5,
                        2078012640
                    ]
                ]
            },
            "bert.encoder.layer.11.attention.output.LayerNorm.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1006443936
                    ]
                ]
            },
            "bert.encoder.layer.11.attention.output.LayerNorm.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        2079819648
                    ]
                ]
            },
            "bert.encoder.layer.11.intermediate.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    8
                ],
                "t": 1,
                "mblock": [
                    4,
                    2
                ],
                "ublock": [
                    4,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1064888960
                    ],
                    [
                        3,
                        2138630784
                    ],
                    [
                        4,
                        1064888960
                    ],
                    [
                        4,
                        2138630784
                    ],
                    [
                        5,
                        1064888960
                    ],
                    [
                        5,
                        2138630784
                    ],
                    [
                        0,
                        795654752
                    ],
                    [
                        0,
                        2137832032
                    ],
                    [
                        1,
                        1064156768
                    ],
                    [
                        1,
                        2137898592
                    ],
                    [
                        2,
                        1064156768
                    ],
                    [
                        2,
                        2137898592
                    ],
                    [
                        3,
                        1064356448
                    ],
                    [
                        3,
                        2138098272
                    ],
                    [
                        4,
                        1064356448
                    ],
                    [
                        4,
                        2138098272
                    ]
                ]
            },
            "bert.encoder.layer.11.intermediate.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    8
                ],
                "t": 1,
                "mblock": [
                    1,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1004445856
                    ],
                    [
                        4,
                        2078187680
                    ],
                    [
                        5,
                        1004445856
                    ],
                    [
                        5,
                        2078187680
                    ],
                    [
                        0,
                        735411328
                    ],
                    [
                        0,
                        2077588608
                    ],
                    [
                        1,
                        1004079744
                    ],
                    [
                        1,
                        2077821568
                    ]
                ]
            },
            "bert.encoder.layer.11.output.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    8
                ],
                "t": 1,
                "mblock": [
                    8,
                    1
                ],
                "ublock": [
                    8,
                    4
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1060628864
                    ],
                    [
                        3,
                        2134370688
                    ],
                    [
                        4,
                        1060628864
                    ],
                    [
                        4,
                        2134370688
                    ],
                    [
                        5,
                        1060628864
                    ],
                    [
                        5,
                        2134370688
                    ],
                    [
                        0,
                        791394656
                    ],
                    [
                        0,
                        2133571936
                    ],
                    [
                        1,
                        1059896672
                    ],
                    [
                        1,
                        2133638496
                    ],
                    [
                        2,
                        1059896672
                    ],
                    [
                        2,
                        2133638496
                    ],
                    [
                        3,
                        1060096352
                    ],
                    [
                        3,
                        2133838176
                    ],
                    [
                        4,
                        1060096352
                    ],
                    [
                        4,
                        2133838176
                    ]
                ]
            },
            "bert.encoder.layer.11.output.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    8
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    4
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1003712160
                    ],
                    [
                        3,
                        2077453984
                    ],
                    [
                        4,
                        1003795360
                    ],
                    [
                        4,
                        2077537184
                    ],
                    [
                        5,
                        1003795360
                    ],
                    [
                        5,
                        2077537184
                    ],
                    [
                        0,
                        734760832
                    ],
                    [
                        0,
                        2076938112
                    ]
                ]
            },
            "bert.encoder.layer.11.output.LayerNorm.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1006510560
                    ]
                ]
            },
            "bert.encoder.layer.11.output.LayerNorm.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1006710336
                    ]
                ]
            },
            "bert.encoder.layer.12.attention.self.query.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    4,
                    2
                ],
                "t": 1,
                "mblock": [
                    2,
                    2
                ],
                "ublock": [
                    4,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1010039072
                    ],
                    [
                        4,
                        2083780896
                    ],
                    [
                        5,
                        1010039072
                    ],
                    [
                        5,
                        2083780896
                    ],
                    [
                        0,
                        740937984
                    ],
                    [
                        0,
                        2083115264
                    ],
                    [
                        1,
                        1009573120
                    ],
                    [
                        1,
                        2083314944
                    ]
                ]
            },
            "bert.encoder.layer.12.attention.self.query.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    2
                ],
                "t": 1,
                "mblock": [
                    1,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1004645728
                    ],
                    [
                        5,
                        2078387552
                    ]
                ]
            },
            "bert.encoder.layer.12.attention.self.key.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    4,
                    2
                ],
                "t": 1,
                "mblock": [
                    2,
                    2
                ],
                "ublock": [
                    4,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        2084180352
                    ],
                    [
                        1,
                        1010638208
                    ],
                    [
                        1,
                        2084380032
                    ],
                    [
                        2,
                        1010638208
                    ],
                    [
                        2,
                        2084380032
                    ],
                    [
                        3,
                        1010837888
                    ],
                    [
                        3,
                        2084579712
                    ],
                    [
                        4,
                        1010837888
                    ]
                ]
            },
            "bert.encoder.layer.12.attention.self.key.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    2
                ],
                "t": 1,
                "mblock": [
                    1,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        735644512
                    ],
                    [
                        0,
                        2077821792
                    ]
                ]
            },
            "bert.encoder.layer.12.attention.self.value.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    2,
                    1
                ],
                "ublock": [
                    8,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1016163328
                    ],
                    [
                        5,
                        2089905152
                    ],
                    [
                        0,
                        747062240
                    ],
                    [
                        0,
                        2089239520
                    ],
                    [
                        1,
                        1015697376
                    ],
                    [
                        1,
                        2089439200
                    ],
                    [
                        2,
                        1015697376
                    ],
                    [
                        2,
                        2089439200
                    ]
                ]
            },
            "bert.encoder.layer.12.attention.self.value.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1004170784
                    ],
                    [
                        4,
                        2077912608
                    ],
                    [
                        5,
                        1004170784
                    ],
                    [
                        5,
                        2077912608
                    ]
                ]
            },
            "bert.encoder.layer.12.attention.output.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    8,
                    1
                ],
                "ublock": [
                    2,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1015431104
                    ],
                    [
                        1,
                        2089172928
                    ],
                    [
                        2,
                        1015431104
                    ],
                    [
                        2,
                        2089172928
                    ],
                    [
                        3,
                        1015630784
                    ],
                    [
                        3,
                        2089372608
                    ],
                    [
                        4,
                        1015630784
                    ],
                    [
                        4,
                        2089372608
                    ]
                ]
            },
            "bert.encoder.layer.12.attention.output.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        735136256
                    ],
                    [
                        0,
                        2077313536
                    ],
                    [
                        1,
                        1003804672
                    ],
                    [
                        1,
                        2077546496
                    ]
                ]
            },
            "bert.encoder.layer.12.attention.output.LayerNorm.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        2079719648
                    ]
                ]
            },
            "bert.encoder.layer.12.attention.output.LayerNorm.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        2079786208
                    ]
                ]
            },
            "bert.encoder.layer.12.intermediate.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    8
                ],
                "t": 1,
                "mblock": [
                    4,
                    2
                ],
                "ublock": [
                    4,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1058831648
                    ],
                    [
                        1,
                        2132573472
                    ],
                    [
                        2,
                        1058831648
                    ],
                    [
                        2,
                        2132573472
                    ],
                    [
                        3,
                        1059031328
                    ],
                    [
                        3,
                        2132773152
                    ],
                    [
                        4,
                        1059031328
                    ],
                    [
                        4,
                        2132773152
                    ],
                    [
                        5,
                        1059031328
                    ],
                    [
                        5,
                        2132773152
                    ],
                    [
                        0,
                        789797120
                    ],
                    [
                        0,
                        2131974400
                    ],
                    [
                        1,
                        1058299136
                    ],
                    [
                        1,
                        2132040960
                    ],
                    [
                        2,
                        1058299136
                    ],
                    [
                        2,
                        2132040960
                    ]
                ]
            },
            "bert.encoder.layer.12.intermediate.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    8
                ],
                "t": 1,
                "mblock": [
                    1,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1004279616
                    ],
                    [
                        1,
                        2078021440
                    ],
                    [
                        2,
                        1004312896
                    ],
                    [
                        2,
                        2078054720
                    ],
                    [
                        3,
                        1004545856
                    ],
                    [
                        3,
                        2078287680
                    ],
                    [
                        4,
                        1004612416
                    ],
                    [
                        4,
                        2078354240
                    ]
                ]
            },
            "bert.encoder.layer.12.output.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    8
                ],
                "t": 1,
                "mblock": [
                    8,
                    1
                ],
                "ublock": [
                    8,
                    4
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1049446112
                    ],
                    [
                        5,
                        2123187936
                    ],
                    [
                        0,
                        780211904
                    ],
                    [
                        0,
                        2122389184
                    ],
                    [
                        1,
                        1048713920
                    ],
                    [
                        1,
                        2122455744
                    ],
                    [
                        2,
                        1048713920
                    ],
                    [
                        2,
                        2122455744
                    ],
                    [
                        3,
                        1048913600
                    ],
                    [
                        3,
                        2122655424
                    ],
                    [
                        4,
                        1048913600
                    ],
                    [
                        4,
                        2122655424
                    ],
                    [
                        5,
                        1048913600
                    ],
                    [
                        5,
                        2122655424
                    ],
                    [
                        0,
                        779679392
                    ],
                    [
                        0,
                        2121856672
                    ]
                ]
            },
            "bert.encoder.layer.12.output.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    8
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    4
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1003812064
                    ],
                    [
                        4,
                        2077553888
                    ],
                    [
                        5,
                        1003812064
                    ],
                    [
                        5,
                        2077553888
                    ],
                    [
                        0,
                        734777536
                    ],
                    [
                        0,
                        2076954816
                    ],
                    [
                        1,
                        1003445952
                    ],
                    [
                        1,
                        2077187776
                    ]
                ]
            },
            "bert.encoder.layer.12.output.LayerNorm.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        737009856
                    ]
                ]
            },
            "bert.encoder.layer.12.output.LayerNorm.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1005611680
                    ]
                ]
            },
            "bert.encoder.layer.13.attention.self.query.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    2,
                    1
                ],
                "ublock": [
                    8,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        2084579712
                    ],
                    [
                        5,
                        1010837888
                    ],
                    [
                        5,
                        2084579712
                    ],
                    [
                        0,
                        741736800
                    ],
                    [
                        0,
                        2083914080
                    ],
                    [
                        1,
                        1010371936
                    ],
                    [
                        1,
                        2084113760
                    ],
                    [
                        2,
                        1010371936
                    ]
                ]
            },
            "bert.encoder.layer.13.attention.self.query.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1003829600
                    ],
                    [
                        2,
                        2077571424
                    ],
                    [
                        3,
                        1004062560
                    ],
                    [
                        3,
                        2077804384
                    ]
                ]
            },
            "bert.encoder.layer.13.attention.self.key.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    2,
                    1
                ],
                "ublock": [
                    8,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        741204256
                    ],
                    [
                        0,
                        2083381536
                    ],
                    [
                        1,
                        1009839392
                    ],
                    [
                        1,
                        2083581216
                    ],
                    [
                        2,
                        1009839392
                    ],
                    [
                        2,
                        2083581216
                    ],
                    [
                        3,
                        1010039072
                    ],
                    [
                        3,
                        2083780896
                    ]
                ]
            },
            "bert.encoder.layer.13.attention.self.key.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1004087424
                    ],
                    [
                        4,
                        2077829248
                    ],
                    [
                        5,
                        1004087424
                    ],
                    [
                        5,
                        2077829248
                    ]
                ]
            },
            "bert.encoder.layer.13.attention.self.value.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    2,
                    1
                ],
                "ublock": [
                    8,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1009040576
                    ],
                    [
                        2,
                        2082782400
                    ],
                    [
                        3,
                        1009240256
                    ],
                    [
                        3,
                        2082982080
                    ],
                    [
                        4,
                        1009240256
                    ],
                    [
                        4,
                        2082982080
                    ],
                    [
                        5,
                        1009240256
                    ],
                    [
                        5,
                        2082982080
                    ]
                ]
            },
            "bert.encoder.layer.13.attention.self.value.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        735086240
                    ],
                    [
                        0,
                        2077263520
                    ],
                    [
                        1,
                        1003754656
                    ],
                    [
                        1,
                        2077496480
                    ]
                ]
            },
            "bert.encoder.layer.13.attention.output.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    8,
                    1
                ],
                "ublock": [
                    2,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        2087774976
                    ],
                    [
                        0,
                        744932064
                    ],
                    [
                        0,
                        2087109344
                    ],
                    [
                        1,
                        1013567200
                    ],
                    [
                        1,
                        2087309024
                    ],
                    [
                        2,
                        1013567200
                    ],
                    [
                        2,
                        2087309024
                    ],
                    [
                        3,
                        1013766880
                    ]
                ]
            },
            "bert.encoder.layer.13.attention.output.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1003812928
                    ],
                    [
                        2,
                        2077554752
                    ],
                    [
                        3,
                        1004045888
                    ],
                    [
                        3,
                        2077787712
                    ]
                ]
            },
            "bert.encoder.layer.13.attention.output.LayerNorm.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        2080119168
                    ]
                ]
            },
            "bert.encoder.layer.13.attention.output.LayerNorm.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        737342816
                    ]
                ]
            },
            "bert.encoder.layer.13.intermediate.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    8
                ],
                "t": 1,
                "mblock": [
                    4,
                    2
                ],
                "ublock": [
                    4,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1046051360
                    ],
                    [
                        1,
                        2119793184
                    ],
                    [
                        2,
                        1046051360
                    ],
                    [
                        2,
                        2119793184
                    ],
                    [
                        3,
                        1046251040
                    ],
                    [
                        3,
                        2119992864
                    ],
                    [
                        4,
                        1046251040
                    ],
                    [
                        4,
                        2119992864
                    ],
                    [
                        5,
                        1046251040
                    ],
                    [
                        5,
                        2119992864
                    ],
                    [
                        0,
                        777016832
                    ],
                    [
                        0,
                        2119194112
                    ],
                    [
                        1,
                        1045518848
                    ],
                    [
                        1,
                        2119260672
                    ],
                    [
                        2,
                        1045518848
                    ],
                    [
                        2,
                        2119260672
                    ]
                ]
            },
            "bert.encoder.layer.13.intermediate.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    8
                ],
                "t": 1,
                "mblock": [
                    1,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1005045472
                    ],
                    [
                        5,
                        2078787296
                    ],
                    [
                        0,
                        736010944
                    ],
                    [
                        0,
                        2078188224
                    ],
                    [
                        1,
                        1004679360
                    ],
                    [
                        1,
                        2078421184
                    ],
                    [
                        2,
                        1004712640
                    ],
                    [
                        2,
                        2078454464
                    ]
                ]
            },
            "bert.encoder.layer.13.output.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    8
                ],
                "t": 1,
                "mblock": [
                    8,
                    1
                ],
                "ublock": [
                    8,
                    4
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1032938240
                    ],
                    [
                        3,
                        2106680064
                    ],
                    [
                        4,
                        1032938240
                    ],
                    [
                        4,
                        2106680064
                    ],
                    [
                        5,
                        1032938240
                    ],
                    [
                        5,
                        2106680064
                    ],
                    [
                        0,
                        763704032
                    ],
                    [
                        0,
                        2105881312
                    ],
                    [
                        1,
                        1032206048
                    ],
                    [
                        1,
                        2105947872
                    ],
                    [
                        2,
                        1032206048
                    ],
                    [
                        2,
                        2105947872
                    ],
                    [
                        3,
                        1032405728
                    ],
                    [
                        3,
                        2106147552
                    ],
                    [
                        4,
                        1032405728
                    ],
                    [
                        4,
                        2106147552
                    ]
                ]
            },
            "bert.encoder.layer.13.output.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    8
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    4
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1003479360
                    ],
                    [
                        1,
                        2077221184
                    ],
                    [
                        2,
                        1003520960
                    ],
                    [
                        2,
                        2077262784
                    ],
                    [
                        3,
                        1003753920
                    ],
                    [
                        3,
                        2077495744
                    ],
                    [
                        4,
                        1003837120
                    ],
                    [
                        4,
                        2077578944
                    ]
                ]
            },
            "bert.encoder.layer.13.output.LayerNorm.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1005944640
                    ]
                ]
            },
            "bert.encoder.layer.13.output.LayerNorm.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        2079686464
                    ]
                ]
            },
            "bert.encoder.layer.14.attention.self.query.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    4,
                    2
                ],
                "t": 1,
                "mblock": [
                    2,
                    2
                ],
                "ublock": [
                    4,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        2101354848
                    ],
                    [
                        0,
                        758511936
                    ],
                    [
                        0,
                        2100689216
                    ],
                    [
                        1,
                        1027147072
                    ],
                    [
                        1,
                        2100888896
                    ],
                    [
                        2,
                        1027147072
                    ],
                    [
                        2,
                        2100888896
                    ],
                    [
                        3,
                        1027346752
                    ]
                ]
            },
            "bert.encoder.layer.14.attention.self.query.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    2
                ],
                "t": 1,
                "mblock": [
                    1,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1004346240
                    ],
                    [
                        1,
                        2078088064
                    ]
                ]
            },
            "bert.encoder.layer.14.attention.self.key.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    4,
                    2
                ],
                "t": 1,
                "mblock": [
                    2,
                    2
                ],
                "ublock": [
                    4,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        2101088576
                    ],
                    [
                        4,
                        1027346752
                    ],
                    [
                        4,
                        2101088576
                    ],
                    [
                        5,
                        1027346752
                    ],
                    [
                        5,
                        2101088576
                    ],
                    [
                        0,
                        758245664
                    ],
                    [
                        0,
                        2100422944
                    ],
                    [
                        1,
                        1026880800
                    ]
                ]
            },
            "bert.encoder.layer.14.attention.self.key.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    2
                ],
                "t": 1,
                "mblock": [
                    1,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1004779264
                    ],
                    [
                        2,
                        2078521088
                    ]
                ]
            },
            "bert.encoder.layer.14.attention.self.value.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    2,
                    1
                ],
                "ublock": [
                    8,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1019891136
                    ],
                    [
                        4,
                        2093632960
                    ],
                    [
                        5,
                        1019891136
                    ],
                    [
                        5,
                        2093632960
                    ],
                    [
                        0,
                        750790048
                    ],
                    [
                        0,
                        2092967328
                    ],
                    [
                        1,
                        1019425184
                    ],
                    [
                        1,
                        2093167008
                    ]
                ]
            },
            "bert.encoder.layer.14.attention.self.value.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1004204128
                    ],
                    [
                        4,
                        2077945952
                    ],
                    [
                        5,
                        1004204128
                    ],
                    [
                        5,
                        2077945952
                    ]
                ]
            },
            "bert.encoder.layer.14.attention.output.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    8,
                    1
                ],
                "ublock": [
                    2,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1019425184
                    ],
                    [
                        2,
                        2093167008
                    ],
                    [
                        3,
                        1019624864
                    ],
                    [
                        3,
                        2093366688
                    ],
                    [
                        4,
                        1019624864
                    ],
                    [
                        4,
                        2093366688
                    ],
                    [
                        5,
                        1019624864
                    ],
                    [
                        5,
                        2093366688
                    ]
                ]
            },
            "bert.encoder.layer.14.attention.output.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1003712896
                    ],
                    [
                        2,
                        2077454720
                    ],
                    [
                        3,
                        1003945856
                    ],
                    [
                        3,
                        2077687680
                    ]
                ]
            },
            "bert.encoder.layer.14.attention.output.LayerNorm.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        2079619872
                    ]
                ]
            },
            "bert.encoder.layer.14.attention.output.LayerNorm.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1006111008
                    ]
                ]
            },
            "bert.encoder.layer.14.intermediate.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    8
                ],
                "t": 1,
                "mblock": [
                    4,
                    2
                ],
                "ublock": [
                    4,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1035068288
                    ],
                    [
                        3,
                        2108810112
                    ],
                    [
                        4,
                        1035068288
                    ],
                    [
                        4,
                        2108810112
                    ],
                    [
                        5,
                        1035068288
                    ],
                    [
                        5,
                        2108810112
                    ],
                    [
                        0,
                        765834080
                    ],
                    [
                        0,
                        2108011360
                    ],
                    [
                        1,
                        1034336096
                    ],
                    [
                        1,
                        2108077920
                    ],
                    [
                        2,
                        1034336096
                    ],
                    [
                        2,
                        2108077920
                    ],
                    [
                        3,
                        1034535776
                    ],
                    [
                        3,
                        2108277600
                    ],
                    [
                        4,
                        1034535776
                    ],
                    [
                        4,
                        2108277600
                    ]
                ]
            },
            "bert.encoder.layer.14.intermediate.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    8
                ],
                "t": 1,
                "mblock": [
                    1,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1004945536
                    ],
                    [
                        4,
                        2078687360
                    ],
                    [
                        5,
                        1004945536
                    ],
                    [
                        5,
                        2078687360
                    ],
                    [
                        0,
                        735911008
                    ],
                    [
                        0,
                        2078088288
                    ],
                    [
                        1,
                        1004579424
                    ],
                    [
                        1,
                        2078321248
                    ]
                ]
            },
            "bert.encoder.layer.14.output.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    8
                ],
                "t": 1,
                "mblock": [
                    8,
                    1
                ],
                "ublock": [
                    8,
                    4
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1033271072
                    ],
                    [
                        1,
                        2107012896
                    ],
                    [
                        2,
                        1033271072
                    ],
                    [
                        2,
                        2107012896
                    ],
                    [
                        3,
                        1033470752
                    ],
                    [
                        3,
                        2107212576
                    ],
                    [
                        4,
                        1033470752
                    ],
                    [
                        4,
                        2107212576
                    ],
                    [
                        5,
                        1033470752
                    ],
                    [
                        5,
                        2107212576
                    ],
                    [
                        0,
                        764236544
                    ],
                    [
                        0,
                        2106413824
                    ],
                    [
                        1,
                        1032738560
                    ],
                    [
                        1,
                        2106480384
                    ],
                    [
                        2,
                        1032738560
                    ],
                    [
                        2,
                        2106480384
                    ]
                ]
            },
            "bert.encoder.layer.14.output.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    8
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    4
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1003803712
                    ],
                    [
                        5,
                        2077545536
                    ],
                    [
                        0,
                        734769184
                    ],
                    [
                        0,
                        2076946464
                    ],
                    [
                        1,
                        1003437600
                    ],
                    [
                        1,
                        2077179424
                    ],
                    [
                        2,
                        1003479200
                    ],
                    [
                        2,
                        2077221024
                    ]
                ]
            },
            "bert.encoder.layer.14.output.LayerNorm.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        2079852800
                    ]
                ]
            },
            "bert.encoder.layer.14.output.LayerNorm.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1006110976
                    ]
                ]
            },
            "bert.encoder.layer.15.attention.self.query.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    2,
                    1
                ],
                "ublock": [
                    8,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        753452768
                    ],
                    [
                        0,
                        2095630048
                    ],
                    [
                        1,
                        1022087904
                    ],
                    [
                        1,
                        2095829728
                    ],
                    [
                        2,
                        1022087904
                    ],
                    [
                        2,
                        2095829728
                    ],
                    [
                        3,
                        1022287584
                    ],
                    [
                        3,
                        2096029408
                    ]
                ]
            },
            "bert.encoder.layer.15.attention.self.query.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1004079680
                    ],
                    [
                        2,
                        2077821504
                    ],
                    [
                        3,
                        1004312640
                    ],
                    [
                        3,
                        2078054464
                    ]
                ]
            },
            "bert.encoder.layer.15.attention.self.key.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    2,
                    1
                ],
                "ublock": [
                    8,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        2096362272
                    ],
                    [
                        3,
                        1022820128
                    ],
                    [
                        3,
                        2096561952
                    ],
                    [
                        4,
                        1022820128
                    ],
                    [
                        4,
                        2096561952
                    ],
                    [
                        5,
                        1022820128
                    ],
                    [
                        5,
                        2096561952
                    ],
                    [
                        0,
                        753719040
                    ]
                ]
            },
            "bert.encoder.layer.15.attention.self.key.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1004354176
                    ],
                    [
                        4,
                        2078096000
                    ],
                    [
                        5,
                        1004354176
                    ],
                    [
                        5,
                        2078096000
                    ]
                ]
            },
            "bert.encoder.layer.15.attention.self.value.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    2,
                    1
                ],
                "ublock": [
                    8,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        2096428864
                    ],
                    [
                        1,
                        1022886720
                    ],
                    [
                        1,
                        2096628544
                    ],
                    [
                        2,
                        1022886720
                    ],
                    [
                        2,
                        2096628544
                    ],
                    [
                        3,
                        1023086400
                    ],
                    [
                        3,
                        2096828224
                    ],
                    [
                        4,
                        1023086400
                    ]
                ]
            },
            "bert.encoder.layer.15.attention.self.value.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1004404192
                    ],
                    [
                        4,
                        2078146016
                    ],
                    [
                        5,
                        1004404192
                    ],
                    [
                        5,
                        2078146016
                    ]
                ]
            },
            "bert.encoder.layer.15.attention.output.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    8,
                    1
                ],
                "ublock": [
                    2,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1023152992
                    ],
                    [
                        1,
                        2096894816
                    ],
                    [
                        2,
                        1023152992
                    ],
                    [
                        2,
                        2096894816
                    ],
                    [
                        3,
                        1023352672
                    ],
                    [
                        3,
                        2097094496
                    ],
                    [
                        4,
                        1023352672
                    ],
                    [
                        4,
                        2097094496
                    ]
                ]
            },
            "bert.encoder.layer.15.attention.output.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1004370848
                    ],
                    [
                        4,
                        2078112672
                    ],
                    [
                        5,
                        1004370848
                    ],
                    [
                        5,
                        2078112672
                    ]
                ]
            },
            "bert.encoder.layer.15.attention.output.LayerNorm.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        2079852832
                    ]
                ]
            },
            "bert.encoder.layer.15.attention.output.LayerNorm.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1005878048
                    ]
                ]
            },
            "bert.encoder.layer.15.intermediate.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    8
                ],
                "t": 1,
                "mblock": [
                    4,
                    2
                ],
                "ublock": [
                    4,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1045186016
                    ],
                    [
                        5,
                        2118927840
                    ],
                    [
                        0,
                        775951808
                    ],
                    [
                        0,
                        2118129088
                    ],
                    [
                        1,
                        1044453824
                    ],
                    [
                        1,
                        2118195648
                    ],
                    [
                        2,
                        1044453824
                    ],
                    [
                        2,
                        2118195648
                    ],
                    [
                        3,
                        1044653504
                    ],
                    [
                        3,
                        2118395328
                    ],
                    [
                        4,
                        1044653504
                    ],
                    [
                        4,
                        2118395328
                    ],
                    [
                        5,
                        1044653504
                    ],
                    [
                        5,
                        2118395328
                    ],
                    [
                        0,
                        775419296
                    ],
                    [
                        0,
                        2117596576
                    ]
                ]
            },
            "bert.encoder.layer.15.intermediate.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    8
                ],
                "t": 1,
                "mblock": [
                    1,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1004512800
                    ],
                    [
                        1,
                        2078254624
                    ],
                    [
                        2,
                        1004546080
                    ],
                    [
                        2,
                        2078287904
                    ],
                    [
                        3,
                        1004779040
                    ],
                    [
                        3,
                        2078520864
                    ],
                    [
                        4,
                        1004845600
                    ],
                    [
                        4,
                        2078587424
                    ]
                ]
            },
            "bert.encoder.layer.15.output.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    8
                ],
                "t": 1,
                "mblock": [
                    8,
                    1
                ],
                "ublock": [
                    8,
                    4
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1045718528
                    ],
                    [
                        3,
                        2119460352
                    ],
                    [
                        4,
                        1045718528
                    ],
                    [
                        4,
                        2119460352
                    ],
                    [
                        5,
                        1045718528
                    ],
                    [
                        5,
                        2119460352
                    ],
                    [
                        0,
                        776484320
                    ],
                    [
                        0,
                        2118661600
                    ],
                    [
                        1,
                        1044986336
                    ],
                    [
                        1,
                        2118728160
                    ],
                    [
                        2,
                        1044986336
                    ],
                    [
                        2,
                        2118728160
                    ],
                    [
                        3,
                        1045186016
                    ],
                    [
                        3,
                        2118927840
                    ],
                    [
                        4,
                        1045186016
                    ],
                    [
                        4,
                        2118927840
                    ]
                ]
            },
            "bert.encoder.layer.15.output.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    8
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    4
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        2076929760
                    ],
                    [
                        1,
                        1003420896
                    ],
                    [
                        1,
                        2077162720
                    ],
                    [
                        2,
                        1003462496
                    ],
                    [
                        2,
                        2077204320
                    ],
                    [
                        3,
                        1003695456
                    ],
                    [
                        3,
                        2077437280
                    ],
                    [
                        4,
                        1003778656
                    ]
                ]
            },
            "bert.encoder.layer.15.output.LayerNorm.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        2079619872
                    ]
                ]
            },
            "bert.encoder.layer.15.output.LayerNorm.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1005878048
                    ]
                ]
            },
            "bert.encoder.layer.16.attention.self.query.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    4,
                    2
                ],
                "t": 1,
                "mblock": [
                    2,
                    2
                ],
                "ublock": [
                    4,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        2094431776
                    ],
                    [
                        5,
                        1020689952
                    ],
                    [
                        5,
                        2094431776
                    ],
                    [
                        0,
                        751588864
                    ],
                    [
                        0,
                        2093766144
                    ],
                    [
                        1,
                        1020224000
                    ],
                    [
                        1,
                        2093965824
                    ],
                    [
                        2,
                        1020224000
                    ]
                ]
            },
            "bert.encoder.layer.16.attention.self.query.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    2
                ],
                "t": 1,
                "mblock": [
                    1,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1004446144
                    ],
                    [
                        2,
                        2078187968
                    ]
                ]
            },
            "bert.encoder.layer.16.attention.self.key.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    4,
                    2
                ],
                "t": 1,
                "mblock": [
                    2,
                    2
                ],
                "ublock": [
                    4,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        2094498368
                    ],
                    [
                        3,
                        1020956224
                    ],
                    [
                        3,
                        2094698048
                    ],
                    [
                        4,
                        1020956224
                    ],
                    [
                        4,
                        2094698048
                    ],
                    [
                        5,
                        1020956224
                    ],
                    [
                        5,
                        2094698048
                    ],
                    [
                        0,
                        751855136
                    ]
                ]
            },
            "bert.encoder.layer.16.attention.self.key.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    2
                ],
                "t": 1,
                "mblock": [
                    1,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1004379552
                    ],
                    [
                        1,
                        2078121376
                    ]
                ]
            },
            "bert.encoder.layer.16.attention.self.value.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    2,
                    1
                ],
                "ublock": [
                    8,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        2100556032
                    ],
                    [
                        4,
                        1026814208
                    ],
                    [
                        4,
                        2100556032
                    ],
                    [
                        5,
                        1026814208
                    ],
                    [
                        5,
                        2100556032
                    ],
                    [
                        0,
                        757713120
                    ],
                    [
                        0,
                        2099890400
                    ],
                    [
                        1,
                        1026348256
                    ]
                ]
            },
            "bert.encoder.layer.16.attention.self.value.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        735302976
                    ],
                    [
                        0,
                        2077480256
                    ],
                    [
                        1,
                        1003971392
                    ],
                    [
                        1,
                        2077713216
                    ]
                ]
            },
            "bert.encoder.layer.16.attention.output.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    8,
                    1
                ],
                "ublock": [
                    2,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        2100822304
                    ],
                    [
                        0,
                        757979392
                    ],
                    [
                        0,
                        2100156672
                    ],
                    [
                        1,
                        1026614528
                    ],
                    [
                        1,
                        2100356352
                    ],
                    [
                        2,
                        1026614528
                    ],
                    [
                        2,
                        2100356352
                    ],
                    [
                        3,
                        1026814208
                    ]
                ]
            },
            "bert.encoder.layer.16.attention.output.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1003962976
                    ],
                    [
                        2,
                        2077704800
                    ],
                    [
                        3,
                        1004195936
                    ],
                    [
                        3,
                        2077937760
                    ]
                ]
            },
            "bert.encoder.layer.16.attention.output.LayerNorm.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1006177600
                    ]
                ]
            },
            "bert.encoder.layer.16.attention.output.LayerNorm.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        2079686464
                    ]
                ]
            },
            "bert.encoder.layer.16.intermediate.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    8
                ],
                "t": 1,
                "mblock": [
                    4,
                    2
                ],
                "ublock": [
                    4,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1039328384
                    ],
                    [
                        3,
                        2113070208
                    ],
                    [
                        4,
                        1039328384
                    ],
                    [
                        4,
                        2113070208
                    ],
                    [
                        5,
                        1039328384
                    ],
                    [
                        5,
                        2113070208
                    ],
                    [
                        0,
                        770094176
                    ],
                    [
                        0,
                        2112271456
                    ],
                    [
                        1,
                        1038596192
                    ],
                    [
                        1,
                        2112338016
                    ],
                    [
                        2,
                        1038596192
                    ],
                    [
                        2,
                        2112338016
                    ],
                    [
                        3,
                        1038795872
                    ],
                    [
                        3,
                        2112537696
                    ],
                    [
                        4,
                        1038795872
                    ],
                    [
                        4,
                        2112537696
                    ]
                ]
            },
            "bert.encoder.layer.16.intermediate.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    8
                ],
                "t": 1,
                "mblock": [
                    1,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1005012160
                    ],
                    [
                        4,
                        2078753984
                    ],
                    [
                        5,
                        1005012160
                    ],
                    [
                        5,
                        2078753984
                    ],
                    [
                        0,
                        735977632
                    ],
                    [
                        0,
                        2078154912
                    ],
                    [
                        1,
                        1004646048
                    ],
                    [
                        1,
                        2078387872
                    ]
                ]
            },
            "bert.encoder.layer.16.output.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    8
                ],
                "t": 1,
                "mblock": [
                    8,
                    1
                ],
                "ublock": [
                    8,
                    4
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1037198336
                    ],
                    [
                        3,
                        2110940160
                    ],
                    [
                        4,
                        1037198336
                    ],
                    [
                        4,
                        2110940160
                    ],
                    [
                        5,
                        1037198336
                    ],
                    [
                        5,
                        2110940160
                    ],
                    [
                        0,
                        767964128
                    ],
                    [
                        0,
                        2110141408
                    ],
                    [
                        1,
                        1036466144
                    ],
                    [
                        1,
                        2110207968
                    ],
                    [
                        2,
                        1036466144
                    ],
                    [
                        2,
                        2110207968
                    ],
                    [
                        3,
                        1036665824
                    ],
                    [
                        3,
                        2110407648
                    ],
                    [
                        4,
                        1036665824
                    ],
                    [
                        4,
                        2110407648
                    ]
                ]
            },
            "bert.encoder.layer.16.output.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    8
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    4
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        2077520480
                    ],
                    [
                        5,
                        1003778656
                    ],
                    [
                        5,
                        2077520480
                    ],
                    [
                        0,
                        734744128
                    ],
                    [
                        0,
                        2076921408
                    ],
                    [
                        1,
                        1003412544
                    ],
                    [
                        1,
                        2077154368
                    ],
                    [
                        2,
                        1003454144
                    ]
                ]
            },
            "bert.encoder.layer.16.output.LayerNorm.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1005944640
                    ]
                ]
            },
            "bert.encoder.layer.16.output.LayerNorm.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        2079453504
                    ]
                ]
            },
            "bert.encoder.layer.17.attention.self.query.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    2,
                    1
                ],
                "ublock": [
                    8,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        756914304
                    ],
                    [
                        0,
                        2099091584
                    ],
                    [
                        1,
                        1025549440
                    ],
                    [
                        1,
                        2099291264
                    ],
                    [
                        2,
                        1025549440
                    ],
                    [
                        2,
                        2099291264
                    ],
                    [
                        3,
                        1025749120
                    ],
                    [
                        3,
                        2099490944
                    ]
                ]
            },
            "bert.encoder.layer.17.attention.self.query.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1004012992
                    ],
                    [
                        2,
                        2077754816
                    ],
                    [
                        3,
                        1004245952
                    ],
                    [
                        3,
                        2077987776
                    ]
                ]
            },
            "bert.encoder.layer.17.attention.self.key.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    2,
                    1
                ],
                "ublock": [
                    8,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        2098758720
                    ],
                    [
                        2,
                        1025016896
                    ],
                    [
                        2,
                        2098758720
                    ],
                    [
                        3,
                        1025216576
                    ],
                    [
                        3,
                        2098958400
                    ],
                    [
                        4,
                        1025216576
                    ],
                    [
                        4,
                        2098958400
                    ],
                    [
                        5,
                        1025216576
                    ]
                ]
            },
            "bert.encoder.layer.17.attention.self.key.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        735286304
                    ],
                    [
                        0,
                        2077463584
                    ],
                    [
                        1,
                        1003954720
                    ],
                    [
                        1,
                        2077696544
                    ]
                ]
            },
            "bert.encoder.layer.17.attention.self.value.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    2,
                    1
                ],
                "ublock": [
                    8,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        2089971744
                    ],
                    [
                        2,
                        1016229920
                    ],
                    [
                        2,
                        2089971744
                    ],
                    [
                        3,
                        1016429600
                    ],
                    [
                        3,
                        2090171424
                    ],
                    [
                        4,
                        1016429600
                    ],
                    [
                        4,
                        2090171424
                    ],
                    [
                        5,
                        1016429600
                    ]
                ]
            },
            "bert.encoder.layer.17.attention.self.value.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1004304160
                    ],
                    [
                        4,
                        2078045984
                    ],
                    [
                        5,
                        1004304160
                    ],
                    [
                        5,
                        2078045984
                    ]
                ]
            },
            "bert.encoder.layer.17.attention.output.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    8,
                    1
                ],
                "ublock": [
                    2,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        2085178848
                    ],
                    [
                        3,
                        1011636704
                    ],
                    [
                        3,
                        2085378528
                    ],
                    [
                        4,
                        1011636704
                    ],
                    [
                        4,
                        2085378528
                    ],
                    [
                        5,
                        1011636704
                    ],
                    [
                        5,
                        2085378528
                    ],
                    [
                        0,
                        742535616
                    ]
                ]
            },
            "bert.encoder.layer.17.attention.output.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1003979648
                    ],
                    [
                        2,
                        2077721472
                    ],
                    [
                        3,
                        1004212608
                    ],
                    [
                        3,
                        2077954432
                    ]
                ]
            },
            "bert.encoder.layer.17.attention.output.LayerNorm.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        2079386912
                    ]
                ]
            },
            "bert.encoder.layer.17.attention.output.LayerNorm.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1005478496
                    ]
                ]
            },
            "bert.encoder.layer.17.intermediate.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    8
                ],
                "t": 1,
                "mblock": [
                    4,
                    2
                ],
                "ublock": [
                    4,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1063091744
                    ],
                    [
                        1,
                        2136833568
                    ],
                    [
                        2,
                        1063091744
                    ],
                    [
                        2,
                        2136833568
                    ],
                    [
                        3,
                        1063291424
                    ],
                    [
                        3,
                        2137033248
                    ],
                    [
                        4,
                        1063291424
                    ],
                    [
                        4,
                        2137033248
                    ],
                    [
                        5,
                        1063291424
                    ],
                    [
                        5,
                        2137033248
                    ],
                    [
                        0,
                        794057216
                    ],
                    [
                        0,
                        2136234496
                    ],
                    [
                        1,
                        1062559232
                    ],
                    [
                        1,
                        2136301056
                    ],
                    [
                        2,
                        1062559232
                    ],
                    [
                        2,
                        2136301056
                    ]
                ]
            },
            "bert.encoder.layer.17.intermediate.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    8
                ],
                "t": 1,
                "mblock": [
                    1,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1004645792
                    ],
                    [
                        3,
                        2078387616
                    ],
                    [
                        4,
                        1004712352
                    ],
                    [
                        4,
                        2078454176
                    ],
                    [
                        5,
                        1004712352
                    ],
                    [
                        5,
                        2078454176
                    ],
                    [
                        0,
                        735677824
                    ],
                    [
                        0,
                        2077855104
                    ]
                ]
            },
            "bert.encoder.layer.17.output.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    8
                ],
                "t": 1,
                "mblock": [
                    8,
                    1
                ],
                "ublock": [
                    8,
                    4
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1062758912
                    ],
                    [
                        3,
                        2136500736
                    ],
                    [
                        4,
                        1062758912
                    ],
                    [
                        4,
                        2136500736
                    ],
                    [
                        5,
                        1062758912
                    ],
                    [
                        5,
                        2136500736
                    ],
                    [
                        0,
                        793524704
                    ],
                    [
                        0,
                        2135701984
                    ],
                    [
                        1,
                        1062026720
                    ],
                    [
                        1,
                        2135768544
                    ],
                    [
                        2,
                        1062026720
                    ],
                    [
                        2,
                        2135768544
                    ],
                    [
                        3,
                        1062226400
                    ],
                    [
                        3,
                        2135968224
                    ],
                    [
                        4,
                        1062226400
                    ],
                    [
                        4,
                        2135968224
                    ]
                ]
            },
            "bert.encoder.layer.17.output.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    8
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    4
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1003770304
                    ],
                    [
                        4,
                        2077512128
                    ],
                    [
                        5,
                        1003770304
                    ],
                    [
                        5,
                        2077512128
                    ],
                    [
                        0,
                        734735776
                    ],
                    [
                        0,
                        2076913056
                    ],
                    [
                        1,
                        1003404192
                    ],
                    [
                        1,
                        2077146016
                    ]
                ]
            },
            "bert.encoder.layer.17.output.LayerNorm.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        2078987360
                    ]
                ]
            },
            "bert.encoder.layer.17.output.LayerNorm.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        736810080
                    ]
                ]
            },
            "bert.encoder.layer.18.attention.self.query.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    4,
                    2
                ],
                "t": 1,
                "mblock": [
                    2,
                    2
                ],
                "ublock": [
                    4,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        2087242432
                    ],
                    [
                        0,
                        744399520
                    ],
                    [
                        0,
                        2086576800
                    ],
                    [
                        1,
                        1013034656
                    ],
                    [
                        1,
                        2086776480
                    ],
                    [
                        2,
                        1013034656
                    ],
                    [
                        2,
                        2086776480
                    ],
                    [
                        3,
                        1013234336
                    ]
                ]
            },
            "bert.encoder.layer.18.attention.self.query.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    2
                ],
                "t": 1,
                "mblock": [
                    1,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1004812288
                    ],
                    [
                        4,
                        2078554112
                    ]
                ]
            },
            "bert.encoder.layer.18.attention.self.key.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    4,
                    2
                ],
                "t": 1,
                "mblock": [
                    2,
                    2
                ],
                "ublock": [
                    4,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        2087042752
                    ],
                    [
                        2,
                        1013300928
                    ],
                    [
                        2,
                        2087042752
                    ],
                    [
                        3,
                        1013500608
                    ],
                    [
                        3,
                        2087242432
                    ],
                    [
                        4,
                        1013500608
                    ],
                    [
                        4,
                        2087242432
                    ],
                    [
                        5,
                        1013500608
                    ]
                ]
            },
            "bert.encoder.layer.18.attention.self.key.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    2
                ],
                "t": 1,
                "mblock": [
                    1,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1004845600
                    ],
                    [
                        5,
                        2078587424
                    ]
                ]
            },
            "bert.encoder.layer.18.attention.self.value.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    2,
                    1
                ],
                "ublock": [
                    8,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        2085112256
                    ],
                    [
                        5,
                        1011370432
                    ],
                    [
                        5,
                        2085112256
                    ],
                    [
                        0,
                        742269344
                    ],
                    [
                        0,
                        2084446624
                    ],
                    [
                        1,
                        1010904480
                    ],
                    [
                        1,
                        2084646304
                    ],
                    [
                        2,
                        1010904480
                    ]
                ]
            },
            "bert.encoder.layer.18.attention.self.value.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1004063008
                    ],
                    [
                        2,
                        2077804832
                    ],
                    [
                        3,
                        1004295968
                    ],
                    [
                        3,
                        2078037792
                    ]
                ]
            },
            "bert.encoder.layer.18.attention.output.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    8,
                    1
                ],
                "ublock": [
                    2,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        740671712
                    ],
                    [
                        0,
                        2082848992
                    ],
                    [
                        1,
                        1009306848
                    ],
                    [
                        1,
                        2083048672
                    ],
                    [
                        2,
                        1009306848
                    ],
                    [
                        2,
                        2083048672
                    ],
                    [
                        3,
                        1009506528
                    ],
                    [
                        3,
                        2083248352
                    ]
                ]
            },
            "bert.encoder.layer.18.attention.output.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        735369664
                    ],
                    [
                        0,
                        2077546944
                    ],
                    [
                        1,
                        1004038080
                    ],
                    [
                        1,
                        2077779904
                    ]
                ]
            },
            "bert.encoder.layer.18.attention.output.LayerNorm.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        2079353504
                    ]
                ]
            },
            "bert.encoder.layer.18.attention.output.LayerNorm.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1005611680
                    ]
                ]
            },
            "bert.encoder.layer.18.intermediate.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    8
                ],
                "t": 1,
                "mblock": [
                    4,
                    2
                ],
                "ublock": [
                    4,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1052108672
                    ],
                    [
                        3,
                        2125850496
                    ],
                    [
                        4,
                        1052108672
                    ],
                    [
                        4,
                        2125850496
                    ],
                    [
                        5,
                        1052108672
                    ],
                    [
                        5,
                        2125850496
                    ],
                    [
                        0,
                        782874464
                    ],
                    [
                        0,
                        2125051744
                    ],
                    [
                        1,
                        1051376480
                    ],
                    [
                        1,
                        2125118304
                    ],
                    [
                        2,
                        1051376480
                    ],
                    [
                        2,
                        2125118304
                    ],
                    [
                        3,
                        1051576160
                    ],
                    [
                        3,
                        2125317984
                    ],
                    [
                        4,
                        1051576160
                    ],
                    [
                        4,
                        2125317984
                    ]
                ]
            },
            "bert.encoder.layer.18.intermediate.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    8
                ],
                "t": 1,
                "mblock": [
                    1,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1004845664
                    ],
                    [
                        3,
                        2078587488
                    ],
                    [
                        4,
                        1004912224
                    ],
                    [
                        4,
                        2078654048
                    ],
                    [
                        5,
                        1004912224
                    ],
                    [
                        5,
                        2078654048
                    ],
                    [
                        0,
                        735877696
                    ],
                    [
                        0,
                        2078054976
                    ]
                ]
            },
            "bert.encoder.layer.18.output.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    8
                ],
                "t": 1,
                "mblock": [
                    8,
                    1
                ],
                "ublock": [
                    8,
                    4
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1049978624
                    ],
                    [
                        3,
                        2123720448
                    ],
                    [
                        4,
                        1049978624
                    ],
                    [
                        4,
                        2123720448
                    ],
                    [
                        5,
                        1049978624
                    ],
                    [
                        5,
                        2123720448
                    ],
                    [
                        0,
                        780744416
                    ],
                    [
                        0,
                        2122921696
                    ],
                    [
                        1,
                        1049246432
                    ],
                    [
                        1,
                        2122988256
                    ],
                    [
                        2,
                        1049246432
                    ],
                    [
                        2,
                        2122988256
                    ],
                    [
                        3,
                        1049446112
                    ],
                    [
                        3,
                        2123187936
                    ],
                    [
                        4,
                        1049446112
                    ],
                    [
                        4,
                        2123187936
                    ]
                ]
            },
            "bert.encoder.layer.18.output.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    8
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    4
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        2077612352
                    ],
                    [
                        5,
                        1003870528
                    ],
                    [
                        5,
                        2077612352
                    ],
                    [
                        0,
                        734836000
                    ],
                    [
                        0,
                        2077013280
                    ],
                    [
                        1,
                        1003504416
                    ],
                    [
                        1,
                        2077246240
                    ],
                    [
                        2,
                        1003546016
                    ]
                ]
            },
            "bert.encoder.layer.18.output.LayerNorm.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        2079353504
                    ]
                ]
            },
            "bert.encoder.layer.18.output.LayerNorm.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1006110976
                    ]
                ]
            },
            "bert.encoder.layer.19.attention.self.query.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    2,
                    1
                ],
                "ublock": [
                    8,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        2090570880
                    ],
                    [
                        1,
                        1017028736
                    ],
                    [
                        1,
                        2090770560
                    ],
                    [
                        2,
                        1017028736
                    ],
                    [
                        2,
                        2090770560
                    ],
                    [
                        3,
                        1017228416
                    ],
                    [
                        3,
                        2090970240
                    ],
                    [
                        4,
                        1017228416
                    ]
                ]
            },
            "bert.encoder.layer.19.attention.self.query.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1004037408
                    ],
                    [
                        4,
                        2077779232
                    ],
                    [
                        5,
                        1004037408
                    ],
                    [
                        5,
                        2077779232
                    ]
                ]
            },
            "bert.encoder.layer.19.attention.self.key.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    2,
                    1
                ],
                "ublock": [
                    8,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        2091103424
                    ],
                    [
                        1,
                        1017561280
                    ],
                    [
                        1,
                        2091303104
                    ],
                    [
                        2,
                        1017561280
                    ],
                    [
                        2,
                        2091303104
                    ],
                    [
                        3,
                        1017760960
                    ],
                    [
                        3,
                        2091502784
                    ],
                    [
                        4,
                        1017760960
                    ]
                ]
            },
            "bert.encoder.layer.19.attention.self.key.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1003729568
                    ],
                    [
                        2,
                        2077471392
                    ],
                    [
                        3,
                        1003962528
                    ],
                    [
                        3,
                        2077704352
                    ]
                ]
            },
            "bert.encoder.layer.19.attention.self.value.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    2,
                    1
                ],
                "ublock": [
                    8,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        2092101920
                    ],
                    [
                        3,
                        1018559776
                    ],
                    [
                        3,
                        2092301600
                    ],
                    [
                        4,
                        1018559776
                    ],
                    [
                        4,
                        2092301600
                    ],
                    [
                        5,
                        1018559776
                    ],
                    [
                        5,
                        2092301600
                    ],
                    [
                        0,
                        749458688
                    ]
                ]
            },
            "bert.encoder.layer.19.attention.self.value.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        735036224
                    ],
                    [
                        0,
                        2077213504
                    ],
                    [
                        1,
                        1003704640
                    ],
                    [
                        1,
                        2077446464
                    ]
                ]
            },
            "bert.encoder.layer.19.attention.output.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    8,
                    1
                ],
                "ublock": [
                    2,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        2092567872
                    ],
                    [
                        5,
                        1018826048
                    ],
                    [
                        5,
                        2092567872
                    ],
                    [
                        0,
                        749724960
                    ],
                    [
                        0,
                        2091902240
                    ],
                    [
                        1,
                        1018360096
                    ],
                    [
                        1,
                        2092101920
                    ],
                    [
                        2,
                        1018360096
                    ]
                ]
            },
            "bert.encoder.layer.19.attention.output.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1003762912
                    ],
                    [
                        2,
                        2077504736
                    ],
                    [
                        3,
                        1003995872
                    ],
                    [
                        3,
                        2077737696
                    ]
                ]
            },
            "bert.encoder.layer.19.attention.output.LayerNorm.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        2079786208
                    ]
                ]
            },
            "bert.encoder.layer.19.attention.output.LayerNorm.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1006344192
                    ]
                ]
            },
            "bert.encoder.layer.19.intermediate.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    8
                ],
                "t": 1,
                "mblock": [
                    4,
                    2
                ],
                "ublock": [
                    4,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1050311456
                    ],
                    [
                        1,
                        2124053280
                    ],
                    [
                        2,
                        1050311456
                    ],
                    [
                        2,
                        2124053280
                    ],
                    [
                        3,
                        1050511136
                    ],
                    [
                        3,
                        2124252960
                    ],
                    [
                        4,
                        1050511136
                    ],
                    [
                        4,
                        2124252960
                    ],
                    [
                        5,
                        1050511136
                    ],
                    [
                        5,
                        2124252960
                    ],
                    [
                        0,
                        781276928
                    ],
                    [
                        0,
                        2123454208
                    ],
                    [
                        1,
                        1049778944
                    ],
                    [
                        1,
                        2123520768
                    ],
                    [
                        2,
                        1049778944
                    ],
                    [
                        2,
                        2123520768
                    ]
                ]
            },
            "bert.encoder.layer.19.intermediate.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    8
                ],
                "t": 1,
                "mblock": [
                    1,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        735777760
                    ],
                    [
                        0,
                        2077955040
                    ],
                    [
                        1,
                        1004446176
                    ],
                    [
                        1,
                        2078188000
                    ],
                    [
                        2,
                        1004479456
                    ],
                    [
                        2,
                        2078221280
                    ],
                    [
                        3,
                        1004712416
                    ],
                    [
                        3,
                        2078454240
                    ]
                ]
            },
            "bert.encoder.layer.19.output.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    8
                ],
                "t": 1,
                "mblock": [
                    8,
                    1
                ],
                "ublock": [
                    8,
                    4
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1052441504
                    ],
                    [
                        1,
                        2126183328
                    ],
                    [
                        2,
                        1052441504
                    ],
                    [
                        2,
                        2126183328
                    ],
                    [
                        3,
                        1052641184
                    ],
                    [
                        3,
                        2126383008
                    ],
                    [
                        4,
                        1052641184
                    ],
                    [
                        4,
                        2126383008
                    ],
                    [
                        5,
                        1052641184
                    ],
                    [
                        5,
                        2126383008
                    ],
                    [
                        0,
                        783406976
                    ],
                    [
                        0,
                        2125584256
                    ],
                    [
                        1,
                        1051908992
                    ],
                    [
                        1,
                        2125650816
                    ],
                    [
                        2,
                        1051908992
                    ],
                    [
                        2,
                        2125650816
                    ]
                ]
            },
            "bert.encoder.layer.19.output.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    8
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    4
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1003496064
                    ],
                    [
                        1,
                        2077237888
                    ],
                    [
                        2,
                        1003537664
                    ],
                    [
                        2,
                        2077279488
                    ],
                    [
                        3,
                        1003770624
                    ],
                    [
                        3,
                        2077512448
                    ],
                    [
                        4,
                        1003853824
                    ],
                    [
                        4,
                        2077595648
                    ]
                ]
            },
            "bert.encoder.layer.19.output.LayerNorm.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1006044384
                    ]
                ]
            },
            "bert.encoder.layer.19.output.LayerNorm.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1006044384
                    ]
                ]
            },
            "bert.encoder.layer.20.attention.self.query.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    4,
                    2
                ],
                "t": 1,
                "mblock": [
                    2,
                    2
                ],
                "ublock": [
                    4,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        2088107840
                    ],
                    [
                        3,
                        1014565696
                    ],
                    [
                        3,
                        2088307520
                    ],
                    [
                        4,
                        1014565696
                    ],
                    [
                        4,
                        2088307520
                    ],
                    [
                        5,
                        1014565696
                    ],
                    [
                        5,
                        2088307520
                    ],
                    [
                        0,
                        745464608
                    ]
                ]
            },
            "bert.encoder.layer.20.attention.self.query.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    2
                ],
                "t": 1,
                "mblock": [
                    1,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1004412832
                    ],
                    [
                        2,
                        2078154656
                    ]
                ]
            },
            "bert.encoder.layer.20.attention.self.key.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    4,
                    2
                ],
                "t": 1,
                "mblock": [
                    2,
                    2
                ],
                "ublock": [
                    4,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        2087641888
                    ],
                    [
                        1,
                        1014099744
                    ],
                    [
                        1,
                        2087841568
                    ],
                    [
                        2,
                        1014099744
                    ],
                    [
                        2,
                        2087841568
                    ],
                    [
                        3,
                        1014299424
                    ],
                    [
                        3,
                        2088041248
                    ],
                    [
                        4,
                        1014299424
                    ]
                ]
            },
            "bert.encoder.layer.20.attention.self.key.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    2
                ],
                "t": 1,
                "mblock": [
                    1,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1004812288
                    ],
                    [
                        5,
                        2078554112
                    ]
                ]
            },
            "bert.encoder.layer.20.attention.self.value.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    2,
                    1
                ],
                "ublock": [
                    8,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1015364512
                    ],
                    [
                        3,
                        2089106336
                    ],
                    [
                        4,
                        1015364512
                    ],
                    [
                        4,
                        2089106336
                    ],
                    [
                        5,
                        1015364512
                    ],
                    [
                        5,
                        2089106336
                    ],
                    [
                        0,
                        746263424
                    ],
                    [
                        0,
                        2088440704
                    ]
                ]
            },
            "bert.encoder.layer.20.attention.self.value.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1004154112
                    ],
                    [
                        4,
                        2077895936
                    ],
                    [
                        5,
                        1004154112
                    ],
                    [
                        5,
                        2077895936
                    ]
                ]
            },
            "bert.encoder.layer.20.attention.output.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    8,
                    1
                ],
                "ublock": [
                    2,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1015630784
                    ],
                    [
                        5,
                        2089372608
                    ],
                    [
                        0,
                        746529696
                    ],
                    [
                        0,
                        2088706976
                    ],
                    [
                        1,
                        1015164832
                    ],
                    [
                        1,
                        2088906656
                    ],
                    [
                        2,
                        1015164832
                    ],
                    [
                        2,
                        2088906656
                    ]
                ]
            },
            "bert.encoder.layer.20.attention.output.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        735119584
                    ],
                    [
                        0,
                        2077296864
                    ],
                    [
                        1,
                        1003788000
                    ],
                    [
                        1,
                        2077529824
                    ]
                ]
            },
            "bert.encoder.layer.20.attention.output.LayerNorm.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        737076448
                    ]
                ]
            },
            "bert.encoder.layer.20.attention.output.LayerNorm.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        2079852800
                    ]
                ]
            },
            "bert.encoder.layer.20.intermediate.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    8
                ],
                "t": 1,
                "mblock": [
                    4,
                    2
                ],
                "ublock": [
                    4,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1047316064
                    ],
                    [
                        5,
                        2121057888
                    ],
                    [
                        0,
                        778081856
                    ],
                    [
                        0,
                        2120259136
                    ],
                    [
                        1,
                        1046583872
                    ],
                    [
                        1,
                        2120325696
                    ],
                    [
                        2,
                        1046583872
                    ],
                    [
                        2,
                        2120325696
                    ],
                    [
                        3,
                        1046783552
                    ],
                    [
                        3,
                        2120525376
                    ],
                    [
                        4,
                        1046783552
                    ],
                    [
                        4,
                        2120525376
                    ],
                    [
                        5,
                        1046783552
                    ],
                    [
                        5,
                        2120525376
                    ],
                    [
                        0,
                        777549344
                    ],
                    [
                        0,
                        2119726624
                    ]
                ]
            },
            "bert.encoder.layer.20.intermediate.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    8
                ],
                "t": 1,
                "mblock": [
                    1,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1004679328
                    ],
                    [
                        2,
                        2078421152
                    ],
                    [
                        3,
                        1004912288
                    ],
                    [
                        3,
                        2078654112
                    ],
                    [
                        4,
                        1004978848
                    ],
                    [
                        4,
                        2078720672
                    ],
                    [
                        5,
                        1004978848
                    ],
                    [
                        5,
                        2078720672
                    ]
                ]
            },
            "bert.encoder.layer.20.output.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    8
                ],
                "t": 1,
                "mblock": [
                    8,
                    1
                ],
                "ublock": [
                    8,
                    4
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1054238720
                    ],
                    [
                        3,
                        2127980544
                    ],
                    [
                        4,
                        1054238720
                    ],
                    [
                        4,
                        2127980544
                    ],
                    [
                        5,
                        1054238720
                    ],
                    [
                        5,
                        2127980544
                    ],
                    [
                        0,
                        785004512
                    ],
                    [
                        0,
                        2127181792
                    ],
                    [
                        1,
                        1053506528
                    ],
                    [
                        1,
                        2127248352
                    ],
                    [
                        2,
                        1053506528
                    ],
                    [
                        2,
                        2127248352
                    ],
                    [
                        3,
                        1053706208
                    ],
                    [
                        3,
                        2127448032
                    ],
                    [
                        4,
                        1053706208
                    ],
                    [
                        4,
                        2127448032
                    ]
                ]
            },
            "bert.encoder.layer.20.output.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    8
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    4
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1003853824
                    ],
                    [
                        5,
                        2077595648
                    ],
                    [
                        0,
                        734819296
                    ],
                    [
                        0,
                        2076996576
                    ],
                    [
                        1,
                        1003487712
                    ],
                    [
                        1,
                        2077229536
                    ],
                    [
                        2,
                        1003529312
                    ],
                    [
                        2,
                        2077271136
                    ]
                ]
            },
            "bert.encoder.layer.20.output.LayerNorm.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        2079120544
                    ]
                ]
            },
            "bert.encoder.layer.20.output.LayerNorm.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1006344192
                    ]
                ]
            },
            "bert.encoder.layer.21.attention.self.query.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    2,
                    1
                ],
                "ublock": [
                    8,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        2091036832
                    ],
                    [
                        3,
                        1017494688
                    ],
                    [
                        3,
                        2091236512
                    ],
                    [
                        4,
                        1017494688
                    ],
                    [
                        4,
                        2091236512
                    ],
                    [
                        5,
                        1017494688
                    ],
                    [
                        5,
                        2091236512
                    ],
                    [
                        0,
                        748393600
                    ]
                ]
            },
            "bert.encoder.layer.21.attention.self.query.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        735069568
                    ],
                    [
                        0,
                        2077246848
                    ],
                    [
                        1,
                        1003737984
                    ],
                    [
                        1,
                        2077479808
                    ]
                ]
            },
            "bert.encoder.layer.21.attention.self.key.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    2,
                    1
                ],
                "ublock": [
                    8,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        2090703968
                    ],
                    [
                        0,
                        747861056
                    ],
                    [
                        0,
                        2090038336
                    ],
                    [
                        1,
                        1016496192
                    ],
                    [
                        1,
                        2090238016
                    ],
                    [
                        2,
                        1016496192
                    ],
                    [
                        2,
                        2090238016
                    ],
                    [
                        3,
                        1016695872
                    ]
                ]
            },
            "bert.encoder.layer.21.attention.self.key.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        735052896
                    ],
                    [
                        0,
                        2077230176
                    ],
                    [
                        1,
                        1003721312
                    ],
                    [
                        1,
                        2077463136
                    ]
                ]
            },
            "bert.encoder.layer.21.attention.self.value.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    2,
                    1
                ],
                "ublock": [
                    8,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1010571616
                    ],
                    [
                        4,
                        2084313440
                    ],
                    [
                        5,
                        1010571616
                    ],
                    [
                        5,
                        2084313440
                    ],
                    [
                        0,
                        741470528
                    ],
                    [
                        0,
                        2083647808
                    ],
                    [
                        1,
                        1010105664
                    ],
                    [
                        1,
                        2083847488
                    ]
                ]
            },
            "bert.encoder.layer.21.attention.self.value.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1003779584
                    ],
                    [
                        2,
                        2077521408
                    ],
                    [
                        3,
                        1004012544
                    ],
                    [
                        3,
                        2077754368
                    ]
                ]
            },
            "bert.encoder.layer.21.attention.output.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    8,
                    1
                ],
                "ublock": [
                    2,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1010105664
                    ],
                    [
                        2,
                        2083847488
                    ],
                    [
                        3,
                        1010305344
                    ],
                    [
                        3,
                        2084047168
                    ],
                    [
                        4,
                        1010305344
                    ],
                    [
                        4,
                        2084047168
                    ],
                    [
                        5,
                        1010305344
                    ],
                    [
                        5,
                        2084047168
                    ]
                ]
            },
            "bert.encoder.layer.21.attention.output.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1004104096
                    ],
                    [
                        4,
                        2077845920
                    ],
                    [
                        5,
                        1004104096
                    ],
                    [
                        5,
                        2077845920
                    ]
                ]
            },
            "bert.encoder.layer.21.attention.output.LayerNorm.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        2080452160
                    ]
                ]
            },
            "bert.encoder.layer.21.attention.output.LayerNorm.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        2080086016
                    ]
                ]
            },
            "bert.encoder.layer.21.intermediate.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    8
                ],
                "t": 1,
                "mblock": [
                    4,
                    2
                ],
                "ublock": [
                    4,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1056368768
                    ],
                    [
                        3,
                        2130110592
                    ],
                    [
                        4,
                        1056368768
                    ],
                    [
                        4,
                        2130110592
                    ],
                    [
                        5,
                        1056368768
                    ],
                    [
                        5,
                        2130110592
                    ],
                    [
                        0,
                        787134560
                    ],
                    [
                        0,
                        2129311840
                    ],
                    [
                        1,
                        1055636576
                    ],
                    [
                        1,
                        2129378400
                    ],
                    [
                        2,
                        1055636576
                    ],
                    [
                        2,
                        2129378400
                    ],
                    [
                        3,
                        1055836256
                    ],
                    [
                        3,
                        2129578080
                    ],
                    [
                        4,
                        1055836256
                    ],
                    [
                        4,
                        2129578080
                    ]
                ]
            },
            "bert.encoder.layer.21.intermediate.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    8
                ],
                "t": 1,
                "mblock": [
                    1,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1004612416
                    ],
                    [
                        5,
                        2078354240
                    ],
                    [
                        0,
                        735577888
                    ],
                    [
                        0,
                        2077755168
                    ],
                    [
                        1,
                        1004246304
                    ],
                    [
                        1,
                        2077988128
                    ],
                    [
                        2,
                        1004279584
                    ],
                    [
                        2,
                        2078021408
                    ]
                ]
            },
            "bert.encoder.layer.21.output.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    8
                ],
                "t": 1,
                "mblock": [
                    8,
                    1
                ],
                "ublock": [
                    8,
                    4
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1058498816
                    ],
                    [
                        3,
                        2132240640
                    ],
                    [
                        4,
                        1058498816
                    ],
                    [
                        4,
                        2132240640
                    ],
                    [
                        5,
                        1058498816
                    ],
                    [
                        5,
                        2132240640
                    ],
                    [
                        0,
                        789264608
                    ],
                    [
                        0,
                        2131441888
                    ],
                    [
                        1,
                        1057766624
                    ],
                    [
                        1,
                        2131508448
                    ],
                    [
                        2,
                        1057766624
                    ],
                    [
                        2,
                        2131508448
                    ],
                    [
                        3,
                        1057966304
                    ],
                    [
                        3,
                        2131708128
                    ],
                    [
                        4,
                        1057966304
                    ],
                    [
                        4,
                        2131708128
                    ]
                ]
            },
            "bert.encoder.layer.21.output.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    8
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    4
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1003762272
                    ],
                    [
                        3,
                        2077504096
                    ],
                    [
                        4,
                        1003845472
                    ],
                    [
                        4,
                        2077587296
                    ],
                    [
                        5,
                        1003845472
                    ],
                    [
                        5,
                        2077587296
                    ],
                    [
                        0,
                        734810944
                    ],
                    [
                        0,
                        2076988224
                    ]
                ]
            },
            "bert.encoder.layer.21.output.LayerNorm.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        2079952832
                    ]
                ]
            },
            "bert.encoder.layer.21.output.LayerNorm.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1006077824
                    ]
                ]
            },
            "bert.encoder.layer.22.attention.self.query.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    4,
                    2
                ],
                "t": 1,
                "mblock": [
                    2,
                    2
                ],
                "ublock": [
                    4,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1012968064
                    ],
                    [
                        3,
                        2086709888
                    ],
                    [
                        4,
                        1012968064
                    ],
                    [
                        4,
                        2086709888
                    ],
                    [
                        5,
                        1012968064
                    ],
                    [
                        5,
                        2086709888
                    ],
                    [
                        0,
                        743866976
                    ],
                    [
                        0,
                        2086044256
                    ]
                ]
            },
            "bert.encoder.layer.22.attention.self.query.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    2
                ],
                "t": 1,
                "mblock": [
                    1,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1004346208
                    ],
                    [
                        2,
                        2078088032
                    ]
                ]
            },
            "bert.encoder.layer.22.attention.self.key.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    4,
                    2
                ],
                "t": 1,
                "mblock": [
                    2,
                    2
                ],
                "ublock": [
                    4,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1012502112
                    ],
                    [
                        1,
                        2086243936
                    ],
                    [
                        2,
                        1012502112
                    ],
                    [
                        2,
                        2086243936
                    ],
                    [
                        3,
                        1012701792
                    ],
                    [
                        3,
                        2086443616
                    ],
                    [
                        4,
                        1012701792
                    ],
                    [
                        4,
                        2086443616
                    ]
                ]
            },
            "bert.encoder.layer.22.attention.self.key.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    2
                ],
                "t": 1,
                "mblock": [
                    1,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1004312928
                    ],
                    [
                        1,
                        2078054752
                    ]
                ]
            },
            "bert.encoder.layer.22.attention.self.value.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    2,
                    1
                ],
                "ublock": [
                    8,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        2084712896
                    ],
                    [
                        1,
                        1011170752
                    ],
                    [
                        1,
                        2084912576
                    ],
                    [
                        2,
                        1011170752
                    ],
                    [
                        2,
                        2084912576
                    ],
                    [
                        3,
                        1011370432
                    ],
                    [
                        3,
                        2085112256
                    ],
                    [
                        4,
                        1011370432
                    ]
                ]
            },
            "bert.encoder.layer.22.attention.self.value.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1003746240
                    ],
                    [
                        2,
                        2077488064
                    ],
                    [
                        3,
                        1003979200
                    ],
                    [
                        3,
                        2077721024
                    ]
                ]
            },
            "bert.encoder.layer.22.attention.output.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    8,
                    1
                ],
                "ublock": [
                    2,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        2098692128
                    ],
                    [
                        4,
                        1024950304
                    ],
                    [
                        4,
                        2098692128
                    ],
                    [
                        5,
                        1024950304
                    ],
                    [
                        5,
                        2098692128
                    ],
                    [
                        0,
                        755849216
                    ],
                    [
                        0,
                        2098026496
                    ],
                    [
                        1,
                        1024484352
                    ]
                ]
            },
            "bert.encoder.layer.22.attention.output.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        735002880
                    ],
                    [
                        0,
                        2077180160
                    ],
                    [
                        1,
                        1003671296
                    ],
                    [
                        1,
                        2077413120
                    ]
                ]
            },
            "bert.encoder.layer.22.attention.output.LayerNorm.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        2080119200
                    ]
                ]
            },
            "bert.encoder.layer.22.attention.output.LayerNorm.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1006377376
                    ]
                ]
            },
            "bert.encoder.layer.22.intermediate.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    8
                ],
                "t": 1,
                "mblock": [
                    4,
                    2
                ],
                "ublock": [
                    4,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1034535776
                    ],
                    [
                        5,
                        2108277600
                    ],
                    [
                        0,
                        765301568
                    ],
                    [
                        0,
                        2107478848
                    ],
                    [
                        1,
                        1033803584
                    ],
                    [
                        1,
                        2107545408
                    ],
                    [
                        2,
                        1033803584
                    ],
                    [
                        2,
                        2107545408
                    ],
                    [
                        3,
                        1034003264
                    ],
                    [
                        3,
                        2107745088
                    ],
                    [
                        4,
                        1034003264
                    ],
                    [
                        4,
                        2107745088
                    ],
                    [
                        5,
                        1034003264
                    ],
                    [
                        5,
                        2107745088
                    ],
                    [
                        0,
                        764769056
                    ],
                    [
                        0,
                        2106946336
                    ]
                ]
            },
            "bert.encoder.layer.22.intermediate.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    8
                ],
                "t": 1,
                "mblock": [
                    1,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1004445920
                    ],
                    [
                        3,
                        2078187744
                    ],
                    [
                        4,
                        1004512480
                    ],
                    [
                        4,
                        2078254304
                    ],
                    [
                        5,
                        1004512480
                    ],
                    [
                        5,
                        2078254304
                    ],
                    [
                        0,
                        735477952
                    ],
                    [
                        0,
                        2077655232
                    ]
                ]
            },
            "bert.encoder.layer.22.output.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    8
                ],
                "t": 1,
                "mblock": [
                    8,
                    1
                ],
                "ublock": [
                    8,
                    4
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1037531168
                    ],
                    [
                        1,
                        2111272992
                    ],
                    [
                        2,
                        1037531168
                    ],
                    [
                        2,
                        2111272992
                    ],
                    [
                        3,
                        1037730848
                    ],
                    [
                        3,
                        2111472672
                    ],
                    [
                        4,
                        1037730848
                    ],
                    [
                        4,
                        2111472672
                    ],
                    [
                        5,
                        1037730848
                    ],
                    [
                        5,
                        2111472672
                    ],
                    [
                        0,
                        768496640
                    ],
                    [
                        0,
                        2110673920
                    ],
                    [
                        1,
                        1036998656
                    ],
                    [
                        1,
                        2110740480
                    ],
                    [
                        2,
                        1036998656
                    ],
                    [
                        2,
                        2110740480
                    ]
                ]
            },
            "bert.encoder.layer.22.output.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    8
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    4
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1003912288
                    ],
                    [
                        4,
                        2077654112
                    ],
                    [
                        5,
                        1003912288
                    ],
                    [
                        5,
                        2077654112
                    ],
                    [
                        0,
                        734877760
                    ],
                    [
                        0,
                        2077055040
                    ],
                    [
                        1,
                        1003546176
                    ],
                    [
                        1,
                        2077288000
                    ]
                ]
            },
            "bert.encoder.layer.22.output.LayerNorm.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        2079886240
                    ]
                ]
            },
            "bert.encoder.layer.22.output.LayerNorm.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1006211008
                    ]
                ]
            },
            "bert.encoder.layer.23.attention.self.query.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    2,
                    1
                ],
                "ublock": [
                    8,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1020423680
                    ],
                    [
                        4,
                        2094165504
                    ],
                    [
                        5,
                        1020423680
                    ],
                    [
                        5,
                        2094165504
                    ],
                    [
                        0,
                        751322592
                    ],
                    [
                        0,
                        2093499872
                    ],
                    [
                        1,
                        1019957728
                    ],
                    [
                        1,
                        2093699552
                    ]
                ]
            },
            "bert.encoder.layer.23.attention.self.query.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1004029664
                    ],
                    [
                        2,
                        2077771488
                    ],
                    [
                        3,
                        1004262624
                    ],
                    [
                        3,
                        2078004448
                    ]
                ]
            },
            "bert.encoder.layer.23.attention.self.key.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    2,
                    1
                ],
                "ublock": [
                    8,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        2094964320
                    ],
                    [
                        5,
                        1021222496
                    ],
                    [
                        5,
                        2094964320
                    ],
                    [
                        0,
                        752121408
                    ],
                    [
                        0,
                        2094298688
                    ],
                    [
                        1,
                        1020756544
                    ],
                    [
                        1,
                        2094498368
                    ],
                    [
                        2,
                        1020756544
                    ]
                ]
            },
            "bert.encoder.layer.23.attention.self.key.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        735336320
                    ],
                    [
                        0,
                        2077513600
                    ],
                    [
                        1,
                        1004004736
                    ],
                    [
                        1,
                        2077746560
                    ]
                ]
            },
            "bert.encoder.layer.23.attention.self.value.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    2,
                    1
                ],
                "ublock": [
                    8,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1019957728
                    ],
                    [
                        2,
                        2093699552
                    ],
                    [
                        3,
                        1020157408
                    ],
                    [
                        3,
                        2093899232
                    ],
                    [
                        4,
                        1020157408
                    ],
                    [
                        4,
                        2093899232
                    ],
                    [
                        5,
                        1020157408
                    ],
                    [
                        5,
                        2093899232
                    ]
                ]
            },
            "bert.encoder.layer.23.attention.self.value.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1003912960
                    ],
                    [
                        2,
                        2077654784
                    ],
                    [
                        3,
                        1004145920
                    ],
                    [
                        3,
                        2077887744
                    ]
                ]
            },
            "bert.encoder.layer.23.attention.output.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    8,
                    1
                ],
                "ublock": [
                    2,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1019358592
                    ],
                    [
                        4,
                        2093100416
                    ],
                    [
                        5,
                        1019358592
                    ],
                    [
                        5,
                        2093100416
                    ],
                    [
                        0,
                        750257504
                    ],
                    [
                        0,
                        2092434784
                    ],
                    [
                        1,
                        1018892640
                    ],
                    [
                        1,
                        2092634464
                    ]
                ]
            },
            "bert.encoder.layer.23.attention.output.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    4
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1004254144
                    ],
                    [
                        4,
                        2077995968
                    ],
                    [
                        5,
                        1004254144
                    ],
                    [
                        5,
                        2077995968
                    ]
                ]
            },
            "bert.encoder.layer.23.attention.output.LayerNorm.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        737542592
                    ]
                ]
            },
            "bert.encoder.layer.23.attention.output.LayerNorm.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        2080318944
                    ]
                ]
            },
            "bert.encoder.layer.23.intermediate.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    8
                ],
                "t": 1,
                "mblock": [
                    4,
                    2
                ],
                "ublock": [
                    4,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1040925920
                    ],
                    [
                        5,
                        2114667744
                    ],
                    [
                        0,
                        771691712
                    ],
                    [
                        0,
                        2113868992
                    ],
                    [
                        1,
                        1040193728
                    ],
                    [
                        1,
                        2113935552
                    ],
                    [
                        2,
                        1040193728
                    ],
                    [
                        2,
                        2113935552
                    ],
                    [
                        3,
                        1040393408
                    ],
                    [
                        3,
                        2114135232
                    ],
                    [
                        4,
                        1040393408
                    ],
                    [
                        4,
                        2114135232
                    ],
                    [
                        5,
                        1040393408
                    ],
                    [
                        5,
                        2114135232
                    ],
                    [
                        0,
                        771159200
                    ],
                    [
                        0,
                        2113336480
                    ]
                ]
            },
            "bert.encoder.layer.23.intermediate.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    8
                ],
                "t": 1,
                "mblock": [
                    1,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1004212992
                    ],
                    [
                        1,
                        2077954816
                    ],
                    [
                        2,
                        1004246272
                    ],
                    [
                        2,
                        2077988096
                    ],
                    [
                        3,
                        1004479232
                    ],
                    [
                        3,
                        2078221056
                    ],
                    [
                        4,
                        1004545792
                    ],
                    [
                        4,
                        2078287616
                    ]
                ]
            },
            "bert.encoder.layer.23.output.dense.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    2,
                    8
                ],
                "t": 1,
                "mblock": [
                    8,
                    1
                ],
                "ublock": [
                    8,
                    4
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1035401120
                    ],
                    [
                        1,
                        2109142944
                    ],
                    [
                        2,
                        1035401120
                    ],
                    [
                        2,
                        2109142944
                    ],
                    [
                        3,
                        1035600800
                    ],
                    [
                        3,
                        2109342624
                    ],
                    [
                        4,
                        1035600800
                    ],
                    [
                        4,
                        2109342624
                    ],
                    [
                        5,
                        1035600800
                    ],
                    [
                        5,
                        2109342624
                    ],
                    [
                        0,
                        766366592
                    ],
                    [
                        0,
                        2108543872
                    ],
                    [
                        1,
                        1034868608
                    ],
                    [
                        1,
                        2108610432
                    ],
                    [
                        2,
                        1034868608
                    ],
                    [
                        2,
                        2108610432
                    ]
                ]
            },
            "bert.encoder.layer.23.output.dense.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    8
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    4
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        2077420576
                    ],
                    [
                        4,
                        1003761952
                    ],
                    [
                        4,
                        2077503776
                    ],
                    [
                        5,
                        1003761952
                    ],
                    [
                        5,
                        2077503776
                    ],
                    [
                        0,
                        734727424
                    ],
                    [
                        0,
                        2076904704
                    ],
                    [
                        1,
                        1003395840
                    ]
                ]
            },
            "bert.encoder.layer.23.output.LayerNorm.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1006577120
                    ]
                ]
            },
            "bert.encoder.layer.23.output.LayerNorm.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        2080318944
                    ]
                ]
            },
            "qa_outputs.weight": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    8,
                    1
                ],
                "ublock": [
                    4,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1006577120
                    ]
                ]
            },
            "qa_outputs.bias": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1003362048
                    ]
                ]
            },
            "qa_outputs.weight_fork_clone19": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    8,
                    1
                ],
                "ublock": [
                    4,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        2080252384
                    ]
                ]
            },
            "qa_outputs.bias_fork_clone12": {
                "input": "HOST",
                "type": "ram",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        2077338944
                    ]
                ]
            },
            "lc.input_tensor.layernorm_0.dc.reduce_sum.0.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        2077415776
                    ]
                ]
            },
            "dc.input_tensor.layernorm_0.1": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    4,
                    1
                ],
                "t": 1,
                "mblock": [
                    3,
                    4
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1009040544
                    ],
                    [
                        4,
                        2082782368
                    ],
                    [
                        5,
                        1009040544
                    ],
                    [
                        5,
                        2082782368
                    ]
                ]
            },
            "lc.input_tensor.layernorm_0.dc.reduce_sum.5.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1003364160
                    ]
                ]
            },
            "dc.input_tensor.layernorm_0.6": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    4,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    3,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1003730624
                    ],
                    [
                        4,
                        2077472448
                    ],
                    [
                        5,
                        1003730624
                    ],
                    [
                        5,
                        2077472448
                    ]
                ]
            },
            "dc.input_tensor.layernorm_0.8": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    4,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    3,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        734696096
                    ],
                    [
                        0,
                        2076873376
                    ],
                    [
                        1,
                        1003364512
                    ],
                    [
                        1,
                        2077106336
                    ]
                ]
            },
            "input_1_multiply_18": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1003676064
                    ]
                ]
            },
            "input_0_subtract_21": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1003355712
                    ]
                ]
            },
            "input_1_multiply_22": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1003314176
                    ]
                ]
            },
            "lc.input_tensor.softmax_24.dc.reduce_sum.3.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1003359936
                    ]
                ]
            },
            "dc.input_tensor.softmax_24.4": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 16,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1008641152
                    ],
                    [
                        2,
                        2082382976
                    ]
                ]
            },
            "lc.input_tensor.layernorm_44.dc.reduce_sum.0.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        2076823040
                    ]
                ]
            },
            "dc.input_tensor.layernorm_44.1": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    6,
                    4
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1028478400
                    ],
                    [
                        2,
                        2102220224
                    ]
                ]
            },
            "lc.input_tensor.layernorm_44.dc.reduce_sum.5.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        2077053888
                    ]
                ]
            },
            "dc.input_tensor.layernorm_44.6": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1003617088
                    ],
                    [
                        1,
                        2077358912
                    ]
                ]
            },
            "dc.input_tensor.layernorm_44.8": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1003891648
                    ],
                    [
                        3,
                        2077633472
                    ]
                ]
            },
            "lc.input_tensor.layernorm_58.dc.reduce_sum.0.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1003678176
                    ]
                ]
            },
            "dc.input_tensor.layernorm_58.1": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    1
                ],
                "t": 1,
                "mblock": [
                    4,
                    4
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        2100289760
                    ],
                    [
                        0,
                        757446848
                    ],
                    [
                        0,
                        2099624128
                    ]
                ]
            },
            "lc.input_tensor.layernorm_58.dc.reduce_sum.5.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        2077101760
                    ]
                ]
            },
            "dc.input_tensor.layernorm_58.6": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    4,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1003454304
                    ],
                    [
                        1,
                        2077196128
                    ],
                    [
                        2,
                        1003495904
                    ]
                ]
            },
            "dc.input_tensor.layernorm_58.8": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    4,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1003429248
                    ],
                    [
                        1,
                        2077171072
                    ],
                    [
                        2,
                        1003470848
                    ]
                ]
            },
            "input_1_multiply_75": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1003588672
                    ]
                ]
            },
            "lc.input_tensor.softmax_77.dc.reduce_sum.3.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1003595008
                    ]
                ]
            },
            "dc.input_tensor.softmax_77.4": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    1
                ],
                "t": 16,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    4,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        2081384352
                    ],
                    [
                        3,
                        1007842208
                    ],
                    [
                        3,
                        2081584032
                    ]
                ]
            },
            "lc.input_tensor.layernorm_97.dc.reduce_sum.0.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        2077097536
                    ]
                ]
            },
            "dc.input_tensor.layernorm_97.1": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    2
                ],
                "t": 1,
                "mblock": [
                    12,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1028877792
                    ],
                    [
                        1,
                        2102619616
                    ]
                ]
            },
            "lc.input_tensor.layernorm_97.dc.reduce_sum.5.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        2077424224
                    ]
                ]
            },
            "dc.input_tensor.layernorm_97.6": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1003970688
                    ],
                    [
                        4,
                        2077712512
                    ]
                ]
            },
            "dc.input_tensor.layernorm_97.8": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1003671200
                    ],
                    [
                        2,
                        2077413024
                    ]
                ]
            },
            "lc.input_tensor.layernorm_111.dc.reduce_sum.0.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        2077422112
                    ]
                ]
            },
            "dc.input_tensor.layernorm_111.1": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    2
                ],
                "t": 1,
                "mblock": [
                    12,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1027879296
                    ],
                    [
                        5,
                        2101621120
                    ]
                ]
            },
            "lc.input_tensor.layernorm_111.dc.reduce_sum.5.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        2077424224
                    ]
                ]
            },
            "dc.input_tensor.layernorm_111.6": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    6,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    2,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1003374656
                    ],
                    [
                        2,
                        2077116480
                    ],
                    [
                        3,
                        1003607616
                    ],
                    [
                        3,
                        2077349440
                    ],
                    [
                        4,
                        1003692896
                    ],
                    [
                        4,
                        2077434720
                    ]
                ]
            },
            "dc.input_tensor.layernorm_111.8": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    6,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    2,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1003697088
                    ],
                    [
                        5,
                        2077438912
                    ],
                    [
                        0,
                        734662560
                    ],
                    [
                        0,
                        2076839840
                    ],
                    [
                        1,
                        1003330976
                    ],
                    [
                        1,
                        2077072800
                    ]
                ]
            },
            "input_1_multiply_128": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        2077084864
                    ]
                ]
            },
            "lc.input_tensor.softmax_130.dc.reduce_sum.3.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1003343040
                    ]
                ]
            },
            "dc.input_tensor.softmax_130.4": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 16,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1008641152
                    ],
                    [
                        1,
                        2082382976
                    ]
                ]
            },
            "lc.input_tensor.layernorm_150.dc.reduce_sum.0.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1003663392
                    ]
                ]
            },
            "dc.input_tensor.layernorm_150.1": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    6,
                    4
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1028478400
                    ],
                    [
                        1,
                        2102220224
                    ]
                ]
            },
            "lc.input_tensor.layernorm_150.dc.reduce_sum.5.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        2077405216
                    ]
                ]
            },
            "dc.input_tensor.layernorm_150.6": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1003970688
                    ],
                    [
                        5,
                        2077712512
                    ]
                ]
            },
            "dc.input_tensor.layernorm_150.8": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        734923648
                    ],
                    [
                        0,
                        2077100928
                    ]
                ]
            },
            "lc.input_tensor.layernorm_164.dc.reduce_sum.0.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        2076808256
                    ]
                ]
            },
            "dc.input_tensor.layernorm_164.1": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    1
                ],
                "t": 1,
                "mblock": [
                    4,
                    4
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        745198336
                    ],
                    [
                        0,
                        2087375616
                    ],
                    [
                        1,
                        1013833472
                    ]
                ]
            },
            "lc.input_tensor.layernorm_164.dc.reduce_sum.5.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        734628864
                    ]
                ]
            },
            "dc.input_tensor.layernorm_164.6": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    4,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        2077570592
                    ],
                    [
                        5,
                        1003828768
                    ],
                    [
                        5,
                        2077570592
                    ]
                ]
            },
            "dc.input_tensor.layernorm_164.8": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    4,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        734794240
                    ],
                    [
                        0,
                        2076971520
                    ],
                    [
                        1,
                        1003462656
                    ]
                ]
            },
            "input_1_multiply_181": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        2076801920
                    ]
                ]
            },
            "lc.input_tensor.softmax_183.dc.reduce_sum.3.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        2077403104
                    ]
                ]
            },
            "dc.input_tensor.softmax_183.4": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    1
                ],
                "t": 16,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    4,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1008041984
                    ],
                    [
                        1,
                        2081783808
                    ],
                    [
                        2,
                        1008041984
                    ]
                ]
            },
            "lc.input_tensor.layernorm_203.dc.reduce_sum.0.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        2077400992
                    ]
                ]
            },
            "dc.input_tensor.layernorm_203.1": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    2
                ],
                "t": 1,
                "mblock": [
                    12,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1030874752
                    ],
                    [
                        1,
                        2104616576
                    ]
                ]
            },
            "lc.input_tensor.layernorm_203.dc.reduce_sum.5.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        2077315712
                    ]
                ]
            },
            "dc.input_tensor.layernorm_203.6": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1003658688
                    ],
                    [
                        2,
                        2077400512
                    ]
                ]
            },
            "dc.input_tensor.layernorm_203.8": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1003916672
                    ],
                    [
                        3,
                        2077658496
                    ]
                ]
            },
            "lc.input_tensor.layernorm_217.dc.reduce_sum.0.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        2077411552
                    ]
                ]
            },
            "dc.input_tensor.layernorm_217.1": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    2
                ],
                "t": 1,
                "mblock": [
                    12,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1029476864
                    ],
                    [
                        3,
                        2103218688
                    ]
                ]
            },
            "lc.input_tensor.layernorm_217.dc.reduce_sum.5.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1003669728
                    ]
                ]
            },
            "dc.input_tensor.layernorm_217.6": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    6,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    2,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1003378848
                    ],
                    [
                        2,
                        2077120672
                    ],
                    [
                        3,
                        1003611808
                    ],
                    [
                        3,
                        2077353632
                    ],
                    [
                        4,
                        1003697088
                    ],
                    [
                        4,
                        2077438912
                    ]
                ]
            },
            "dc.input_tensor.layernorm_217.8": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    6,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    2,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1003688704
                    ],
                    [
                        5,
                        2077430528
                    ],
                    [
                        0,
                        734654176
                    ],
                    [
                        0,
                        2076831456
                    ],
                    [
                        1,
                        1003322592
                    ],
                    [
                        1,
                        2077064416
                    ]
                ]
            },
            "input_1_multiply_234": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        2077047552
                    ]
                ]
            },
            "lc.input_tensor.softmax_236.dc.reduce_sum.3.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1003307840
                    ]
                ]
            },
            "dc.input_tensor.softmax_236.4": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 16,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        739806304
                    ],
                    [
                        0,
                        2081983584
                    ]
                ]
            },
            "lc.input_tensor.layernorm_256.dc.reduce_sum.0.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        2077413664
                    ]
                ]
            },
            "dc.input_tensor.layernorm_256.1": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    6,
                    4
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1030475360
                    ],
                    [
                        2,
                        2104217184
                    ]
                ]
            },
            "lc.input_tensor.layernorm_256.dc.reduce_sum.5.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1003671840
                    ]
                ]
            },
            "dc.input_tensor.layernorm_256.6": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1003983200
                    ],
                    [
                        4,
                        2077725024
                    ]
                ]
            },
            "dc.input_tensor.layernorm_256.8": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1003904160
                    ],
                    [
                        3,
                        2077645984
                    ]
                ]
            },
            "lc.input_tensor.layernorm_270.dc.reduce_sum.0.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1003665504
                    ]
                ]
            },
            "dc.input_tensor.layernorm_270.1": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    1
                ],
                "t": 1,
                "mblock": [
                    4,
                    4
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        2086510208
                    ],
                    [
                        2,
                        1012768384
                    ],
                    [
                        2,
                        2086510208
                    ]
                ]
            },
            "lc.input_tensor.layernorm_270.dc.reduce_sum.5.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1003665504
                    ]
                ]
            },
            "dc.input_tensor.layernorm_270.6": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    4,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1003445792
                    ],
                    [
                        2,
                        2077187616
                    ],
                    [
                        3,
                        1003678752
                    ]
                ]
            },
            "dc.input_tensor.layernorm_270.8": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    4,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1003370784
                    ],
                    [
                        1,
                        2077112608
                    ],
                    [
                        2,
                        1003412384
                    ]
                ]
            },
            "input_1_multiply_287": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1003667616
                    ]
                ]
            },
            "lc.input_tensor.softmax_289.dc.reduce_sum.3.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        2077409440
                    ]
                ]
            },
            "dc.input_tensor.softmax_289.4": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    1
                ],
                "t": 16,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    4,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1008441376
                    ],
                    [
                        4,
                        2082183200
                    ],
                    [
                        5,
                        1008441376
                    ]
                ]
            },
            "lc.input_tensor.layernorm_309.dc.reduce_sum.0.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        2077091200
                    ]
                ]
            },
            "dc.input_tensor.layernorm_309.1": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    2
                ],
                "t": 1,
                "mblock": [
                    12,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1030675040
                    ],
                    [
                        5,
                        2104416864
                    ]
                ]
            },
            "lc.input_tensor.layernorm_309.dc.reduce_sum.5.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        2077045440
                    ]
                ]
            },
            "dc.input_tensor.layernorm_309.6": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        734961184
                    ],
                    [
                        0,
                        2077138464
                    ]
                ]
            },
            "dc.input_tensor.layernorm_309.8": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1003629600
                    ],
                    [
                        1,
                        2077371424
                    ]
                ]
            },
            "lc.input_tensor.layernorm_323.dc.reduce_sum.0.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1003582336
                    ]
                ]
            },
            "dc.input_tensor.layernorm_323.1": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    2
                ],
                "t": 1,
                "mblock": [
                    12,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        761041440
                    ],
                    [
                        0,
                        2103218720
                    ]
                ]
            },
            "lc.input_tensor.layernorm_323.dc.reduce_sum.5.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        2077409440
                    ]
                ]
            },
            "dc.input_tensor.layernorm_323.6": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    6,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    2,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1003726432
                    ],
                    [
                        5,
                        2077468256
                    ],
                    [
                        0,
                        734691904
                    ],
                    [
                        0,
                        2076869184
                    ],
                    [
                        1,
                        1003360320
                    ],
                    [
                        1,
                        2077102144
                    ]
                ]
            },
            "dc.input_tensor.layernorm_323.8": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    6,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    2,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1003709664
                    ],
                    [
                        5,
                        2077451488
                    ],
                    [
                        0,
                        734675136
                    ],
                    [
                        0,
                        2076852416
                    ],
                    [
                        1,
                        1003343552
                    ],
                    [
                        1,
                        2077085376
                    ]
                ]
            },
            "input_1_multiply_340": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1003347264
                    ]
                ]
            },
            "lc.input_tensor.softmax_342.dc.reduce_sum.3.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        2077407328
                    ]
                ]
            },
            "dc.input_tensor.softmax_342.4": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 16,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1008441440
                    ],
                    [
                        2,
                        2082183264
                    ]
                ]
            },
            "lc.input_tensor.layernorm_362.dc.reduce_sum.0.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1003305728
                    ]
                ]
            },
            "dc.input_tensor.layernorm_362.1": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    6,
                    4
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1029676576
                    ],
                    [
                        1,
                        2103418400
                    ]
                ]
            },
            "lc.input_tensor.layernorm_362.dc.reduce_sum.5.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1003353600
                    ]
                ]
            },
            "dc.input_tensor.layernorm_362.6": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1003579552
                    ],
                    [
                        1,
                        2077321376
                    ]
                ]
            },
            "dc.input_tensor.layernorm_362.8": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        734911136
                    ],
                    [
                        0,
                        2077088416
                    ]
                ]
            },
            "lc.input_tensor.layernorm_376.dc.reduce_sum.0.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1003351488
                    ]
                ]
            },
            "dc.input_tensor.layernorm_376.1": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    1
                ],
                "t": 1,
                "mblock": [
                    4,
                    4
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1023352672
                    ],
                    [
                        5,
                        2097094496
                    ],
                    [
                        0,
                        754251584
                    ]
                ]
            },
            "lc.input_tensor.layernorm_376.dc.reduce_sum.5.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        2077093312
                    ]
                ]
            },
            "dc.input_tensor.layernorm_376.6": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    4,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1003862176
                    ],
                    [
                        4,
                        2077604000
                    ],
                    [
                        5,
                        1003862176
                    ]
                ]
            },
            "dc.input_tensor.layernorm_376.8": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    4,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        2077629056
                    ],
                    [
                        0,
                        734852704
                    ],
                    [
                        0,
                        2077029984
                    ]
                ]
            },
            "input_1_multiply_393": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        2076804032
                    ]
                ]
            },
            "lc.input_tensor.softmax_395.dc.reduce_sum.3.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        2077036992
                    ]
                ]
            },
            "dc.input_tensor.softmax_395.4": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    1
                ],
                "t": 16,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    4,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1008308224
                    ],
                    [
                        4,
                        2082050048
                    ],
                    [
                        5,
                        1008308224
                    ]
                ]
            },
            "lc.input_tensor.layernorm_415.dc.reduce_sum.0.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1003340928
                    ]
                ]
            },
            "dc.input_tensor.layernorm_415.1": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    2
                ],
                "t": 1,
                "mblock": [
                    12,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1031074432
                    ],
                    [
                        4,
                        2104816256
                    ]
                ]
            },
            "lc.input_tensor.layernorm_415.dc.reduce_sum.5.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        2077082752
                    ]
                ]
            },
            "dc.input_tensor.layernorm_415.6": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1003621152
                    ],
                    [
                        2,
                        2077362976
                    ]
                ]
            },
            "dc.input_tensor.layernorm_415.8": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1003933152
                    ],
                    [
                        5,
                        2077674976
                    ]
                ]
            },
            "lc.input_tensor.layernorm_429.dc.reduce_sum.0.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1003338816
                    ]
                ]
            },
            "dc.input_tensor.layernorm_429.1": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    2
                ],
                "t": 1,
                "mblock": [
                    12,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1029277184
                    ],
                    [
                        1,
                        2103019008
                    ]
                ]
            },
            "lc.input_tensor.layernorm_429.dc.reduce_sum.5.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        2077080640
                    ]
                ]
            },
            "dc.input_tensor.layernorm_429.6": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    6,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    2,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1003387232
                    ],
                    [
                        2,
                        2077129056
                    ],
                    [
                        3,
                        1003620192
                    ],
                    [
                        3,
                        2077362016
                    ],
                    [
                        4,
                        1003705472
                    ],
                    [
                        4,
                        2077447296
                    ]
                ]
            },
            "dc.input_tensor.layernorm_429.8": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    6,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    2,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1003705472
                    ],
                    [
                        5,
                        2077447296
                    ],
                    [
                        0,
                        734670944
                    ],
                    [
                        0,
                        2076848224
                    ],
                    [
                        1,
                        1003339360
                    ],
                    [
                        1,
                        2077081184
                    ]
                ]
            },
            "input_1_multiply_446": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1003578112
                    ]
                ]
            },
            "lc.input_tensor.softmax_448.dc.reduce_sum.3.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        2077319936
                    ]
                ]
            },
            "dc.input_tensor.softmax_448.4": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 16,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1008840864
                    ],
                    [
                        1,
                        2082582688
                    ]
                ]
            },
            "lc.input_tensor.layernorm_468.dc.reduce_sum.0.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        2076806144
                    ]
                ]
            },
            "dc.input_tensor.layernorm_468.1": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    6,
                    4
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1029676576
                    ],
                    [
                        2,
                        2103418400
                    ]
                ]
            },
            "lc.input_tensor.layernorm_468.dc.reduce_sum.5.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        2077039104
                    ]
                ]
            },
            "dc.input_tensor.layernorm_468.6": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1003596128
                    ],
                    [
                        2,
                        2077337952
                    ]
                ]
            },
            "dc.input_tensor.layernorm_468.8": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1003554528
                    ],
                    [
                        1,
                        2077296352
                    ]
                ]
            },
            "lc.input_tensor.layernorm_482.dc.reduce_sum.0.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        2077400992
                    ]
                ]
            },
            "dc.input_tensor.layernorm_482.1": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    1
                ],
                "t": 1,
                "mblock": [
                    4,
                    4
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        2090171424
                    ],
                    [
                        0,
                        747328512
                    ],
                    [
                        0,
                        2089505792
                    ]
                ]
            },
            "lc.input_tensor.layernorm_482.dc.reduce_sum.5.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1003680288
                    ]
                ]
            },
            "dc.input_tensor.layernorm_482.6": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    4,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        2077562240
                    ],
                    [
                        0,
                        734785888
                    ],
                    [
                        0,
                        2076963168
                    ]
                ]
            },
            "dc.input_tensor.layernorm_482.8": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    4,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1003837120
                    ],
                    [
                        5,
                        2077578944
                    ],
                    [
                        0,
                        734802592
                    ]
                ]
            },
            "input_1_multiply_499": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        2077417888
                    ]
                ]
            },
            "lc.input_tensor.softmax_501.dc.reduce_sum.3.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        2077417888
                    ]
                ]
            },
            "dc.input_tensor.softmax_501.4": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    1
                ],
                "t": 16,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    4,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1007908768
                    ],
                    [
                        4,
                        2081650592
                    ],
                    [
                        5,
                        1007908768
                    ]
                ]
            },
            "lc.input_tensor.layernorm_521.dc.reduce_sum.0.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        734641536
                    ]
                ]
            },
            "dc.input_tensor.layernorm_521.1": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    2
                ],
                "t": 1,
                "mblock": [
                    12,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1028278688
                    ],
                    [
                        3,
                        2102020512
                    ]
                ]
            },
            "lc.input_tensor.layernorm_521.dc.reduce_sum.5.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        2077330496
                    ]
                ]
            },
            "dc.input_tensor.layernorm_521.6": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        734898624
                    ],
                    [
                        0,
                        2077075904
                    ]
                ]
            },
            "dc.input_tensor.layernorm_521.8": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1003592064
                    ],
                    [
                        1,
                        2077333888
                    ]
                ]
            },
            "lc.input_tensor.layernorm_535.dc.reduce_sum.0.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        2077099648
                    ]
                ]
            },
            "dc.input_tensor.layernorm_535.1": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    2
                ],
                "t": 1,
                "mblock": [
                    12,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        759443872
                    ],
                    [
                        0,
                        2101621152
                    ]
                ]
            },
            "lc.input_tensor.layernorm_535.dc.reduce_sum.5.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1003590784
                    ]
                ]
            },
            "dc.input_tensor.layernorm_535.6": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    6,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    2,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1003692896
                    ],
                    [
                        5,
                        2077434720
                    ],
                    [
                        0,
                        734658368
                    ],
                    [
                        0,
                        2076835648
                    ],
                    [
                        1,
                        1003326784
                    ],
                    [
                        1,
                        2077068608
                    ]
                ]
            },
            "dc.input_tensor.layernorm_535.8": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    6,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    2,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1003370464
                    ],
                    [
                        2,
                        2077112288
                    ],
                    [
                        3,
                        1003603424
                    ],
                    [
                        3,
                        2077345248
                    ],
                    [
                        4,
                        1003688704
                    ],
                    [
                        4,
                        2077430528
                    ]
                ]
            },
            "input_1_multiply_552": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1003592896
                    ]
                ]
            },
            "lc.input_tensor.softmax_554.dc.reduce_sum.3.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1003673952
                    ]
                ]
            },
            "dc.input_tensor.softmax_554.4": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 16,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1008840864
                    ],
                    [
                        2,
                        2082582688
                    ]
                ]
            },
            "lc.input_tensor.layernorm_574.dc.reduce_sum.0.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        2077105984
                    ]
                ]
            },
            "dc.input_tensor.layernorm_574.1": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    6,
                    4
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1027679616
                    ],
                    [
                        2,
                        2101421440
                    ]
                ]
            },
            "lc.input_tensor.layernorm_574.dc.reduce_sum.5.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1003682400
                    ]
                ]
            },
            "dc.input_tensor.layernorm_574.6": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1003829088
                    ],
                    [
                        3,
                        2077570912
                    ]
                ]
            },
            "dc.input_tensor.layernorm_574.8": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1003646176
                    ],
                    [
                        2,
                        2077388000
                    ]
                ]
            },
            "lc.input_tensor.layernorm_588.dc.reduce_sum.0.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1003680288
                    ]
                ]
            },
            "dc.input_tensor.layernorm_588.1": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    1
                ],
                "t": 1,
                "mblock": [
                    4,
                    4
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        2097627040
                    ],
                    [
                        4,
                        1023885216
                    ],
                    [
                        4,
                        2097627040
                    ]
                ]
            },
            "lc.input_tensor.layernorm_588.dc.reduce_sum.5.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1003316288
                    ]
                ]
            },
            "dc.input_tensor.layernorm_588.6": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    4,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        2077154208
                    ],
                    [
                        3,
                        1003645344
                    ],
                    [
                        3,
                        2077387168
                    ]
                ]
            },
            "dc.input_tensor.layernorm_588.8": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    4,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        2077195968
                    ],
                    [
                        3,
                        1003687104
                    ],
                    [
                        3,
                        2077428928
                    ]
                ]
            },
            "input_1_multiply_605": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        2077334720
                    ]
                ]
            },
            "lc.input_tensor.softmax_607.dc.reduce_sum.3.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        2077420000
                    ]
                ]
            },
            "dc.input_tensor.softmax_607.4": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    1
                ],
                "t": 16,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    4,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        2081783808
                    ],
                    [
                        3,
                        1008241664
                    ],
                    [
                        3,
                        2081983488
                    ]
                ]
            },
            "lc.input_tensor.layernorm_627.dc.reduce_sum.0.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1003357824
                    ]
                ]
            },
            "dc.input_tensor.layernorm_627.1": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    2
                ],
                "t": 1,
                "mblock": [
                    12,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1028079008
                    ],
                    [
                        2,
                        2101820832
                    ]
                ]
            },
            "lc.input_tensor.layernorm_627.dc.reduce_sum.5.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        2077332608
                    ]
                ]
            },
            "dc.input_tensor.layernorm_627.6": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1003633664
                    ],
                    [
                        2,
                        2077375488
                    ]
                ]
            },
            "dc.input_tensor.layernorm_627.8": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1003866624
                    ],
                    [
                        3,
                        2077608448
                    ]
                ]
            },
            "lc.input_tensor.layernorm_641.dc.reduce_sum.0.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        2077420000
                    ]
                ]
            },
            "dc.input_tensor.layernorm_641.1": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    2
                ],
                "t": 1,
                "mblock": [
                    12,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        759044480
                    ],
                    [
                        0,
                        2101221760
                    ]
                ]
            },
            "lc.input_tensor.layernorm_641.dc.reduce_sum.5.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        2076816704
                    ]
                ]
            },
            "dc.input_tensor.layernorm_641.6": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    6,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    2,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1003399808
                    ],
                    [
                        2,
                        2077141632
                    ],
                    [
                        3,
                        1003632768
                    ],
                    [
                        3,
                        2077374592
                    ],
                    [
                        4,
                        1003718048
                    ],
                    [
                        4,
                        2077459872
                    ]
                ]
            },
            "dc.input_tensor.layernorm_641.8": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    6,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    2,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1003722240
                    ],
                    [
                        5,
                        2077464064
                    ],
                    [
                        0,
                        734687712
                    ],
                    [
                        0,
                        2076864992
                    ],
                    [
                        1,
                        1003356128
                    ],
                    [
                        1,
                        2077097952
                    ]
                ]
            },
            "input_1_multiply_658": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1003676064
                    ]
                ]
            },
            "lc.input_tensor.softmax_660.dc.reduce_sum.3.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        2077051776
                    ]
                ]
            },
            "dc.input_tensor.softmax_660.4": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 16,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        740205728
                    ],
                    [
                        0,
                        2082383008
                    ]
                ]
            },
            "lc.input_tensor.layernorm_680.dc.reduce_sum.0.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        734647872
                    ]
                ]
            },
            "dc.input_tensor.layernorm_680.1": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    6,
                    4
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1027879296
                    ],
                    [
                        3,
                        2101621120
                    ]
                ]
            },
            "lc.input_tensor.layernorm_680.dc.reduce_sum.5.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        2076825152
                    ]
                ]
            },
            "dc.input_tensor.layernorm_680.6": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1003567040
                    ],
                    [
                        1,
                        2077308864
                    ]
                ]
            },
            "dc.input_tensor.layernorm_680.8": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1003920640
                    ],
                    [
                        4,
                        2077662464
                    ]
                ]
            },
            "lc.input_tensor.layernorm_694.dc.reduce_sum.0.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        2077422112
                    ]
                ]
            },
            "dc.input_tensor.layernorm_694.1": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    1
                ],
                "t": 1,
                "mblock": [
                    4,
                    4
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1018826048
                    ],
                    [
                        3,
                        2092567872
                    ],
                    [
                        4,
                        1018826048
                    ]
                ]
            },
            "lc.input_tensor.layernorm_694.dc.reduce_sum.5.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1003661280
                    ]
                ]
            },
            "dc.input_tensor.layernorm_694.6": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    4,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1003587776
                    ],
                    [
                        2,
                        2077329600
                    ],
                    [
                        3,
                        1003820736
                    ]
                ]
            },
            "dc.input_tensor.layernorm_694.8": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    4,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        2077604000
                    ],
                    [
                        0,
                        734827648
                    ],
                    [
                        0,
                        2077004928
                    ]
                ]
            },
            "input_1_multiply_711": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        2077317824
                    ]
                ]
            },
            "lc.input_tensor.softmax_713.dc.reduce_sum.3.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1003576000
                    ]
                ]
            },
            "dc.input_tensor.softmax_713.4": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    1
                ],
                "t": 16,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    4,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        2081650592
                    ],
                    [
                        0,
                        738874240
                    ],
                    [
                        0,
                        2081051520
                    ]
                ]
            },
            "lc.input_tensor.layernorm_733.dc.reduce_sum.0.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        2077405216
                    ]
                ]
            },
            "dc.input_tensor.layernorm_733.1": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    2
                ],
                "t": 1,
                "mblock": [
                    12,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1030675040
                    ],
                    [
                        3,
                        2104416864
                    ]
                ]
            },
            "lc.input_tensor.layernorm_733.dc.reduce_sum.5.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1003663392
                    ]
                ]
            },
            "dc.input_tensor.layernorm_733.6": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1003841600
                    ],
                    [
                        3,
                        2077583424
                    ]
                ]
            },
            "dc.input_tensor.layernorm_733.8": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1003608640
                    ],
                    [
                        2,
                        2077350464
                    ]
                ]
            },
            "lc.input_tensor.layernorm_747.dc.reduce_sum.0.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1003345152
                    ]
                ]
            },
            "dc.input_tensor.layernorm_747.1": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    2
                ],
                "t": 1,
                "mblock": [
                    12,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1030675040
                    ],
                    [
                        4,
                        2104416864
                    ]
                ]
            },
            "lc.input_tensor.layernorm_747.dc.reduce_sum.5.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1003299392
                    ]
                ]
            },
            "dc.input_tensor.layernorm_747.6": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    6,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    2,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1003383040
                    ],
                    [
                        2,
                        2077124864
                    ],
                    [
                        3,
                        1003616000
                    ],
                    [
                        3,
                        2077357824
                    ],
                    [
                        4,
                        1003701280
                    ],
                    [
                        4,
                        2077443104
                    ]
                ]
            },
            "dc.input_tensor.layernorm_747.8": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    6,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    2,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1003701280
                    ],
                    [
                        5,
                        2077443104
                    ],
                    [
                        0,
                        734666752
                    ],
                    [
                        0,
                        2076844032
                    ],
                    [
                        1,
                        1003335168
                    ],
                    [
                        1,
                        2077076992
                    ]
                ]
            },
            "input_1_multiply_764": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        2077313600
                    ]
                ]
            },
            "lc.input_tensor.softmax_766.dc.reduce_sum.3.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1003571776
                    ]
                ]
            },
            "dc.input_tensor.softmax_766.4": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 16,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1009040544
                    ],
                    [
                        3,
                        2082782368
                    ]
                ]
            },
            "lc.input_tensor.layernorm_786.dc.reduce_sum.0.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        2077034880
                    ]
                ]
            },
            "dc.input_tensor.layernorm_786.1": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    6,
                    4
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1031074432
                    ],
                    [
                        3,
                        2104816256
                    ]
                ]
            },
            "lc.input_tensor.layernorm_786.dc.reduce_sum.5.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1003659168
                    ]
                ]
            },
            "dc.input_tensor.layernorm_786.6": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1003933152
                    ],
                    [
                        4,
                        2077674976
                    ]
                ]
            },
            "dc.input_tensor.layernorm_786.8": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1003854112
                    ],
                    [
                        3,
                        2077595936
                    ]
                ]
            },
            "lc.input_tensor.layernorm_800.dc.reduce_sum.0.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1003295168
                    ]
                ]
            },
            "dc.input_tensor.layernorm_800.1": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    1
                ],
                "t": 1,
                "mblock": [
                    4,
                    4
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        2095297184
                    ],
                    [
                        2,
                        1021555360
                    ],
                    [
                        2,
                        2095297184
                    ]
                ]
            },
            "lc.input_tensor.layernorm_800.dc.reduce_sum.5.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        734635200
                    ]
                ]
            },
            "dc.input_tensor.layernorm_800.6": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    4,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        2077562560
                    ],
                    [
                        4,
                        1003903936
                    ],
                    [
                        4,
                        2077645760
                    ]
                ]
            },
            "dc.input_tensor.layernorm_800.8": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    4,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1003812384
                    ],
                    [
                        3,
                        2077554208
                    ],
                    [
                        4,
                        1003895584
                    ]
                ]
            },
            "input_1_multiply_817": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        2077326272
                    ]
                ]
            },
            "lc.input_tensor.softmax_819.dc.reduce_sum.3.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1003584448
                    ]
                ]
            },
            "dc.input_tensor.softmax_819.4": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    1
                ],
                "t": 16,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    4,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1007642528
                    ],
                    [
                        1,
                        2081384352
                    ],
                    [
                        2,
                        1007642528
                    ]
                ]
            },
            "lc.input_tensor.layernorm_839.dc.reduce_sum.0.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        2076814592
                    ]
                ]
            },
            "dc.input_tensor.layernorm_839.1": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    2
                ],
                "t": 1,
                "mblock": [
                    12,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1031074432
                    ],
                    [
                        5,
                        2104816256
                    ]
                ]
            },
            "lc.input_tensor.layernorm_839.dc.reduce_sum.5.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        2077413664
                    ]
                ]
            },
            "dc.input_tensor.layernorm_839.6": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1003945664
                    ],
                    [
                        4,
                        2077687488
                    ]
                ]
            },
            "dc.input_tensor.layernorm_839.8": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1003945664
                    ],
                    [
                        5,
                        2077687488
                    ]
                ]
            },
            "lc.input_tensor.layernorm_853.dc.reduce_sum.0.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        2077328384
                    ]
                ]
            },
            "dc.input_tensor.layernorm_853.1": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    2
                ],
                "t": 1,
                "mblock": [
                    12,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1031274144
                    ],
                    [
                        1,
                        2105015968
                    ]
                ]
            },
            "lc.input_tensor.layernorm_853.dc.reduce_sum.5.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        2077049664
                    ]
                ]
            },
            "dc.input_tensor.layernorm_853.6": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    6,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    2,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1003366272
                    ],
                    [
                        2,
                        2077108096
                    ],
                    [
                        3,
                        1003599232
                    ],
                    [
                        3,
                        2077341056
                    ],
                    [
                        4,
                        1003684512
                    ],
                    [
                        4,
                        2077426336
                    ]
                ]
            },
            "dc.input_tensor.layernorm_853.8": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    6,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    2,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1003684512
                    ],
                    [
                        5,
                        2077426336
                    ],
                    [
                        0,
                        734649984
                    ],
                    [
                        0,
                        2076827264
                    ],
                    [
                        1,
                        1003318400
                    ],
                    [
                        1,
                        2077060224
                    ]
                ]
            },
            "input_1_multiply_870": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1003580224
                    ]
                ]
            },
            "lc.input_tensor.softmax_872.dc.reduce_sum.3.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        2077089088
                    ]
                ]
            },
            "dc.input_tensor.softmax_872.4": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 16,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1008840832
                    ],
                    [
                        3,
                        2082582656
                    ]
                ]
            },
            "lc.input_tensor.layernorm_892.dc.reduce_sum.0.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        2077043328
                    ]
                ]
            },
            "dc.input_tensor.layernorm_892.1": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    6,
                    4
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1029876256
                    ],
                    [
                        4,
                        2103618080
                    ]
                ]
            },
            "lc.input_tensor.layernorm_892.dc.reduce_sum.5.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        2076812480
                    ]
                ]
            },
            "dc.input_tensor.layernorm_892.6": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        734886112
                    ],
                    [
                        0,
                        2077063392
                    ]
                ]
            },
            "dc.input_tensor.layernorm_892.8": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1003920640
                    ],
                    [
                        5,
                        2077662464
                    ]
                ]
            },
            "lc.input_tensor.layernorm_906.dc.reduce_sum.0.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1003349376
                    ]
                ]
            },
            "dc.input_tensor.layernorm_906.1": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    1
                ],
                "t": 1,
                "mblock": [
                    4,
                    4
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1026015392
                    ],
                    [
                        3,
                        2099757216
                    ],
                    [
                        4,
                        1026015392
                    ]
                ]
            },
            "lc.input_tensor.layernorm_906.dc.reduce_sum.5.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1003303616
                    ]
                ]
            },
            "dc.input_tensor.layernorm_906.6": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    4,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        2077237728
                    ],
                    [
                        3,
                        1003728864
                    ],
                    [
                        3,
                        2077470688
                    ]
                ]
            },
            "dc.input_tensor.layernorm_906.8": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    4,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        2077478720
                    ],
                    [
                        0,
                        734702368
                    ],
                    [
                        0,
                        2076879648
                    ]
                ]
            },
            "input_1_multiply_923": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        2077324160
                    ]
                ]
            },
            "lc.input_tensor.softmax_925.dc.reduce_sum.3.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1003667616
                    ]
                ]
            },
            "dc.input_tensor.softmax_925.4": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    1
                ],
                "t": 16,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    4,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        2082183200
                    ],
                    [
                        0,
                        739406848
                    ],
                    [
                        0,
                        2081584128
                    ]
                ]
            },
            "lc.input_tensor.layernorm_945.dc.reduce_sum.0.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        734633088
                    ]
                ]
            },
            "dc.input_tensor.layernorm_945.1": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    2
                ],
                "t": 1,
                "mblock": [
                    12,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1031473824
                    ],
                    [
                        3,
                        2105215648
                    ]
                ]
            },
            "lc.input_tensor.layernorm_945.dc.reduce_sum.5.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1003301504
                    ]
                ]
            },
            "dc.input_tensor.layernorm_945.6": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        734973696
                    ],
                    [
                        0,
                        2077150976
                    ]
                ]
            },
            "dc.input_tensor.layernorm_945.8": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1004008224
                    ],
                    [
                        5,
                        2077750048
                    ]
                ]
            },
            "lc.input_tensor.layernorm_959.dc.reduce_sum.0.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        2077322048
                    ]
                ]
            },
            "dc.input_tensor.layernorm_959.1": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    2
                ],
                "t": 1,
                "mblock": [
                    12,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1030075968
                    ],
                    [
                        1,
                        2103817792
                    ]
                ]
            },
            "lc.input_tensor.layernorm_959.dc.reduce_sum.5.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        2077407328
                    ]
                ]
            },
            "dc.input_tensor.layernorm_959.6": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    6,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    2,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1003404000
                    ],
                    [
                        2,
                        2077145824
                    ],
                    [
                        3,
                        1003636960
                    ],
                    [
                        3,
                        2077378784
                    ],
                    [
                        4,
                        1003722240
                    ],
                    [
                        4,
                        2077464064
                    ]
                ]
            },
            "dc.input_tensor.layernorm_959.8": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    6,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    2,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1003408192
                    ],
                    [
                        2,
                        2077150016
                    ],
                    [
                        3,
                        1003641152
                    ],
                    [
                        3,
                        2077382976
                    ],
                    [
                        4,
                        1003726432
                    ],
                    [
                        4,
                        2077468256
                    ]
                ]
            },
            "input_1_multiply_976": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        2077095424
                    ]
                ]
            },
            "lc.input_tensor.softmax_978.dc.reduce_sum.3.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1003586560
                    ]
                ]
            },
            "dc.input_tensor.softmax_978.4": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 16,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1008441440
                    ],
                    [
                        1,
                        2082183264
                    ]
                ]
            },
            "lc.input_tensor.layernorm_998.dc.reduce_sum.0.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1003671840
                    ]
                ]
            },
            "dc.input_tensor.layernorm_998.1": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    6,
                    4
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1029876256
                    ],
                    [
                        3,
                        2103618080
                    ]
                ]
            },
            "lc.input_tensor.layernorm_998.dc.reduce_sum.5.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        734637312
                    ]
                ]
            },
            "dc.input_tensor.layernorm_998.6": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        734936160
                    ],
                    [
                        0,
                        2077113440
                    ]
                ]
            },
            "dc.input_tensor.layernorm_998.8": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1003958176
                    ],
                    [
                        4,
                        2077700000
                    ]
                ]
            },
            "lc.input_tensor.layernorm_1012.dc.reduce_sum.0.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1003669728
                    ]
                ]
            },
            "dc.input_tensor.layernorm_1012.1": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    1
                ],
                "t": 1,
                "mblock": [
                    4,
                    4
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1016962144
                    ],
                    [
                        4,
                        2090703968
                    ],
                    [
                        5,
                        1016962144
                    ]
                ]
            },
            "lc.input_tensor.layernorm_1012.dc.reduce_sum.5.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        2077411552
                    ]
                ]
            },
            "dc.input_tensor.layernorm_1012.6": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    4,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        734861056
                    ],
                    [
                        0,
                        2077038336
                    ],
                    [
                        1,
                        1003529472
                    ]
                ]
            },
            "dc.input_tensor.layernorm_1012.8": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    4,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        2077637408
                    ],
                    [
                        5,
                        1003895584
                    ],
                    [
                        5,
                        2077637408
                    ]
                ]
            },
            "input_1_multiply_1029": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        2076810368
                    ]
                ]
            },
            "lc.input_tensor.softmax_1031.dc.reduce_sum.3.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        734626752
                    ]
                ]
            },
            "dc.input_tensor.softmax_1031.4": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    1
                ],
                "t": 16,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    4,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        2081517504
                    ],
                    [
                        3,
                        1007975360
                    ],
                    [
                        3,
                        2081717184
                    ]
                ]
            },
            "lc.input_tensor.layernorm_1051.dc.reduce_sum.0.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1003573888
                    ]
                ]
            },
            "dc.input_tensor.layernorm_1051.1": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    2
                ],
                "t": 1,
                "mblock": [
                    12,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        762239616
                    ],
                    [
                        0,
                        2104416896
                    ]
                ]
            },
            "lc.input_tensor.layernorm_1051.dc.reduce_sum.5.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1003659168
                    ]
                ]
            },
            "dc.input_tensor.layernorm_1051.6": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        734948672
                    ],
                    [
                        0,
                        2077125952
                    ]
                ]
            },
            "dc.input_tensor.layernorm_1051.8": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1003983200
                    ],
                    [
                        5,
                        2077725024
                    ]
                ]
            },
            "lc.input_tensor.layernorm_1065.dc.reduce_sum.0.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        734624640
                    ]
                ]
            },
            "dc.input_tensor.layernorm_1065.1": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    2
                ],
                "t": 1,
                "mblock": [
                    12,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1030475360
                    ],
                    [
                        1,
                        2104217184
                    ]
                ]
            },
            "lc.input_tensor.layernorm_1065.dc.reduce_sum.5.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1003293056
                    ]
                ]
            },
            "dc.input_tensor.layernorm_1065.6": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    6,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    2,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1003395616
                    ],
                    [
                        2,
                        2077137440
                    ],
                    [
                        3,
                        1003628576
                    ],
                    [
                        3,
                        2077370400
                    ],
                    [
                        4,
                        1003713856
                    ],
                    [
                        4,
                        2077455680
                    ]
                ]
            },
            "dc.input_tensor.layernorm_1065.8": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    6,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    2,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1003713856
                    ],
                    [
                        5,
                        2077455680
                    ],
                    [
                        0,
                        734679328
                    ],
                    [
                        0,
                        2076856608
                    ],
                    [
                        1,
                        1003347744
                    ],
                    [
                        1,
                        2077089568
                    ]
                ]
            },
            "input_1_multiply_1082": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1003657056
                    ]
                ]
            },
            "lc.input_tensor.softmax_1084.dc.reduce_sum.3.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        2077398880
                    ]
                ]
            },
            "dc.input_tensor.softmax_1084.4": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 16,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1008641120
                    ],
                    [
                        3,
                        2082382944
                    ]
                ]
            },
            "lc.input_tensor.layernorm_1104.dc.reduce_sum.0.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        2077041216
                    ]
                ]
            },
            "dc.input_tensor.layernorm_1104.1": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    6,
                    4
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1029476864
                    ],
                    [
                        5,
                        2103218688
                    ]
                ]
            },
            "lc.input_tensor.layernorm_1104.dc.reduce_sum.5.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        2077086976
                    ]
                ]
            },
            "dc.input_tensor.layernorm_1104.6": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1003958176
                    ],
                    [
                        5,
                        2077700000
                    ]
                ]
            },
            "dc.input_tensor.layernorm_1104.8": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1003683712
                    ],
                    [
                        2,
                        2077425536
                    ]
                ]
            },
            "lc.input_tensor.layernorm_1118.dc.reduce_sum.0.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        734630976
                    ]
                ]
            },
            "dc.input_tensor.layernorm_1118.1": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    1
                ],
                "t": 1,
                "mblock": [
                    4,
                    4
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        2092368192
                    ],
                    [
                        2,
                        1018626368
                    ],
                    [
                        2,
                        2092368192
                    ]
                ]
            },
            "lc.input_tensor.layernorm_1118.dc.reduce_sum.5.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1003297280
                    ]
                ]
            },
            "dc.input_tensor.layernorm_1118.6": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    4,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1003487552
                    ],
                    [
                        2,
                        2077229376
                    ],
                    [
                        3,
                        1003720512
                    ]
                ]
            },
            "dc.input_tensor.layernorm_1118.8": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    4,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        2077462336
                    ],
                    [
                        4,
                        1003803712
                    ],
                    [
                        4,
                        2077545536
                    ]
                ]
            },
            "input_1_multiply_1135": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1003661280
                    ]
                ]
            },
            "lc.input_tensor.softmax_1137.dc.reduce_sum.3.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        2077403104
                    ]
                ]
            },
            "dc.input_tensor.softmax_1137.4": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    1
                ],
                "t": 16,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    4,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        2082050112
                    ],
                    [
                        3,
                        1008507968
                    ],
                    [
                        3,
                        2082249792
                    ]
                ]
            },
            "lc.input_tensor.layernorm_1157.dc.reduce_sum.0.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1003682400
                    ]
                ]
            },
            "dc.input_tensor.layernorm_1157.1": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    2
                ],
                "t": 1,
                "mblock": [
                    12,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1029077472
                    ],
                    [
                        3,
                        2102819296
                    ]
                ]
            },
            "lc.input_tensor.layernorm_1157.dc.reduce_sum.5.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        2077336832
                    ]
                ]
            },
            "dc.input_tensor.layernorm_1157.6": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1003642112
                    ],
                    [
                        1,
                        2077383936
                    ]
                ]
            },
            "dc.input_tensor.layernorm_1157.8": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1004008224
                    ],
                    [
                        4,
                        2077750048
                    ]
                ]
            },
            "lc.input_tensor.layernorm_1171.dc.reduce_sum.0.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        2077103872
                    ]
                ]
            },
            "dc.input_tensor.layernorm_1171.1": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    2
                ],
                "t": 1,
                "mblock": [
                    12,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1028278688
                    ],
                    [
                        4,
                        2102020512
                    ]
                ]
            },
            "lc.input_tensor.layernorm_1171.dc.reduce_sum.5.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        2077058112
                    ]
                ]
            },
            "dc.input_tensor.layernorm_1171.6": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    6,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    2,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1003718048
                    ],
                    [
                        5,
                        2077459872
                    ],
                    [
                        0,
                        734683520
                    ],
                    [
                        0,
                        2076860800
                    ],
                    [
                        1,
                        1003351936
                    ],
                    [
                        1,
                        2077093760
                    ]
                ]
            },
            "dc.input_tensor.layernorm_1171.8": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    6,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    2,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1003391424
                    ],
                    [
                        2,
                        2077133248
                    ],
                    [
                        3,
                        1003624384
                    ],
                    [
                        3,
                        2077366208
                    ],
                    [
                        4,
                        1003709664
                    ],
                    [
                        4,
                        2077451488
                    ]
                ]
            },
            "input_1_multiply_1188": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        2076818816
                    ]
                ]
            },
            "lc.input_tensor.softmax_1190.dc.reduce_sum.3.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1003309952
                    ]
                ]
            },
            "dc.input_tensor.softmax_1190.4": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 16,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        740006016
                    ],
                    [
                        0,
                        2082183296
                    ]
                ]
            },
            "lc.input_tensor.layernorm_1210.dc.reduce_sum.0.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        2077415776
                    ]
                ]
            },
            "dc.input_tensor.layernorm_1210.1": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    6,
                    4
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1029077472
                    ],
                    [
                        4,
                        2102819296
                    ]
                ]
            },
            "lc.input_tensor.layernorm_1210.dc.reduce_sum.5.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        734639424
                    ]
                ]
            },
            "dc.input_tensor.layernorm_1210.6": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1003995712
                    ],
                    [
                        5,
                        2077737536
                    ]
                ]
            },
            "dc.input_tensor.layernorm_1210.8": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1003995712
                    ],
                    [
                        4,
                        2077737536
                    ]
                ]
            },
            "lc.input_tensor.layernorm_1224.dc.reduce_sum.0.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1003678176
                    ]
                ]
            },
            "dc.input_tensor.layernorm_1224.1": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    1
                ],
                "t": 1,
                "mblock": [
                    4,
                    4
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        758778208
                    ],
                    [
                        0,
                        2100955488
                    ],
                    [
                        1,
                        1027413344
                    ]
                ]
            },
            "lc.input_tensor.layernorm_1224.dc.reduce_sum.5.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        2076820928
                    ]
                ]
            },
            "dc.input_tensor.layernorm_1224.6": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    4,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1003521120
                    ],
                    [
                        1,
                        2077262944
                    ],
                    [
                        2,
                        1003562720
                    ]
                ]
            },
            "dc.input_tensor.layernorm_1224.8": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    4,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        2077287840
                    ],
                    [
                        3,
                        1003778976
                    ],
                    [
                        3,
                        2077520800
                    ]
                ]
            },
            "input_1_multiply_1241": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1003312064
                    ]
                ]
            },
            "lc.input_tensor.softmax_1243.dc.reduce_sum.3.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        734643648
                    ]
                ]
            },
            "dc.input_tensor.softmax_1243.4": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    1
                ],
                "t": 16,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    4,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1008308288
                    ],
                    [
                        1,
                        2082050112
                    ],
                    [
                        2,
                        1008308288
                    ]
                ]
            },
            "lc.input_tensor.layernorm_1263.dc.reduce_sum.0.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        2077056000
                    ]
                ]
            },
            "dc.input_tensor.layernorm_1263.1": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    2
                ],
                "t": 1,
                "mblock": [
                    12,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        760242656
                    ],
                    [
                        0,
                        2102419936
                    ]
                ]
            },
            "lc.input_tensor.layernorm_1263.dc.reduce_sum.5.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1003673952
                    ]
                ]
            },
            "dc.input_tensor.layernorm_1263.6": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1003604576
                    ],
                    [
                        1,
                        2077346400
                    ]
                ]
            },
            "dc.input_tensor.layernorm_1263.8": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1003879136
                    ],
                    [
                        3,
                        2077620960
                    ]
                ]
            },
            "lc.input_tensor.layernorm_1277.dc.reduce_sum.0.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        734645760
                    ]
                ]
            },
            "dc.input_tensor.layernorm_1277.1": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    2
                ],
                "t": 1,
                "mblock": [
                    12,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1029077472
                    ],
                    [
                        5,
                        2102819296
                    ]
                ]
            },
            "lc.input_tensor.layernorm_1277.dc.reduce_sum.5.0": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    1,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1003597120
                    ]
                ]
            },
            "dc.input_tensor.layernorm_1277.6": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    4,
                    1
                ],
                "ublock": [
                    3,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1004096352
                    ]
                ]
            },
            "dc.input_tensor.layernorm_1277.8": {
                "input": "HOST",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    4,
                    1
                ],
                "ublock": [
                    3,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1004121344
                    ]
                ]
            },
            "e2e__fused_op_2_0": {
                "input": "_fused_op_2",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    4,
                    2
                ],
                "t": 16,
                "mblock": [
                    3,
                    1
                ],
                "ublock": [
                    1,
                    6
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1065953984
                    ],
                    [
                        3,
                        2139695808
                    ],
                    [
                        4,
                        1065953984
                    ],
                    [
                        4,
                        2139695808
                    ],
                    [
                        5,
                        1065953984
                    ],
                    [
                        5,
                        2139695808
                    ],
                    [
                        0,
                        796719776
                    ],
                    [
                        0,
                        2138897056
                    ]
                ]
            },
            "e2e_softmax_24.dc.reduce_max.0_0": {
                "input": "softmax_24.dc.reduce_max.0",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    4,
                    1
                ],
                "t": 16,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    3,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1006976672
                    ],
                    [
                        3,
                        2080718496
                    ],
                    [
                        4,
                        1007043232
                    ],
                    [
                        4,
                        2080785056
                    ]
                ]
            },
            "e2e__fused_op_1_0": {
                "input": "_fused_op_1",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    4,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    3,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1008840832
                    ],
                    [
                        4,
                        2082582656
                    ],
                    [
                        5,
                        1008840832
                    ],
                    [
                        5,
                        2082582656
                    ]
                ]
            },
            "e2e_gelu_50_0": {
                "input": "gelu_50",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    2
                ],
                "t": 2,
                "mblock": [
                    6,
                    4
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        802111360
                    ],
                    [
                        0,
                        2144288640
                    ],
                    [
                        1,
                        1070546816
                    ],
                    [
                        1,
                        2144288640
                    ]
                ]
            },
            "e2e__fused_op_6_0": {
                "input": "_fused_op_6",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1028877792
                    ],
                    [
                        2,
                        2102619616
                    ]
                ]
            },
            "e2e__fused_op_8_0": {
                "input": "_fused_op_8",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    4,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        2099757216
                    ],
                    [
                        5,
                        1026015392
                    ],
                    [
                        5,
                        2099757216
                    ]
                ]
            },
            "e2e_matmul_61_0": {
                "input": "matmul_61",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    4
                ],
                "t": 1,
                "mblock": [
                    4,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1005578272
                    ],
                    [
                        3,
                        2079320096
                    ],
                    [
                        4,
                        1005644832
                    ],
                    [
                        4,
                        2079386656
                    ],
                    [
                        5,
                        1005644832
                    ],
                    [
                        5,
                        2079386656
                    ],
                    [
                        0,
                        736610304
                    ],
                    [
                        0,
                        2078787584
                    ],
                    [
                        1,
                        1005278720
                    ],
                    [
                        1,
                        2079020544
                    ],
                    [
                        2,
                        1005278720
                    ],
                    [
                        2,
                        2079020544
                    ]
                ]
            },
            "e2e_multiply_22_attempt_1_input_op_fork_nop0_0": {
                "input": "multiply_22_attempt_1_input_op_fork_nop0",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    2
                ],
                "ublock": [
                    1,
                    6
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        2077863168
                    ]
                ]
            },
            "e2e_matmul_92_0": {
                "input": "matmul_92",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    6,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1007342848
                    ],
                    [
                        5,
                        2081084672
                    ],
                    [
                        0,
                        738308320
                    ],
                    [
                        0,
                        2080485600
                    ],
                    [
                        1,
                        1006976736
                    ],
                    [
                        1,
                        2080718560
                    ],
                    [
                        2,
                        1006976736
                    ],
                    [
                        2,
                        2080718560
                    ]
                ]
            },
            "e2e_layernorm_111.dc.reduce_sum.5.lc1_0": {
                "input": "layernorm_111.dc.reduce_sum.5.lc1",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 2,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        2078162688
                    ]
                ]
            },
            "e2e__fused_op_14_0": {
                "input": "_fused_op_14",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    2
                ],
                "t": 1,
                "mblock": [
                    12,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1028678080
                    ],
                    [
                        4,
                        2102419904
                    ]
                ]
            },
            "e2e__fused_op_16_0": {
                "input": "_fused_op_16",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    6,
                    1
                ],
                "t": 16,
                "mblock": [
                    2,
                    2
                ],
                "ublock": [
                    1,
                    6
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        799715104
                    ],
                    [
                        0,
                        2141892384
                    ],
                    [
                        1,
                        1068150560
                    ],
                    [
                        1,
                        2141892384
                    ],
                    [
                        2,
                        1068150560
                    ],
                    [
                        2,
                        2141892384
                    ]
                ]
            },
            "e2e_softmax_130.dc.reduce_max.0_0": {
                "input": "softmax_130.dc.reduce_max.0",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    6,
                    1
                ],
                "t": 16,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    2,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1005378464
                    ],
                    [
                        4,
                        2079120288
                    ],
                    [
                        5,
                        1005378464
                    ],
                    [
                        5,
                        2079120288
                    ],
                    [
                        0,
                        736343936
                    ],
                    [
                        0,
                        2078521216
                    ]
                ]
            },
            "e2e__fused_op_15_0": {
                "input": "_fused_op_15",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    6,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    2,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1008041920
                    ],
                    [
                        4,
                        2081783744
                    ],
                    [
                        5,
                        1008041920
                    ],
                    [
                        5,
                        2081783744
                    ],
                    [
                        0,
                        739007392
                    ],
                    [
                        0,
                        2081184672
                    ]
                ]
            },
            "e2e_gelu_156_0": {
                "input": "gelu_156",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    2
                ],
                "t": 2,
                "mblock": [
                    6,
                    4
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        798916352
                    ],
                    [
                        0,
                        2141093632
                    ],
                    [
                        1,
                        1067351808
                    ],
                    [
                        1,
                        2141093632
                    ]
                ]
            },
            "e2e__fused_op_20_0": {
                "input": "_fused_op_20",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1028278688
                    ],
                    [
                        5,
                        2102020512
                    ]
                ]
            },
            "e2e__fused_op_22_0": {
                "input": "_fused_op_22",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    4,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1014831968
                    ],
                    [
                        3,
                        2088573792
                    ],
                    [
                        4,
                        1014831968
                    ]
                ]
            },
            "e2e_matmul_167_0": {
                "input": "matmul_167",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    4
                ],
                "t": 1,
                "mblock": [
                    4,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1005644864
                    ],
                    [
                        3,
                        2079386688
                    ],
                    [
                        4,
                        1005711424
                    ],
                    [
                        4,
                        2079453248
                    ],
                    [
                        5,
                        1005711424
                    ],
                    [
                        5,
                        2079453248
                    ],
                    [
                        0,
                        736676896
                    ],
                    [
                        0,
                        2078854176
                    ],
                    [
                        1,
                        1005345312
                    ],
                    [
                        1,
                        2079087136
                    ],
                    [
                        2,
                        1005345312
                    ],
                    [
                        2,
                        2079087136
                    ]
                ]
            },
            "e2e_matmul_198_0": {
                "input": "matmul_198",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    6,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1007542592
                    ],
                    [
                        5,
                        2081284416
                    ],
                    [
                        0,
                        738508064
                    ],
                    [
                        0,
                        2080685344
                    ],
                    [
                        1,
                        1007176480
                    ],
                    [
                        1,
                        2080918304
                    ],
                    [
                        2,
                        1007176480
                    ],
                    [
                        2,
                        2080918304
                    ]
                ]
            },
            "e2e_layernorm_217.dc.reduce_sum.5.lc1_0": {
                "input": "layernorm_217.dc.reduce_sum.5.lc1",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 2,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1004329312
                    ]
                ]
            },
            "e2e__fused_op_28_0": {
                "input": "_fused_op_28",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    2
                ],
                "t": 1,
                "mblock": [
                    12,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        760642048
                    ],
                    [
                        0,
                        2102819328
                    ]
                ]
            },
            "e2e__fused_op_30_0": {
                "input": "_fused_op_30",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    6,
                    1
                ],
                "t": 16,
                "mblock": [
                    2,
                    2
                ],
                "ublock": [
                    1,
                    6
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1070546816
                    ],
                    [
                        2,
                        2144288640
                    ],
                    [
                        3,
                        1070546816
                    ],
                    [
                        3,
                        2144288640
                    ],
                    [
                        4,
                        1070546816
                    ],
                    [
                        4,
                        2144288640
                    ]
                ]
            },
            "e2e_softmax_236.dc.reduce_max.0_0": {
                "input": "softmax_236.dc.reduce_max.0",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    6,
                    1
                ],
                "t": 16,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    2,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1005112096
                    ],
                    [
                        5,
                        2078853920
                    ],
                    [
                        0,
                        736077568
                    ],
                    [
                        0,
                        2078254848
                    ],
                    [
                        1,
                        1004745984
                    ],
                    [
                        1,
                        2078487808
                    ]
                ]
            },
            "e2e__fused_op_29_0": {
                "input": "_fused_op_29",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    6,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    2,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1008574528
                    ],
                    [
                        4,
                        2082316352
                    ],
                    [
                        5,
                        1008574528
                    ],
                    [
                        5,
                        2082316352
                    ],
                    [
                        0,
                        739540000
                    ],
                    [
                        0,
                        2081717280
                    ]
                ]
            },
            "e2e_gelu_262_0": {
                "input": "gelu_262",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    2
                ],
                "t": 2,
                "mblock": [
                    6,
                    4
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1072144320
                    ],
                    [
                        3,
                        2145886144
                    ],
                    [
                        4,
                        1072144320
                    ],
                    [
                        4,
                        2145886144
                    ]
                ]
            },
            "e2e__fused_op_34_0": {
                "input": "_fused_op_34",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1030075968
                    ],
                    [
                        2,
                        2103817792
                    ]
                ]
            },
            "e2e__fused_op_36_0": {
                "input": "_fused_op_36",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    4,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1012169248
                    ],
                    [
                        5,
                        2085911072
                    ],
                    [
                        0,
                        743068160
                    ]
                ]
            },
            "e2e_matmul_273_0": {
                "input": "matmul_273",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    4
                ],
                "t": 1,
                "mblock": [
                    4,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        736210752
                    ],
                    [
                        0,
                        2078388032
                    ],
                    [
                        1,
                        1004879168
                    ],
                    [
                        1,
                        2078620992
                    ],
                    [
                        2,
                        1004879168
                    ],
                    [
                        2,
                        2078620992
                    ],
                    [
                        3,
                        1005112128
                    ],
                    [
                        3,
                        2078853952
                    ],
                    [
                        4,
                        1005178688
                    ],
                    [
                        4,
                        2078920512
                    ],
                    [
                        5,
                        1005178688
                    ],
                    [
                        5,
                        2078920512
                    ]
                ]
            },
            "e2e_matmul_304_0": {
                "input": "matmul_304",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    6,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1007176416
                    ],
                    [
                        3,
                        2080918240
                    ],
                    [
                        4,
                        1007242976
                    ],
                    [
                        4,
                        2080984800
                    ],
                    [
                        5,
                        1007242976
                    ],
                    [
                        5,
                        2080984800
                    ],
                    [
                        0,
                        738208448
                    ],
                    [
                        0,
                        2080385728
                    ]
                ]
            },
            "e2e_layernorm_323.dc.reduce_sum.5.lc1_0": {
                "input": "layernorm_323.dc.reduce_sum.5.lc1",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 2,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        2077796576
                    ]
                ]
            },
            "e2e__fused_op_42_0": {
                "input": "_fused_op_42",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    2
                ],
                "t": 1,
                "mblock": [
                    12,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1029876256
                    ],
                    [
                        5,
                        2103618080
                    ]
                ]
            },
            "e2e__fused_op_44_0": {
                "input": "_fused_op_44",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    6,
                    1
                ],
                "t": 16,
                "mblock": [
                    2,
                    2
                ],
                "ublock": [
                    1,
                    6
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        804507616
                    ],
                    [
                        0,
                        2146684896
                    ],
                    [
                        1,
                        1072943072
                    ],
                    [
                        1,
                        2146684896
                    ],
                    [
                        2,
                        1072943072
                    ],
                    [
                        2,
                        2146684896
                    ]
                ]
            },
            "e2e_softmax_342.dc.reduce_max.0_0": {
                "input": "softmax_342.dc.reduce_max.0",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    6,
                    1
                ],
                "t": 16,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    2,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1005178720
                    ],
                    [
                        3,
                        2078920544
                    ],
                    [
                        4,
                        1005245280
                    ],
                    [
                        4,
                        2078987104
                    ],
                    [
                        5,
                        1005245280
                    ],
                    [
                        5,
                        2078987104
                    ]
                ]
            },
            "e2e__fused_op_43_0": {
                "input": "_fused_op_43",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    6,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    2,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1007775616
                    ],
                    [
                        4,
                        2081517440
                    ],
                    [
                        5,
                        1007775616
                    ],
                    [
                        5,
                        2081517440
                    ],
                    [
                        0,
                        738741088
                    ],
                    [
                        0,
                        2080918368
                    ]
                ]
            },
            "e2e_gelu_368_0": {
                "input": "gelu_368",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    2
                ],
                "t": 2,
                "mblock": [
                    6,
                    4
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1066553056
                    ],
                    [
                        5,
                        2140294880
                    ],
                    [
                        0,
                        797318848
                    ],
                    [
                        0,
                        2139496128
                    ]
                ]
            },
            "e2e__fused_op_48_0": {
                "input": "_fused_op_48",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        761840224
                    ],
                    [
                        0,
                        2104017504
                    ]
                ]
            },
            "e2e__fused_op_50_0": {
                "input": "_fused_op_50",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    4,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1022287584
                    ],
                    [
                        4,
                        2096029408
                    ],
                    [
                        5,
                        1022287584
                    ]
                ]
            },
            "e2e_matmul_379_0": {
                "input": "matmul_379",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    4
                ],
                "t": 1,
                "mblock": [
                    4,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        2079220320
                    ],
                    [
                        2,
                        1005478496
                    ],
                    [
                        2,
                        2079220320
                    ],
                    [
                        3,
                        1005711456
                    ],
                    [
                        3,
                        2079453280
                    ],
                    [
                        4,
                        1005778016
                    ],
                    [
                        4,
                        2079519840
                    ],
                    [
                        5,
                        1005778016
                    ],
                    [
                        5,
                        2079519840
                    ],
                    [
                        0,
                        736743488
                    ],
                    [
                        0,
                        2078920768
                    ],
                    [
                        1,
                        1005411904
                    ]
                ]
            },
            "e2e_matmul_410_0": {
                "input": "matmul_410",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    6,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1006843488
                    ],
                    [
                        5,
                        2080585312
                    ],
                    [
                        0,
                        737808960
                    ],
                    [
                        0,
                        2079986240
                    ],
                    [
                        1,
                        1006477376
                    ],
                    [
                        1,
                        2080219200
                    ],
                    [
                        2,
                        1006477376
                    ],
                    [
                        2,
                        2080219200
                    ]
                ]
            },
            "e2e_layernorm_429.dc.reduce_sum.5.lc1_0": {
                "input": "layernorm_429.dc.reduce_sum.5.lc1",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 2,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        2077563616
                    ]
                ]
            },
            "e2e__fused_op_56_0": {
                "input": "_fused_op_56",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    2
                ],
                "t": 1,
                "mblock": [
                    12,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        761440832
                    ],
                    [
                        0,
                        2103618112
                    ]
                ]
            },
            "e2e_multiply_22_attempt_1_input_op_fork_nop1_0": {
                "input": "multiply_22_attempt_1_input_op_fork_nop1",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    2
                ],
                "ublock": [
                    1,
                    6
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        2078071136
                    ]
                ]
            },
            "e2e__fused_op_58_0": {
                "input": "_fused_op_58",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    6,
                    1
                ],
                "t": 16,
                "mblock": [
                    2,
                    2
                ],
                "ublock": [
                    1,
                    6
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1072943072
                    ],
                    [
                        3,
                        2146684896
                    ],
                    [
                        4,
                        1072943072
                    ],
                    [
                        4,
                        2146684896
                    ],
                    [
                        5,
                        1072943072
                    ],
                    [
                        5,
                        2146684896
                    ]
                ]
            },
            "e2e_softmax_448.dc.reduce_max.0_0": {
                "input": "softmax_448.dc.reduce_max.0",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    6,
                    1
                ],
                "t": 16,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    2,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1005078944
                    ],
                    [
                        1,
                        2078820768
                    ],
                    [
                        2,
                        1005078944
                    ],
                    [
                        2,
                        2078820768
                    ],
                    [
                        3,
                        1005311904
                    ],
                    [
                        3,
                        2079053728
                    ]
                ]
            },
            "e2e__fused_op_57_0": {
                "input": "_fused_op_57",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    6,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    2,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        2082050048
                    ],
                    [
                        0,
                        739273696
                    ],
                    [
                        0,
                        2081450976
                    ],
                    [
                        1,
                        1007908832
                    ],
                    [
                        1,
                        2081650656
                    ],
                    [
                        2,
                        1007908832
                    ]
                ]
            },
            "e2e_gelu_474_0": {
                "input": "gelu_474",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    2
                ],
                "t": 2,
                "mblock": [
                    6,
                    4
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1068949312
                    ],
                    [
                        1,
                        2142691136
                    ],
                    [
                        2,
                        1068949312
                    ],
                    [
                        2,
                        2142691136
                    ]
                ]
            },
            "e2e__fused_op_62_0": {
                "input": "_fused_op_62",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1031473824
                    ],
                    [
                        5,
                        2105215648
                    ]
                ]
            },
            "e2e__fused_op_64_0": {
                "input": "_fused_op_64",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    4,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        2088041248
                    ],
                    [
                        5,
                        1014299424
                    ],
                    [
                        5,
                        2088041248
                    ]
                ]
            },
            "e2e_matmul_485_0": {
                "input": "matmul_485",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    4
                ],
                "t": 1,
                "mblock": [
                    4,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1005445088
                    ],
                    [
                        3,
                        2079186912
                    ],
                    [
                        4,
                        1005511648
                    ],
                    [
                        4,
                        2079253472
                    ],
                    [
                        5,
                        1005511648
                    ],
                    [
                        5,
                        2079253472
                    ],
                    [
                        0,
                        736477120
                    ],
                    [
                        0,
                        2078654400
                    ],
                    [
                        1,
                        1005145536
                    ],
                    [
                        1,
                        2078887360
                    ],
                    [
                        2,
                        1005145536
                    ],
                    [
                        2,
                        2078887360
                    ]
                ]
            },
            "e2e_matmul_516_0": {
                "input": "matmul_516",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    6,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1006876800
                    ],
                    [
                        3,
                        2080618624
                    ],
                    [
                        4,
                        1006943360
                    ],
                    [
                        4,
                        2080685184
                    ],
                    [
                        5,
                        1006943360
                    ],
                    [
                        5,
                        2080685184
                    ],
                    [
                        0,
                        737908832
                    ],
                    [
                        0,
                        2080086112
                    ]
                ]
            },
            "e2e_layernorm_535.dc.reduce_sum.5.lc1_0": {
                "input": "layernorm_535.dc.reduce_sum.5.lc1",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 2,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1004354304
                    ]
                ]
            },
            "e2e__fused_op_70_0": {
                "input": "_fused_op_70",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    2
                ],
                "t": 1,
                "mblock": [
                    12,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1027879296
                    ],
                    [
                        4,
                        2101621120
                    ]
                ]
            },
            "e2e__fused_op_72_0": {
                "input": "_fused_op_72",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    6,
                    1
                ],
                "t": 16,
                "mblock": [
                    2,
                    2
                ],
                "ublock": [
                    1,
                    6
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1068150560
                    ],
                    [
                        3,
                        2141892384
                    ],
                    [
                        4,
                        1068150560
                    ],
                    [
                        4,
                        2141892384
                    ],
                    [
                        5,
                        1068150560
                    ],
                    [
                        5,
                        2141892384
                    ]
                ]
            },
            "e2e_softmax_554.dc.reduce_max.0_0": {
                "input": "softmax_554.dc.reduce_max.0",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    6,
                    1
                ],
                "t": 16,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    2,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1005311872
                    ],
                    [
                        4,
                        2079053696
                    ],
                    [
                        5,
                        1005311872
                    ],
                    [
                        5,
                        2079053696
                    ],
                    [
                        0,
                        736277344
                    ],
                    [
                        0,
                        2078454624
                    ]
                ]
            },
            "e2e__fused_op_71_0": {
                "input": "_fused_op_71",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    6,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    2,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1007642464
                    ],
                    [
                        4,
                        2081384288
                    ],
                    [
                        5,
                        1007642464
                    ],
                    [
                        5,
                        2081384288
                    ],
                    [
                        0,
                        738607936
                    ],
                    [
                        0,
                        2080785216
                    ]
                ]
            },
            "e2e_gelu_580_0": {
                "input": "gelu_580",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    2
                ],
                "t": 2,
                "mblock": [
                    6,
                    4
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1067351808
                    ],
                    [
                        5,
                        2141093632
                    ],
                    [
                        0,
                        798117600
                    ],
                    [
                        0,
                        2140294880
                    ]
                ]
            },
            "e2e__fused_op_76_0": {
                "input": "_fused_op_76",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1028678080
                    ],
                    [
                        5,
                        2102419904
                    ]
                ]
            },
            "e2e__fused_op_78_0": {
                "input": "_fused_op_78",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    4,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        2093965824
                    ],
                    [
                        3,
                        1020423680
                    ],
                    [
                        3,
                        2094165504
                    ]
                ]
            },
            "e2e_matmul_591_0": {
                "input": "matmul_591",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    4
                ],
                "t": 1,
                "mblock": [
                    4,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        2079952832
                    ],
                    [
                        3,
                        1006443968
                    ],
                    [
                        3,
                        2080185792
                    ],
                    [
                        4,
                        1006510528
                    ],
                    [
                        4,
                        2080252352
                    ],
                    [
                        5,
                        1006510528
                    ],
                    [
                        5,
                        2080252352
                    ],
                    [
                        0,
                        737476000
                    ],
                    [
                        0,
                        2079653280
                    ],
                    [
                        1,
                        1006144416
                    ],
                    [
                        1,
                        2079886240
                    ],
                    [
                        2,
                        1006144416
                    ]
                ]
            },
            "e2e_matmul_622_0": {
                "input": "matmul_622",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    6,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1007376160
                    ],
                    [
                        3,
                        2081117984
                    ],
                    [
                        4,
                        1007442720
                    ],
                    [
                        4,
                        2081184544
                    ],
                    [
                        5,
                        1007442720
                    ],
                    [
                        5,
                        2081184544
                    ],
                    [
                        0,
                        738408192
                    ],
                    [
                        0,
                        2080585472
                    ]
                ]
            },
            "e2e_layernorm_641.dc.reduce_sum.5.lc1_0": {
                "input": "layernorm_641.dc.reduce_sum.5.lc1",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 2,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        2077838176
                    ]
                ]
            },
            "e2e__fused_op_84_0": {
                "input": "_fused_op_84",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    2
                ],
                "t": 1,
                "mblock": [
                    12,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1027679616
                    ],
                    [
                        1,
                        2101421440
                    ]
                ]
            },
            "e2e__fused_op_86_0": {
                "input": "_fused_op_86",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    6,
                    1
                ],
                "t": 16,
                "mblock": [
                    2,
                    2
                ],
                "ublock": [
                    1,
                    6
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1068949312
                    ],
                    [
                        3,
                        2142691136
                    ],
                    [
                        4,
                        1068949312
                    ],
                    [
                        4,
                        2142691136
                    ],
                    [
                        5,
                        1068949312
                    ],
                    [
                        5,
                        2142691136
                    ]
                ]
            },
            "e2e_softmax_660.dc.reduce_max.0_0": {
                "input": "softmax_660.dc.reduce_max.0",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    6,
                    1
                ],
                "t": 16,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    2,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1006776896
                    ],
                    [
                        4,
                        2080518720
                    ],
                    [
                        5,
                        1006776896
                    ],
                    [
                        5,
                        2080518720
                    ],
                    [
                        0,
                        737742368
                    ],
                    [
                        0,
                        2079919648
                    ]
                ]
            },
            "e2e__fused_op_85_0": {
                "input": "_fused_op_85",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    6,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    2,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        2081916896
                    ],
                    [
                        0,
                        739140544
                    ],
                    [
                        0,
                        2081317824
                    ],
                    [
                        1,
                        1007775680
                    ],
                    [
                        1,
                        2081517504
                    ],
                    [
                        2,
                        1007775680
                    ]
                ]
            },
            "e2e_gelu_686_0": {
                "input": "gelu_686",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    2
                ],
                "t": 2,
                "mblock": [
                    6,
                    4
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1066553056
                    ],
                    [
                        3,
                        2140294880
                    ],
                    [
                        4,
                        1066553056
                    ],
                    [
                        4,
                        2140294880
                    ]
                ]
            },
            "e2e__fused_op_90_0": {
                "input": "_fused_op_90",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1030874752
                    ],
                    [
                        2,
                        2104616576
                    ]
                ]
            },
            "e2e__fused_op_92_0": {
                "input": "_fused_op_92",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    4,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        2084113760
                    ],
                    [
                        3,
                        1010571616
                    ],
                    [
                        3,
                        2084313440
                    ]
                ]
            },
            "e2e_matmul_697_0": {
                "input": "matmul_697",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    4
                ],
                "t": 1,
                "mblock": [
                    4,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1005844640
                    ],
                    [
                        3,
                        2079586464
                    ],
                    [
                        4,
                        1005911200
                    ],
                    [
                        4,
                        2079653024
                    ],
                    [
                        5,
                        1005911200
                    ],
                    [
                        5,
                        2079653024
                    ],
                    [
                        0,
                        736876672
                    ],
                    [
                        0,
                        2079053952
                    ],
                    [
                        1,
                        1005545088
                    ],
                    [
                        1,
                        2079286912
                    ],
                    [
                        2,
                        1005545088
                    ],
                    [
                        2,
                        2079286912
                    ]
                ]
            },
            "e2e_matmul_728_0": {
                "input": "matmul_728",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    6,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1007076608
                    ],
                    [
                        1,
                        2080818432
                    ],
                    [
                        2,
                        1007076608
                    ],
                    [
                        2,
                        2080818432
                    ],
                    [
                        3,
                        1007276288
                    ],
                    [
                        3,
                        2081018112
                    ],
                    [
                        4,
                        1007342848
                    ],
                    [
                        4,
                        2081084672
                    ]
                ]
            },
            "e2e_layernorm_747.dc.reduce_sum.5.lc1_0": {
                "input": "layernorm_747.dc.reduce_sum.5.lc1",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 2,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        735386336
                    ]
                ]
            },
            "e2e__fused_op_98_0": {
                "input": "_fused_op_98",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    2
                ],
                "t": 1,
                "mblock": [
                    12,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1030275648
                    ],
                    [
                        3,
                        2104017472
                    ]
                ]
            },
            "e2e__fused_op_100_0": {
                "input": "_fused_op_100",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    6,
                    1
                ],
                "t": 16,
                "mblock": [
                    2,
                    2
                ],
                "ublock": [
                    1,
                    6
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1070546816
                    ],
                    [
                        5,
                        2144288640
                    ],
                    [
                        0,
                        801312608
                    ],
                    [
                        0,
                        2143489888
                    ],
                    [
                        1,
                        1069748064
                    ],
                    [
                        1,
                        2143489888
                    ]
                ]
            },
            "e2e_softmax_766.dc.reduce_max.0_0": {
                "input": "softmax_766.dc.reduce_max.0",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    6,
                    1
                ],
                "t": 16,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    2,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        2079919424
                    ],
                    [
                        4,
                        1006244160
                    ],
                    [
                        4,
                        2079985984
                    ],
                    [
                        5,
                        1006244160
                    ],
                    [
                        5,
                        2079985984
                    ],
                    [
                        0,
                        737209632
                    ]
                ]
            },
            "e2e__fused_op_99_0": {
                "input": "_fused_op_99",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    6,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    2,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1007376224
                    ],
                    [
                        1,
                        2081118048
                    ],
                    [
                        2,
                        1007376224
                    ],
                    [
                        2,
                        2081118048
                    ],
                    [
                        3,
                        1007575904
                    ],
                    [
                        3,
                        2081317728
                    ]
                ]
            },
            "e2e_gelu_792_0": {
                "input": "gelu_792",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    2
                ],
                "t": 2,
                "mblock": [
                    6,
                    4
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1066553056
                    ],
                    [
                        1,
                        2140294880
                    ],
                    [
                        2,
                        1066553056
                    ],
                    [
                        2,
                        2140294880
                    ]
                ]
            },
            "e2e__fused_op_104_0": {
                "input": "_fused_op_104",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1031274144
                    ],
                    [
                        2,
                        2105015968
                    ]
                ]
            },
            "e2e__fused_op_106_0": {
                "input": "_fused_op_106",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    4,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        2095896320
                    ],
                    [
                        1,
                        1022354176
                    ],
                    [
                        1,
                        2096096000
                    ]
                ]
            },
            "e2e_matmul_803_0": {
                "input": "matmul_803",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    4
                ],
                "t": 1,
                "mblock": [
                    4,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1006177568
                    ],
                    [
                        4,
                        2079919392
                    ],
                    [
                        5,
                        1006177568
                    ],
                    [
                        5,
                        2079919392
                    ],
                    [
                        0,
                        737143040
                    ],
                    [
                        0,
                        2079320320
                    ],
                    [
                        1,
                        1005811456
                    ],
                    [
                        1,
                        2079553280
                    ],
                    [
                        2,
                        1005811456
                    ],
                    [
                        2,
                        2079553280
                    ],
                    [
                        3,
                        1006044416
                    ],
                    [
                        3,
                        2079786240
                    ]
                ]
            },
            "e2e_matmul_834_0": {
                "input": "matmul_834",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    6,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1006577248
                    ],
                    [
                        1,
                        2080319072
                    ],
                    [
                        2,
                        1006577248
                    ],
                    [
                        2,
                        2080319072
                    ],
                    [
                        3,
                        1006776928
                    ],
                    [
                        3,
                        2080518752
                    ],
                    [
                        4,
                        1006843488
                    ],
                    [
                        4,
                        2080585312
                    ]
                ]
            },
            "e2e_layernorm_853.dc.reduce_sum.5.lc1_0": {
                "input": "layernorm_853.dc.reduce_sum.5.lc1",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 2,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1004420864
                    ]
                ]
            },
            "e2e__fused_op_112_0": {
                "input": "_fused_op_112",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    2
                ],
                "t": 1,
                "mblock": [
                    12,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1029476864
                    ],
                    [
                        4,
                        2103218688
                    ]
                ]
            },
            "e2e_multiply_22_attempt_1_input_op_fork_nop2_0": {
                "input": "multiply_22_attempt_1_input_op_fork_nop2",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    2
                ],
                "ublock": [
                    1,
                    6
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1004054752
                    ]
                ]
            },
            "e2e__fused_op_114_0": {
                "input": "_fused_op_114",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    6,
                    1
                ],
                "t": 16,
                "mblock": [
                    2,
                    2
                ],
                "ublock": [
                    1,
                    6
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1069748064
                    ],
                    [
                        4,
                        2143489888
                    ],
                    [
                        5,
                        1069748064
                    ],
                    [
                        5,
                        2143489888
                    ],
                    [
                        0,
                        800513856
                    ],
                    [
                        0,
                        2142691136
                    ]
                ]
            },
            "e2e_softmax_872.dc.reduce_max.0_0": {
                "input": "softmax_872.dc.reduce_max.0",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    6,
                    1
                ],
                "t": 16,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    2,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        2079819648
                    ],
                    [
                        3,
                        1006310784
                    ],
                    [
                        3,
                        2080052608
                    ],
                    [
                        4,
                        1006377344
                    ],
                    [
                        4,
                        2080119168
                    ],
                    [
                        5,
                        1006377344
                    ]
                ]
            },
            "e2e__fused_op_113_0": {
                "input": "_fused_op_113",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    6,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    2,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1008175136
                    ],
                    [
                        1,
                        2081916960
                    ],
                    [
                        2,
                        1008175136
                    ],
                    [
                        2,
                        2081916960
                    ],
                    [
                        3,
                        1008374816
                    ],
                    [
                        3,
                        2082116640
                    ]
                ]
            },
            "e2e_gelu_898_0": {
                "input": "gelu_898",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    2
                ],
                "t": 2,
                "mblock": [
                    6,
                    4
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1071345568
                    ],
                    [
                        1,
                        2145087392
                    ],
                    [
                        2,
                        1071345568
                    ],
                    [
                        2,
                        2145087392
                    ]
                ]
            },
            "e2e__fused_op_118_0": {
                "input": "_fused_op_118",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1030275648
                    ],
                    [
                        4,
                        2104017472
                    ]
                ]
            },
            "e2e__fused_op_120_0": {
                "input": "_fused_op_120",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    4,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1025283168
                    ],
                    [
                        2,
                        2099024992
                    ],
                    [
                        3,
                        1025482848
                    ]
                ]
            },
            "e2e_matmul_909_0": {
                "input": "matmul_909",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    4
                ],
                "t": 1,
                "mblock": [
                    4,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        2079520096
                    ],
                    [
                        1,
                        1006011232
                    ],
                    [
                        1,
                        2079753056
                    ],
                    [
                        2,
                        1006011232
                    ],
                    [
                        2,
                        2079753056
                    ],
                    [
                        3,
                        1006244192
                    ],
                    [
                        3,
                        2079986016
                    ],
                    [
                        4,
                        1006310752
                    ],
                    [
                        4,
                        2080052576
                    ],
                    [
                        5,
                        1006310752
                    ],
                    [
                        5,
                        2080052576
                    ],
                    [
                        0,
                        737276224
                    ]
                ]
            },
            "e2e_matmul_940_0": {
                "input": "matmul_940",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    6,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1006876864
                    ],
                    [
                        1,
                        2080618688
                    ],
                    [
                        2,
                        1006876864
                    ],
                    [
                        2,
                        2080618688
                    ],
                    [
                        3,
                        1007076544
                    ],
                    [
                        3,
                        2080818368
                    ],
                    [
                        4,
                        1007143104
                    ],
                    [
                        4,
                        2080884928
                    ]
                ]
            },
            "e2e_layernorm_959.dc.reduce_sum.5.lc1_0": {
                "input": "layernorm_959.dc.reduce_sum.5.lc1",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 2,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        2078162688
                    ]
                ]
            },
            "e2e__fused_op_126_0": {
                "input": "_fused_op_126",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    2
                ],
                "t": 1,
                "mblock": [
                    12,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1030275648
                    ],
                    [
                        5,
                        2104017472
                    ]
                ]
            },
            "e2e__fused_op_128_0": {
                "input": "_fused_op_128",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    6,
                    1
                ],
                "t": 16,
                "mblock": [
                    2,
                    2
                ],
                "ublock": [
                    1,
                    6
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1071345568
                    ],
                    [
                        3,
                        2145087392
                    ],
                    [
                        4,
                        1071345568
                    ],
                    [
                        4,
                        2145087392
                    ],
                    [
                        5,
                        1071345568
                    ],
                    [
                        5,
                        2145087392
                    ]
                ]
            },
            "e2e_softmax_978.dc.reduce_max.0_0": {
                "input": "softmax_978.dc.reduce_max.0",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    6,
                    1
                ],
                "t": 16,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    2,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1005778048
                    ],
                    [
                        3,
                        2079519872
                    ],
                    [
                        4,
                        1005844608
                    ],
                    [
                        4,
                        2079586432
                    ],
                    [
                        5,
                        1005844608
                    ],
                    [
                        5,
                        2079586432
                    ]
                ]
            },
            "e2e__fused_op_127_0": {
                "input": "_fused_op_127",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    6,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    2,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1008707680
                    ],
                    [
                        4,
                        2082449504
                    ],
                    [
                        5,
                        1008707680
                    ],
                    [
                        5,
                        2082449504
                    ],
                    [
                        0,
                        739673152
                    ],
                    [
                        0,
                        2081850432
                    ]
                ]
            },
            "e2e_gelu_1004_0": {
                "input": "gelu_1004",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    2
                ],
                "t": 2,
                "mblock": [
                    6,
                    4
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1069748064
                    ],
                    [
                        2,
                        2143489888
                    ],
                    [
                        3,
                        1069748064
                    ],
                    [
                        3,
                        2143489888
                    ]
                ]
            },
            "e2e__fused_op_132_0": {
                "input": "_fused_op_132",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1029277184
                    ],
                    [
                        2,
                        2103019008
                    ]
                ]
            },
            "e2e__fused_op_134_0": {
                "input": "_fused_op_134",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    4,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        749991232
                    ],
                    [
                        0,
                        2092168512
                    ],
                    [
                        1,
                        1018626368
                    ]
                ]
            },
            "e2e_matmul_1015_0": {
                "input": "matmul_1015",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    4
                ],
                "t": 1,
                "mblock": [
                    4,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        2079187136
                    ],
                    [
                        1,
                        1005678272
                    ],
                    [
                        1,
                        2079420096
                    ],
                    [
                        2,
                        1005678272
                    ],
                    [
                        2,
                        2079420096
                    ],
                    [
                        3,
                        1005911232
                    ],
                    [
                        3,
                        2079653056
                    ],
                    [
                        4,
                        1005977792
                    ],
                    [
                        4,
                        2079719616
                    ],
                    [
                        5,
                        1005977792
                    ],
                    [
                        5,
                        2079719616
                    ],
                    [
                        0,
                        736943264
                    ]
                ]
            },
            "e2e_matmul_1046_0": {
                "input": "matmul_1046",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    6,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1007276352
                    ],
                    [
                        1,
                        2081018176
                    ],
                    [
                        2,
                        1007276352
                    ],
                    [
                        2,
                        2081018176
                    ],
                    [
                        3,
                        1007476032
                    ],
                    [
                        3,
                        2081217856
                    ],
                    [
                        4,
                        1007542592
                    ],
                    [
                        4,
                        2081284416
                    ]
                ]
            },
            "e2e_layernorm_1065.dc.reduce_sum.5.lc1_0": {
                "input": "layernorm_1065.dc.reduce_sum.5.lc1",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 2,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        2078096128
                    ]
                ]
            },
            "e2e__fused_op_140_0": {
                "input": "_fused_op_140",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    2
                ],
                "t": 1,
                "mblock": [
                    12,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        1031473824
                    ],
                    [
                        4,
                        2105215648
                    ]
                ]
            },
            "e2e__fused_op_142_0": {
                "input": "_fused_op_142",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    6,
                    1
                ],
                "t": 16,
                "mblock": [
                    2,
                    2
                ],
                "ublock": [
                    1,
                    6
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        1067351808
                    ],
                    [
                        2,
                        2141093632
                    ],
                    [
                        3,
                        1067351808
                    ],
                    [
                        3,
                        2141093632
                    ],
                    [
                        4,
                        1067351808
                    ],
                    [
                        4,
                        2141093632
                    ]
                ]
            },
            "e2e_softmax_1084.dc.reduce_max.0_0": {
                "input": "softmax_1084.dc.reduce_max.0",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    6,
                    1
                ],
                "t": 16,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    2,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        2079253728
                    ],
                    [
                        1,
                        1005744864
                    ],
                    [
                        1,
                        2079486688
                    ],
                    [
                        2,
                        1005744864
                    ],
                    [
                        2,
                        2079486688
                    ],
                    [
                        3,
                        1005977824
                    ]
                ]
            },
            "e2e__fused_op_141_0": {
                "input": "_fused_op_141",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    6,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    2,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1007509376
                    ],
                    [
                        1,
                        2081251200
                    ],
                    [
                        2,
                        1007509376
                    ],
                    [
                        2,
                        2081251200
                    ],
                    [
                        3,
                        1007709056
                    ],
                    [
                        3,
                        2081450880
                    ]
                ]
            },
            "e2e_gelu_1110_0": {
                "input": "gelu_1110",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    2
                ],
                "t": 2,
                "mblock": [
                    6,
                    4
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1065754304
                    ],
                    [
                        1,
                        2139496128
                    ],
                    [
                        2,
                        1065754304
                    ],
                    [
                        2,
                        2139496128
                    ]
                ]
            },
            "e2e__fused_op_146_0": {
                "input": "_fused_op_146",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        759843264
                    ],
                    [
                        0,
                        2102020544
                    ]
                ]
            },
            "e2e__fused_op_148_0": {
                "input": "_fused_op_148",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    4,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        2090970240
                    ],
                    [
                        5,
                        1017228416
                    ],
                    [
                        5,
                        2090970240
                    ]
                ]
            },
            "e2e_matmul_1121_0": {
                "input": "matmul_1121",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    4
                ],
                "t": 1,
                "mblock": [
                    4,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1006410784
                    ],
                    [
                        1,
                        2080152608
                    ],
                    [
                        2,
                        1006410784
                    ],
                    [
                        2,
                        2080152608
                    ],
                    [
                        3,
                        1006643744
                    ],
                    [
                        3,
                        2080385568
                    ],
                    [
                        4,
                        1006710304
                    ],
                    [
                        4,
                        2080452128
                    ],
                    [
                        5,
                        1006710304
                    ],
                    [
                        5,
                        2080452128
                    ],
                    [
                        0,
                        737675776
                    ],
                    [
                        0,
                        2079853056
                    ]
                ]
            },
            "e2e_matmul_1152_0": {
                "input": "matmul_1152",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    6,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1007143104
                    ],
                    [
                        5,
                        2080884928
                    ],
                    [
                        0,
                        738108576
                    ],
                    [
                        0,
                        2080285856
                    ],
                    [
                        1,
                        1006776992
                    ],
                    [
                        1,
                        2080518816
                    ],
                    [
                        2,
                        1006776992
                    ],
                    [
                        2,
                        2080518816
                    ]
                ]
            },
            "e2e_layernorm_1171.dc.reduce_sum.5.lc1_0": {
                "input": "layernorm_1171.dc.reduce_sum.5.lc1",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    1
                ],
                "t": 2,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1004420864
                    ]
                ]
            },
            "e2e__fused_op_154_0": {
                "input": "_fused_op_154",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    1,
                    2
                ],
                "t": 1,
                "mblock": [
                    12,
                    2
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        1,
                        1028079008
                    ],
                    [
                        1,
                        2101820832
                    ]
                ]
            },
            "e2e__fused_op_156_0": {
                "input": "_fused_op_156",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    6,
                    1
                ],
                "t": 16,
                "mblock": [
                    2,
                    2
                ],
                "ublock": [
                    1,
                    6
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        0,
                        803708864
                    ],
                    [
                        0,
                        2145886144
                    ],
                    [
                        1,
                        1072144320
                    ],
                    [
                        1,
                        2145886144
                    ],
                    [
                        2,
                        1072144320
                    ],
                    [
                        2,
                        2145886144
                    ]
                ]
            },
            "e2e_softmax_1190.dc.reduce_max.0_0": {
                "input": "softmax_1190.dc.reduce_max.0",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    6,
                    1
                ],
                "t": 16,
                "mblock": [
                    1,
                    1
                ],
                "ublock": [
                    2,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        4,
                        2080185760
                    ],
                    [
                        5,
                        1006443936
                    ],
                    [
                        5,
                        2080185760
                    ],
                    [
                        0,
                        737409408
                    ],
                    [
                        0,
                        2079586688
                    ],
                    [
                        1,
                        1006077824
                    ]
                ]
            },
            "e2e__fused_op_155_0": {
                "input": "_fused_op_155",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    6,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    2,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        2081650656
                    ],
                    [
                        3,
                        1008108512
                    ],
                    [
                        3,
                        2081850336
                    ],
                    [
                        4,
                        1008175072
                    ],
                    [
                        4,
                        2081916896
                    ],
                    [
                        5,
                        1008175072
                    ]
                ]
            },
            "e2e_gelu_1216_0": {
                "input": "gelu_1216",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    2
                ],
                "t": 2,
                "mblock": [
                    6,
                    4
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "c",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1072144320
                    ],
                    [
                        5,
                        2145886144
                    ],
                    [
                        0,
                        802910112
                    ],
                    [
                        0,
                        2145087392
                    ]
                ]
            },
            "e2e__fused_op_160_0": {
                "input": "_fused_op_160",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    6,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        3,
                        1028678080
                    ],
                    [
                        3,
                        2102419904
                    ]
                ]
            },
            "e2e__fused_op_162_0": {
                "input": "_fused_op_162",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    1
                ],
                "t": 1,
                "mblock": [
                    1,
                    32
                ],
                "ublock": [
                    4,
                    1
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1021488768
                    ],
                    [
                        5,
                        2095230592
                    ],
                    [
                        0,
                        752387680
                    ]
                ]
            },
            "e2e_matmul_1227_0": {
                "input": "matmul_1227",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    3,
                    4
                ],
                "t": 1,
                "mblock": [
                    4,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        2,
                        2080086016
                    ],
                    [
                        3,
                        1006577152
                    ],
                    [
                        3,
                        2080318976
                    ],
                    [
                        4,
                        1006643712
                    ],
                    [
                        4,
                        2080385536
                    ],
                    [
                        5,
                        1006643712
                    ],
                    [
                        5,
                        2080385536
                    ],
                    [
                        0,
                        737609184
                    ],
                    [
                        0,
                        2079786464
                    ],
                    [
                        1,
                        1006277600
                    ],
                    [
                        1,
                        2080019424
                    ],
                    [
                        2,
                        1006277600
                    ]
                ]
            },
            "e2e_matmul_1258_0": {
                "input": "matmul_1258",
                "type": "queue",
                "entries": 1,
                "grid_size": [
                    2,
                    4
                ],
                "t": 1,
                "mblock": [
                    6,
                    1
                ],
                "ublock": [
                    1,
                    8
                ],
                "ublock_order": "r",
                "tile_dim": [
                    32,
                    32
                ],
                "df": "Float16_b",
                "target_device": 0,
                "loc": "dram",
                "dram": [
                    [
                        5,
                        1007043232
                    ],
                    [
                        5,
                        2080785056
                    ],
                    [
                        0,
                        738008704
                    ],
                    [
                        0,
                        2080185984
                    ],
                    [
                        1,
                        1006677120
                    ],
                    [
                        1,
                        2080418944
                    ],
                    [
                        2,
                        1006677120
                    ],
                    [
                        2,
                        2080418944
                    ]
                ]
            }
        },
        "graphs": {
            "fwd_0_0_temporal_epoch_0": {
                "target_device": 0,
                "input_count": 1,
                "layernorm_0.dc.reduce_sum.0.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        0
                    ],
                    "grid_size": [
                        4,
                        1
                    ],
                    "inputs": [
                        "pybuda_6_i0",
                        "lc.input_tensor.layernorm_0.dc.reduce_sum.0.0"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        3,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "_fused_op_0": {
                    "type": "fused_op",
                    "grid_loc": [
                        0,
                        1
                    ],
                    "grid_size": [
                        4,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_0.1",
                        "layernorm_0.dc.reduce_sum.0.lc1",
                        "pybuda_6_i0"
                    ],
                    "t": 1,
                    "mblock": [
                        3,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        96,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        48
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 32
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 0
                    }
                },
                "layernorm_0.dc.multiply.4": {
                    "type": "multiply",
                    "grid_loc": [
                        0,
                        3
                    ],
                    "grid_size": [
                        4,
                        1
                    ],
                    "inputs": [
                        "_fused_op_0",
                        "_fused_op_0"
                    ],
                    "t": 1,
                    "mblock": [
                        3,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "layernorm_0.dc.reduce_sum.5.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        5
                    ],
                    "grid_size": [
                        4,
                        1
                    ],
                    "inputs": [
                        "layernorm_0.dc.multiply.4",
                        "lc.input_tensor.layernorm_0.dc.reduce_sum.5.0"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        3,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_1_29655_29656": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        4
                    ],
                    "grid_size": [
                        4,
                        1
                    ],
                    "inputs": [
                        "_fused_op_0"
                    ],
                    "t": 1,
                    "mblock": [
                        3,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        240
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29655_29656": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        6
                    ],
                    "grid_size": [
                        4,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29655_29656"
                    ],
                    "t": 1,
                    "mblock": [
                        3,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        240
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_1": {
                    "type": "fused_op",
                    "grid_loc": [
                        1,
                        7
                    ],
                    "grid_size": [
                        4,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_0.6",
                        "layernorm_0.dc.reduce_sum.5.lc1",
                        "dc.input_tensor.layernorm_0.8",
                        "buffer_0_29655_29656",
                        "bert.embeddings.LayerNorm.weight",
                        "bert.embeddings.LayerNorm.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        32
                    ],
                    "ublock": [
                        3,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        3,
                        0,
                        3,
                        36,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0,
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_5_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_4_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 1,
                        "kernel_broadcast": {
                            "input_5": 96,
                            "input_4": 96
                        }
                    }
                },
                "matmul_4": {
                    "type": "matmul",
                    "grid_loc": [
                        4,
                        0
                    ],
                    "grid_size": [
                        4,
                        2
                    ],
                    "inputs": [
                        "_fused_op_1",
                        "bert.encoder.layer.0.attention.self.query.weight",
                        "bert.encoder.layer.0.attention.self.query.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        3,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        64,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 16
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_10": {
                    "type": "matmul",
                    "grid_loc": [
                        4,
                        2
                    ],
                    "grid_size": [
                        4,
                        2
                    ],
                    "inputs": [
                        "_fused_op_1",
                        "bert.encoder.layer.0.attention.self.key.weight",
                        "bert.encoder.layer.0.attention.self.key.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        3,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 16
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_16": {
                    "type": "matmul",
                    "grid_loc": [
                        4,
                        5
                    ],
                    "grid_size": [
                        4,
                        1
                    ],
                    "inputs": [
                        "matmul_4",
                        "matmul_10"
                    ],
                    "t": 16,
                    "mblock": [
                        3,
                        2
                    ],
                    "ublock": [
                        1,
                        6
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        339,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        "transpose",
                        {
                            "vslice": 16
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hslice": 16
                        }
                    ],
                    "attributes": {
                        "l1_acc": true,
                        "m_k": 2,
                        "min_buffer_input": 0,
                        "u_kt": 1
                    }
                },
                "subtract_21": {
                    "type": "subtract",
                    "grid_loc": [
                        0,
                        2
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "input_0_subtract_21",
                        "attention_mask_1"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        2
                    ],
                    "ublock": [
                        1,
                        6
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        48
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_0_tms": [
                        {
                            "broadcast": {
                                "c": 12
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_0": 1
                        }
                    }
                },
                "multiply_22": {
                    "type": "multiply",
                    "grid_loc": [
                        0,
                        4
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "subtract_21",
                        "input_1_multiply_22"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        2
                    ],
                    "ublock": [
                        1,
                        6
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 12
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        }
                    }
                },
                "multiply_22_attempt_1_input_op_fork_nop0": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        6
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "multiply_22"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        2
                    ],
                    "ublock": [
                        1,
                        6
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_2": {
                    "type": "fused_op",
                    "grid_loc": [
                        5,
                        6
                    ],
                    "grid_size": [
                        4,
                        2
                    ],
                    "inputs": [
                        "matmul_16",
                        "input_1_multiply_18",
                        "multiply_22_attempt_1_input_op_fork_nop0"
                    ],
                    "t": 16,
                    "mblock": [
                        3,
                        1
                    ],
                    "ublock": [
                        1,
                        6
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 12
                            }
                        },
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 2,
                        "kernel_broadcast": {
                            "input_1": 1
                        }
                    }
                },
                "softmax_24.dc.reduce_max.0": {
                    "type": "reduce",
                    "grid_loc": [
                        5,
                        4
                    ],
                    "grid_size": [
                        4,
                        1
                    ],
                    "inputs": [
                        "_fused_op_2"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        3,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "dim": "c",
                        "m_k": 1,
                        "type": "max",
                        "u_kt": 12
                    }
                },
                "multiply_22_attempt_1_input_op_fork_nop1": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        7
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "multiply_22"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        2
                    ],
                    "ublock": [
                        1,
                        6
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "multiply_22_attempt_1_input_op_fork_nop2": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        2
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "multiply_22"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        2
                    ],
                    "ublock": [
                        1,
                        6
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                }
            },
            "fwd_0_1_temporal_epoch_1": {
                "target_device": 0,
                "input_count": 1,
                "_fused_op_3": {
                    "type": "fused_op",
                    "grid_loc": [
                        0,
                        0
                    ],
                    "grid_size": [
                        2,
                        6
                    ],
                    "inputs": [
                        "e2e__fused_op_2_0",
                        "e2e_softmax_24.dc.reduce_max.0_0"
                    ],
                    "t": 16,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        3,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 32,
                    "input_dram_io_buf_size_tiles": [
                        24,
                        24
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 12
                            }
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 3
                    }
                },
                "softmax_24.dc.reduce_sum.3.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        6
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "_fused_op_3",
                        "lc.input_tensor.softmax_24.dc.reduce_sum.3.0"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 3,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_28": {
                    "type": "matmul",
                    "grid_loc": [
                        2,
                        1
                    ],
                    "grid_size": [
                        2,
                        4
                    ],
                    "inputs": [
                        "e2e__fused_op_1_0",
                        "bert.encoder.layer.0.attention.self.value.weight",
                        "bert.encoder.layer.0.attention.self.value.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 4,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                },
                "buffer_0_29658_29659": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        7
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "_fused_op_3"
                    ],
                    "t": 16,
                    "mblock": [
                        6,
                        2
                    ],
                    "ublock": [
                        1,
                        6
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        288
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_4": {
                    "type": "fused_op",
                    "grid_loc": [
                        2,
                        0
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "softmax_24.dc.reduce_sum.3.lc1",
                        "dc.input_tensor.softmax_24.4",
                        "buffer_0_29658_29659"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        12
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        96,
                        174
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 4
                    }
                },
                "matmul_35": {
                    "type": "matmul",
                    "grid_loc": [
                        2,
                        5
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "_fused_op_4",
                        "matmul_28"
                    ],
                    "t": 16,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        3,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 32,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "hslice": 16
                        }
                    ],
                    "attributes": {
                        "l1_acc": true,
                        "m_k": 2,
                        "min_buffer_input": 0,
                        "u_kt": 6
                    }
                },
                "matmul_39": {
                    "type": "matmul",
                    "grid_loc": [
                        4,
                        0
                    ],
                    "grid_size": [
                        2,
                        4
                    ],
                    "inputs": [
                        "matmul_35",
                        "bert.encoder.layer.0.attention.output.dense.weight",
                        "bert.encoder.layer.0.attention.output.dense.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 16
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 16,
                        "min_buffer_input": 0,
                        "u_kt": 2
                    }
                },
                "add_43": {
                    "type": "add",
                    "grid_loc": [
                        2,
                        6
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "matmul_39",
                        "e2e__fused_op_1_0"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        48
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "layernorm_44.dc.reduce_sum.0.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        2,
                        7
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "add_43",
                        "lc.input_tensor.layernorm_44.dc.reduce_sum.0.0"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_1_27200_29660": {
                    "type": "nop",
                    "grid_loc": [
                        4,
                        4
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "add_43"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_27200_29660": {
                    "type": "nop",
                    "grid_loc": [
                        4,
                        5
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "buffer_1_27200_29660"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_5": {
                    "type": "fused_op",
                    "grid_loc": [
                        4,
                        6
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_44.1",
                        "layernorm_44.dc.reduce_sum.0.lc1",
                        "buffer_0_27200_29660"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 32
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 5
                    }
                },
                "layernorm_44.dc.multiply.4": {
                    "type": "multiply",
                    "grid_loc": [
                        4,
                        7
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "_fused_op_5",
                        "_fused_op_5"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "layernorm_44.dc.reduce_sum.5.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        6,
                        0
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "layernorm_44.dc.multiply.4",
                        "lc.input_tensor.layernorm_44.dc.reduce_sum.5.0"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_2_29660_29661": {
                    "type": "nop",
                    "grid_loc": [
                        6,
                        1
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "_fused_op_5"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_1_29660_29661": {
                    "type": "nop",
                    "grid_loc": [
                        6,
                        2
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "buffer_2_29660_29661"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29660_29661": {
                    "type": "nop",
                    "grid_loc": [
                        6,
                        3
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29660_29661"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_6": {
                    "type": "fused_op",
                    "grid_loc": [
                        6,
                        4
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_44.6",
                        "layernorm_44.dc.reduce_sum.5.lc1",
                        "dc.input_tensor.layernorm_44.8",
                        "buffer_0_29660_29661",
                        "bert.encoder.layer.0.attention.output.LayerNorm.weight",
                        "bert.encoder.layer.0.attention.output.LayerNorm.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        32
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        6,
                        0,
                        6,
                        0,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0,
                        0,
                        24,
                        24
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_5_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_4_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 6
                    }
                },
                "matmul_47": {
                    "type": "matmul",
                    "grid_loc": [
                        8,
                        0
                    ],
                    "grid_size": [
                        2,
                        8
                    ],
                    "inputs": [
                        "_fused_op_6",
                        "bert.encoder.layer.0.intermediate.dense.weight",
                        "bert.encoder.layer.0.intermediate.dense.bias"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "hslice": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "hslice": 2
                        }
                    ],
                    "input_0_tms": [
                        {
                            "broadcast": {
                                "r": 2
                            }
                        },
                        {
                            "vslice": 2
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "gelu_50": {
                    "type": "gelu",
                    "grid_loc": [
                        6,
                        5
                    ],
                    "grid_size": [
                        2,
                        2
                    ],
                    "inputs": [
                        "matmul_47"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "approximate_mode": false
                    }
                }
            },
            "fwd_0_2_temporal_epoch_2": {
                "target_device": 0,
                "input_count": 1,
                "matmul_53": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        0
                    ],
                    "grid_size": [
                        3,
                        8
                    ],
                    "inputs": [
                        "e2e_gelu_50_0",
                        "bert.encoder.layer.0.output.dense.weight",
                        "bert.encoder.layer.0.output.dense.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        2,
                        4
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 4
                        },
                        "l1_acc": true,
                        "m_k": 16,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                },
                "add_57": {
                    "type": "add",
                    "grid_loc": [
                        3,
                        0
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "matmul_53",
                        "e2e__fused_op_6_0"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        48
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "layernorm_58.dc.reduce_sum.0.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        3,
                        1
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "add_57",
                        "lc.input_tensor.layernorm_58.dc.reduce_sum.0.0"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_1_27232_29662": {
                    "type": "nop",
                    "grid_loc": [
                        3,
                        2
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "add_57"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_27232_29662": {
                    "type": "nop",
                    "grid_loc": [
                        3,
                        3
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "buffer_1_27232_29662"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_7": {
                    "type": "fused_op",
                    "grid_loc": [
                        3,
                        4
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_58.1",
                        "layernorm_58.dc.reduce_sum.0.lc1",
                        "buffer_0_27232_29662"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        128,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 32
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 7
                    }
                },
                "layernorm_58.dc.multiply.4": {
                    "type": "multiply",
                    "grid_loc": [
                        3,
                        5
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "_fused_op_7",
                        "_fused_op_7"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "layernorm_58.dc.reduce_sum.5.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        3,
                        6
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "layernorm_58.dc.multiply.4",
                        "lc.input_tensor.layernorm_58.dc.reduce_sum.5.0"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_1_29662_29663": {
                    "type": "nop",
                    "grid_loc": [
                        3,
                        7
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "_fused_op_7"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        176
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29662_29663": {
                    "type": "nop",
                    "grid_loc": [
                        6,
                        0
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29662_29663"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        176
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_8": {
                    "type": "fused_op",
                    "grid_loc": [
                        6,
                        1
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_58.6",
                        "layernorm_58.dc.reduce_sum.5.lc1",
                        "dc.input_tensor.layernorm_58.8",
                        "buffer_0_29662_29663",
                        "bert.encoder.layer.0.output.LayerNorm.weight",
                        "bert.encoder.layer.0.output.LayerNorm.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        32
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        4,
                        0,
                        4,
                        0,
                        128,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0,
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_5_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_4_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 8
                    }
                },
                "matmul_61": {
                    "type": "matmul",
                    "grid_loc": [
                        6,
                        2
                    ],
                    "grid_size": [
                        3,
                        4
                    ],
                    "inputs": [
                        "_fused_op_8",
                        "bert.encoder.layer.1.attention.self.query.weight",
                        "bert.encoder.layer.1.attention.self.query.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 4,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                }
            },
            "fwd_0_3_temporal_epoch_3": {
                "target_device": 0,
                "input_count": 1,
                "matmul_67": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        0
                    ],
                    "grid_size": [
                        3,
                        4
                    ],
                    "inputs": [
                        "e2e__fused_op_8_0",
                        "bert.encoder.layer.1.attention.self.key.weight",
                        "bert.encoder.layer.1.attention.self.key.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 4,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                },
                "matmul_73": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        4
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "e2e_matmul_61_0",
                        "matmul_67"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        6
                    ],
                    "ublock": [
                        4,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        "transpose",
                        {
                            "vslice": 16
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hslice": 16
                        }
                    ],
                    "attributes": {
                        "l1_acc": true,
                        "m_k": 2,
                        "min_buffer_input": 0,
                        "u_kt": 1
                    }
                },
                "_fused_op_9": {
                    "type": "fused_op",
                    "grid_loc": [
                        0,
                        5
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "matmul_73",
                        "input_1_multiply_75",
                        "e2e_multiply_22_attempt_1_input_op_fork_nop0_0"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        6
                    ],
                    "ublock": [
                        4,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        48
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 12
                            }
                        },
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 9,
                        "kernel_broadcast": {
                            "input_1": 1
                        }
                    }
                },
                "softmax_77.dc.reduce_max.0": {
                    "type": "reduce",
                    "grid_loc": [
                        0,
                        6
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "_fused_op_9"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "dim": "c",
                        "m_k": 1,
                        "type": "max",
                        "u_kt": 12
                    }
                },
                "_fused_op_10": {
                    "type": "fused_op",
                    "grid_loc": [
                        3,
                        0
                    ],
                    "grid_size": [
                        3,
                        6
                    ],
                    "inputs": [
                        "_fused_op_9",
                        "softmax_77.dc.reduce_max.0"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        400,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 12
                            }
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 10
                    }
                },
                "softmax_77.dc.reduce_sum.3.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        7
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "_fused_op_10",
                        "lc.input_tensor.softmax_77.dc.reduce_sum.3.0"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 3,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_81": {
                    "type": "matmul",
                    "grid_loc": [
                        6,
                        0
                    ],
                    "grid_size": [
                        3,
                        4
                    ],
                    "inputs": [
                        "e2e__fused_op_8_0",
                        "bert.encoder.layer.1.attention.self.value.weight",
                        "bert.encoder.layer.1.attention.self.value.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 4,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                },
                "_fused_op_11": {
                    "type": "fused_op",
                    "grid_loc": [
                        3,
                        6
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "softmax_77.dc.reduce_sum.3.lc1",
                        "dc.input_tensor.softmax_77.4",
                        "_fused_op_10"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        12
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        64,
                        260
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 11
                    }
                },
                "matmul_88": {
                    "type": "matmul",
                    "grid_loc": [
                        3,
                        7
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "_fused_op_11",
                        "matmul_81"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 32,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "hslice": 16
                        }
                    ],
                    "attributes": {
                        "l1_acc": true,
                        "m_k": 3,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_92": {
                    "type": "matmul",
                    "grid_loc": [
                        6,
                        4
                    ],
                    "grid_size": [
                        2,
                        4
                    ],
                    "inputs": [
                        "matmul_88",
                        "bert.encoder.layer.1.attention.output.dense.weight",
                        "bert.encoder.layer.1.attention.output.dense.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 16
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 16,
                        "min_buffer_input": 0,
                        "u_kt": 2
                    }
                }
            },
            "fwd_0_4_temporal_epoch_4": {
                "target_device": 0,
                "input_count": 1,
                "add_96": {
                    "type": "add",
                    "grid_loc": [
                        0,
                        0
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "e2e_matmul_92_0",
                        "e2e__fused_op_8_0"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        24,
                        24
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "hslice": 2
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hslice": 2
                        }
                    ]
                },
                "layernorm_97.dc.reduce_sum.0.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        1
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "add_96",
                        "lc.input_tensor.layernorm_97.dc.reduce_sum.0.0"
                    ],
                    "t": 1,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_3_27304_29667": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        2
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "add_96"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_2_27304_29667": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        3
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_3_27304_29667"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_1_27304_29667": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        4
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_2_27304_29667"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_27304_29667": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        5
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_1_27304_29667"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_12": {
                    "type": "fused_op",
                    "grid_loc": [
                        0,
                        6
                    ],
                    "grid_size": [
                        1,
                        2
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_97.1",
                        "layernorm_97.dc.reduce_sum.0.lc1",
                        "buffer_0_27304_29667"
                    ],
                    "t": 1,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 32
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 12
                    }
                },
                "layernorm_97.dc.multiply.4": {
                    "type": "multiply",
                    "grid_loc": [
                        1,
                        0
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "_fused_op_12",
                        "_fused_op_12"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "vslice": 2
                        }
                    ],
                    "input_0_tms": [
                        {
                            "vslice": 2
                        }
                    ]
                },
                "layernorm_97.dc.reduce_sum.5.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        1,
                        1
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "layernorm_97.dc.multiply.4",
                        "lc.input_tensor.layernorm_97.dc.reduce_sum.5.0"
                    ],
                    "t": 2,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 2
                            }
                        },
                        {
                            "broadcast": {
                                "r": 32
                            }
                        },
                        {
                            "hslice": 2
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_4_29667_29668": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        2
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "_fused_op_12"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_0_tms": [
                        {
                            "vslice": 2
                        }
                    ]
                },
                "buffer_3_29667_29668": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        3
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_4_29667_29668"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_2_29667_29668": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        4
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_3_29667_29668"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_1_29667_29668": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        5
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_2_29667_29668"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29667_29668": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        6
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29667_29668"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_13": {
                    "type": "fused_op",
                    "grid_loc": [
                        1,
                        7
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_97.6",
                        "layernorm_97.dc.reduce_sum.5.lc1",
                        "dc.input_tensor.layernorm_97.8",
                        "buffer_0_29667_29668",
                        "bert.encoder.layer.1.attention.output.LayerNorm.weight",
                        "bert.encoder.layer.1.attention.output.LayerNorm.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        32
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        6,
                        0,
                        6,
                        0,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0,
                        0,
                        24,
                        24
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_5_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_4_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_3_tms": [
                        {
                            "vstack": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "vstack": 2
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 6
                    }
                },
                "matmul_100": {
                    "type": "matmul",
                    "grid_loc": [
                        3,
                        0
                    ],
                    "grid_size": [
                        2,
                        8
                    ],
                    "inputs": [
                        "_fused_op_13",
                        "bert.encoder.layer.1.intermediate.dense.weight",
                        "bert.encoder.layer.1.intermediate.dense.bias"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "hslice": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "hslice": 2
                        }
                    ],
                    "input_0_tms": [
                        {
                            "broadcast": {
                                "r": 2
                            }
                        },
                        {
                            "vslice": 2
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "gelu_103": {
                    "type": "gelu",
                    "grid_loc": [
                        2,
                        0
                    ],
                    "grid_size": [
                        1,
                        4
                    ],
                    "inputs": [
                        "matmul_100"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "approximate_mode": false
                    }
                },
                "matmul_106": {
                    "type": "matmul",
                    "grid_loc": [
                        5,
                        0
                    ],
                    "grid_size": [
                        2,
                        8
                    ],
                    "inputs": [
                        "gelu_103",
                        "bert.encoder.layer.1.output.dense.weight",
                        "bert.encoder.layer.1.output.dense.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        3,
                        1
                    ],
                    "ublock": [
                        2,
                        4
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 4
                        },
                        "l1_acc": true,
                        "m_k": 16,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                },
                "buffer_7_29668_27336": {
                    "type": "nop",
                    "grid_loc": [
                        2,
                        4
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "_fused_op_13"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_0_tms": [
                        {
                            "hslice": 2
                        }
                    ]
                },
                "buffer_6_29668_27336": {
                    "type": "nop",
                    "grid_loc": [
                        2,
                        5
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_7_29668_27336"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_5_29668_27336": {
                    "type": "nop",
                    "grid_loc": [
                        2,
                        6
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_6_29668_27336"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_4_29668_27336": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        0
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_5_29668_27336"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_3_29668_27336": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        1
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_4_29668_27336"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_2_29668_27336": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        2
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_3_29668_27336"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_1_29668_27336": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        3
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_2_29668_27336"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29668_27336": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        4
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29668_27336"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "add_110": {
                    "type": "add",
                    "grid_loc": [
                        7,
                        5
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "matmul_106",
                        "buffer_0_29668_27336"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_0_tms": [
                        {
                            "hslice": 2
                        }
                    ]
                },
                "layernorm_111.dc.reduce_sum.0.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        7,
                        6
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "add_110",
                        "lc.input_tensor.layernorm_111.dc.reduce_sum.0.0"
                    ],
                    "t": 1,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_3_27336_29669": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        7
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "add_110"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_2_27336_29669": {
                    "type": "nop",
                    "grid_loc": [
                        8,
                        0
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_3_27336_29669"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_1_27336_29669": {
                    "type": "nop",
                    "grid_loc": [
                        8,
                        1
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_2_27336_29669"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_27336_29669": {
                    "type": "nop",
                    "grid_loc": [
                        8,
                        2
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_1_27336_29669"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_14": {
                    "type": "fused_op",
                    "grid_loc": [
                        8,
                        3
                    ],
                    "grid_size": [
                        1,
                        2
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_111.1",
                        "layernorm_111.dc.reduce_sum.0.lc1",
                        "buffer_0_27336_29669"
                    ],
                    "t": 1,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 32
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 12
                    }
                },
                "layernorm_111.dc.multiply.4": {
                    "type": "multiply",
                    "grid_loc": [
                        8,
                        5
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "_fused_op_14",
                        "_fused_op_14"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "vslice": 2
                        }
                    ],
                    "input_0_tms": [
                        {
                            "vslice": 2
                        }
                    ]
                },
                "layernorm_111.dc.reduce_sum.5.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        8,
                        6
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "layernorm_111.dc.multiply.4",
                        "lc.input_tensor.layernorm_111.dc.reduce_sum.5.0"
                    ],
                    "t": 2,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 2
                            }
                        },
                        {
                            "broadcast": {
                                "r": 32
                            }
                        },
                        {
                            "hslice": 2
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                }
            },
            "fwd_0_5_temporal_epoch_5": {
                "target_device": 0,
                "input_count": 1,
                "_fused_op_15": {
                    "type": "fused_op",
                    "grid_loc": [
                        0,
                        0
                    ],
                    "grid_size": [
                        6,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_111.6",
                        "e2e_layernorm_111.dc.reduce_sum.5.lc1_0",
                        "dc.input_tensor.layernorm_111.8",
                        "e2e__fused_op_14_0",
                        "bert.encoder.layer.1.output.LayerNorm.weight",
                        "bert.encoder.layer.1.output.LayerNorm.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        32
                    ],
                    "ublock": [
                        2,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        2,
                        0,
                        2,
                        0,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        24,
                        0,
                        24,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_5_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_4_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_1_tms": [
                        {
                            "vstack": 2
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 15,
                        "kernel_broadcast": {
                            "input_5": 64,
                            "input_4": 64
                        }
                    }
                },
                "matmul_114": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        1
                    ],
                    "grid_size": [
                        6,
                        2
                    ],
                    "inputs": [
                        "_fused_op_15",
                        "bert.encoder.layer.2.attention.self.query.weight",
                        "bert.encoder.layer.2.attention.self.query.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        2,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        96,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 16
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_120": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        3
                    ],
                    "grid_size": [
                        6,
                        2
                    ],
                    "inputs": [
                        "_fused_op_15",
                        "bert.encoder.layer.2.attention.self.key.weight",
                        "bert.encoder.layer.2.attention.self.key.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        2,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 16
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_126": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        5
                    ],
                    "grid_size": [
                        6,
                        1
                    ],
                    "inputs": [
                        "matmul_114",
                        "matmul_120"
                    ],
                    "t": 16,
                    "mblock": [
                        2,
                        2
                    ],
                    "ublock": [
                        1,
                        6
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        363,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        "transpose",
                        {
                            "vslice": 16
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hslice": 16
                        }
                    ],
                    "attributes": {
                        "l1_acc": true,
                        "m_k": 2,
                        "min_buffer_input": 0,
                        "u_kt": 1
                    }
                },
                "_fused_op_16": {
                    "type": "fused_op",
                    "grid_loc": [
                        0,
                        6
                    ],
                    "grid_size": [
                        6,
                        1
                    ],
                    "inputs": [
                        "matmul_126",
                        "input_1_multiply_128",
                        "e2e_multiply_22_attempt_1_input_op_fork_nop0_0"
                    ],
                    "t": 16,
                    "mblock": [
                        2,
                        2
                    ],
                    "ublock": [
                        1,
                        6
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        48
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 12
                            }
                        },
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 16,
                        "kernel_broadcast": {
                            "input_1": 1
                        }
                    }
                },
                "softmax_130.dc.reduce_max.0": {
                    "type": "reduce",
                    "grid_loc": [
                        0,
                        7
                    ],
                    "grid_size": [
                        6,
                        1
                    ],
                    "inputs": [
                        "_fused_op_16"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        2,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "dim": "c",
                        "m_k": 1,
                        "type": "max",
                        "u_kt": 12
                    }
                }
            },
            "fwd_0_6_temporal_epoch_6": {
                "target_device": 0,
                "input_count": 1,
                "_fused_op_17": {
                    "type": "fused_op",
                    "grid_loc": [
                        0,
                        0
                    ],
                    "grid_size": [
                        2,
                        6
                    ],
                    "inputs": [
                        "e2e__fused_op_16_0",
                        "e2e_softmax_130.dc.reduce_max.0_0"
                    ],
                    "t": 16,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        3,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 32,
                    "input_dram_io_buf_size_tiles": [
                        24,
                        24
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 12
                            }
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 3
                    }
                },
                "softmax_130.dc.reduce_sum.3.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        6
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "_fused_op_17",
                        "lc.input_tensor.softmax_130.dc.reduce_sum.3.0"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 3,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_134": {
                    "type": "matmul",
                    "grid_loc": [
                        2,
                        1
                    ],
                    "grid_size": [
                        2,
                        4
                    ],
                    "inputs": [
                        "e2e__fused_op_15_0",
                        "bert.encoder.layer.2.attention.self.value.weight",
                        "bert.encoder.layer.2.attention.self.value.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 4,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                },
                "buffer_0_29672_29673": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        7
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "_fused_op_17"
                    ],
                    "t": 16,
                    "mblock": [
                        6,
                        2
                    ],
                    "ublock": [
                        1,
                        6
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        288
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_18": {
                    "type": "fused_op",
                    "grid_loc": [
                        2,
                        0
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "softmax_130.dc.reduce_sum.3.lc1",
                        "dc.input_tensor.softmax_130.4",
                        "buffer_0_29672_29673"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        12
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        96,
                        174
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 4
                    }
                },
                "matmul_141": {
                    "type": "matmul",
                    "grid_loc": [
                        2,
                        5
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "_fused_op_18",
                        "matmul_134"
                    ],
                    "t": 16,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        3,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 32,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "hslice": 16
                        }
                    ],
                    "attributes": {
                        "l1_acc": true,
                        "m_k": 2,
                        "min_buffer_input": 0,
                        "u_kt": 6
                    }
                },
                "matmul_145": {
                    "type": "matmul",
                    "grid_loc": [
                        4,
                        0
                    ],
                    "grid_size": [
                        2,
                        4
                    ],
                    "inputs": [
                        "matmul_141",
                        "bert.encoder.layer.2.attention.output.dense.weight",
                        "bert.encoder.layer.2.attention.output.dense.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 16
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 16,
                        "min_buffer_input": 0,
                        "u_kt": 2
                    }
                },
                "add_149": {
                    "type": "add",
                    "grid_loc": [
                        2,
                        6
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "matmul_145",
                        "e2e__fused_op_15_0"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        48
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "layernorm_150.dc.reduce_sum.0.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        2,
                        7
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "add_149",
                        "lc.input_tensor.layernorm_150.dc.reduce_sum.0.0"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_1_27408_29674": {
                    "type": "nop",
                    "grid_loc": [
                        4,
                        4
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "add_149"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_27408_29674": {
                    "type": "nop",
                    "grid_loc": [
                        4,
                        5
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "buffer_1_27408_29674"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_19": {
                    "type": "fused_op",
                    "grid_loc": [
                        4,
                        6
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_150.1",
                        "layernorm_150.dc.reduce_sum.0.lc1",
                        "buffer_0_27408_29674"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 32
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 5
                    }
                },
                "layernorm_150.dc.multiply.4": {
                    "type": "multiply",
                    "grid_loc": [
                        4,
                        7
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "_fused_op_19",
                        "_fused_op_19"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "layernorm_150.dc.reduce_sum.5.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        6,
                        0
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "layernorm_150.dc.multiply.4",
                        "lc.input_tensor.layernorm_150.dc.reduce_sum.5.0"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_2_29674_29675": {
                    "type": "nop",
                    "grid_loc": [
                        6,
                        1
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "_fused_op_19"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_1_29674_29675": {
                    "type": "nop",
                    "grid_loc": [
                        6,
                        2
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "buffer_2_29674_29675"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29674_29675": {
                    "type": "nop",
                    "grid_loc": [
                        6,
                        3
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29674_29675"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_20": {
                    "type": "fused_op",
                    "grid_loc": [
                        6,
                        4
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_150.6",
                        "layernorm_150.dc.reduce_sum.5.lc1",
                        "dc.input_tensor.layernorm_150.8",
                        "buffer_0_29674_29675",
                        "bert.encoder.layer.2.attention.output.LayerNorm.weight",
                        "bert.encoder.layer.2.attention.output.LayerNorm.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        32
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        6,
                        0,
                        6,
                        0,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0,
                        0,
                        24,
                        24
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_5_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_4_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 6
                    }
                },
                "matmul_153": {
                    "type": "matmul",
                    "grid_loc": [
                        8,
                        0
                    ],
                    "grid_size": [
                        2,
                        8
                    ],
                    "inputs": [
                        "_fused_op_20",
                        "bert.encoder.layer.2.intermediate.dense.weight",
                        "bert.encoder.layer.2.intermediate.dense.bias"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "hslice": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "hslice": 2
                        }
                    ],
                    "input_0_tms": [
                        {
                            "broadcast": {
                                "r": 2
                            }
                        },
                        {
                            "vslice": 2
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "gelu_156": {
                    "type": "gelu",
                    "grid_loc": [
                        6,
                        5
                    ],
                    "grid_size": [
                        2,
                        2
                    ],
                    "inputs": [
                        "matmul_153"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "approximate_mode": false
                    }
                }
            },
            "fwd_0_7_temporal_epoch_7": {
                "target_device": 0,
                "input_count": 1,
                "matmul_159": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        0
                    ],
                    "grid_size": [
                        3,
                        8
                    ],
                    "inputs": [
                        "e2e_gelu_156_0",
                        "bert.encoder.layer.2.output.dense.weight",
                        "bert.encoder.layer.2.output.dense.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        2,
                        4
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 4
                        },
                        "l1_acc": true,
                        "m_k": 16,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                },
                "add_163": {
                    "type": "add",
                    "grid_loc": [
                        3,
                        0
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "matmul_159",
                        "e2e__fused_op_20_0"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        48
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "layernorm_164.dc.reduce_sum.0.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        3,
                        1
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "add_163",
                        "lc.input_tensor.layernorm_164.dc.reduce_sum.0.0"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_1_27440_29676": {
                    "type": "nop",
                    "grid_loc": [
                        3,
                        2
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "add_163"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_27440_29676": {
                    "type": "nop",
                    "grid_loc": [
                        3,
                        3
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "buffer_1_27440_29676"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_21": {
                    "type": "fused_op",
                    "grid_loc": [
                        3,
                        4
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_164.1",
                        "layernorm_164.dc.reduce_sum.0.lc1",
                        "buffer_0_27440_29676"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        128,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 32
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 7
                    }
                },
                "layernorm_164.dc.multiply.4": {
                    "type": "multiply",
                    "grid_loc": [
                        3,
                        5
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "_fused_op_21",
                        "_fused_op_21"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "layernorm_164.dc.reduce_sum.5.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        3,
                        6
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "layernorm_164.dc.multiply.4",
                        "lc.input_tensor.layernorm_164.dc.reduce_sum.5.0"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_1_29676_29677": {
                    "type": "nop",
                    "grid_loc": [
                        3,
                        7
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "_fused_op_21"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        176
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29676_29677": {
                    "type": "nop",
                    "grid_loc": [
                        6,
                        0
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29676_29677"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        176
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_22": {
                    "type": "fused_op",
                    "grid_loc": [
                        6,
                        1
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_164.6",
                        "layernorm_164.dc.reduce_sum.5.lc1",
                        "dc.input_tensor.layernorm_164.8",
                        "buffer_0_29676_29677",
                        "bert.encoder.layer.2.output.LayerNorm.weight",
                        "bert.encoder.layer.2.output.LayerNorm.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        32
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        4,
                        0,
                        4,
                        0,
                        128,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0,
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_5_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_4_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 8
                    }
                },
                "matmul_167": {
                    "type": "matmul",
                    "grid_loc": [
                        6,
                        2
                    ],
                    "grid_size": [
                        3,
                        4
                    ],
                    "inputs": [
                        "_fused_op_22",
                        "bert.encoder.layer.3.attention.self.query.weight",
                        "bert.encoder.layer.3.attention.self.query.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 4,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                }
            },
            "fwd_0_8_temporal_epoch_8": {
                "target_device": 0,
                "input_count": 1,
                "matmul_173": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        0
                    ],
                    "grid_size": [
                        3,
                        4
                    ],
                    "inputs": [
                        "e2e__fused_op_22_0",
                        "bert.encoder.layer.3.attention.self.key.weight",
                        "bert.encoder.layer.3.attention.self.key.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 4,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                },
                "matmul_179": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        4
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "e2e_matmul_167_0",
                        "matmul_173"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        6
                    ],
                    "ublock": [
                        4,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        "transpose",
                        {
                            "vslice": 16
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hslice": 16
                        }
                    ],
                    "attributes": {
                        "l1_acc": true,
                        "m_k": 2,
                        "min_buffer_input": 0,
                        "u_kt": 1
                    }
                },
                "_fused_op_23": {
                    "type": "fused_op",
                    "grid_loc": [
                        0,
                        5
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "matmul_179",
                        "input_1_multiply_181",
                        "e2e_multiply_22_attempt_1_input_op_fork_nop0_0"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        6
                    ],
                    "ublock": [
                        4,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        48
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 12
                            }
                        },
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 9,
                        "kernel_broadcast": {
                            "input_1": 1
                        }
                    }
                },
                "softmax_183.dc.reduce_max.0": {
                    "type": "reduce",
                    "grid_loc": [
                        0,
                        6
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "_fused_op_23"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "dim": "c",
                        "m_k": 1,
                        "type": "max",
                        "u_kt": 12
                    }
                },
                "_fused_op_24": {
                    "type": "fused_op",
                    "grid_loc": [
                        3,
                        0
                    ],
                    "grid_size": [
                        3,
                        6
                    ],
                    "inputs": [
                        "_fused_op_23",
                        "softmax_183.dc.reduce_max.0"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        400,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 12
                            }
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 10
                    }
                },
                "softmax_183.dc.reduce_sum.3.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        7
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "_fused_op_24",
                        "lc.input_tensor.softmax_183.dc.reduce_sum.3.0"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 3,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_187": {
                    "type": "matmul",
                    "grid_loc": [
                        6,
                        0
                    ],
                    "grid_size": [
                        3,
                        4
                    ],
                    "inputs": [
                        "e2e__fused_op_22_0",
                        "bert.encoder.layer.3.attention.self.value.weight",
                        "bert.encoder.layer.3.attention.self.value.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 4,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                },
                "_fused_op_25": {
                    "type": "fused_op",
                    "grid_loc": [
                        3,
                        6
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "softmax_183.dc.reduce_sum.3.lc1",
                        "dc.input_tensor.softmax_183.4",
                        "_fused_op_24"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        12
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        64,
                        260
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 11
                    }
                },
                "matmul_194": {
                    "type": "matmul",
                    "grid_loc": [
                        3,
                        7
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "_fused_op_25",
                        "matmul_187"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 32,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "hslice": 16
                        }
                    ],
                    "attributes": {
                        "l1_acc": true,
                        "m_k": 3,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_198": {
                    "type": "matmul",
                    "grid_loc": [
                        6,
                        4
                    ],
                    "grid_size": [
                        2,
                        4
                    ],
                    "inputs": [
                        "matmul_194",
                        "bert.encoder.layer.3.attention.output.dense.weight",
                        "bert.encoder.layer.3.attention.output.dense.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 16
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 16,
                        "min_buffer_input": 0,
                        "u_kt": 2
                    }
                }
            },
            "fwd_0_9_temporal_epoch_9": {
                "target_device": 0,
                "input_count": 1,
                "add_202": {
                    "type": "add",
                    "grid_loc": [
                        0,
                        0
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "e2e_matmul_198_0",
                        "e2e__fused_op_22_0"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        24,
                        24
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "hslice": 2
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hslice": 2
                        }
                    ]
                },
                "layernorm_203.dc.reduce_sum.0.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        1
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "add_202",
                        "lc.input_tensor.layernorm_203.dc.reduce_sum.0.0"
                    ],
                    "t": 1,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_3_27512_29681": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        2
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "add_202"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_2_27512_29681": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        3
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_3_27512_29681"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_1_27512_29681": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        4
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_2_27512_29681"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_27512_29681": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        5
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_1_27512_29681"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_26": {
                    "type": "fused_op",
                    "grid_loc": [
                        0,
                        6
                    ],
                    "grid_size": [
                        1,
                        2
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_203.1",
                        "layernorm_203.dc.reduce_sum.0.lc1",
                        "buffer_0_27512_29681"
                    ],
                    "t": 1,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 32
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 12
                    }
                },
                "layernorm_203.dc.multiply.4": {
                    "type": "multiply",
                    "grid_loc": [
                        1,
                        0
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "_fused_op_26",
                        "_fused_op_26"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "vslice": 2
                        }
                    ],
                    "input_0_tms": [
                        {
                            "vslice": 2
                        }
                    ]
                },
                "layernorm_203.dc.reduce_sum.5.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        1,
                        1
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "layernorm_203.dc.multiply.4",
                        "lc.input_tensor.layernorm_203.dc.reduce_sum.5.0"
                    ],
                    "t": 2,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 2
                            }
                        },
                        {
                            "broadcast": {
                                "r": 32
                            }
                        },
                        {
                            "hslice": 2
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_4_29681_29682": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        2
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "_fused_op_26"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_0_tms": [
                        {
                            "vslice": 2
                        }
                    ]
                },
                "buffer_3_29681_29682": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        3
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_4_29681_29682"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_2_29681_29682": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        4
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_3_29681_29682"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_1_29681_29682": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        5
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_2_29681_29682"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29681_29682": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        6
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29681_29682"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_27": {
                    "type": "fused_op",
                    "grid_loc": [
                        1,
                        7
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_203.6",
                        "layernorm_203.dc.reduce_sum.5.lc1",
                        "dc.input_tensor.layernorm_203.8",
                        "buffer_0_29681_29682",
                        "bert.encoder.layer.3.attention.output.LayerNorm.weight",
                        "bert.encoder.layer.3.attention.output.LayerNorm.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        32
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        6,
                        0,
                        6,
                        0,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0,
                        0,
                        24,
                        24
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_5_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_4_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_3_tms": [
                        {
                            "vstack": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "vstack": 2
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 6
                    }
                },
                "matmul_206": {
                    "type": "matmul",
                    "grid_loc": [
                        3,
                        0
                    ],
                    "grid_size": [
                        2,
                        8
                    ],
                    "inputs": [
                        "_fused_op_27",
                        "bert.encoder.layer.3.intermediate.dense.weight",
                        "bert.encoder.layer.3.intermediate.dense.bias"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "hslice": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "hslice": 2
                        }
                    ],
                    "input_0_tms": [
                        {
                            "broadcast": {
                                "r": 2
                            }
                        },
                        {
                            "vslice": 2
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "gelu_209": {
                    "type": "gelu",
                    "grid_loc": [
                        2,
                        0
                    ],
                    "grid_size": [
                        1,
                        4
                    ],
                    "inputs": [
                        "matmul_206"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "approximate_mode": false
                    }
                },
                "matmul_212": {
                    "type": "matmul",
                    "grid_loc": [
                        5,
                        0
                    ],
                    "grid_size": [
                        2,
                        8
                    ],
                    "inputs": [
                        "gelu_209",
                        "bert.encoder.layer.3.output.dense.weight",
                        "bert.encoder.layer.3.output.dense.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        3,
                        1
                    ],
                    "ublock": [
                        2,
                        4
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 4
                        },
                        "l1_acc": true,
                        "m_k": 16,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                },
                "buffer_7_29682_27544": {
                    "type": "nop",
                    "grid_loc": [
                        2,
                        4
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "_fused_op_27"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_0_tms": [
                        {
                            "hslice": 2
                        }
                    ]
                },
                "buffer_6_29682_27544": {
                    "type": "nop",
                    "grid_loc": [
                        2,
                        5
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_7_29682_27544"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_5_29682_27544": {
                    "type": "nop",
                    "grid_loc": [
                        2,
                        6
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_6_29682_27544"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_4_29682_27544": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        0
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_5_29682_27544"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_3_29682_27544": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        1
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_4_29682_27544"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_2_29682_27544": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        2
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_3_29682_27544"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_1_29682_27544": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        3
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_2_29682_27544"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29682_27544": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        4
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29682_27544"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "add_216": {
                    "type": "add",
                    "grid_loc": [
                        7,
                        5
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "matmul_212",
                        "buffer_0_29682_27544"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_0_tms": [
                        {
                            "hslice": 2
                        }
                    ]
                },
                "layernorm_217.dc.reduce_sum.0.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        7,
                        6
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "add_216",
                        "lc.input_tensor.layernorm_217.dc.reduce_sum.0.0"
                    ],
                    "t": 1,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_3_27544_29683": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        7
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "add_216"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_2_27544_29683": {
                    "type": "nop",
                    "grid_loc": [
                        8,
                        0
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_3_27544_29683"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_1_27544_29683": {
                    "type": "nop",
                    "grid_loc": [
                        8,
                        1
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_2_27544_29683"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_27544_29683": {
                    "type": "nop",
                    "grid_loc": [
                        8,
                        2
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_1_27544_29683"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_28": {
                    "type": "fused_op",
                    "grid_loc": [
                        8,
                        3
                    ],
                    "grid_size": [
                        1,
                        2
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_217.1",
                        "layernorm_217.dc.reduce_sum.0.lc1",
                        "buffer_0_27544_29683"
                    ],
                    "t": 1,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 32
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 12
                    }
                },
                "layernorm_217.dc.multiply.4": {
                    "type": "multiply",
                    "grid_loc": [
                        8,
                        5
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "_fused_op_28",
                        "_fused_op_28"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "vslice": 2
                        }
                    ],
                    "input_0_tms": [
                        {
                            "vslice": 2
                        }
                    ]
                },
                "layernorm_217.dc.reduce_sum.5.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        8,
                        6
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "layernorm_217.dc.multiply.4",
                        "lc.input_tensor.layernorm_217.dc.reduce_sum.5.0"
                    ],
                    "t": 2,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 2
                            }
                        },
                        {
                            "broadcast": {
                                "r": 32
                            }
                        },
                        {
                            "hslice": 2
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                }
            },
            "fwd_0_10_temporal_epoch_10": {
                "target_device": 0,
                "input_count": 1,
                "_fused_op_29": {
                    "type": "fused_op",
                    "grid_loc": [
                        0,
                        0
                    ],
                    "grid_size": [
                        6,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_217.6",
                        "e2e_layernorm_217.dc.reduce_sum.5.lc1_0",
                        "dc.input_tensor.layernorm_217.8",
                        "e2e__fused_op_28_0",
                        "bert.encoder.layer.3.output.LayerNorm.weight",
                        "bert.encoder.layer.3.output.LayerNorm.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        32
                    ],
                    "ublock": [
                        2,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        2,
                        0,
                        2,
                        0,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        24,
                        0,
                        24,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_5_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_4_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_1_tms": [
                        {
                            "vstack": 2
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 15,
                        "kernel_broadcast": {
                            "input_5": 64,
                            "input_4": 64
                        }
                    }
                },
                "matmul_220": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        1
                    ],
                    "grid_size": [
                        6,
                        2
                    ],
                    "inputs": [
                        "_fused_op_29",
                        "bert.encoder.layer.4.attention.self.query.weight",
                        "bert.encoder.layer.4.attention.self.query.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        2,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        96,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 16
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_226": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        3
                    ],
                    "grid_size": [
                        6,
                        2
                    ],
                    "inputs": [
                        "_fused_op_29",
                        "bert.encoder.layer.4.attention.self.key.weight",
                        "bert.encoder.layer.4.attention.self.key.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        2,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 16
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_232": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        5
                    ],
                    "grid_size": [
                        6,
                        1
                    ],
                    "inputs": [
                        "matmul_220",
                        "matmul_226"
                    ],
                    "t": 16,
                    "mblock": [
                        2,
                        2
                    ],
                    "ublock": [
                        1,
                        6
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        363,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        "transpose",
                        {
                            "vslice": 16
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hslice": 16
                        }
                    ],
                    "attributes": {
                        "l1_acc": true,
                        "m_k": 2,
                        "min_buffer_input": 0,
                        "u_kt": 1
                    }
                },
                "_fused_op_30": {
                    "type": "fused_op",
                    "grid_loc": [
                        0,
                        6
                    ],
                    "grid_size": [
                        6,
                        1
                    ],
                    "inputs": [
                        "matmul_232",
                        "input_1_multiply_234",
                        "e2e_multiply_22_attempt_1_input_op_fork_nop0_0"
                    ],
                    "t": 16,
                    "mblock": [
                        2,
                        2
                    ],
                    "ublock": [
                        1,
                        6
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        48
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 12
                            }
                        },
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 16,
                        "kernel_broadcast": {
                            "input_1": 1
                        }
                    }
                },
                "softmax_236.dc.reduce_max.0": {
                    "type": "reduce",
                    "grid_loc": [
                        0,
                        7
                    ],
                    "grid_size": [
                        6,
                        1
                    ],
                    "inputs": [
                        "_fused_op_30"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        2,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "dim": "c",
                        "m_k": 1,
                        "type": "max",
                        "u_kt": 12
                    }
                }
            },
            "fwd_0_11_temporal_epoch_11": {
                "target_device": 0,
                "input_count": 1,
                "_fused_op_31": {
                    "type": "fused_op",
                    "grid_loc": [
                        0,
                        0
                    ],
                    "grid_size": [
                        2,
                        6
                    ],
                    "inputs": [
                        "e2e__fused_op_30_0",
                        "e2e_softmax_236.dc.reduce_max.0_0"
                    ],
                    "t": 16,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        3,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 32,
                    "input_dram_io_buf_size_tiles": [
                        24,
                        24
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 12
                            }
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 3
                    }
                },
                "softmax_236.dc.reduce_sum.3.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        6
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "_fused_op_31",
                        "lc.input_tensor.softmax_236.dc.reduce_sum.3.0"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 3,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_240": {
                    "type": "matmul",
                    "grid_loc": [
                        2,
                        1
                    ],
                    "grid_size": [
                        2,
                        4
                    ],
                    "inputs": [
                        "e2e__fused_op_29_0",
                        "bert.encoder.layer.4.attention.self.value.weight",
                        "bert.encoder.layer.4.attention.self.value.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 4,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                },
                "buffer_0_29686_29687": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        7
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "_fused_op_31"
                    ],
                    "t": 16,
                    "mblock": [
                        6,
                        2
                    ],
                    "ublock": [
                        1,
                        6
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        288
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_32": {
                    "type": "fused_op",
                    "grid_loc": [
                        2,
                        0
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "softmax_236.dc.reduce_sum.3.lc1",
                        "dc.input_tensor.softmax_236.4",
                        "buffer_0_29686_29687"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        12
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        96,
                        174
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 4
                    }
                },
                "matmul_247": {
                    "type": "matmul",
                    "grid_loc": [
                        2,
                        5
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "_fused_op_32",
                        "matmul_240"
                    ],
                    "t": 16,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        3,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 32,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "hslice": 16
                        }
                    ],
                    "attributes": {
                        "l1_acc": true,
                        "m_k": 2,
                        "min_buffer_input": 0,
                        "u_kt": 6
                    }
                },
                "matmul_251": {
                    "type": "matmul",
                    "grid_loc": [
                        4,
                        0
                    ],
                    "grid_size": [
                        2,
                        4
                    ],
                    "inputs": [
                        "matmul_247",
                        "bert.encoder.layer.4.attention.output.dense.weight",
                        "bert.encoder.layer.4.attention.output.dense.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 16
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 16,
                        "min_buffer_input": 0,
                        "u_kt": 2
                    }
                },
                "add_255": {
                    "type": "add",
                    "grid_loc": [
                        2,
                        6
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "matmul_251",
                        "e2e__fused_op_29_0"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        48
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "layernorm_256.dc.reduce_sum.0.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        2,
                        7
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "add_255",
                        "lc.input_tensor.layernorm_256.dc.reduce_sum.0.0"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_1_27616_29688": {
                    "type": "nop",
                    "grid_loc": [
                        4,
                        4
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "add_255"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_27616_29688": {
                    "type": "nop",
                    "grid_loc": [
                        4,
                        5
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "buffer_1_27616_29688"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_33": {
                    "type": "fused_op",
                    "grid_loc": [
                        4,
                        6
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_256.1",
                        "layernorm_256.dc.reduce_sum.0.lc1",
                        "buffer_0_27616_29688"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 32
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 5
                    }
                },
                "layernorm_256.dc.multiply.4": {
                    "type": "multiply",
                    "grid_loc": [
                        4,
                        7
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "_fused_op_33",
                        "_fused_op_33"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "layernorm_256.dc.reduce_sum.5.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        6,
                        0
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "layernorm_256.dc.multiply.4",
                        "lc.input_tensor.layernorm_256.dc.reduce_sum.5.0"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_2_29688_29689": {
                    "type": "nop",
                    "grid_loc": [
                        6,
                        1
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "_fused_op_33"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_1_29688_29689": {
                    "type": "nop",
                    "grid_loc": [
                        6,
                        2
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "buffer_2_29688_29689"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29688_29689": {
                    "type": "nop",
                    "grid_loc": [
                        6,
                        3
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29688_29689"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_34": {
                    "type": "fused_op",
                    "grid_loc": [
                        6,
                        4
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_256.6",
                        "layernorm_256.dc.reduce_sum.5.lc1",
                        "dc.input_tensor.layernorm_256.8",
                        "buffer_0_29688_29689",
                        "bert.encoder.layer.4.attention.output.LayerNorm.weight",
                        "bert.encoder.layer.4.attention.output.LayerNorm.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        32
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        6,
                        0,
                        6,
                        0,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0,
                        0,
                        24,
                        24
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_5_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_4_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 6
                    }
                },
                "matmul_259": {
                    "type": "matmul",
                    "grid_loc": [
                        8,
                        0
                    ],
                    "grid_size": [
                        2,
                        8
                    ],
                    "inputs": [
                        "_fused_op_34",
                        "bert.encoder.layer.4.intermediate.dense.weight",
                        "bert.encoder.layer.4.intermediate.dense.bias"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "hslice": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "hslice": 2
                        }
                    ],
                    "input_0_tms": [
                        {
                            "broadcast": {
                                "r": 2
                            }
                        },
                        {
                            "vslice": 2
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "gelu_262": {
                    "type": "gelu",
                    "grid_loc": [
                        6,
                        5
                    ],
                    "grid_size": [
                        2,
                        2
                    ],
                    "inputs": [
                        "matmul_259"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "approximate_mode": false
                    }
                }
            },
            "fwd_0_12_temporal_epoch_12": {
                "target_device": 0,
                "input_count": 1,
                "matmul_265": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        0
                    ],
                    "grid_size": [
                        3,
                        8
                    ],
                    "inputs": [
                        "e2e_gelu_262_0",
                        "bert.encoder.layer.4.output.dense.weight",
                        "bert.encoder.layer.4.output.dense.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        2,
                        4
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 4
                        },
                        "l1_acc": true,
                        "m_k": 16,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                },
                "add_269": {
                    "type": "add",
                    "grid_loc": [
                        3,
                        0
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "matmul_265",
                        "e2e__fused_op_34_0"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        48
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "layernorm_270.dc.reduce_sum.0.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        3,
                        1
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "add_269",
                        "lc.input_tensor.layernorm_270.dc.reduce_sum.0.0"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_1_27648_29690": {
                    "type": "nop",
                    "grid_loc": [
                        3,
                        2
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "add_269"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_27648_29690": {
                    "type": "nop",
                    "grid_loc": [
                        3,
                        3
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "buffer_1_27648_29690"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_35": {
                    "type": "fused_op",
                    "grid_loc": [
                        3,
                        4
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_270.1",
                        "layernorm_270.dc.reduce_sum.0.lc1",
                        "buffer_0_27648_29690"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        128,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 32
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 7
                    }
                },
                "layernorm_270.dc.multiply.4": {
                    "type": "multiply",
                    "grid_loc": [
                        3,
                        5
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "_fused_op_35",
                        "_fused_op_35"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "layernorm_270.dc.reduce_sum.5.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        3,
                        6
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "layernorm_270.dc.multiply.4",
                        "lc.input_tensor.layernorm_270.dc.reduce_sum.5.0"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_1_29690_29691": {
                    "type": "nop",
                    "grid_loc": [
                        3,
                        7
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "_fused_op_35"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        176
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29690_29691": {
                    "type": "nop",
                    "grid_loc": [
                        6,
                        0
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29690_29691"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        176
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_36": {
                    "type": "fused_op",
                    "grid_loc": [
                        6,
                        1
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_270.6",
                        "layernorm_270.dc.reduce_sum.5.lc1",
                        "dc.input_tensor.layernorm_270.8",
                        "buffer_0_29690_29691",
                        "bert.encoder.layer.4.output.LayerNorm.weight",
                        "bert.encoder.layer.4.output.LayerNorm.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        32
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        4,
                        0,
                        4,
                        0,
                        128,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0,
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_5_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_4_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 8
                    }
                },
                "matmul_273": {
                    "type": "matmul",
                    "grid_loc": [
                        6,
                        2
                    ],
                    "grid_size": [
                        3,
                        4
                    ],
                    "inputs": [
                        "_fused_op_36",
                        "bert.encoder.layer.5.attention.self.query.weight",
                        "bert.encoder.layer.5.attention.self.query.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 4,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                }
            },
            "fwd_0_13_temporal_epoch_13": {
                "target_device": 0,
                "input_count": 1,
                "matmul_279": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        0
                    ],
                    "grid_size": [
                        3,
                        4
                    ],
                    "inputs": [
                        "e2e__fused_op_36_0",
                        "bert.encoder.layer.5.attention.self.key.weight",
                        "bert.encoder.layer.5.attention.self.key.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 4,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                },
                "matmul_285": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        4
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "e2e_matmul_273_0",
                        "matmul_279"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        6
                    ],
                    "ublock": [
                        4,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        "transpose",
                        {
                            "vslice": 16
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hslice": 16
                        }
                    ],
                    "attributes": {
                        "l1_acc": true,
                        "m_k": 2,
                        "min_buffer_input": 0,
                        "u_kt": 1
                    }
                },
                "_fused_op_37": {
                    "type": "fused_op",
                    "grid_loc": [
                        0,
                        5
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "matmul_285",
                        "input_1_multiply_287",
                        "e2e_multiply_22_attempt_1_input_op_fork_nop0_0"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        6
                    ],
                    "ublock": [
                        4,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        48
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 12
                            }
                        },
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 9,
                        "kernel_broadcast": {
                            "input_1": 1
                        }
                    }
                },
                "softmax_289.dc.reduce_max.0": {
                    "type": "reduce",
                    "grid_loc": [
                        0,
                        6
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "_fused_op_37"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "dim": "c",
                        "m_k": 1,
                        "type": "max",
                        "u_kt": 12
                    }
                },
                "_fused_op_38": {
                    "type": "fused_op",
                    "grid_loc": [
                        3,
                        0
                    ],
                    "grid_size": [
                        3,
                        6
                    ],
                    "inputs": [
                        "_fused_op_37",
                        "softmax_289.dc.reduce_max.0"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        400,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 12
                            }
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 10
                    }
                },
                "softmax_289.dc.reduce_sum.3.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        7
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "_fused_op_38",
                        "lc.input_tensor.softmax_289.dc.reduce_sum.3.0"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 3,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_293": {
                    "type": "matmul",
                    "grid_loc": [
                        6,
                        0
                    ],
                    "grid_size": [
                        3,
                        4
                    ],
                    "inputs": [
                        "e2e__fused_op_36_0",
                        "bert.encoder.layer.5.attention.self.value.weight",
                        "bert.encoder.layer.5.attention.self.value.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 4,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                },
                "_fused_op_39": {
                    "type": "fused_op",
                    "grid_loc": [
                        3,
                        6
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "softmax_289.dc.reduce_sum.3.lc1",
                        "dc.input_tensor.softmax_289.4",
                        "_fused_op_38"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        12
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        64,
                        260
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 11
                    }
                },
                "matmul_300": {
                    "type": "matmul",
                    "grid_loc": [
                        3,
                        7
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "_fused_op_39",
                        "matmul_293"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 32,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "hslice": 16
                        }
                    ],
                    "attributes": {
                        "l1_acc": true,
                        "m_k": 3,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_304": {
                    "type": "matmul",
                    "grid_loc": [
                        6,
                        4
                    ],
                    "grid_size": [
                        2,
                        4
                    ],
                    "inputs": [
                        "matmul_300",
                        "bert.encoder.layer.5.attention.output.dense.weight",
                        "bert.encoder.layer.5.attention.output.dense.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 16
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 16,
                        "min_buffer_input": 0,
                        "u_kt": 2
                    }
                }
            },
            "fwd_0_14_temporal_epoch_14": {
                "target_device": 0,
                "input_count": 1,
                "add_308": {
                    "type": "add",
                    "grid_loc": [
                        0,
                        0
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "e2e_matmul_304_0",
                        "e2e__fused_op_36_0"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        24,
                        24
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "hslice": 2
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hslice": 2
                        }
                    ]
                },
                "layernorm_309.dc.reduce_sum.0.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        1
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "add_308",
                        "lc.input_tensor.layernorm_309.dc.reduce_sum.0.0"
                    ],
                    "t": 1,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_3_27720_29695": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        2
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "add_308"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_2_27720_29695": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        3
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_3_27720_29695"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_1_27720_29695": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        4
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_2_27720_29695"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_27720_29695": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        5
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_1_27720_29695"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_40": {
                    "type": "fused_op",
                    "grid_loc": [
                        0,
                        6
                    ],
                    "grid_size": [
                        1,
                        2
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_309.1",
                        "layernorm_309.dc.reduce_sum.0.lc1",
                        "buffer_0_27720_29695"
                    ],
                    "t": 1,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 32
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 12
                    }
                },
                "layernorm_309.dc.multiply.4": {
                    "type": "multiply",
                    "grid_loc": [
                        1,
                        0
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "_fused_op_40",
                        "_fused_op_40"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "vslice": 2
                        }
                    ],
                    "input_0_tms": [
                        {
                            "vslice": 2
                        }
                    ]
                },
                "layernorm_309.dc.reduce_sum.5.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        1,
                        1
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "layernorm_309.dc.multiply.4",
                        "lc.input_tensor.layernorm_309.dc.reduce_sum.5.0"
                    ],
                    "t": 2,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 2
                            }
                        },
                        {
                            "broadcast": {
                                "r": 32
                            }
                        },
                        {
                            "hslice": 2
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_4_29695_29696": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        2
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "_fused_op_40"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_0_tms": [
                        {
                            "vslice": 2
                        }
                    ]
                },
                "buffer_3_29695_29696": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        3
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_4_29695_29696"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_2_29695_29696": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        4
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_3_29695_29696"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_1_29695_29696": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        5
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_2_29695_29696"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29695_29696": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        6
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29695_29696"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_41": {
                    "type": "fused_op",
                    "grid_loc": [
                        1,
                        7
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_309.6",
                        "layernorm_309.dc.reduce_sum.5.lc1",
                        "dc.input_tensor.layernorm_309.8",
                        "buffer_0_29695_29696",
                        "bert.encoder.layer.5.attention.output.LayerNorm.weight",
                        "bert.encoder.layer.5.attention.output.LayerNorm.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        32
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        6,
                        0,
                        6,
                        0,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0,
                        0,
                        24,
                        24
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_5_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_4_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_3_tms": [
                        {
                            "vstack": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "vstack": 2
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 6
                    }
                },
                "matmul_312": {
                    "type": "matmul",
                    "grid_loc": [
                        3,
                        0
                    ],
                    "grid_size": [
                        2,
                        8
                    ],
                    "inputs": [
                        "_fused_op_41",
                        "bert.encoder.layer.5.intermediate.dense.weight",
                        "bert.encoder.layer.5.intermediate.dense.bias"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "hslice": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "hslice": 2
                        }
                    ],
                    "input_0_tms": [
                        {
                            "broadcast": {
                                "r": 2
                            }
                        },
                        {
                            "vslice": 2
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "gelu_315": {
                    "type": "gelu",
                    "grid_loc": [
                        2,
                        0
                    ],
                    "grid_size": [
                        1,
                        4
                    ],
                    "inputs": [
                        "matmul_312"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "approximate_mode": false
                    }
                },
                "matmul_318": {
                    "type": "matmul",
                    "grid_loc": [
                        5,
                        0
                    ],
                    "grid_size": [
                        2,
                        8
                    ],
                    "inputs": [
                        "gelu_315",
                        "bert.encoder.layer.5.output.dense.weight",
                        "bert.encoder.layer.5.output.dense.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        3,
                        1
                    ],
                    "ublock": [
                        2,
                        4
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 4
                        },
                        "l1_acc": true,
                        "m_k": 16,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                },
                "buffer_7_29696_27752": {
                    "type": "nop",
                    "grid_loc": [
                        2,
                        4
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "_fused_op_41"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_0_tms": [
                        {
                            "hslice": 2
                        }
                    ]
                },
                "buffer_6_29696_27752": {
                    "type": "nop",
                    "grid_loc": [
                        2,
                        5
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_7_29696_27752"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_5_29696_27752": {
                    "type": "nop",
                    "grid_loc": [
                        2,
                        6
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_6_29696_27752"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_4_29696_27752": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        0
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_5_29696_27752"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_3_29696_27752": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        1
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_4_29696_27752"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_2_29696_27752": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        2
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_3_29696_27752"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_1_29696_27752": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        3
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_2_29696_27752"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29696_27752": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        4
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29696_27752"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "add_322": {
                    "type": "add",
                    "grid_loc": [
                        7,
                        5
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "matmul_318",
                        "buffer_0_29696_27752"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_0_tms": [
                        {
                            "hslice": 2
                        }
                    ]
                },
                "layernorm_323.dc.reduce_sum.0.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        7,
                        6
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "add_322",
                        "lc.input_tensor.layernorm_323.dc.reduce_sum.0.0"
                    ],
                    "t": 1,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_3_27752_29697": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        7
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "add_322"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_2_27752_29697": {
                    "type": "nop",
                    "grid_loc": [
                        8,
                        0
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_3_27752_29697"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_1_27752_29697": {
                    "type": "nop",
                    "grid_loc": [
                        8,
                        1
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_2_27752_29697"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_27752_29697": {
                    "type": "nop",
                    "grid_loc": [
                        8,
                        2
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_1_27752_29697"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_42": {
                    "type": "fused_op",
                    "grid_loc": [
                        8,
                        3
                    ],
                    "grid_size": [
                        1,
                        2
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_323.1",
                        "layernorm_323.dc.reduce_sum.0.lc1",
                        "buffer_0_27752_29697"
                    ],
                    "t": 1,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 32
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 12
                    }
                },
                "layernorm_323.dc.multiply.4": {
                    "type": "multiply",
                    "grid_loc": [
                        8,
                        5
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "_fused_op_42",
                        "_fused_op_42"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "vslice": 2
                        }
                    ],
                    "input_0_tms": [
                        {
                            "vslice": 2
                        }
                    ]
                },
                "layernorm_323.dc.reduce_sum.5.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        8,
                        6
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "layernorm_323.dc.multiply.4",
                        "lc.input_tensor.layernorm_323.dc.reduce_sum.5.0"
                    ],
                    "t": 2,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 2
                            }
                        },
                        {
                            "broadcast": {
                                "r": 32
                            }
                        },
                        {
                            "hslice": 2
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                }
            },
            "fwd_0_15_temporal_epoch_15": {
                "target_device": 0,
                "input_count": 1,
                "_fused_op_43": {
                    "type": "fused_op",
                    "grid_loc": [
                        0,
                        0
                    ],
                    "grid_size": [
                        6,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_323.6",
                        "e2e_layernorm_323.dc.reduce_sum.5.lc1_0",
                        "dc.input_tensor.layernorm_323.8",
                        "e2e__fused_op_42_0",
                        "bert.encoder.layer.5.output.LayerNorm.weight",
                        "bert.encoder.layer.5.output.LayerNorm.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        32
                    ],
                    "ublock": [
                        2,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        2,
                        0,
                        2,
                        0,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        24,
                        0,
                        24,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_5_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_4_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_1_tms": [
                        {
                            "vstack": 2
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 15,
                        "kernel_broadcast": {
                            "input_5": 64,
                            "input_4": 64
                        }
                    }
                },
                "matmul_326": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        1
                    ],
                    "grid_size": [
                        6,
                        2
                    ],
                    "inputs": [
                        "_fused_op_43",
                        "bert.encoder.layer.6.attention.self.query.weight",
                        "bert.encoder.layer.6.attention.self.query.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        2,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        96,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 16
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_332": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        3
                    ],
                    "grid_size": [
                        6,
                        2
                    ],
                    "inputs": [
                        "_fused_op_43",
                        "bert.encoder.layer.6.attention.self.key.weight",
                        "bert.encoder.layer.6.attention.self.key.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        2,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 16
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_338": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        5
                    ],
                    "grid_size": [
                        6,
                        1
                    ],
                    "inputs": [
                        "matmul_326",
                        "matmul_332"
                    ],
                    "t": 16,
                    "mblock": [
                        2,
                        2
                    ],
                    "ublock": [
                        1,
                        6
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        363,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        "transpose",
                        {
                            "vslice": 16
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hslice": 16
                        }
                    ],
                    "attributes": {
                        "l1_acc": true,
                        "m_k": 2,
                        "min_buffer_input": 0,
                        "u_kt": 1
                    }
                },
                "_fused_op_44": {
                    "type": "fused_op",
                    "grid_loc": [
                        0,
                        6
                    ],
                    "grid_size": [
                        6,
                        1
                    ],
                    "inputs": [
                        "matmul_338",
                        "input_1_multiply_340",
                        "e2e_multiply_22_attempt_1_input_op_fork_nop0_0"
                    ],
                    "t": 16,
                    "mblock": [
                        2,
                        2
                    ],
                    "ublock": [
                        1,
                        6
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        48
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 12
                            }
                        },
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 16,
                        "kernel_broadcast": {
                            "input_1": 1
                        }
                    }
                },
                "softmax_342.dc.reduce_max.0": {
                    "type": "reduce",
                    "grid_loc": [
                        0,
                        7
                    ],
                    "grid_size": [
                        6,
                        1
                    ],
                    "inputs": [
                        "_fused_op_44"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        2,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "dim": "c",
                        "m_k": 1,
                        "type": "max",
                        "u_kt": 12
                    }
                }
            },
            "fwd_0_16_temporal_epoch_16": {
                "target_device": 0,
                "input_count": 1,
                "_fused_op_45": {
                    "type": "fused_op",
                    "grid_loc": [
                        0,
                        0
                    ],
                    "grid_size": [
                        2,
                        6
                    ],
                    "inputs": [
                        "e2e__fused_op_44_0",
                        "e2e_softmax_342.dc.reduce_max.0_0"
                    ],
                    "t": 16,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        3,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 32,
                    "input_dram_io_buf_size_tiles": [
                        24,
                        24
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 12
                            }
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 3
                    }
                },
                "softmax_342.dc.reduce_sum.3.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        6
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "_fused_op_45",
                        "lc.input_tensor.softmax_342.dc.reduce_sum.3.0"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 3,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_346": {
                    "type": "matmul",
                    "grid_loc": [
                        2,
                        1
                    ],
                    "grid_size": [
                        2,
                        4
                    ],
                    "inputs": [
                        "e2e__fused_op_43_0",
                        "bert.encoder.layer.6.attention.self.value.weight",
                        "bert.encoder.layer.6.attention.self.value.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 4,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                },
                "buffer_0_29700_29701": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        7
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "_fused_op_45"
                    ],
                    "t": 16,
                    "mblock": [
                        6,
                        2
                    ],
                    "ublock": [
                        1,
                        6
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        288
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_46": {
                    "type": "fused_op",
                    "grid_loc": [
                        2,
                        0
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "softmax_342.dc.reduce_sum.3.lc1",
                        "dc.input_tensor.softmax_342.4",
                        "buffer_0_29700_29701"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        12
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        96,
                        174
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 4
                    }
                },
                "matmul_353": {
                    "type": "matmul",
                    "grid_loc": [
                        2,
                        5
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "_fused_op_46",
                        "matmul_346"
                    ],
                    "t": 16,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        3,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 32,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "hslice": 16
                        }
                    ],
                    "attributes": {
                        "l1_acc": true,
                        "m_k": 2,
                        "min_buffer_input": 0,
                        "u_kt": 6
                    }
                },
                "matmul_357": {
                    "type": "matmul",
                    "grid_loc": [
                        4,
                        0
                    ],
                    "grid_size": [
                        2,
                        4
                    ],
                    "inputs": [
                        "matmul_353",
                        "bert.encoder.layer.6.attention.output.dense.weight",
                        "bert.encoder.layer.6.attention.output.dense.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 16
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 16,
                        "min_buffer_input": 0,
                        "u_kt": 2
                    }
                },
                "add_361": {
                    "type": "add",
                    "grid_loc": [
                        2,
                        6
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "matmul_357",
                        "e2e__fused_op_43_0"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        48
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "layernorm_362.dc.reduce_sum.0.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        2,
                        7
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "add_361",
                        "lc.input_tensor.layernorm_362.dc.reduce_sum.0.0"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_1_27824_29702": {
                    "type": "nop",
                    "grid_loc": [
                        4,
                        4
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "add_361"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_27824_29702": {
                    "type": "nop",
                    "grid_loc": [
                        4,
                        5
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "buffer_1_27824_29702"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_47": {
                    "type": "fused_op",
                    "grid_loc": [
                        4,
                        6
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_362.1",
                        "layernorm_362.dc.reduce_sum.0.lc1",
                        "buffer_0_27824_29702"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 32
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 5
                    }
                },
                "layernorm_362.dc.multiply.4": {
                    "type": "multiply",
                    "grid_loc": [
                        4,
                        7
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "_fused_op_47",
                        "_fused_op_47"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "layernorm_362.dc.reduce_sum.5.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        6,
                        0
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "layernorm_362.dc.multiply.4",
                        "lc.input_tensor.layernorm_362.dc.reduce_sum.5.0"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_2_29702_29703": {
                    "type": "nop",
                    "grid_loc": [
                        6,
                        1
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "_fused_op_47"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_1_29702_29703": {
                    "type": "nop",
                    "grid_loc": [
                        6,
                        2
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "buffer_2_29702_29703"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29702_29703": {
                    "type": "nop",
                    "grid_loc": [
                        6,
                        3
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29702_29703"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_48": {
                    "type": "fused_op",
                    "grid_loc": [
                        6,
                        4
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_362.6",
                        "layernorm_362.dc.reduce_sum.5.lc1",
                        "dc.input_tensor.layernorm_362.8",
                        "buffer_0_29702_29703",
                        "bert.encoder.layer.6.attention.output.LayerNorm.weight",
                        "bert.encoder.layer.6.attention.output.LayerNorm.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        32
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        6,
                        0,
                        6,
                        0,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0,
                        0,
                        24,
                        24
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_5_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_4_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 6
                    }
                },
                "matmul_365": {
                    "type": "matmul",
                    "grid_loc": [
                        8,
                        0
                    ],
                    "grid_size": [
                        2,
                        8
                    ],
                    "inputs": [
                        "_fused_op_48",
                        "bert.encoder.layer.6.intermediate.dense.weight",
                        "bert.encoder.layer.6.intermediate.dense.bias"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "hslice": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "hslice": 2
                        }
                    ],
                    "input_0_tms": [
                        {
                            "broadcast": {
                                "r": 2
                            }
                        },
                        {
                            "vslice": 2
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "gelu_368": {
                    "type": "gelu",
                    "grid_loc": [
                        6,
                        5
                    ],
                    "grid_size": [
                        2,
                        2
                    ],
                    "inputs": [
                        "matmul_365"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "approximate_mode": false
                    }
                }
            },
            "fwd_0_17_temporal_epoch_17": {
                "target_device": 0,
                "input_count": 1,
                "matmul_371": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        0
                    ],
                    "grid_size": [
                        3,
                        8
                    ],
                    "inputs": [
                        "e2e_gelu_368_0",
                        "bert.encoder.layer.6.output.dense.weight",
                        "bert.encoder.layer.6.output.dense.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        2,
                        4
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 4
                        },
                        "l1_acc": true,
                        "m_k": 16,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                },
                "add_375": {
                    "type": "add",
                    "grid_loc": [
                        3,
                        0
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "matmul_371",
                        "e2e__fused_op_48_0"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        48
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "layernorm_376.dc.reduce_sum.0.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        3,
                        1
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "add_375",
                        "lc.input_tensor.layernorm_376.dc.reduce_sum.0.0"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_1_27856_29704": {
                    "type": "nop",
                    "grid_loc": [
                        3,
                        2
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "add_375"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_27856_29704": {
                    "type": "nop",
                    "grid_loc": [
                        3,
                        3
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "buffer_1_27856_29704"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_49": {
                    "type": "fused_op",
                    "grid_loc": [
                        3,
                        4
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_376.1",
                        "layernorm_376.dc.reduce_sum.0.lc1",
                        "buffer_0_27856_29704"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        128,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 32
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 7
                    }
                },
                "layernorm_376.dc.multiply.4": {
                    "type": "multiply",
                    "grid_loc": [
                        3,
                        5
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "_fused_op_49",
                        "_fused_op_49"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "layernorm_376.dc.reduce_sum.5.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        3,
                        6
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "layernorm_376.dc.multiply.4",
                        "lc.input_tensor.layernorm_376.dc.reduce_sum.5.0"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_1_29704_29705": {
                    "type": "nop",
                    "grid_loc": [
                        3,
                        7
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "_fused_op_49"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        176
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29704_29705": {
                    "type": "nop",
                    "grid_loc": [
                        6,
                        0
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29704_29705"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        176
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_50": {
                    "type": "fused_op",
                    "grid_loc": [
                        6,
                        1
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_376.6",
                        "layernorm_376.dc.reduce_sum.5.lc1",
                        "dc.input_tensor.layernorm_376.8",
                        "buffer_0_29704_29705",
                        "bert.encoder.layer.6.output.LayerNorm.weight",
                        "bert.encoder.layer.6.output.LayerNorm.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        32
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        4,
                        0,
                        4,
                        0,
                        128,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0,
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_5_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_4_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 8
                    }
                },
                "matmul_379": {
                    "type": "matmul",
                    "grid_loc": [
                        6,
                        2
                    ],
                    "grid_size": [
                        3,
                        4
                    ],
                    "inputs": [
                        "_fused_op_50",
                        "bert.encoder.layer.7.attention.self.query.weight",
                        "bert.encoder.layer.7.attention.self.query.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 4,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                }
            },
            "fwd_0_18_temporal_epoch_18": {
                "target_device": 0,
                "input_count": 1,
                "matmul_385": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        0
                    ],
                    "grid_size": [
                        3,
                        4
                    ],
                    "inputs": [
                        "e2e__fused_op_50_0",
                        "bert.encoder.layer.7.attention.self.key.weight",
                        "bert.encoder.layer.7.attention.self.key.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 4,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                },
                "matmul_391": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        4
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "e2e_matmul_379_0",
                        "matmul_385"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        6
                    ],
                    "ublock": [
                        4,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        "transpose",
                        {
                            "vslice": 16
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hslice": 16
                        }
                    ],
                    "attributes": {
                        "l1_acc": true,
                        "m_k": 2,
                        "min_buffer_input": 0,
                        "u_kt": 1
                    }
                },
                "_fused_op_51": {
                    "type": "fused_op",
                    "grid_loc": [
                        0,
                        5
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "matmul_391",
                        "input_1_multiply_393",
                        "e2e_multiply_22_attempt_1_input_op_fork_nop0_0"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        6
                    ],
                    "ublock": [
                        4,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        48
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 12
                            }
                        },
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 9,
                        "kernel_broadcast": {
                            "input_1": 1
                        }
                    }
                },
                "softmax_395.dc.reduce_max.0": {
                    "type": "reduce",
                    "grid_loc": [
                        0,
                        6
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "_fused_op_51"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "dim": "c",
                        "m_k": 1,
                        "type": "max",
                        "u_kt": 12
                    }
                },
                "_fused_op_52": {
                    "type": "fused_op",
                    "grid_loc": [
                        3,
                        0
                    ],
                    "grid_size": [
                        3,
                        6
                    ],
                    "inputs": [
                        "_fused_op_51",
                        "softmax_395.dc.reduce_max.0"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        400,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 12
                            }
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 10
                    }
                },
                "softmax_395.dc.reduce_sum.3.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        7
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "_fused_op_52",
                        "lc.input_tensor.softmax_395.dc.reduce_sum.3.0"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 3,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_399": {
                    "type": "matmul",
                    "grid_loc": [
                        6,
                        0
                    ],
                    "grid_size": [
                        3,
                        4
                    ],
                    "inputs": [
                        "e2e__fused_op_50_0",
                        "bert.encoder.layer.7.attention.self.value.weight",
                        "bert.encoder.layer.7.attention.self.value.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 4,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                },
                "_fused_op_53": {
                    "type": "fused_op",
                    "grid_loc": [
                        3,
                        6
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "softmax_395.dc.reduce_sum.3.lc1",
                        "dc.input_tensor.softmax_395.4",
                        "_fused_op_52"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        12
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        64,
                        260
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 11
                    }
                },
                "matmul_406": {
                    "type": "matmul",
                    "grid_loc": [
                        3,
                        7
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "_fused_op_53",
                        "matmul_399"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 32,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "hslice": 16
                        }
                    ],
                    "attributes": {
                        "l1_acc": true,
                        "m_k": 3,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_410": {
                    "type": "matmul",
                    "grid_loc": [
                        6,
                        4
                    ],
                    "grid_size": [
                        2,
                        4
                    ],
                    "inputs": [
                        "matmul_406",
                        "bert.encoder.layer.7.attention.output.dense.weight",
                        "bert.encoder.layer.7.attention.output.dense.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 16
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 16,
                        "min_buffer_input": 0,
                        "u_kt": 2
                    }
                }
            },
            "fwd_0_19_temporal_epoch_19": {
                "target_device": 0,
                "input_count": 1,
                "add_414": {
                    "type": "add",
                    "grid_loc": [
                        0,
                        0
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "e2e_matmul_410_0",
                        "e2e__fused_op_50_0"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        24,
                        24
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "hslice": 2
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hslice": 2
                        }
                    ]
                },
                "layernorm_415.dc.reduce_sum.0.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        1
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "add_414",
                        "lc.input_tensor.layernorm_415.dc.reduce_sum.0.0"
                    ],
                    "t": 1,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_3_27928_29709": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        2
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "add_414"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_2_27928_29709": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        3
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_3_27928_29709"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_1_27928_29709": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        4
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_2_27928_29709"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_27928_29709": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        5
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_1_27928_29709"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_54": {
                    "type": "fused_op",
                    "grid_loc": [
                        0,
                        6
                    ],
                    "grid_size": [
                        1,
                        2
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_415.1",
                        "layernorm_415.dc.reduce_sum.0.lc1",
                        "buffer_0_27928_29709"
                    ],
                    "t": 1,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 32
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 12
                    }
                },
                "layernorm_415.dc.multiply.4": {
                    "type": "multiply",
                    "grid_loc": [
                        1,
                        0
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "_fused_op_54",
                        "_fused_op_54"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "vslice": 2
                        }
                    ],
                    "input_0_tms": [
                        {
                            "vslice": 2
                        }
                    ]
                },
                "layernorm_415.dc.reduce_sum.5.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        1,
                        1
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "layernorm_415.dc.multiply.4",
                        "lc.input_tensor.layernorm_415.dc.reduce_sum.5.0"
                    ],
                    "t": 2,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 2
                            }
                        },
                        {
                            "broadcast": {
                                "r": 32
                            }
                        },
                        {
                            "hslice": 2
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_4_29709_29710": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        2
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "_fused_op_54"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_0_tms": [
                        {
                            "vslice": 2
                        }
                    ]
                },
                "buffer_3_29709_29710": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        3
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_4_29709_29710"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_2_29709_29710": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        4
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_3_29709_29710"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_1_29709_29710": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        5
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_2_29709_29710"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29709_29710": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        6
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29709_29710"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_55": {
                    "type": "fused_op",
                    "grid_loc": [
                        1,
                        7
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_415.6",
                        "layernorm_415.dc.reduce_sum.5.lc1",
                        "dc.input_tensor.layernorm_415.8",
                        "buffer_0_29709_29710",
                        "bert.encoder.layer.7.attention.output.LayerNorm.weight",
                        "bert.encoder.layer.7.attention.output.LayerNorm.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        32
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        6,
                        0,
                        6,
                        0,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0,
                        0,
                        24,
                        24
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_5_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_4_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_3_tms": [
                        {
                            "vstack": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "vstack": 2
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 6
                    }
                },
                "matmul_418": {
                    "type": "matmul",
                    "grid_loc": [
                        3,
                        0
                    ],
                    "grid_size": [
                        2,
                        8
                    ],
                    "inputs": [
                        "_fused_op_55",
                        "bert.encoder.layer.7.intermediate.dense.weight",
                        "bert.encoder.layer.7.intermediate.dense.bias"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "hslice": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "hslice": 2
                        }
                    ],
                    "input_0_tms": [
                        {
                            "broadcast": {
                                "r": 2
                            }
                        },
                        {
                            "vslice": 2
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "gelu_421": {
                    "type": "gelu",
                    "grid_loc": [
                        2,
                        0
                    ],
                    "grid_size": [
                        1,
                        4
                    ],
                    "inputs": [
                        "matmul_418"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "approximate_mode": false
                    }
                },
                "matmul_424": {
                    "type": "matmul",
                    "grid_loc": [
                        5,
                        0
                    ],
                    "grid_size": [
                        2,
                        8
                    ],
                    "inputs": [
                        "gelu_421",
                        "bert.encoder.layer.7.output.dense.weight",
                        "bert.encoder.layer.7.output.dense.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        3,
                        1
                    ],
                    "ublock": [
                        2,
                        4
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 4
                        },
                        "l1_acc": true,
                        "m_k": 16,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                },
                "buffer_7_29710_27960": {
                    "type": "nop",
                    "grid_loc": [
                        2,
                        4
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "_fused_op_55"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_0_tms": [
                        {
                            "hslice": 2
                        }
                    ]
                },
                "buffer_6_29710_27960": {
                    "type": "nop",
                    "grid_loc": [
                        2,
                        5
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_7_29710_27960"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_5_29710_27960": {
                    "type": "nop",
                    "grid_loc": [
                        2,
                        6
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_6_29710_27960"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_4_29710_27960": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        0
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_5_29710_27960"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_3_29710_27960": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        1
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_4_29710_27960"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_2_29710_27960": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        2
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_3_29710_27960"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_1_29710_27960": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        3
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_2_29710_27960"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29710_27960": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        4
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29710_27960"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "add_428": {
                    "type": "add",
                    "grid_loc": [
                        7,
                        5
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "matmul_424",
                        "buffer_0_29710_27960"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_0_tms": [
                        {
                            "hslice": 2
                        }
                    ]
                },
                "layernorm_429.dc.reduce_sum.0.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        7,
                        6
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "add_428",
                        "lc.input_tensor.layernorm_429.dc.reduce_sum.0.0"
                    ],
                    "t": 1,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_3_27960_29711": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        7
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "add_428"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_2_27960_29711": {
                    "type": "nop",
                    "grid_loc": [
                        8,
                        0
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_3_27960_29711"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_1_27960_29711": {
                    "type": "nop",
                    "grid_loc": [
                        8,
                        1
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_2_27960_29711"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_27960_29711": {
                    "type": "nop",
                    "grid_loc": [
                        8,
                        2
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_1_27960_29711"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_56": {
                    "type": "fused_op",
                    "grid_loc": [
                        8,
                        3
                    ],
                    "grid_size": [
                        1,
                        2
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_429.1",
                        "layernorm_429.dc.reduce_sum.0.lc1",
                        "buffer_0_27960_29711"
                    ],
                    "t": 1,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 32
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 12
                    }
                },
                "layernorm_429.dc.multiply.4": {
                    "type": "multiply",
                    "grid_loc": [
                        8,
                        5
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "_fused_op_56",
                        "_fused_op_56"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "vslice": 2
                        }
                    ],
                    "input_0_tms": [
                        {
                            "vslice": 2
                        }
                    ]
                },
                "layernorm_429.dc.reduce_sum.5.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        8,
                        6
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "layernorm_429.dc.multiply.4",
                        "lc.input_tensor.layernorm_429.dc.reduce_sum.5.0"
                    ],
                    "t": 2,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 2
                            }
                        },
                        {
                            "broadcast": {
                                "r": 32
                            }
                        },
                        {
                            "hslice": 2
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                }
            },
            "fwd_0_20_temporal_epoch_20": {
                "target_device": 0,
                "input_count": 1,
                "_fused_op_57": {
                    "type": "fused_op",
                    "grid_loc": [
                        0,
                        0
                    ],
                    "grid_size": [
                        6,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_429.6",
                        "e2e_layernorm_429.dc.reduce_sum.5.lc1_0",
                        "dc.input_tensor.layernorm_429.8",
                        "e2e__fused_op_56_0",
                        "bert.encoder.layer.7.output.LayerNorm.weight",
                        "bert.encoder.layer.7.output.LayerNorm.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        32
                    ],
                    "ublock": [
                        2,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        2,
                        0,
                        2,
                        0,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        24,
                        0,
                        24,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_5_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_4_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_1_tms": [
                        {
                            "vstack": 2
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 15,
                        "kernel_broadcast": {
                            "input_5": 64,
                            "input_4": 64
                        }
                    }
                },
                "matmul_432": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        1
                    ],
                    "grid_size": [
                        6,
                        2
                    ],
                    "inputs": [
                        "_fused_op_57",
                        "bert.encoder.layer.8.attention.self.query.weight",
                        "bert.encoder.layer.8.attention.self.query.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        2,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        96,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 16
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_438": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        3
                    ],
                    "grid_size": [
                        6,
                        2
                    ],
                    "inputs": [
                        "_fused_op_57",
                        "bert.encoder.layer.8.attention.self.key.weight",
                        "bert.encoder.layer.8.attention.self.key.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        2,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 16
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_444": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        5
                    ],
                    "grid_size": [
                        6,
                        1
                    ],
                    "inputs": [
                        "matmul_432",
                        "matmul_438"
                    ],
                    "t": 16,
                    "mblock": [
                        2,
                        2
                    ],
                    "ublock": [
                        1,
                        6
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        363,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        "transpose",
                        {
                            "vslice": 16
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hslice": 16
                        }
                    ],
                    "attributes": {
                        "l1_acc": true,
                        "m_k": 2,
                        "min_buffer_input": 0,
                        "u_kt": 1
                    }
                },
                "_fused_op_58": {
                    "type": "fused_op",
                    "grid_loc": [
                        0,
                        6
                    ],
                    "grid_size": [
                        6,
                        1
                    ],
                    "inputs": [
                        "matmul_444",
                        "input_1_multiply_446",
                        "e2e_multiply_22_attempt_1_input_op_fork_nop1_0"
                    ],
                    "t": 16,
                    "mblock": [
                        2,
                        2
                    ],
                    "ublock": [
                        1,
                        6
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        48
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 12
                            }
                        },
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 16,
                        "kernel_broadcast": {
                            "input_1": 1
                        }
                    }
                },
                "softmax_448.dc.reduce_max.0": {
                    "type": "reduce",
                    "grid_loc": [
                        0,
                        7
                    ],
                    "grid_size": [
                        6,
                        1
                    ],
                    "inputs": [
                        "_fused_op_58"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        2,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "dim": "c",
                        "m_k": 1,
                        "type": "max",
                        "u_kt": 12
                    }
                }
            },
            "fwd_0_21_temporal_epoch_21": {
                "target_device": 0,
                "input_count": 1,
                "_fused_op_59": {
                    "type": "fused_op",
                    "grid_loc": [
                        0,
                        0
                    ],
                    "grid_size": [
                        2,
                        6
                    ],
                    "inputs": [
                        "e2e__fused_op_58_0",
                        "e2e_softmax_448.dc.reduce_max.0_0"
                    ],
                    "t": 16,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        3,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 32,
                    "input_dram_io_buf_size_tiles": [
                        24,
                        24
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 12
                            }
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 3
                    }
                },
                "softmax_448.dc.reduce_sum.3.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        6
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "_fused_op_59",
                        "lc.input_tensor.softmax_448.dc.reduce_sum.3.0"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 3,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_452": {
                    "type": "matmul",
                    "grid_loc": [
                        2,
                        1
                    ],
                    "grid_size": [
                        2,
                        4
                    ],
                    "inputs": [
                        "e2e__fused_op_57_0",
                        "bert.encoder.layer.8.attention.self.value.weight",
                        "bert.encoder.layer.8.attention.self.value.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 4,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                },
                "buffer_0_29714_29715": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        7
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "_fused_op_59"
                    ],
                    "t": 16,
                    "mblock": [
                        6,
                        2
                    ],
                    "ublock": [
                        1,
                        6
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        288
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_60": {
                    "type": "fused_op",
                    "grid_loc": [
                        2,
                        0
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "softmax_448.dc.reduce_sum.3.lc1",
                        "dc.input_tensor.softmax_448.4",
                        "buffer_0_29714_29715"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        12
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        96,
                        174
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 4
                    }
                },
                "matmul_459": {
                    "type": "matmul",
                    "grid_loc": [
                        2,
                        5
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "_fused_op_60",
                        "matmul_452"
                    ],
                    "t": 16,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        3,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 32,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "hslice": 16
                        }
                    ],
                    "attributes": {
                        "l1_acc": true,
                        "m_k": 2,
                        "min_buffer_input": 0,
                        "u_kt": 6
                    }
                },
                "matmul_463": {
                    "type": "matmul",
                    "grid_loc": [
                        4,
                        0
                    ],
                    "grid_size": [
                        2,
                        4
                    ],
                    "inputs": [
                        "matmul_459",
                        "bert.encoder.layer.8.attention.output.dense.weight",
                        "bert.encoder.layer.8.attention.output.dense.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 16
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 16,
                        "min_buffer_input": 0,
                        "u_kt": 2
                    }
                },
                "add_467": {
                    "type": "add",
                    "grid_loc": [
                        2,
                        6
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "matmul_463",
                        "e2e__fused_op_57_0"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        48
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "layernorm_468.dc.reduce_sum.0.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        2,
                        7
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "add_467",
                        "lc.input_tensor.layernorm_468.dc.reduce_sum.0.0"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_1_28032_29716": {
                    "type": "nop",
                    "grid_loc": [
                        4,
                        4
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "add_467"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_28032_29716": {
                    "type": "nop",
                    "grid_loc": [
                        4,
                        5
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "buffer_1_28032_29716"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_61": {
                    "type": "fused_op",
                    "grid_loc": [
                        4,
                        6
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_468.1",
                        "layernorm_468.dc.reduce_sum.0.lc1",
                        "buffer_0_28032_29716"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 32
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 5
                    }
                },
                "layernorm_468.dc.multiply.4": {
                    "type": "multiply",
                    "grid_loc": [
                        4,
                        7
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "_fused_op_61",
                        "_fused_op_61"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "layernorm_468.dc.reduce_sum.5.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        6,
                        0
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "layernorm_468.dc.multiply.4",
                        "lc.input_tensor.layernorm_468.dc.reduce_sum.5.0"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_2_29716_29717": {
                    "type": "nop",
                    "grid_loc": [
                        6,
                        1
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "_fused_op_61"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_1_29716_29717": {
                    "type": "nop",
                    "grid_loc": [
                        6,
                        2
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "buffer_2_29716_29717"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29716_29717": {
                    "type": "nop",
                    "grid_loc": [
                        6,
                        3
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29716_29717"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_62": {
                    "type": "fused_op",
                    "grid_loc": [
                        6,
                        4
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_468.6",
                        "layernorm_468.dc.reduce_sum.5.lc1",
                        "dc.input_tensor.layernorm_468.8",
                        "buffer_0_29716_29717",
                        "bert.encoder.layer.8.attention.output.LayerNorm.weight",
                        "bert.encoder.layer.8.attention.output.LayerNorm.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        32
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        6,
                        0,
                        6,
                        0,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0,
                        0,
                        24,
                        24
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_5_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_4_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 6
                    }
                },
                "matmul_471": {
                    "type": "matmul",
                    "grid_loc": [
                        8,
                        0
                    ],
                    "grid_size": [
                        2,
                        8
                    ],
                    "inputs": [
                        "_fused_op_62",
                        "bert.encoder.layer.8.intermediate.dense.weight",
                        "bert.encoder.layer.8.intermediate.dense.bias"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "hslice": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "hslice": 2
                        }
                    ],
                    "input_0_tms": [
                        {
                            "broadcast": {
                                "r": 2
                            }
                        },
                        {
                            "vslice": 2
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "gelu_474": {
                    "type": "gelu",
                    "grid_loc": [
                        6,
                        5
                    ],
                    "grid_size": [
                        2,
                        2
                    ],
                    "inputs": [
                        "matmul_471"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "approximate_mode": false
                    }
                }
            },
            "fwd_0_22_temporal_epoch_22": {
                "target_device": 0,
                "input_count": 1,
                "matmul_477": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        0
                    ],
                    "grid_size": [
                        3,
                        8
                    ],
                    "inputs": [
                        "e2e_gelu_474_0",
                        "bert.encoder.layer.8.output.dense.weight",
                        "bert.encoder.layer.8.output.dense.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        2,
                        4
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 4
                        },
                        "l1_acc": true,
                        "m_k": 16,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                },
                "add_481": {
                    "type": "add",
                    "grid_loc": [
                        3,
                        0
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "matmul_477",
                        "e2e__fused_op_62_0"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        48
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "layernorm_482.dc.reduce_sum.0.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        3,
                        1
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "add_481",
                        "lc.input_tensor.layernorm_482.dc.reduce_sum.0.0"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_1_28064_29718": {
                    "type": "nop",
                    "grid_loc": [
                        3,
                        2
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "add_481"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_28064_29718": {
                    "type": "nop",
                    "grid_loc": [
                        3,
                        3
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "buffer_1_28064_29718"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_63": {
                    "type": "fused_op",
                    "grid_loc": [
                        3,
                        4
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_482.1",
                        "layernorm_482.dc.reduce_sum.0.lc1",
                        "buffer_0_28064_29718"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        128,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 32
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 7
                    }
                },
                "layernorm_482.dc.multiply.4": {
                    "type": "multiply",
                    "grid_loc": [
                        3,
                        5
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "_fused_op_63",
                        "_fused_op_63"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "layernorm_482.dc.reduce_sum.5.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        3,
                        6
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "layernorm_482.dc.multiply.4",
                        "lc.input_tensor.layernorm_482.dc.reduce_sum.5.0"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_1_29718_29719": {
                    "type": "nop",
                    "grid_loc": [
                        3,
                        7
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "_fused_op_63"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        176
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29718_29719": {
                    "type": "nop",
                    "grid_loc": [
                        6,
                        0
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29718_29719"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        176
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_64": {
                    "type": "fused_op",
                    "grid_loc": [
                        6,
                        1
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_482.6",
                        "layernorm_482.dc.reduce_sum.5.lc1",
                        "dc.input_tensor.layernorm_482.8",
                        "buffer_0_29718_29719",
                        "bert.encoder.layer.8.output.LayerNorm.weight",
                        "bert.encoder.layer.8.output.LayerNorm.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        32
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        4,
                        0,
                        4,
                        0,
                        128,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0,
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_5_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_4_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 8
                    }
                },
                "matmul_485": {
                    "type": "matmul",
                    "grid_loc": [
                        6,
                        2
                    ],
                    "grid_size": [
                        3,
                        4
                    ],
                    "inputs": [
                        "_fused_op_64",
                        "bert.encoder.layer.9.attention.self.query.weight",
                        "bert.encoder.layer.9.attention.self.query.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 4,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                }
            },
            "fwd_0_23_temporal_epoch_23": {
                "target_device": 0,
                "input_count": 1,
                "matmul_491": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        0
                    ],
                    "grid_size": [
                        3,
                        4
                    ],
                    "inputs": [
                        "e2e__fused_op_64_0",
                        "bert.encoder.layer.9.attention.self.key.weight",
                        "bert.encoder.layer.9.attention.self.key.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 4,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                },
                "matmul_497": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        4
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "e2e_matmul_485_0",
                        "matmul_491"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        6
                    ],
                    "ublock": [
                        4,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        "transpose",
                        {
                            "vslice": 16
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hslice": 16
                        }
                    ],
                    "attributes": {
                        "l1_acc": true,
                        "m_k": 2,
                        "min_buffer_input": 0,
                        "u_kt": 1
                    }
                },
                "_fused_op_65": {
                    "type": "fused_op",
                    "grid_loc": [
                        0,
                        5
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "matmul_497",
                        "input_1_multiply_499",
                        "e2e_multiply_22_attempt_1_input_op_fork_nop1_0"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        6
                    ],
                    "ublock": [
                        4,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        48
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 12
                            }
                        },
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 9,
                        "kernel_broadcast": {
                            "input_1": 1
                        }
                    }
                },
                "softmax_501.dc.reduce_max.0": {
                    "type": "reduce",
                    "grid_loc": [
                        0,
                        6
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "_fused_op_65"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "dim": "c",
                        "m_k": 1,
                        "type": "max",
                        "u_kt": 12
                    }
                },
                "_fused_op_66": {
                    "type": "fused_op",
                    "grid_loc": [
                        3,
                        0
                    ],
                    "grid_size": [
                        3,
                        6
                    ],
                    "inputs": [
                        "_fused_op_65",
                        "softmax_501.dc.reduce_max.0"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        400,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 12
                            }
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 10
                    }
                },
                "softmax_501.dc.reduce_sum.3.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        7
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "_fused_op_66",
                        "lc.input_tensor.softmax_501.dc.reduce_sum.3.0"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 3,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_505": {
                    "type": "matmul",
                    "grid_loc": [
                        6,
                        0
                    ],
                    "grid_size": [
                        3,
                        4
                    ],
                    "inputs": [
                        "e2e__fused_op_64_0",
                        "bert.encoder.layer.9.attention.self.value.weight",
                        "bert.encoder.layer.9.attention.self.value.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 4,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                },
                "_fused_op_67": {
                    "type": "fused_op",
                    "grid_loc": [
                        3,
                        6
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "softmax_501.dc.reduce_sum.3.lc1",
                        "dc.input_tensor.softmax_501.4",
                        "_fused_op_66"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        12
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        64,
                        260
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 11
                    }
                },
                "matmul_512": {
                    "type": "matmul",
                    "grid_loc": [
                        3,
                        7
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "_fused_op_67",
                        "matmul_505"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 32,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "hslice": 16
                        }
                    ],
                    "attributes": {
                        "l1_acc": true,
                        "m_k": 3,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_516": {
                    "type": "matmul",
                    "grid_loc": [
                        6,
                        4
                    ],
                    "grid_size": [
                        2,
                        4
                    ],
                    "inputs": [
                        "matmul_512",
                        "bert.encoder.layer.9.attention.output.dense.weight",
                        "bert.encoder.layer.9.attention.output.dense.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 16
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 16,
                        "min_buffer_input": 0,
                        "u_kt": 2
                    }
                }
            },
            "fwd_0_24_temporal_epoch_24": {
                "target_device": 0,
                "input_count": 1,
                "add_520": {
                    "type": "add",
                    "grid_loc": [
                        0,
                        0
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "e2e_matmul_516_0",
                        "e2e__fused_op_64_0"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        24,
                        24
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "hslice": 2
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hslice": 2
                        }
                    ]
                },
                "layernorm_521.dc.reduce_sum.0.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        1
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "add_520",
                        "lc.input_tensor.layernorm_521.dc.reduce_sum.0.0"
                    ],
                    "t": 1,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_3_28136_29723": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        2
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "add_520"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_2_28136_29723": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        3
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_3_28136_29723"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_1_28136_29723": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        4
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_2_28136_29723"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_28136_29723": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        5
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_1_28136_29723"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_68": {
                    "type": "fused_op",
                    "grid_loc": [
                        0,
                        6
                    ],
                    "grid_size": [
                        1,
                        2
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_521.1",
                        "layernorm_521.dc.reduce_sum.0.lc1",
                        "buffer_0_28136_29723"
                    ],
                    "t": 1,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 32
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 12
                    }
                },
                "layernorm_521.dc.multiply.4": {
                    "type": "multiply",
                    "grid_loc": [
                        1,
                        0
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "_fused_op_68",
                        "_fused_op_68"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "vslice": 2
                        }
                    ],
                    "input_0_tms": [
                        {
                            "vslice": 2
                        }
                    ]
                },
                "layernorm_521.dc.reduce_sum.5.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        1,
                        1
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "layernorm_521.dc.multiply.4",
                        "lc.input_tensor.layernorm_521.dc.reduce_sum.5.0"
                    ],
                    "t": 2,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 2
                            }
                        },
                        {
                            "broadcast": {
                                "r": 32
                            }
                        },
                        {
                            "hslice": 2
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_4_29723_29724": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        2
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "_fused_op_68"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_0_tms": [
                        {
                            "vslice": 2
                        }
                    ]
                },
                "buffer_3_29723_29724": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        3
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_4_29723_29724"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_2_29723_29724": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        4
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_3_29723_29724"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_1_29723_29724": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        5
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_2_29723_29724"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29723_29724": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        6
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29723_29724"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_69": {
                    "type": "fused_op",
                    "grid_loc": [
                        1,
                        7
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_521.6",
                        "layernorm_521.dc.reduce_sum.5.lc1",
                        "dc.input_tensor.layernorm_521.8",
                        "buffer_0_29723_29724",
                        "bert.encoder.layer.9.attention.output.LayerNorm.weight",
                        "bert.encoder.layer.9.attention.output.LayerNorm.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        32
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        6,
                        0,
                        6,
                        0,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0,
                        0,
                        24,
                        24
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_5_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_4_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_3_tms": [
                        {
                            "vstack": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "vstack": 2
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 6
                    }
                },
                "matmul_524": {
                    "type": "matmul",
                    "grid_loc": [
                        3,
                        0
                    ],
                    "grid_size": [
                        2,
                        8
                    ],
                    "inputs": [
                        "_fused_op_69",
                        "bert.encoder.layer.9.intermediate.dense.weight",
                        "bert.encoder.layer.9.intermediate.dense.bias"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "hslice": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "hslice": 2
                        }
                    ],
                    "input_0_tms": [
                        {
                            "broadcast": {
                                "r": 2
                            }
                        },
                        {
                            "vslice": 2
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "gelu_527": {
                    "type": "gelu",
                    "grid_loc": [
                        2,
                        0
                    ],
                    "grid_size": [
                        1,
                        4
                    ],
                    "inputs": [
                        "matmul_524"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "approximate_mode": false
                    }
                },
                "matmul_530": {
                    "type": "matmul",
                    "grid_loc": [
                        5,
                        0
                    ],
                    "grid_size": [
                        2,
                        8
                    ],
                    "inputs": [
                        "gelu_527",
                        "bert.encoder.layer.9.output.dense.weight",
                        "bert.encoder.layer.9.output.dense.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        3,
                        1
                    ],
                    "ublock": [
                        2,
                        4
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 4
                        },
                        "l1_acc": true,
                        "m_k": 16,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                },
                "buffer_7_29724_28168": {
                    "type": "nop",
                    "grid_loc": [
                        2,
                        4
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "_fused_op_69"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_0_tms": [
                        {
                            "hslice": 2
                        }
                    ]
                },
                "buffer_6_29724_28168": {
                    "type": "nop",
                    "grid_loc": [
                        2,
                        5
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_7_29724_28168"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_5_29724_28168": {
                    "type": "nop",
                    "grid_loc": [
                        2,
                        6
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_6_29724_28168"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_4_29724_28168": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        0
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_5_29724_28168"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_3_29724_28168": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        1
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_4_29724_28168"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_2_29724_28168": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        2
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_3_29724_28168"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_1_29724_28168": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        3
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_2_29724_28168"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29724_28168": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        4
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29724_28168"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "add_534": {
                    "type": "add",
                    "grid_loc": [
                        7,
                        5
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "matmul_530",
                        "buffer_0_29724_28168"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_0_tms": [
                        {
                            "hslice": 2
                        }
                    ]
                },
                "layernorm_535.dc.reduce_sum.0.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        7,
                        6
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "add_534",
                        "lc.input_tensor.layernorm_535.dc.reduce_sum.0.0"
                    ],
                    "t": 1,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_3_28168_29725": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        7
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "add_534"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_2_28168_29725": {
                    "type": "nop",
                    "grid_loc": [
                        8,
                        0
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_3_28168_29725"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_1_28168_29725": {
                    "type": "nop",
                    "grid_loc": [
                        8,
                        1
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_2_28168_29725"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_28168_29725": {
                    "type": "nop",
                    "grid_loc": [
                        8,
                        2
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_1_28168_29725"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_70": {
                    "type": "fused_op",
                    "grid_loc": [
                        8,
                        3
                    ],
                    "grid_size": [
                        1,
                        2
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_535.1",
                        "layernorm_535.dc.reduce_sum.0.lc1",
                        "buffer_0_28168_29725"
                    ],
                    "t": 1,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 32
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 12
                    }
                },
                "layernorm_535.dc.multiply.4": {
                    "type": "multiply",
                    "grid_loc": [
                        8,
                        5
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "_fused_op_70",
                        "_fused_op_70"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "vslice": 2
                        }
                    ],
                    "input_0_tms": [
                        {
                            "vslice": 2
                        }
                    ]
                },
                "layernorm_535.dc.reduce_sum.5.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        8,
                        6
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "layernorm_535.dc.multiply.4",
                        "lc.input_tensor.layernorm_535.dc.reduce_sum.5.0"
                    ],
                    "t": 2,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 2
                            }
                        },
                        {
                            "broadcast": {
                                "r": 32
                            }
                        },
                        {
                            "hslice": 2
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                }
            },
            "fwd_0_25_temporal_epoch_25": {
                "target_device": 0,
                "input_count": 1,
                "_fused_op_71": {
                    "type": "fused_op",
                    "grid_loc": [
                        0,
                        0
                    ],
                    "grid_size": [
                        6,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_535.6",
                        "e2e_layernorm_535.dc.reduce_sum.5.lc1_0",
                        "dc.input_tensor.layernorm_535.8",
                        "e2e__fused_op_70_0",
                        "bert.encoder.layer.9.output.LayerNorm.weight",
                        "bert.encoder.layer.9.output.LayerNorm.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        32
                    ],
                    "ublock": [
                        2,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        2,
                        0,
                        2,
                        0,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        24,
                        0,
                        24,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_5_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_4_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_1_tms": [
                        {
                            "vstack": 2
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 15,
                        "kernel_broadcast": {
                            "input_5": 64,
                            "input_4": 64
                        }
                    }
                },
                "matmul_538": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        1
                    ],
                    "grid_size": [
                        6,
                        2
                    ],
                    "inputs": [
                        "_fused_op_71",
                        "bert.encoder.layer.10.attention.self.query.weight",
                        "bert.encoder.layer.10.attention.self.query.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        2,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        96,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 16
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_544": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        3
                    ],
                    "grid_size": [
                        6,
                        2
                    ],
                    "inputs": [
                        "_fused_op_71",
                        "bert.encoder.layer.10.attention.self.key.weight",
                        "bert.encoder.layer.10.attention.self.key.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        2,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 16
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_550": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        5
                    ],
                    "grid_size": [
                        6,
                        1
                    ],
                    "inputs": [
                        "matmul_538",
                        "matmul_544"
                    ],
                    "t": 16,
                    "mblock": [
                        2,
                        2
                    ],
                    "ublock": [
                        1,
                        6
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        363,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        "transpose",
                        {
                            "vslice": 16
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hslice": 16
                        }
                    ],
                    "attributes": {
                        "l1_acc": true,
                        "m_k": 2,
                        "min_buffer_input": 0,
                        "u_kt": 1
                    }
                },
                "_fused_op_72": {
                    "type": "fused_op",
                    "grid_loc": [
                        0,
                        6
                    ],
                    "grid_size": [
                        6,
                        1
                    ],
                    "inputs": [
                        "matmul_550",
                        "input_1_multiply_552",
                        "e2e_multiply_22_attempt_1_input_op_fork_nop1_0"
                    ],
                    "t": 16,
                    "mblock": [
                        2,
                        2
                    ],
                    "ublock": [
                        1,
                        6
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        48
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 12
                            }
                        },
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 16,
                        "kernel_broadcast": {
                            "input_1": 1
                        }
                    }
                },
                "softmax_554.dc.reduce_max.0": {
                    "type": "reduce",
                    "grid_loc": [
                        0,
                        7
                    ],
                    "grid_size": [
                        6,
                        1
                    ],
                    "inputs": [
                        "_fused_op_72"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        2,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "dim": "c",
                        "m_k": 1,
                        "type": "max",
                        "u_kt": 12
                    }
                }
            },
            "fwd_0_26_temporal_epoch_26": {
                "target_device": 0,
                "input_count": 1,
                "_fused_op_73": {
                    "type": "fused_op",
                    "grid_loc": [
                        0,
                        0
                    ],
                    "grid_size": [
                        2,
                        6
                    ],
                    "inputs": [
                        "e2e__fused_op_72_0",
                        "e2e_softmax_554.dc.reduce_max.0_0"
                    ],
                    "t": 16,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        3,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 32,
                    "input_dram_io_buf_size_tiles": [
                        24,
                        24
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 12
                            }
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 3
                    }
                },
                "softmax_554.dc.reduce_sum.3.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        6
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "_fused_op_73",
                        "lc.input_tensor.softmax_554.dc.reduce_sum.3.0"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 3,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_558": {
                    "type": "matmul",
                    "grid_loc": [
                        2,
                        1
                    ],
                    "grid_size": [
                        2,
                        4
                    ],
                    "inputs": [
                        "e2e__fused_op_71_0",
                        "bert.encoder.layer.10.attention.self.value.weight",
                        "bert.encoder.layer.10.attention.self.value.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 4,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                },
                "buffer_0_29728_29729": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        7
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "_fused_op_73"
                    ],
                    "t": 16,
                    "mblock": [
                        6,
                        2
                    ],
                    "ublock": [
                        1,
                        6
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        288
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_74": {
                    "type": "fused_op",
                    "grid_loc": [
                        2,
                        0
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "softmax_554.dc.reduce_sum.3.lc1",
                        "dc.input_tensor.softmax_554.4",
                        "buffer_0_29728_29729"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        12
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        96,
                        174
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 4
                    }
                },
                "matmul_565": {
                    "type": "matmul",
                    "grid_loc": [
                        2,
                        5
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "_fused_op_74",
                        "matmul_558"
                    ],
                    "t": 16,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        3,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 32,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "hslice": 16
                        }
                    ],
                    "attributes": {
                        "l1_acc": true,
                        "m_k": 2,
                        "min_buffer_input": 0,
                        "u_kt": 6
                    }
                },
                "matmul_569": {
                    "type": "matmul",
                    "grid_loc": [
                        4,
                        0
                    ],
                    "grid_size": [
                        2,
                        4
                    ],
                    "inputs": [
                        "matmul_565",
                        "bert.encoder.layer.10.attention.output.dense.weight",
                        "bert.encoder.layer.10.attention.output.dense.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 16
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 16,
                        "min_buffer_input": 0,
                        "u_kt": 2
                    }
                },
                "add_573": {
                    "type": "add",
                    "grid_loc": [
                        2,
                        6
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "matmul_569",
                        "e2e__fused_op_71_0"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        48
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "layernorm_574.dc.reduce_sum.0.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        2,
                        7
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "add_573",
                        "lc.input_tensor.layernorm_574.dc.reduce_sum.0.0"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_1_28240_29730": {
                    "type": "nop",
                    "grid_loc": [
                        4,
                        4
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "add_573"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_28240_29730": {
                    "type": "nop",
                    "grid_loc": [
                        4,
                        5
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "buffer_1_28240_29730"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_75": {
                    "type": "fused_op",
                    "grid_loc": [
                        4,
                        6
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_574.1",
                        "layernorm_574.dc.reduce_sum.0.lc1",
                        "buffer_0_28240_29730"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 32
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 5
                    }
                },
                "layernorm_574.dc.multiply.4": {
                    "type": "multiply",
                    "grid_loc": [
                        4,
                        7
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "_fused_op_75",
                        "_fused_op_75"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "layernorm_574.dc.reduce_sum.5.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        6,
                        0
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "layernorm_574.dc.multiply.4",
                        "lc.input_tensor.layernorm_574.dc.reduce_sum.5.0"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_2_29730_29731": {
                    "type": "nop",
                    "grid_loc": [
                        6,
                        1
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "_fused_op_75"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_1_29730_29731": {
                    "type": "nop",
                    "grid_loc": [
                        6,
                        2
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "buffer_2_29730_29731"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29730_29731": {
                    "type": "nop",
                    "grid_loc": [
                        6,
                        3
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29730_29731"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_76": {
                    "type": "fused_op",
                    "grid_loc": [
                        6,
                        4
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_574.6",
                        "layernorm_574.dc.reduce_sum.5.lc1",
                        "dc.input_tensor.layernorm_574.8",
                        "buffer_0_29730_29731",
                        "bert.encoder.layer.10.attention.output.LayerNorm.weight",
                        "bert.encoder.layer.10.attention.output.LayerNorm.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        32
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        6,
                        0,
                        6,
                        0,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0,
                        0,
                        24,
                        24
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_5_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_4_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 6
                    }
                },
                "matmul_577": {
                    "type": "matmul",
                    "grid_loc": [
                        8,
                        0
                    ],
                    "grid_size": [
                        2,
                        8
                    ],
                    "inputs": [
                        "_fused_op_76",
                        "bert.encoder.layer.10.intermediate.dense.weight",
                        "bert.encoder.layer.10.intermediate.dense.bias"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "hslice": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "hslice": 2
                        }
                    ],
                    "input_0_tms": [
                        {
                            "broadcast": {
                                "r": 2
                            }
                        },
                        {
                            "vslice": 2
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "gelu_580": {
                    "type": "gelu",
                    "grid_loc": [
                        6,
                        5
                    ],
                    "grid_size": [
                        2,
                        2
                    ],
                    "inputs": [
                        "matmul_577"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "approximate_mode": false
                    }
                }
            },
            "fwd_0_27_temporal_epoch_27": {
                "target_device": 0,
                "input_count": 1,
                "matmul_583": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        0
                    ],
                    "grid_size": [
                        3,
                        8
                    ],
                    "inputs": [
                        "e2e_gelu_580_0",
                        "bert.encoder.layer.10.output.dense.weight",
                        "bert.encoder.layer.10.output.dense.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        2,
                        4
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 4
                        },
                        "l1_acc": true,
                        "m_k": 16,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                },
                "add_587": {
                    "type": "add",
                    "grid_loc": [
                        3,
                        0
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "matmul_583",
                        "e2e__fused_op_76_0"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        48
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "layernorm_588.dc.reduce_sum.0.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        3,
                        1
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "add_587",
                        "lc.input_tensor.layernorm_588.dc.reduce_sum.0.0"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_1_28272_29732": {
                    "type": "nop",
                    "grid_loc": [
                        3,
                        2
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "add_587"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_28272_29732": {
                    "type": "nop",
                    "grid_loc": [
                        3,
                        3
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "buffer_1_28272_29732"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_77": {
                    "type": "fused_op",
                    "grid_loc": [
                        3,
                        4
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_588.1",
                        "layernorm_588.dc.reduce_sum.0.lc1",
                        "buffer_0_28272_29732"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        128,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 32
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 7
                    }
                },
                "layernorm_588.dc.multiply.4": {
                    "type": "multiply",
                    "grid_loc": [
                        3,
                        5
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "_fused_op_77",
                        "_fused_op_77"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "layernorm_588.dc.reduce_sum.5.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        3,
                        6
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "layernorm_588.dc.multiply.4",
                        "lc.input_tensor.layernorm_588.dc.reduce_sum.5.0"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_1_29732_29733": {
                    "type": "nop",
                    "grid_loc": [
                        3,
                        7
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "_fused_op_77"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        176
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29732_29733": {
                    "type": "nop",
                    "grid_loc": [
                        6,
                        0
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29732_29733"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        176
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_78": {
                    "type": "fused_op",
                    "grid_loc": [
                        6,
                        1
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_588.6",
                        "layernorm_588.dc.reduce_sum.5.lc1",
                        "dc.input_tensor.layernorm_588.8",
                        "buffer_0_29732_29733",
                        "bert.encoder.layer.10.output.LayerNorm.weight",
                        "bert.encoder.layer.10.output.LayerNorm.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        32
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        4,
                        0,
                        4,
                        0,
                        128,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0,
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_5_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_4_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 8
                    }
                },
                "matmul_591": {
                    "type": "matmul",
                    "grid_loc": [
                        6,
                        2
                    ],
                    "grid_size": [
                        3,
                        4
                    ],
                    "inputs": [
                        "_fused_op_78",
                        "bert.encoder.layer.11.attention.self.query.weight",
                        "bert.encoder.layer.11.attention.self.query.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 4,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                }
            },
            "fwd_0_28_temporal_epoch_28": {
                "target_device": 0,
                "input_count": 1,
                "matmul_597": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        0
                    ],
                    "grid_size": [
                        3,
                        4
                    ],
                    "inputs": [
                        "e2e__fused_op_78_0",
                        "bert.encoder.layer.11.attention.self.key.weight",
                        "bert.encoder.layer.11.attention.self.key.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 4,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                },
                "matmul_603": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        4
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "e2e_matmul_591_0",
                        "matmul_597"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        6
                    ],
                    "ublock": [
                        4,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        "transpose",
                        {
                            "vslice": 16
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hslice": 16
                        }
                    ],
                    "attributes": {
                        "l1_acc": true,
                        "m_k": 2,
                        "min_buffer_input": 0,
                        "u_kt": 1
                    }
                },
                "_fused_op_79": {
                    "type": "fused_op",
                    "grid_loc": [
                        0,
                        5
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "matmul_603",
                        "input_1_multiply_605",
                        "e2e_multiply_22_attempt_1_input_op_fork_nop1_0"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        6
                    ],
                    "ublock": [
                        4,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        48
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 12
                            }
                        },
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 9,
                        "kernel_broadcast": {
                            "input_1": 1
                        }
                    }
                },
                "softmax_607.dc.reduce_max.0": {
                    "type": "reduce",
                    "grid_loc": [
                        0,
                        6
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "_fused_op_79"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "dim": "c",
                        "m_k": 1,
                        "type": "max",
                        "u_kt": 12
                    }
                },
                "_fused_op_80": {
                    "type": "fused_op",
                    "grid_loc": [
                        3,
                        0
                    ],
                    "grid_size": [
                        3,
                        6
                    ],
                    "inputs": [
                        "_fused_op_79",
                        "softmax_607.dc.reduce_max.0"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        400,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 12
                            }
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 10
                    }
                },
                "softmax_607.dc.reduce_sum.3.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        7
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "_fused_op_80",
                        "lc.input_tensor.softmax_607.dc.reduce_sum.3.0"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 3,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_611": {
                    "type": "matmul",
                    "grid_loc": [
                        6,
                        0
                    ],
                    "grid_size": [
                        3,
                        4
                    ],
                    "inputs": [
                        "e2e__fused_op_78_0",
                        "bert.encoder.layer.11.attention.self.value.weight",
                        "bert.encoder.layer.11.attention.self.value.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 4,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                },
                "_fused_op_81": {
                    "type": "fused_op",
                    "grid_loc": [
                        3,
                        6
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "softmax_607.dc.reduce_sum.3.lc1",
                        "dc.input_tensor.softmax_607.4",
                        "_fused_op_80"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        12
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        64,
                        260
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 11
                    }
                },
                "matmul_618": {
                    "type": "matmul",
                    "grid_loc": [
                        3,
                        7
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "_fused_op_81",
                        "matmul_611"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 32,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "hslice": 16
                        }
                    ],
                    "attributes": {
                        "l1_acc": true,
                        "m_k": 3,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_622": {
                    "type": "matmul",
                    "grid_loc": [
                        6,
                        4
                    ],
                    "grid_size": [
                        2,
                        4
                    ],
                    "inputs": [
                        "matmul_618",
                        "bert.encoder.layer.11.attention.output.dense.weight",
                        "bert.encoder.layer.11.attention.output.dense.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 16
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 16,
                        "min_buffer_input": 0,
                        "u_kt": 2
                    }
                }
            },
            "fwd_0_29_temporal_epoch_29": {
                "target_device": 0,
                "input_count": 1,
                "add_626": {
                    "type": "add",
                    "grid_loc": [
                        0,
                        0
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "e2e_matmul_622_0",
                        "e2e__fused_op_78_0"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        24,
                        24
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "hslice": 2
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hslice": 2
                        }
                    ]
                },
                "layernorm_627.dc.reduce_sum.0.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        1
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "add_626",
                        "lc.input_tensor.layernorm_627.dc.reduce_sum.0.0"
                    ],
                    "t": 1,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_3_28344_29737": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        2
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "add_626"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_2_28344_29737": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        3
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_3_28344_29737"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_1_28344_29737": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        4
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_2_28344_29737"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_28344_29737": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        5
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_1_28344_29737"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_82": {
                    "type": "fused_op",
                    "grid_loc": [
                        0,
                        6
                    ],
                    "grid_size": [
                        1,
                        2
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_627.1",
                        "layernorm_627.dc.reduce_sum.0.lc1",
                        "buffer_0_28344_29737"
                    ],
                    "t": 1,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 32
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 12
                    }
                },
                "layernorm_627.dc.multiply.4": {
                    "type": "multiply",
                    "grid_loc": [
                        1,
                        0
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "_fused_op_82",
                        "_fused_op_82"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "vslice": 2
                        }
                    ],
                    "input_0_tms": [
                        {
                            "vslice": 2
                        }
                    ]
                },
                "layernorm_627.dc.reduce_sum.5.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        1,
                        1
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "layernorm_627.dc.multiply.4",
                        "lc.input_tensor.layernorm_627.dc.reduce_sum.5.0"
                    ],
                    "t": 2,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 2
                            }
                        },
                        {
                            "broadcast": {
                                "r": 32
                            }
                        },
                        {
                            "hslice": 2
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_4_29737_29738": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        2
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "_fused_op_82"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_0_tms": [
                        {
                            "vslice": 2
                        }
                    ]
                },
                "buffer_3_29737_29738": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        3
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_4_29737_29738"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_2_29737_29738": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        4
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_3_29737_29738"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_1_29737_29738": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        5
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_2_29737_29738"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29737_29738": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        6
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29737_29738"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_83": {
                    "type": "fused_op",
                    "grid_loc": [
                        1,
                        7
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_627.6",
                        "layernorm_627.dc.reduce_sum.5.lc1",
                        "dc.input_tensor.layernorm_627.8",
                        "buffer_0_29737_29738",
                        "bert.encoder.layer.11.attention.output.LayerNorm.weight",
                        "bert.encoder.layer.11.attention.output.LayerNorm.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        32
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        6,
                        0,
                        6,
                        0,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0,
                        0,
                        24,
                        24
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_5_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_4_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_3_tms": [
                        {
                            "vstack": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "vstack": 2
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 6
                    }
                },
                "matmul_630": {
                    "type": "matmul",
                    "grid_loc": [
                        3,
                        0
                    ],
                    "grid_size": [
                        2,
                        8
                    ],
                    "inputs": [
                        "_fused_op_83",
                        "bert.encoder.layer.11.intermediate.dense.weight",
                        "bert.encoder.layer.11.intermediate.dense.bias"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "hslice": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "hslice": 2
                        }
                    ],
                    "input_0_tms": [
                        {
                            "broadcast": {
                                "r": 2
                            }
                        },
                        {
                            "vslice": 2
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "gelu_633": {
                    "type": "gelu",
                    "grid_loc": [
                        2,
                        0
                    ],
                    "grid_size": [
                        1,
                        4
                    ],
                    "inputs": [
                        "matmul_630"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "approximate_mode": false
                    }
                },
                "matmul_636": {
                    "type": "matmul",
                    "grid_loc": [
                        5,
                        0
                    ],
                    "grid_size": [
                        2,
                        8
                    ],
                    "inputs": [
                        "gelu_633",
                        "bert.encoder.layer.11.output.dense.weight",
                        "bert.encoder.layer.11.output.dense.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        3,
                        1
                    ],
                    "ublock": [
                        2,
                        4
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 4
                        },
                        "l1_acc": true,
                        "m_k": 16,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                },
                "buffer_7_29738_28376": {
                    "type": "nop",
                    "grid_loc": [
                        2,
                        4
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "_fused_op_83"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_0_tms": [
                        {
                            "hslice": 2
                        }
                    ]
                },
                "buffer_6_29738_28376": {
                    "type": "nop",
                    "grid_loc": [
                        2,
                        5
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_7_29738_28376"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_5_29738_28376": {
                    "type": "nop",
                    "grid_loc": [
                        2,
                        6
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_6_29738_28376"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_4_29738_28376": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        0
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_5_29738_28376"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_3_29738_28376": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        1
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_4_29738_28376"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_2_29738_28376": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        2
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_3_29738_28376"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_1_29738_28376": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        3
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_2_29738_28376"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29738_28376": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        4
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29738_28376"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "add_640": {
                    "type": "add",
                    "grid_loc": [
                        7,
                        5
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "matmul_636",
                        "buffer_0_29738_28376"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_0_tms": [
                        {
                            "hslice": 2
                        }
                    ]
                },
                "layernorm_641.dc.reduce_sum.0.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        7,
                        6
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "add_640",
                        "lc.input_tensor.layernorm_641.dc.reduce_sum.0.0"
                    ],
                    "t": 1,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_3_28376_29739": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        7
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "add_640"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_2_28376_29739": {
                    "type": "nop",
                    "grid_loc": [
                        8,
                        0
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_3_28376_29739"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_1_28376_29739": {
                    "type": "nop",
                    "grid_loc": [
                        8,
                        1
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_2_28376_29739"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_28376_29739": {
                    "type": "nop",
                    "grid_loc": [
                        8,
                        2
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_1_28376_29739"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_84": {
                    "type": "fused_op",
                    "grid_loc": [
                        8,
                        3
                    ],
                    "grid_size": [
                        1,
                        2
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_641.1",
                        "layernorm_641.dc.reduce_sum.0.lc1",
                        "buffer_0_28376_29739"
                    ],
                    "t": 1,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 32
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 12
                    }
                },
                "layernorm_641.dc.multiply.4": {
                    "type": "multiply",
                    "grid_loc": [
                        8,
                        5
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "_fused_op_84",
                        "_fused_op_84"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "vslice": 2
                        }
                    ],
                    "input_0_tms": [
                        {
                            "vslice": 2
                        }
                    ]
                },
                "layernorm_641.dc.reduce_sum.5.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        8,
                        6
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "layernorm_641.dc.multiply.4",
                        "lc.input_tensor.layernorm_641.dc.reduce_sum.5.0"
                    ],
                    "t": 2,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 2
                            }
                        },
                        {
                            "broadcast": {
                                "r": 32
                            }
                        },
                        {
                            "hslice": 2
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                }
            },
            "fwd_0_30_temporal_epoch_30": {
                "target_device": 0,
                "input_count": 1,
                "_fused_op_85": {
                    "type": "fused_op",
                    "grid_loc": [
                        0,
                        0
                    ],
                    "grid_size": [
                        6,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_641.6",
                        "e2e_layernorm_641.dc.reduce_sum.5.lc1_0",
                        "dc.input_tensor.layernorm_641.8",
                        "e2e__fused_op_84_0",
                        "bert.encoder.layer.11.output.LayerNorm.weight",
                        "bert.encoder.layer.11.output.LayerNorm.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        32
                    ],
                    "ublock": [
                        2,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        2,
                        0,
                        2,
                        0,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        24,
                        0,
                        24,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_5_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_4_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_1_tms": [
                        {
                            "vstack": 2
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 15,
                        "kernel_broadcast": {
                            "input_5": 64,
                            "input_4": 64
                        }
                    }
                },
                "matmul_644": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        1
                    ],
                    "grid_size": [
                        6,
                        2
                    ],
                    "inputs": [
                        "_fused_op_85",
                        "bert.encoder.layer.12.attention.self.query.weight",
                        "bert.encoder.layer.12.attention.self.query.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        2,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        96,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 16
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_650": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        3
                    ],
                    "grid_size": [
                        6,
                        2
                    ],
                    "inputs": [
                        "_fused_op_85",
                        "bert.encoder.layer.12.attention.self.key.weight",
                        "bert.encoder.layer.12.attention.self.key.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        2,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 16
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_656": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        5
                    ],
                    "grid_size": [
                        6,
                        1
                    ],
                    "inputs": [
                        "matmul_644",
                        "matmul_650"
                    ],
                    "t": 16,
                    "mblock": [
                        2,
                        2
                    ],
                    "ublock": [
                        1,
                        6
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        363,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        "transpose",
                        {
                            "vslice": 16
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hslice": 16
                        }
                    ],
                    "attributes": {
                        "l1_acc": true,
                        "m_k": 2,
                        "min_buffer_input": 0,
                        "u_kt": 1
                    }
                },
                "_fused_op_86": {
                    "type": "fused_op",
                    "grid_loc": [
                        0,
                        6
                    ],
                    "grid_size": [
                        6,
                        1
                    ],
                    "inputs": [
                        "matmul_656",
                        "input_1_multiply_658",
                        "e2e_multiply_22_attempt_1_input_op_fork_nop1_0"
                    ],
                    "t": 16,
                    "mblock": [
                        2,
                        2
                    ],
                    "ublock": [
                        1,
                        6
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        48
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 12
                            }
                        },
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 16,
                        "kernel_broadcast": {
                            "input_1": 1
                        }
                    }
                },
                "softmax_660.dc.reduce_max.0": {
                    "type": "reduce",
                    "grid_loc": [
                        0,
                        7
                    ],
                    "grid_size": [
                        6,
                        1
                    ],
                    "inputs": [
                        "_fused_op_86"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        2,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "dim": "c",
                        "m_k": 1,
                        "type": "max",
                        "u_kt": 12
                    }
                }
            },
            "fwd_0_31_temporal_epoch_31": {
                "target_device": 0,
                "input_count": 1,
                "_fused_op_87": {
                    "type": "fused_op",
                    "grid_loc": [
                        0,
                        0
                    ],
                    "grid_size": [
                        2,
                        6
                    ],
                    "inputs": [
                        "e2e__fused_op_86_0",
                        "e2e_softmax_660.dc.reduce_max.0_0"
                    ],
                    "t": 16,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        3,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 32,
                    "input_dram_io_buf_size_tiles": [
                        24,
                        24
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 12
                            }
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 3
                    }
                },
                "softmax_660.dc.reduce_sum.3.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        6
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "_fused_op_87",
                        "lc.input_tensor.softmax_660.dc.reduce_sum.3.0"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 3,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_664": {
                    "type": "matmul",
                    "grid_loc": [
                        2,
                        1
                    ],
                    "grid_size": [
                        2,
                        4
                    ],
                    "inputs": [
                        "e2e__fused_op_85_0",
                        "bert.encoder.layer.12.attention.self.value.weight",
                        "bert.encoder.layer.12.attention.self.value.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 4,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                },
                "buffer_0_29742_29743": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        7
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "_fused_op_87"
                    ],
                    "t": 16,
                    "mblock": [
                        6,
                        2
                    ],
                    "ublock": [
                        1,
                        6
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        288
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_88": {
                    "type": "fused_op",
                    "grid_loc": [
                        2,
                        0
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "softmax_660.dc.reduce_sum.3.lc1",
                        "dc.input_tensor.softmax_660.4",
                        "buffer_0_29742_29743"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        12
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        96,
                        174
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 4
                    }
                },
                "matmul_671": {
                    "type": "matmul",
                    "grid_loc": [
                        2,
                        5
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "_fused_op_88",
                        "matmul_664"
                    ],
                    "t": 16,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        3,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 32,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "hslice": 16
                        }
                    ],
                    "attributes": {
                        "l1_acc": true,
                        "m_k": 2,
                        "min_buffer_input": 0,
                        "u_kt": 6
                    }
                },
                "matmul_675": {
                    "type": "matmul",
                    "grid_loc": [
                        4,
                        0
                    ],
                    "grid_size": [
                        2,
                        4
                    ],
                    "inputs": [
                        "matmul_671",
                        "bert.encoder.layer.12.attention.output.dense.weight",
                        "bert.encoder.layer.12.attention.output.dense.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 16
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 16,
                        "min_buffer_input": 0,
                        "u_kt": 2
                    }
                },
                "add_679": {
                    "type": "add",
                    "grid_loc": [
                        2,
                        6
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "matmul_675",
                        "e2e__fused_op_85_0"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        48
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "layernorm_680.dc.reduce_sum.0.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        2,
                        7
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "add_679",
                        "lc.input_tensor.layernorm_680.dc.reduce_sum.0.0"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_1_28448_29744": {
                    "type": "nop",
                    "grid_loc": [
                        4,
                        4
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "add_679"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_28448_29744": {
                    "type": "nop",
                    "grid_loc": [
                        4,
                        5
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "buffer_1_28448_29744"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_89": {
                    "type": "fused_op",
                    "grid_loc": [
                        4,
                        6
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_680.1",
                        "layernorm_680.dc.reduce_sum.0.lc1",
                        "buffer_0_28448_29744"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 32
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 5
                    }
                },
                "layernorm_680.dc.multiply.4": {
                    "type": "multiply",
                    "grid_loc": [
                        4,
                        7
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "_fused_op_89",
                        "_fused_op_89"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "layernorm_680.dc.reduce_sum.5.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        6,
                        0
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "layernorm_680.dc.multiply.4",
                        "lc.input_tensor.layernorm_680.dc.reduce_sum.5.0"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_2_29744_29745": {
                    "type": "nop",
                    "grid_loc": [
                        6,
                        1
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "_fused_op_89"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_1_29744_29745": {
                    "type": "nop",
                    "grid_loc": [
                        6,
                        2
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "buffer_2_29744_29745"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29744_29745": {
                    "type": "nop",
                    "grid_loc": [
                        6,
                        3
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29744_29745"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_90": {
                    "type": "fused_op",
                    "grid_loc": [
                        6,
                        4
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_680.6",
                        "layernorm_680.dc.reduce_sum.5.lc1",
                        "dc.input_tensor.layernorm_680.8",
                        "buffer_0_29744_29745",
                        "bert.encoder.layer.12.attention.output.LayerNorm.weight",
                        "bert.encoder.layer.12.attention.output.LayerNorm.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        32
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        6,
                        0,
                        6,
                        0,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0,
                        0,
                        24,
                        24
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_5_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_4_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 6
                    }
                },
                "matmul_683": {
                    "type": "matmul",
                    "grid_loc": [
                        8,
                        0
                    ],
                    "grid_size": [
                        2,
                        8
                    ],
                    "inputs": [
                        "_fused_op_90",
                        "bert.encoder.layer.12.intermediate.dense.weight",
                        "bert.encoder.layer.12.intermediate.dense.bias"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "hslice": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "hslice": 2
                        }
                    ],
                    "input_0_tms": [
                        {
                            "broadcast": {
                                "r": 2
                            }
                        },
                        {
                            "vslice": 2
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "gelu_686": {
                    "type": "gelu",
                    "grid_loc": [
                        6,
                        5
                    ],
                    "grid_size": [
                        2,
                        2
                    ],
                    "inputs": [
                        "matmul_683"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "approximate_mode": false
                    }
                }
            },
            "fwd_0_32_temporal_epoch_32": {
                "target_device": 0,
                "input_count": 1,
                "matmul_689": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        0
                    ],
                    "grid_size": [
                        3,
                        8
                    ],
                    "inputs": [
                        "e2e_gelu_686_0",
                        "bert.encoder.layer.12.output.dense.weight",
                        "bert.encoder.layer.12.output.dense.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        2,
                        4
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 4
                        },
                        "l1_acc": true,
                        "m_k": 16,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                },
                "add_693": {
                    "type": "add",
                    "grid_loc": [
                        3,
                        0
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "matmul_689",
                        "e2e__fused_op_90_0"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        48
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "layernorm_694.dc.reduce_sum.0.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        3,
                        1
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "add_693",
                        "lc.input_tensor.layernorm_694.dc.reduce_sum.0.0"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_1_28480_29746": {
                    "type": "nop",
                    "grid_loc": [
                        3,
                        2
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "add_693"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_28480_29746": {
                    "type": "nop",
                    "grid_loc": [
                        3,
                        3
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "buffer_1_28480_29746"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_91": {
                    "type": "fused_op",
                    "grid_loc": [
                        3,
                        4
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_694.1",
                        "layernorm_694.dc.reduce_sum.0.lc1",
                        "buffer_0_28480_29746"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        128,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 32
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 7
                    }
                },
                "layernorm_694.dc.multiply.4": {
                    "type": "multiply",
                    "grid_loc": [
                        3,
                        5
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "_fused_op_91",
                        "_fused_op_91"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "layernorm_694.dc.reduce_sum.5.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        3,
                        6
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "layernorm_694.dc.multiply.4",
                        "lc.input_tensor.layernorm_694.dc.reduce_sum.5.0"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_1_29746_29747": {
                    "type": "nop",
                    "grid_loc": [
                        3,
                        7
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "_fused_op_91"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        176
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29746_29747": {
                    "type": "nop",
                    "grid_loc": [
                        6,
                        0
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29746_29747"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        176
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_92": {
                    "type": "fused_op",
                    "grid_loc": [
                        6,
                        1
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_694.6",
                        "layernorm_694.dc.reduce_sum.5.lc1",
                        "dc.input_tensor.layernorm_694.8",
                        "buffer_0_29746_29747",
                        "bert.encoder.layer.12.output.LayerNorm.weight",
                        "bert.encoder.layer.12.output.LayerNorm.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        32
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        4,
                        0,
                        4,
                        0,
                        128,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0,
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_5_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_4_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 8
                    }
                },
                "matmul_697": {
                    "type": "matmul",
                    "grid_loc": [
                        6,
                        2
                    ],
                    "grid_size": [
                        3,
                        4
                    ],
                    "inputs": [
                        "_fused_op_92",
                        "bert.encoder.layer.13.attention.self.query.weight",
                        "bert.encoder.layer.13.attention.self.query.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 4,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                }
            },
            "fwd_0_33_temporal_epoch_33": {
                "target_device": 0,
                "input_count": 1,
                "matmul_703": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        0
                    ],
                    "grid_size": [
                        3,
                        4
                    ],
                    "inputs": [
                        "e2e__fused_op_92_0",
                        "bert.encoder.layer.13.attention.self.key.weight",
                        "bert.encoder.layer.13.attention.self.key.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 4,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                },
                "matmul_709": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        4
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "e2e_matmul_697_0",
                        "matmul_703"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        6
                    ],
                    "ublock": [
                        4,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        "transpose",
                        {
                            "vslice": 16
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hslice": 16
                        }
                    ],
                    "attributes": {
                        "l1_acc": true,
                        "m_k": 2,
                        "min_buffer_input": 0,
                        "u_kt": 1
                    }
                },
                "_fused_op_93": {
                    "type": "fused_op",
                    "grid_loc": [
                        0,
                        5
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "matmul_709",
                        "input_1_multiply_711",
                        "e2e_multiply_22_attempt_1_input_op_fork_nop1_0"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        6
                    ],
                    "ublock": [
                        4,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        48
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 12
                            }
                        },
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 9,
                        "kernel_broadcast": {
                            "input_1": 1
                        }
                    }
                },
                "softmax_713.dc.reduce_max.0": {
                    "type": "reduce",
                    "grid_loc": [
                        0,
                        6
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "_fused_op_93"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "dim": "c",
                        "m_k": 1,
                        "type": "max",
                        "u_kt": 12
                    }
                },
                "_fused_op_94": {
                    "type": "fused_op",
                    "grid_loc": [
                        3,
                        0
                    ],
                    "grid_size": [
                        3,
                        6
                    ],
                    "inputs": [
                        "_fused_op_93",
                        "softmax_713.dc.reduce_max.0"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        400,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 12
                            }
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 10
                    }
                },
                "softmax_713.dc.reduce_sum.3.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        7
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "_fused_op_94",
                        "lc.input_tensor.softmax_713.dc.reduce_sum.3.0"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 3,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_717": {
                    "type": "matmul",
                    "grid_loc": [
                        6,
                        0
                    ],
                    "grid_size": [
                        3,
                        4
                    ],
                    "inputs": [
                        "e2e__fused_op_92_0",
                        "bert.encoder.layer.13.attention.self.value.weight",
                        "bert.encoder.layer.13.attention.self.value.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 4,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                },
                "_fused_op_95": {
                    "type": "fused_op",
                    "grid_loc": [
                        3,
                        6
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "softmax_713.dc.reduce_sum.3.lc1",
                        "dc.input_tensor.softmax_713.4",
                        "_fused_op_94"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        12
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        64,
                        260
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 11
                    }
                },
                "matmul_724": {
                    "type": "matmul",
                    "grid_loc": [
                        3,
                        7
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "_fused_op_95",
                        "matmul_717"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 32,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "hslice": 16
                        }
                    ],
                    "attributes": {
                        "l1_acc": true,
                        "m_k": 3,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_728": {
                    "type": "matmul",
                    "grid_loc": [
                        6,
                        4
                    ],
                    "grid_size": [
                        2,
                        4
                    ],
                    "inputs": [
                        "matmul_724",
                        "bert.encoder.layer.13.attention.output.dense.weight",
                        "bert.encoder.layer.13.attention.output.dense.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 16
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 16,
                        "min_buffer_input": 0,
                        "u_kt": 2
                    }
                }
            },
            "fwd_0_34_temporal_epoch_34": {
                "target_device": 0,
                "input_count": 1,
                "add_732": {
                    "type": "add",
                    "grid_loc": [
                        0,
                        0
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "e2e_matmul_728_0",
                        "e2e__fused_op_92_0"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        24,
                        24
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "hslice": 2
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hslice": 2
                        }
                    ]
                },
                "layernorm_733.dc.reduce_sum.0.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        1
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "add_732",
                        "lc.input_tensor.layernorm_733.dc.reduce_sum.0.0"
                    ],
                    "t": 1,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_3_28552_29751": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        2
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "add_732"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_2_28552_29751": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        3
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_3_28552_29751"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_1_28552_29751": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        4
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_2_28552_29751"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_28552_29751": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        5
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_1_28552_29751"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_96": {
                    "type": "fused_op",
                    "grid_loc": [
                        0,
                        6
                    ],
                    "grid_size": [
                        1,
                        2
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_733.1",
                        "layernorm_733.dc.reduce_sum.0.lc1",
                        "buffer_0_28552_29751"
                    ],
                    "t": 1,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 32
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 12
                    }
                },
                "layernorm_733.dc.multiply.4": {
                    "type": "multiply",
                    "grid_loc": [
                        1,
                        0
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "_fused_op_96",
                        "_fused_op_96"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "vslice": 2
                        }
                    ],
                    "input_0_tms": [
                        {
                            "vslice": 2
                        }
                    ]
                },
                "layernorm_733.dc.reduce_sum.5.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        1,
                        1
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "layernorm_733.dc.multiply.4",
                        "lc.input_tensor.layernorm_733.dc.reduce_sum.5.0"
                    ],
                    "t": 2,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 2
                            }
                        },
                        {
                            "broadcast": {
                                "r": 32
                            }
                        },
                        {
                            "hslice": 2
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_4_29751_29752": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        2
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "_fused_op_96"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_0_tms": [
                        {
                            "vslice": 2
                        }
                    ]
                },
                "buffer_3_29751_29752": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        3
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_4_29751_29752"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_2_29751_29752": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        4
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_3_29751_29752"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_1_29751_29752": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        5
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_2_29751_29752"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29751_29752": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        6
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29751_29752"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_97": {
                    "type": "fused_op",
                    "grid_loc": [
                        1,
                        7
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_733.6",
                        "layernorm_733.dc.reduce_sum.5.lc1",
                        "dc.input_tensor.layernorm_733.8",
                        "buffer_0_29751_29752",
                        "bert.encoder.layer.13.attention.output.LayerNorm.weight",
                        "bert.encoder.layer.13.attention.output.LayerNorm.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        32
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        6,
                        0,
                        6,
                        0,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0,
                        0,
                        24,
                        24
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_5_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_4_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_3_tms": [
                        {
                            "vstack": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "vstack": 2
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 6
                    }
                },
                "matmul_736": {
                    "type": "matmul",
                    "grid_loc": [
                        3,
                        0
                    ],
                    "grid_size": [
                        2,
                        8
                    ],
                    "inputs": [
                        "_fused_op_97",
                        "bert.encoder.layer.13.intermediate.dense.weight",
                        "bert.encoder.layer.13.intermediate.dense.bias"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "hslice": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "hslice": 2
                        }
                    ],
                    "input_0_tms": [
                        {
                            "broadcast": {
                                "r": 2
                            }
                        },
                        {
                            "vslice": 2
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "gelu_739": {
                    "type": "gelu",
                    "grid_loc": [
                        2,
                        0
                    ],
                    "grid_size": [
                        1,
                        4
                    ],
                    "inputs": [
                        "matmul_736"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "approximate_mode": false
                    }
                },
                "matmul_742": {
                    "type": "matmul",
                    "grid_loc": [
                        5,
                        0
                    ],
                    "grid_size": [
                        2,
                        8
                    ],
                    "inputs": [
                        "gelu_739",
                        "bert.encoder.layer.13.output.dense.weight",
                        "bert.encoder.layer.13.output.dense.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        3,
                        1
                    ],
                    "ublock": [
                        2,
                        4
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 4
                        },
                        "l1_acc": true,
                        "m_k": 16,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                },
                "buffer_7_29752_28584": {
                    "type": "nop",
                    "grid_loc": [
                        2,
                        4
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "_fused_op_97"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_0_tms": [
                        {
                            "hslice": 2
                        }
                    ]
                },
                "buffer_6_29752_28584": {
                    "type": "nop",
                    "grid_loc": [
                        2,
                        5
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_7_29752_28584"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_5_29752_28584": {
                    "type": "nop",
                    "grid_loc": [
                        2,
                        6
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_6_29752_28584"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_4_29752_28584": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        0
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_5_29752_28584"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_3_29752_28584": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        1
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_4_29752_28584"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_2_29752_28584": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        2
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_3_29752_28584"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_1_29752_28584": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        3
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_2_29752_28584"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29752_28584": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        4
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29752_28584"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "add_746": {
                    "type": "add",
                    "grid_loc": [
                        7,
                        5
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "matmul_742",
                        "buffer_0_29752_28584"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_0_tms": [
                        {
                            "hslice": 2
                        }
                    ]
                },
                "layernorm_747.dc.reduce_sum.0.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        7,
                        6
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "add_746",
                        "lc.input_tensor.layernorm_747.dc.reduce_sum.0.0"
                    ],
                    "t": 1,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_3_28584_29753": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        7
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "add_746"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_2_28584_29753": {
                    "type": "nop",
                    "grid_loc": [
                        8,
                        0
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_3_28584_29753"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_1_28584_29753": {
                    "type": "nop",
                    "grid_loc": [
                        8,
                        1
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_2_28584_29753"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_28584_29753": {
                    "type": "nop",
                    "grid_loc": [
                        8,
                        2
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_1_28584_29753"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_98": {
                    "type": "fused_op",
                    "grid_loc": [
                        8,
                        3
                    ],
                    "grid_size": [
                        1,
                        2
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_747.1",
                        "layernorm_747.dc.reduce_sum.0.lc1",
                        "buffer_0_28584_29753"
                    ],
                    "t": 1,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 32
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 12
                    }
                },
                "layernorm_747.dc.multiply.4": {
                    "type": "multiply",
                    "grid_loc": [
                        8,
                        5
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "_fused_op_98",
                        "_fused_op_98"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "vslice": 2
                        }
                    ],
                    "input_0_tms": [
                        {
                            "vslice": 2
                        }
                    ]
                },
                "layernorm_747.dc.reduce_sum.5.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        8,
                        6
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "layernorm_747.dc.multiply.4",
                        "lc.input_tensor.layernorm_747.dc.reduce_sum.5.0"
                    ],
                    "t": 2,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 2
                            }
                        },
                        {
                            "broadcast": {
                                "r": 32
                            }
                        },
                        {
                            "hslice": 2
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                }
            },
            "fwd_0_35_temporal_epoch_35": {
                "target_device": 0,
                "input_count": 1,
                "_fused_op_99": {
                    "type": "fused_op",
                    "grid_loc": [
                        0,
                        0
                    ],
                    "grid_size": [
                        6,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_747.6",
                        "e2e_layernorm_747.dc.reduce_sum.5.lc1_0",
                        "dc.input_tensor.layernorm_747.8",
                        "e2e__fused_op_98_0",
                        "bert.encoder.layer.13.output.LayerNorm.weight",
                        "bert.encoder.layer.13.output.LayerNorm.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        32
                    ],
                    "ublock": [
                        2,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        2,
                        0,
                        2,
                        0,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        24,
                        0,
                        24,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_5_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_4_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_1_tms": [
                        {
                            "vstack": 2
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 15,
                        "kernel_broadcast": {
                            "input_5": 64,
                            "input_4": 64
                        }
                    }
                },
                "matmul_750": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        1
                    ],
                    "grid_size": [
                        6,
                        2
                    ],
                    "inputs": [
                        "_fused_op_99",
                        "bert.encoder.layer.14.attention.self.query.weight",
                        "bert.encoder.layer.14.attention.self.query.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        2,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        96,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 16
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_756": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        3
                    ],
                    "grid_size": [
                        6,
                        2
                    ],
                    "inputs": [
                        "_fused_op_99",
                        "bert.encoder.layer.14.attention.self.key.weight",
                        "bert.encoder.layer.14.attention.self.key.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        2,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 16
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_762": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        5
                    ],
                    "grid_size": [
                        6,
                        1
                    ],
                    "inputs": [
                        "matmul_750",
                        "matmul_756"
                    ],
                    "t": 16,
                    "mblock": [
                        2,
                        2
                    ],
                    "ublock": [
                        1,
                        6
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        363,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        "transpose",
                        {
                            "vslice": 16
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hslice": 16
                        }
                    ],
                    "attributes": {
                        "l1_acc": true,
                        "m_k": 2,
                        "min_buffer_input": 0,
                        "u_kt": 1
                    }
                },
                "_fused_op_100": {
                    "type": "fused_op",
                    "grid_loc": [
                        0,
                        6
                    ],
                    "grid_size": [
                        6,
                        1
                    ],
                    "inputs": [
                        "matmul_762",
                        "input_1_multiply_764",
                        "e2e_multiply_22_attempt_1_input_op_fork_nop1_0"
                    ],
                    "t": 16,
                    "mblock": [
                        2,
                        2
                    ],
                    "ublock": [
                        1,
                        6
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        48
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 12
                            }
                        },
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 16,
                        "kernel_broadcast": {
                            "input_1": 1
                        }
                    }
                },
                "softmax_766.dc.reduce_max.0": {
                    "type": "reduce",
                    "grid_loc": [
                        0,
                        7
                    ],
                    "grid_size": [
                        6,
                        1
                    ],
                    "inputs": [
                        "_fused_op_100"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        2,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "dim": "c",
                        "m_k": 1,
                        "type": "max",
                        "u_kt": 12
                    }
                }
            },
            "fwd_0_36_temporal_epoch_36": {
                "target_device": 0,
                "input_count": 1,
                "_fused_op_101": {
                    "type": "fused_op",
                    "grid_loc": [
                        0,
                        0
                    ],
                    "grid_size": [
                        2,
                        6
                    ],
                    "inputs": [
                        "e2e__fused_op_100_0",
                        "e2e_softmax_766.dc.reduce_max.0_0"
                    ],
                    "t": 16,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        3,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 32,
                    "input_dram_io_buf_size_tiles": [
                        24,
                        24
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 12
                            }
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 3
                    }
                },
                "softmax_766.dc.reduce_sum.3.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        6
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "_fused_op_101",
                        "lc.input_tensor.softmax_766.dc.reduce_sum.3.0"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 3,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_770": {
                    "type": "matmul",
                    "grid_loc": [
                        2,
                        1
                    ],
                    "grid_size": [
                        2,
                        4
                    ],
                    "inputs": [
                        "e2e__fused_op_99_0",
                        "bert.encoder.layer.14.attention.self.value.weight",
                        "bert.encoder.layer.14.attention.self.value.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 4,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                },
                "buffer_0_29756_29757": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        7
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "_fused_op_101"
                    ],
                    "t": 16,
                    "mblock": [
                        6,
                        2
                    ],
                    "ublock": [
                        1,
                        6
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        288
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_102": {
                    "type": "fused_op",
                    "grid_loc": [
                        2,
                        0
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "softmax_766.dc.reduce_sum.3.lc1",
                        "dc.input_tensor.softmax_766.4",
                        "buffer_0_29756_29757"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        12
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        96,
                        174
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 4
                    }
                },
                "matmul_777": {
                    "type": "matmul",
                    "grid_loc": [
                        2,
                        5
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "_fused_op_102",
                        "matmul_770"
                    ],
                    "t": 16,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        3,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 32,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "hslice": 16
                        }
                    ],
                    "attributes": {
                        "l1_acc": true,
                        "m_k": 2,
                        "min_buffer_input": 0,
                        "u_kt": 6
                    }
                },
                "matmul_781": {
                    "type": "matmul",
                    "grid_loc": [
                        4,
                        0
                    ],
                    "grid_size": [
                        2,
                        4
                    ],
                    "inputs": [
                        "matmul_777",
                        "bert.encoder.layer.14.attention.output.dense.weight",
                        "bert.encoder.layer.14.attention.output.dense.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 16
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 16,
                        "min_buffer_input": 0,
                        "u_kt": 2
                    }
                },
                "add_785": {
                    "type": "add",
                    "grid_loc": [
                        2,
                        6
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "matmul_781",
                        "e2e__fused_op_99_0"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        48
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "layernorm_786.dc.reduce_sum.0.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        2,
                        7
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "add_785",
                        "lc.input_tensor.layernorm_786.dc.reduce_sum.0.0"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_1_28656_29758": {
                    "type": "nop",
                    "grid_loc": [
                        4,
                        4
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "add_785"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_28656_29758": {
                    "type": "nop",
                    "grid_loc": [
                        4,
                        5
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "buffer_1_28656_29758"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_103": {
                    "type": "fused_op",
                    "grid_loc": [
                        4,
                        6
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_786.1",
                        "layernorm_786.dc.reduce_sum.0.lc1",
                        "buffer_0_28656_29758"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 32
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 5
                    }
                },
                "layernorm_786.dc.multiply.4": {
                    "type": "multiply",
                    "grid_loc": [
                        4,
                        7
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "_fused_op_103",
                        "_fused_op_103"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "layernorm_786.dc.reduce_sum.5.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        6,
                        0
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "layernorm_786.dc.multiply.4",
                        "lc.input_tensor.layernorm_786.dc.reduce_sum.5.0"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_2_29758_29759": {
                    "type": "nop",
                    "grid_loc": [
                        6,
                        1
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "_fused_op_103"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_1_29758_29759": {
                    "type": "nop",
                    "grid_loc": [
                        6,
                        2
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "buffer_2_29758_29759"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29758_29759": {
                    "type": "nop",
                    "grid_loc": [
                        6,
                        3
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29758_29759"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_104": {
                    "type": "fused_op",
                    "grid_loc": [
                        6,
                        4
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_786.6",
                        "layernorm_786.dc.reduce_sum.5.lc1",
                        "dc.input_tensor.layernorm_786.8",
                        "buffer_0_29758_29759",
                        "bert.encoder.layer.14.attention.output.LayerNorm.weight",
                        "bert.encoder.layer.14.attention.output.LayerNorm.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        32
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        6,
                        0,
                        6,
                        0,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0,
                        0,
                        24,
                        24
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_5_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_4_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 6
                    }
                },
                "matmul_789": {
                    "type": "matmul",
                    "grid_loc": [
                        8,
                        0
                    ],
                    "grid_size": [
                        2,
                        8
                    ],
                    "inputs": [
                        "_fused_op_104",
                        "bert.encoder.layer.14.intermediate.dense.weight",
                        "bert.encoder.layer.14.intermediate.dense.bias"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "hslice": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "hslice": 2
                        }
                    ],
                    "input_0_tms": [
                        {
                            "broadcast": {
                                "r": 2
                            }
                        },
                        {
                            "vslice": 2
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "gelu_792": {
                    "type": "gelu",
                    "grid_loc": [
                        6,
                        5
                    ],
                    "grid_size": [
                        2,
                        2
                    ],
                    "inputs": [
                        "matmul_789"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "approximate_mode": false
                    }
                }
            },
            "fwd_0_37_temporal_epoch_37": {
                "target_device": 0,
                "input_count": 1,
                "matmul_795": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        0
                    ],
                    "grid_size": [
                        3,
                        8
                    ],
                    "inputs": [
                        "e2e_gelu_792_0",
                        "bert.encoder.layer.14.output.dense.weight",
                        "bert.encoder.layer.14.output.dense.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        2,
                        4
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 4
                        },
                        "l1_acc": true,
                        "m_k": 16,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                },
                "add_799": {
                    "type": "add",
                    "grid_loc": [
                        3,
                        0
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "matmul_795",
                        "e2e__fused_op_104_0"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        48
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "layernorm_800.dc.reduce_sum.0.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        3,
                        1
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "add_799",
                        "lc.input_tensor.layernorm_800.dc.reduce_sum.0.0"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_1_28688_29760": {
                    "type": "nop",
                    "grid_loc": [
                        3,
                        2
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "add_799"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_28688_29760": {
                    "type": "nop",
                    "grid_loc": [
                        3,
                        3
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "buffer_1_28688_29760"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_105": {
                    "type": "fused_op",
                    "grid_loc": [
                        3,
                        4
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_800.1",
                        "layernorm_800.dc.reduce_sum.0.lc1",
                        "buffer_0_28688_29760"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        128,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 32
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 7
                    }
                },
                "layernorm_800.dc.multiply.4": {
                    "type": "multiply",
                    "grid_loc": [
                        3,
                        5
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "_fused_op_105",
                        "_fused_op_105"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "layernorm_800.dc.reduce_sum.5.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        3,
                        6
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "layernorm_800.dc.multiply.4",
                        "lc.input_tensor.layernorm_800.dc.reduce_sum.5.0"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_1_29760_29761": {
                    "type": "nop",
                    "grid_loc": [
                        3,
                        7
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "_fused_op_105"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        176
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29760_29761": {
                    "type": "nop",
                    "grid_loc": [
                        6,
                        0
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29760_29761"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        176
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_106": {
                    "type": "fused_op",
                    "grid_loc": [
                        6,
                        1
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_800.6",
                        "layernorm_800.dc.reduce_sum.5.lc1",
                        "dc.input_tensor.layernorm_800.8",
                        "buffer_0_29760_29761",
                        "bert.encoder.layer.14.output.LayerNorm.weight",
                        "bert.encoder.layer.14.output.LayerNorm.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        32
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        4,
                        0,
                        4,
                        0,
                        128,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0,
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_5_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_4_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 8
                    }
                },
                "matmul_803": {
                    "type": "matmul",
                    "grid_loc": [
                        6,
                        2
                    ],
                    "grid_size": [
                        3,
                        4
                    ],
                    "inputs": [
                        "_fused_op_106",
                        "bert.encoder.layer.15.attention.self.query.weight",
                        "bert.encoder.layer.15.attention.self.query.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 4,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                }
            },
            "fwd_0_38_temporal_epoch_38": {
                "target_device": 0,
                "input_count": 1,
                "matmul_809": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        0
                    ],
                    "grid_size": [
                        3,
                        4
                    ],
                    "inputs": [
                        "e2e__fused_op_106_0",
                        "bert.encoder.layer.15.attention.self.key.weight",
                        "bert.encoder.layer.15.attention.self.key.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 4,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                },
                "matmul_815": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        4
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "e2e_matmul_803_0",
                        "matmul_809"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        6
                    ],
                    "ublock": [
                        4,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        "transpose",
                        {
                            "vslice": 16
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hslice": 16
                        }
                    ],
                    "attributes": {
                        "l1_acc": true,
                        "m_k": 2,
                        "min_buffer_input": 0,
                        "u_kt": 1
                    }
                },
                "_fused_op_107": {
                    "type": "fused_op",
                    "grid_loc": [
                        0,
                        5
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "matmul_815",
                        "input_1_multiply_817",
                        "e2e_multiply_22_attempt_1_input_op_fork_nop1_0"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        6
                    ],
                    "ublock": [
                        4,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        48
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 12
                            }
                        },
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 9,
                        "kernel_broadcast": {
                            "input_1": 1
                        }
                    }
                },
                "softmax_819.dc.reduce_max.0": {
                    "type": "reduce",
                    "grid_loc": [
                        0,
                        6
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "_fused_op_107"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "dim": "c",
                        "m_k": 1,
                        "type": "max",
                        "u_kt": 12
                    }
                },
                "_fused_op_108": {
                    "type": "fused_op",
                    "grid_loc": [
                        3,
                        0
                    ],
                    "grid_size": [
                        3,
                        6
                    ],
                    "inputs": [
                        "_fused_op_107",
                        "softmax_819.dc.reduce_max.0"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        400,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 12
                            }
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 10
                    }
                },
                "softmax_819.dc.reduce_sum.3.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        7
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "_fused_op_108",
                        "lc.input_tensor.softmax_819.dc.reduce_sum.3.0"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 3,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_823": {
                    "type": "matmul",
                    "grid_loc": [
                        6,
                        0
                    ],
                    "grid_size": [
                        3,
                        4
                    ],
                    "inputs": [
                        "e2e__fused_op_106_0",
                        "bert.encoder.layer.15.attention.self.value.weight",
                        "bert.encoder.layer.15.attention.self.value.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 4,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                },
                "_fused_op_109": {
                    "type": "fused_op",
                    "grid_loc": [
                        3,
                        6
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "softmax_819.dc.reduce_sum.3.lc1",
                        "dc.input_tensor.softmax_819.4",
                        "_fused_op_108"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        12
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        64,
                        260
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 11
                    }
                },
                "matmul_830": {
                    "type": "matmul",
                    "grid_loc": [
                        3,
                        7
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "_fused_op_109",
                        "matmul_823"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 32,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "hslice": 16
                        }
                    ],
                    "attributes": {
                        "l1_acc": true,
                        "m_k": 3,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_834": {
                    "type": "matmul",
                    "grid_loc": [
                        6,
                        4
                    ],
                    "grid_size": [
                        2,
                        4
                    ],
                    "inputs": [
                        "matmul_830",
                        "bert.encoder.layer.15.attention.output.dense.weight",
                        "bert.encoder.layer.15.attention.output.dense.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 16
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 16,
                        "min_buffer_input": 0,
                        "u_kt": 2
                    }
                }
            },
            "fwd_0_39_temporal_epoch_39": {
                "target_device": 0,
                "input_count": 1,
                "add_838": {
                    "type": "add",
                    "grid_loc": [
                        0,
                        0
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "e2e_matmul_834_0",
                        "e2e__fused_op_106_0"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        24,
                        24
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "hslice": 2
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hslice": 2
                        }
                    ]
                },
                "layernorm_839.dc.reduce_sum.0.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        1
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "add_838",
                        "lc.input_tensor.layernorm_839.dc.reduce_sum.0.0"
                    ],
                    "t": 1,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_3_28760_29765": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        2
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "add_838"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_2_28760_29765": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        3
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_3_28760_29765"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_1_28760_29765": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        4
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_2_28760_29765"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_28760_29765": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        5
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_1_28760_29765"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_110": {
                    "type": "fused_op",
                    "grid_loc": [
                        0,
                        6
                    ],
                    "grid_size": [
                        1,
                        2
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_839.1",
                        "layernorm_839.dc.reduce_sum.0.lc1",
                        "buffer_0_28760_29765"
                    ],
                    "t": 1,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 32
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 12
                    }
                },
                "layernorm_839.dc.multiply.4": {
                    "type": "multiply",
                    "grid_loc": [
                        1,
                        0
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "_fused_op_110",
                        "_fused_op_110"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "vslice": 2
                        }
                    ],
                    "input_0_tms": [
                        {
                            "vslice": 2
                        }
                    ]
                },
                "layernorm_839.dc.reduce_sum.5.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        1,
                        1
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "layernorm_839.dc.multiply.4",
                        "lc.input_tensor.layernorm_839.dc.reduce_sum.5.0"
                    ],
                    "t": 2,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 2
                            }
                        },
                        {
                            "broadcast": {
                                "r": 32
                            }
                        },
                        {
                            "hslice": 2
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_4_29765_29766": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        2
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "_fused_op_110"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_0_tms": [
                        {
                            "vslice": 2
                        }
                    ]
                },
                "buffer_3_29765_29766": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        3
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_4_29765_29766"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_2_29765_29766": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        4
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_3_29765_29766"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_1_29765_29766": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        5
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_2_29765_29766"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29765_29766": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        6
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29765_29766"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_111": {
                    "type": "fused_op",
                    "grid_loc": [
                        1,
                        7
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_839.6",
                        "layernorm_839.dc.reduce_sum.5.lc1",
                        "dc.input_tensor.layernorm_839.8",
                        "buffer_0_29765_29766",
                        "bert.encoder.layer.15.attention.output.LayerNorm.weight",
                        "bert.encoder.layer.15.attention.output.LayerNorm.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        32
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        6,
                        0,
                        6,
                        0,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0,
                        0,
                        24,
                        24
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_5_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_4_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_3_tms": [
                        {
                            "vstack": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "vstack": 2
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 6
                    }
                },
                "matmul_842": {
                    "type": "matmul",
                    "grid_loc": [
                        3,
                        0
                    ],
                    "grid_size": [
                        2,
                        8
                    ],
                    "inputs": [
                        "_fused_op_111",
                        "bert.encoder.layer.15.intermediate.dense.weight",
                        "bert.encoder.layer.15.intermediate.dense.bias"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "hslice": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "hslice": 2
                        }
                    ],
                    "input_0_tms": [
                        {
                            "broadcast": {
                                "r": 2
                            }
                        },
                        {
                            "vslice": 2
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "gelu_845": {
                    "type": "gelu",
                    "grid_loc": [
                        2,
                        0
                    ],
                    "grid_size": [
                        1,
                        4
                    ],
                    "inputs": [
                        "matmul_842"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "approximate_mode": false
                    }
                },
                "matmul_848": {
                    "type": "matmul",
                    "grid_loc": [
                        5,
                        0
                    ],
                    "grid_size": [
                        2,
                        8
                    ],
                    "inputs": [
                        "gelu_845",
                        "bert.encoder.layer.15.output.dense.weight",
                        "bert.encoder.layer.15.output.dense.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        3,
                        1
                    ],
                    "ublock": [
                        2,
                        4
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 4
                        },
                        "l1_acc": true,
                        "m_k": 16,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                },
                "buffer_7_29766_28792": {
                    "type": "nop",
                    "grid_loc": [
                        2,
                        4
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "_fused_op_111"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_0_tms": [
                        {
                            "hslice": 2
                        }
                    ]
                },
                "buffer_6_29766_28792": {
                    "type": "nop",
                    "grid_loc": [
                        2,
                        5
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_7_29766_28792"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_5_29766_28792": {
                    "type": "nop",
                    "grid_loc": [
                        2,
                        6
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_6_29766_28792"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_4_29766_28792": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        0
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_5_29766_28792"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_3_29766_28792": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        1
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_4_29766_28792"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_2_29766_28792": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        2
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_3_29766_28792"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_1_29766_28792": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        3
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_2_29766_28792"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29766_28792": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        4
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29766_28792"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "add_852": {
                    "type": "add",
                    "grid_loc": [
                        7,
                        5
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "matmul_848",
                        "buffer_0_29766_28792"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_0_tms": [
                        {
                            "hslice": 2
                        }
                    ]
                },
                "layernorm_853.dc.reduce_sum.0.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        7,
                        6
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "add_852",
                        "lc.input_tensor.layernorm_853.dc.reduce_sum.0.0"
                    ],
                    "t": 1,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_3_28792_29767": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        7
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "add_852"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_2_28792_29767": {
                    "type": "nop",
                    "grid_loc": [
                        8,
                        0
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_3_28792_29767"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_1_28792_29767": {
                    "type": "nop",
                    "grid_loc": [
                        8,
                        1
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_2_28792_29767"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_28792_29767": {
                    "type": "nop",
                    "grid_loc": [
                        8,
                        2
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_1_28792_29767"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_112": {
                    "type": "fused_op",
                    "grid_loc": [
                        8,
                        3
                    ],
                    "grid_size": [
                        1,
                        2
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_853.1",
                        "layernorm_853.dc.reduce_sum.0.lc1",
                        "buffer_0_28792_29767"
                    ],
                    "t": 1,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 32
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 12
                    }
                },
                "layernorm_853.dc.multiply.4": {
                    "type": "multiply",
                    "grid_loc": [
                        8,
                        5
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "_fused_op_112",
                        "_fused_op_112"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "vslice": 2
                        }
                    ],
                    "input_0_tms": [
                        {
                            "vslice": 2
                        }
                    ]
                },
                "layernorm_853.dc.reduce_sum.5.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        8,
                        6
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "layernorm_853.dc.multiply.4",
                        "lc.input_tensor.layernorm_853.dc.reduce_sum.5.0"
                    ],
                    "t": 2,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 2
                            }
                        },
                        {
                            "broadcast": {
                                "r": 32
                            }
                        },
                        {
                            "hslice": 2
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                }
            },
            "fwd_0_40_temporal_epoch_40": {
                "target_device": 0,
                "input_count": 1,
                "_fused_op_113": {
                    "type": "fused_op",
                    "grid_loc": [
                        0,
                        0
                    ],
                    "grid_size": [
                        6,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_853.6",
                        "e2e_layernorm_853.dc.reduce_sum.5.lc1_0",
                        "dc.input_tensor.layernorm_853.8",
                        "e2e__fused_op_112_0",
                        "bert.encoder.layer.15.output.LayerNorm.weight",
                        "bert.encoder.layer.15.output.LayerNorm.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        32
                    ],
                    "ublock": [
                        2,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        2,
                        0,
                        2,
                        0,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        24,
                        0,
                        24,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_5_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_4_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_1_tms": [
                        {
                            "vstack": 2
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 15,
                        "kernel_broadcast": {
                            "input_5": 64,
                            "input_4": 64
                        }
                    }
                },
                "matmul_856": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        1
                    ],
                    "grid_size": [
                        6,
                        2
                    ],
                    "inputs": [
                        "_fused_op_113",
                        "bert.encoder.layer.16.attention.self.query.weight",
                        "bert.encoder.layer.16.attention.self.query.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        2,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        96,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 16
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_862": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        3
                    ],
                    "grid_size": [
                        6,
                        2
                    ],
                    "inputs": [
                        "_fused_op_113",
                        "bert.encoder.layer.16.attention.self.key.weight",
                        "bert.encoder.layer.16.attention.self.key.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        2,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 16
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_868": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        5
                    ],
                    "grid_size": [
                        6,
                        1
                    ],
                    "inputs": [
                        "matmul_856",
                        "matmul_862"
                    ],
                    "t": 16,
                    "mblock": [
                        2,
                        2
                    ],
                    "ublock": [
                        1,
                        6
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        363,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        "transpose",
                        {
                            "vslice": 16
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hslice": 16
                        }
                    ],
                    "attributes": {
                        "l1_acc": true,
                        "m_k": 2,
                        "min_buffer_input": 0,
                        "u_kt": 1
                    }
                },
                "_fused_op_114": {
                    "type": "fused_op",
                    "grid_loc": [
                        0,
                        6
                    ],
                    "grid_size": [
                        6,
                        1
                    ],
                    "inputs": [
                        "matmul_868",
                        "input_1_multiply_870",
                        "e2e_multiply_22_attempt_1_input_op_fork_nop2_0"
                    ],
                    "t": 16,
                    "mblock": [
                        2,
                        2
                    ],
                    "ublock": [
                        1,
                        6
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        48
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 12
                            }
                        },
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 16,
                        "kernel_broadcast": {
                            "input_1": 1
                        }
                    }
                },
                "softmax_872.dc.reduce_max.0": {
                    "type": "reduce",
                    "grid_loc": [
                        0,
                        7
                    ],
                    "grid_size": [
                        6,
                        1
                    ],
                    "inputs": [
                        "_fused_op_114"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        2,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "dim": "c",
                        "m_k": 1,
                        "type": "max",
                        "u_kt": 12
                    }
                }
            },
            "fwd_0_41_temporal_epoch_41": {
                "target_device": 0,
                "input_count": 1,
                "_fused_op_115": {
                    "type": "fused_op",
                    "grid_loc": [
                        0,
                        0
                    ],
                    "grid_size": [
                        2,
                        6
                    ],
                    "inputs": [
                        "e2e__fused_op_114_0",
                        "e2e_softmax_872.dc.reduce_max.0_0"
                    ],
                    "t": 16,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        3,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 32,
                    "input_dram_io_buf_size_tiles": [
                        24,
                        24
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 12
                            }
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 3
                    }
                },
                "softmax_872.dc.reduce_sum.3.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        6
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "_fused_op_115",
                        "lc.input_tensor.softmax_872.dc.reduce_sum.3.0"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 3,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_876": {
                    "type": "matmul",
                    "grid_loc": [
                        2,
                        1
                    ],
                    "grid_size": [
                        2,
                        4
                    ],
                    "inputs": [
                        "e2e__fused_op_113_0",
                        "bert.encoder.layer.16.attention.self.value.weight",
                        "bert.encoder.layer.16.attention.self.value.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 4,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                },
                "buffer_0_29770_29771": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        7
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "_fused_op_115"
                    ],
                    "t": 16,
                    "mblock": [
                        6,
                        2
                    ],
                    "ublock": [
                        1,
                        6
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        288
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_116": {
                    "type": "fused_op",
                    "grid_loc": [
                        2,
                        0
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "softmax_872.dc.reduce_sum.3.lc1",
                        "dc.input_tensor.softmax_872.4",
                        "buffer_0_29770_29771"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        12
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        96,
                        174
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 4
                    }
                },
                "matmul_883": {
                    "type": "matmul",
                    "grid_loc": [
                        2,
                        5
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "_fused_op_116",
                        "matmul_876"
                    ],
                    "t": 16,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        3,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 32,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "hslice": 16
                        }
                    ],
                    "attributes": {
                        "l1_acc": true,
                        "m_k": 2,
                        "min_buffer_input": 0,
                        "u_kt": 6
                    }
                },
                "matmul_887": {
                    "type": "matmul",
                    "grid_loc": [
                        4,
                        0
                    ],
                    "grid_size": [
                        2,
                        4
                    ],
                    "inputs": [
                        "matmul_883",
                        "bert.encoder.layer.16.attention.output.dense.weight",
                        "bert.encoder.layer.16.attention.output.dense.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 16
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 16,
                        "min_buffer_input": 0,
                        "u_kt": 2
                    }
                },
                "add_891": {
                    "type": "add",
                    "grid_loc": [
                        2,
                        6
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "matmul_887",
                        "e2e__fused_op_113_0"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        48
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "layernorm_892.dc.reduce_sum.0.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        2,
                        7
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "add_891",
                        "lc.input_tensor.layernorm_892.dc.reduce_sum.0.0"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_1_28864_29772": {
                    "type": "nop",
                    "grid_loc": [
                        4,
                        4
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "add_891"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_28864_29772": {
                    "type": "nop",
                    "grid_loc": [
                        4,
                        5
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "buffer_1_28864_29772"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_117": {
                    "type": "fused_op",
                    "grid_loc": [
                        4,
                        6
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_892.1",
                        "layernorm_892.dc.reduce_sum.0.lc1",
                        "buffer_0_28864_29772"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 32
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 5
                    }
                },
                "layernorm_892.dc.multiply.4": {
                    "type": "multiply",
                    "grid_loc": [
                        4,
                        7
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "_fused_op_117",
                        "_fused_op_117"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "layernorm_892.dc.reduce_sum.5.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        6,
                        0
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "layernorm_892.dc.multiply.4",
                        "lc.input_tensor.layernorm_892.dc.reduce_sum.5.0"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_2_29772_29773": {
                    "type": "nop",
                    "grid_loc": [
                        6,
                        1
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "_fused_op_117"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_1_29772_29773": {
                    "type": "nop",
                    "grid_loc": [
                        6,
                        2
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "buffer_2_29772_29773"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29772_29773": {
                    "type": "nop",
                    "grid_loc": [
                        6,
                        3
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29772_29773"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_118": {
                    "type": "fused_op",
                    "grid_loc": [
                        6,
                        4
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_892.6",
                        "layernorm_892.dc.reduce_sum.5.lc1",
                        "dc.input_tensor.layernorm_892.8",
                        "buffer_0_29772_29773",
                        "bert.encoder.layer.16.attention.output.LayerNorm.weight",
                        "bert.encoder.layer.16.attention.output.LayerNorm.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        32
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        6,
                        0,
                        6,
                        0,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0,
                        0,
                        24,
                        24
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_5_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_4_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 6
                    }
                },
                "matmul_895": {
                    "type": "matmul",
                    "grid_loc": [
                        8,
                        0
                    ],
                    "grid_size": [
                        2,
                        8
                    ],
                    "inputs": [
                        "_fused_op_118",
                        "bert.encoder.layer.16.intermediate.dense.weight",
                        "bert.encoder.layer.16.intermediate.dense.bias"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "hslice": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "hslice": 2
                        }
                    ],
                    "input_0_tms": [
                        {
                            "broadcast": {
                                "r": 2
                            }
                        },
                        {
                            "vslice": 2
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "gelu_898": {
                    "type": "gelu",
                    "grid_loc": [
                        6,
                        5
                    ],
                    "grid_size": [
                        2,
                        2
                    ],
                    "inputs": [
                        "matmul_895"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "approximate_mode": false
                    }
                }
            },
            "fwd_0_42_temporal_epoch_42": {
                "target_device": 0,
                "input_count": 1,
                "matmul_901": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        0
                    ],
                    "grid_size": [
                        3,
                        8
                    ],
                    "inputs": [
                        "e2e_gelu_898_0",
                        "bert.encoder.layer.16.output.dense.weight",
                        "bert.encoder.layer.16.output.dense.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        2,
                        4
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 4
                        },
                        "l1_acc": true,
                        "m_k": 16,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                },
                "add_905": {
                    "type": "add",
                    "grid_loc": [
                        3,
                        0
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "matmul_901",
                        "e2e__fused_op_118_0"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        48
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "layernorm_906.dc.reduce_sum.0.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        3,
                        1
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "add_905",
                        "lc.input_tensor.layernorm_906.dc.reduce_sum.0.0"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_1_28896_29774": {
                    "type": "nop",
                    "grid_loc": [
                        3,
                        2
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "add_905"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_28896_29774": {
                    "type": "nop",
                    "grid_loc": [
                        3,
                        3
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "buffer_1_28896_29774"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_119": {
                    "type": "fused_op",
                    "grid_loc": [
                        3,
                        4
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_906.1",
                        "layernorm_906.dc.reduce_sum.0.lc1",
                        "buffer_0_28896_29774"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        128,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 32
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 7
                    }
                },
                "layernorm_906.dc.multiply.4": {
                    "type": "multiply",
                    "grid_loc": [
                        3,
                        5
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "_fused_op_119",
                        "_fused_op_119"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "layernorm_906.dc.reduce_sum.5.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        3,
                        6
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "layernorm_906.dc.multiply.4",
                        "lc.input_tensor.layernorm_906.dc.reduce_sum.5.0"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_1_29774_29775": {
                    "type": "nop",
                    "grid_loc": [
                        3,
                        7
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "_fused_op_119"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        176
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29774_29775": {
                    "type": "nop",
                    "grid_loc": [
                        6,
                        0
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29774_29775"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        176
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_120": {
                    "type": "fused_op",
                    "grid_loc": [
                        6,
                        1
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_906.6",
                        "layernorm_906.dc.reduce_sum.5.lc1",
                        "dc.input_tensor.layernorm_906.8",
                        "buffer_0_29774_29775",
                        "bert.encoder.layer.16.output.LayerNorm.weight",
                        "bert.encoder.layer.16.output.LayerNorm.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        32
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        4,
                        0,
                        4,
                        0,
                        128,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0,
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_5_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_4_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 8
                    }
                },
                "matmul_909": {
                    "type": "matmul",
                    "grid_loc": [
                        6,
                        2
                    ],
                    "grid_size": [
                        3,
                        4
                    ],
                    "inputs": [
                        "_fused_op_120",
                        "bert.encoder.layer.17.attention.self.query.weight",
                        "bert.encoder.layer.17.attention.self.query.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 4,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                }
            },
            "fwd_0_43_temporal_epoch_43": {
                "target_device": 0,
                "input_count": 1,
                "matmul_915": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        0
                    ],
                    "grid_size": [
                        3,
                        4
                    ],
                    "inputs": [
                        "e2e__fused_op_120_0",
                        "bert.encoder.layer.17.attention.self.key.weight",
                        "bert.encoder.layer.17.attention.self.key.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 4,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                },
                "matmul_921": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        4
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "e2e_matmul_909_0",
                        "matmul_915"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        6
                    ],
                    "ublock": [
                        4,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        "transpose",
                        {
                            "vslice": 16
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hslice": 16
                        }
                    ],
                    "attributes": {
                        "l1_acc": true,
                        "m_k": 2,
                        "min_buffer_input": 0,
                        "u_kt": 1
                    }
                },
                "_fused_op_121": {
                    "type": "fused_op",
                    "grid_loc": [
                        0,
                        5
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "matmul_921",
                        "input_1_multiply_923",
                        "e2e_multiply_22_attempt_1_input_op_fork_nop2_0"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        6
                    ],
                    "ublock": [
                        4,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        48
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 12
                            }
                        },
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 9,
                        "kernel_broadcast": {
                            "input_1": 1
                        }
                    }
                },
                "softmax_925.dc.reduce_max.0": {
                    "type": "reduce",
                    "grid_loc": [
                        0,
                        6
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "_fused_op_121"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "dim": "c",
                        "m_k": 1,
                        "type": "max",
                        "u_kt": 12
                    }
                },
                "_fused_op_122": {
                    "type": "fused_op",
                    "grid_loc": [
                        3,
                        0
                    ],
                    "grid_size": [
                        3,
                        6
                    ],
                    "inputs": [
                        "_fused_op_121",
                        "softmax_925.dc.reduce_max.0"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        400,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 12
                            }
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 10
                    }
                },
                "softmax_925.dc.reduce_sum.3.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        7
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "_fused_op_122",
                        "lc.input_tensor.softmax_925.dc.reduce_sum.3.0"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 3,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_929": {
                    "type": "matmul",
                    "grid_loc": [
                        6,
                        0
                    ],
                    "grid_size": [
                        3,
                        4
                    ],
                    "inputs": [
                        "e2e__fused_op_120_0",
                        "bert.encoder.layer.17.attention.self.value.weight",
                        "bert.encoder.layer.17.attention.self.value.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 4,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                },
                "_fused_op_123": {
                    "type": "fused_op",
                    "grid_loc": [
                        3,
                        6
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "softmax_925.dc.reduce_sum.3.lc1",
                        "dc.input_tensor.softmax_925.4",
                        "_fused_op_122"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        12
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        64,
                        260
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 11
                    }
                },
                "matmul_936": {
                    "type": "matmul",
                    "grid_loc": [
                        3,
                        7
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "_fused_op_123",
                        "matmul_929"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 32,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "hslice": 16
                        }
                    ],
                    "attributes": {
                        "l1_acc": true,
                        "m_k": 3,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_940": {
                    "type": "matmul",
                    "grid_loc": [
                        6,
                        4
                    ],
                    "grid_size": [
                        2,
                        4
                    ],
                    "inputs": [
                        "matmul_936",
                        "bert.encoder.layer.17.attention.output.dense.weight",
                        "bert.encoder.layer.17.attention.output.dense.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 16
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 16,
                        "min_buffer_input": 0,
                        "u_kt": 2
                    }
                }
            },
            "fwd_0_44_temporal_epoch_44": {
                "target_device": 0,
                "input_count": 1,
                "add_944": {
                    "type": "add",
                    "grid_loc": [
                        0,
                        0
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "e2e_matmul_940_0",
                        "e2e__fused_op_120_0"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        24,
                        24
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "hslice": 2
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hslice": 2
                        }
                    ]
                },
                "layernorm_945.dc.reduce_sum.0.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        1
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "add_944",
                        "lc.input_tensor.layernorm_945.dc.reduce_sum.0.0"
                    ],
                    "t": 1,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_3_28968_29779": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        2
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "add_944"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_2_28968_29779": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        3
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_3_28968_29779"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_1_28968_29779": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        4
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_2_28968_29779"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_28968_29779": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        5
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_1_28968_29779"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_124": {
                    "type": "fused_op",
                    "grid_loc": [
                        0,
                        6
                    ],
                    "grid_size": [
                        1,
                        2
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_945.1",
                        "layernorm_945.dc.reduce_sum.0.lc1",
                        "buffer_0_28968_29779"
                    ],
                    "t": 1,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 32
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 12
                    }
                },
                "layernorm_945.dc.multiply.4": {
                    "type": "multiply",
                    "grid_loc": [
                        1,
                        0
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "_fused_op_124",
                        "_fused_op_124"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "vslice": 2
                        }
                    ],
                    "input_0_tms": [
                        {
                            "vslice": 2
                        }
                    ]
                },
                "layernorm_945.dc.reduce_sum.5.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        1,
                        1
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "layernorm_945.dc.multiply.4",
                        "lc.input_tensor.layernorm_945.dc.reduce_sum.5.0"
                    ],
                    "t": 2,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 2
                            }
                        },
                        {
                            "broadcast": {
                                "r": 32
                            }
                        },
                        {
                            "hslice": 2
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_4_29779_29780": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        2
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "_fused_op_124"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_0_tms": [
                        {
                            "vslice": 2
                        }
                    ]
                },
                "buffer_3_29779_29780": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        3
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_4_29779_29780"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_2_29779_29780": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        4
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_3_29779_29780"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_1_29779_29780": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        5
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_2_29779_29780"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29779_29780": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        6
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29779_29780"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_125": {
                    "type": "fused_op",
                    "grid_loc": [
                        1,
                        7
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_945.6",
                        "layernorm_945.dc.reduce_sum.5.lc1",
                        "dc.input_tensor.layernorm_945.8",
                        "buffer_0_29779_29780",
                        "bert.encoder.layer.17.attention.output.LayerNorm.weight",
                        "bert.encoder.layer.17.attention.output.LayerNorm.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        32
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        6,
                        0,
                        6,
                        0,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0,
                        0,
                        24,
                        24
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_5_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_4_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_3_tms": [
                        {
                            "vstack": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "vstack": 2
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 6
                    }
                },
                "matmul_948": {
                    "type": "matmul",
                    "grid_loc": [
                        3,
                        0
                    ],
                    "grid_size": [
                        2,
                        8
                    ],
                    "inputs": [
                        "_fused_op_125",
                        "bert.encoder.layer.17.intermediate.dense.weight",
                        "bert.encoder.layer.17.intermediate.dense.bias"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "hslice": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "hslice": 2
                        }
                    ],
                    "input_0_tms": [
                        {
                            "broadcast": {
                                "r": 2
                            }
                        },
                        {
                            "vslice": 2
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "gelu_951": {
                    "type": "gelu",
                    "grid_loc": [
                        2,
                        0
                    ],
                    "grid_size": [
                        1,
                        4
                    ],
                    "inputs": [
                        "matmul_948"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "approximate_mode": false
                    }
                },
                "matmul_954": {
                    "type": "matmul",
                    "grid_loc": [
                        5,
                        0
                    ],
                    "grid_size": [
                        2,
                        8
                    ],
                    "inputs": [
                        "gelu_951",
                        "bert.encoder.layer.17.output.dense.weight",
                        "bert.encoder.layer.17.output.dense.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        3,
                        1
                    ],
                    "ublock": [
                        2,
                        4
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 4
                        },
                        "l1_acc": true,
                        "m_k": 16,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                },
                "buffer_7_29780_29000": {
                    "type": "nop",
                    "grid_loc": [
                        2,
                        4
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "_fused_op_125"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_0_tms": [
                        {
                            "hslice": 2
                        }
                    ]
                },
                "buffer_6_29780_29000": {
                    "type": "nop",
                    "grid_loc": [
                        2,
                        5
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_7_29780_29000"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_5_29780_29000": {
                    "type": "nop",
                    "grid_loc": [
                        2,
                        6
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_6_29780_29000"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_4_29780_29000": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        0
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_5_29780_29000"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_3_29780_29000": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        1
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_4_29780_29000"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_2_29780_29000": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        2
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_3_29780_29000"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_1_29780_29000": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        3
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_2_29780_29000"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29780_29000": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        4
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29780_29000"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "add_958": {
                    "type": "add",
                    "grid_loc": [
                        7,
                        5
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "matmul_954",
                        "buffer_0_29780_29000"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_0_tms": [
                        {
                            "hslice": 2
                        }
                    ]
                },
                "layernorm_959.dc.reduce_sum.0.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        7,
                        6
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "add_958",
                        "lc.input_tensor.layernorm_959.dc.reduce_sum.0.0"
                    ],
                    "t": 1,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_3_29000_29781": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        7
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "add_958"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_2_29000_29781": {
                    "type": "nop",
                    "grid_loc": [
                        8,
                        0
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_3_29000_29781"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_1_29000_29781": {
                    "type": "nop",
                    "grid_loc": [
                        8,
                        1
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_2_29000_29781"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29000_29781": {
                    "type": "nop",
                    "grid_loc": [
                        8,
                        2
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29000_29781"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_126": {
                    "type": "fused_op",
                    "grid_loc": [
                        8,
                        3
                    ],
                    "grid_size": [
                        1,
                        2
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_959.1",
                        "layernorm_959.dc.reduce_sum.0.lc1",
                        "buffer_0_29000_29781"
                    ],
                    "t": 1,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 32
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 12
                    }
                },
                "layernorm_959.dc.multiply.4": {
                    "type": "multiply",
                    "grid_loc": [
                        8,
                        5
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "_fused_op_126",
                        "_fused_op_126"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "vslice": 2
                        }
                    ],
                    "input_0_tms": [
                        {
                            "vslice": 2
                        }
                    ]
                },
                "layernorm_959.dc.reduce_sum.5.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        8,
                        6
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "layernorm_959.dc.multiply.4",
                        "lc.input_tensor.layernorm_959.dc.reduce_sum.5.0"
                    ],
                    "t": 2,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 2
                            }
                        },
                        {
                            "broadcast": {
                                "r": 32
                            }
                        },
                        {
                            "hslice": 2
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                }
            },
            "fwd_0_45_temporal_epoch_45": {
                "target_device": 0,
                "input_count": 1,
                "_fused_op_127": {
                    "type": "fused_op",
                    "grid_loc": [
                        0,
                        0
                    ],
                    "grid_size": [
                        6,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_959.6",
                        "e2e_layernorm_959.dc.reduce_sum.5.lc1_0",
                        "dc.input_tensor.layernorm_959.8",
                        "e2e__fused_op_126_0",
                        "bert.encoder.layer.17.output.LayerNorm.weight",
                        "bert.encoder.layer.17.output.LayerNorm.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        32
                    ],
                    "ublock": [
                        2,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        2,
                        0,
                        2,
                        0,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        24,
                        0,
                        24,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_5_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_4_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_1_tms": [
                        {
                            "vstack": 2
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 15,
                        "kernel_broadcast": {
                            "input_5": 64,
                            "input_4": 64
                        }
                    }
                },
                "matmul_962": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        1
                    ],
                    "grid_size": [
                        6,
                        2
                    ],
                    "inputs": [
                        "_fused_op_127",
                        "bert.encoder.layer.18.attention.self.query.weight",
                        "bert.encoder.layer.18.attention.self.query.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        2,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        96,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 16
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_968": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        3
                    ],
                    "grid_size": [
                        6,
                        2
                    ],
                    "inputs": [
                        "_fused_op_127",
                        "bert.encoder.layer.18.attention.self.key.weight",
                        "bert.encoder.layer.18.attention.self.key.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        2,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 16
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_974": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        5
                    ],
                    "grid_size": [
                        6,
                        1
                    ],
                    "inputs": [
                        "matmul_962",
                        "matmul_968"
                    ],
                    "t": 16,
                    "mblock": [
                        2,
                        2
                    ],
                    "ublock": [
                        1,
                        6
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        363,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        "transpose",
                        {
                            "vslice": 16
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hslice": 16
                        }
                    ],
                    "attributes": {
                        "l1_acc": true,
                        "m_k": 2,
                        "min_buffer_input": 0,
                        "u_kt": 1
                    }
                },
                "_fused_op_128": {
                    "type": "fused_op",
                    "grid_loc": [
                        0,
                        6
                    ],
                    "grid_size": [
                        6,
                        1
                    ],
                    "inputs": [
                        "matmul_974",
                        "input_1_multiply_976",
                        "e2e_multiply_22_attempt_1_input_op_fork_nop2_0"
                    ],
                    "t": 16,
                    "mblock": [
                        2,
                        2
                    ],
                    "ublock": [
                        1,
                        6
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        48
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 12
                            }
                        },
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 16,
                        "kernel_broadcast": {
                            "input_1": 1
                        }
                    }
                },
                "softmax_978.dc.reduce_max.0": {
                    "type": "reduce",
                    "grid_loc": [
                        0,
                        7
                    ],
                    "grid_size": [
                        6,
                        1
                    ],
                    "inputs": [
                        "_fused_op_128"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        2,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "dim": "c",
                        "m_k": 1,
                        "type": "max",
                        "u_kt": 12
                    }
                }
            },
            "fwd_0_46_temporal_epoch_46": {
                "target_device": 0,
                "input_count": 1,
                "_fused_op_129": {
                    "type": "fused_op",
                    "grid_loc": [
                        0,
                        0
                    ],
                    "grid_size": [
                        2,
                        6
                    ],
                    "inputs": [
                        "e2e__fused_op_128_0",
                        "e2e_softmax_978.dc.reduce_max.0_0"
                    ],
                    "t": 16,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        3,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 32,
                    "input_dram_io_buf_size_tiles": [
                        24,
                        24
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 12
                            }
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 3
                    }
                },
                "softmax_978.dc.reduce_sum.3.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        6
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "_fused_op_129",
                        "lc.input_tensor.softmax_978.dc.reduce_sum.3.0"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 3,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_982": {
                    "type": "matmul",
                    "grid_loc": [
                        2,
                        1
                    ],
                    "grid_size": [
                        2,
                        4
                    ],
                    "inputs": [
                        "e2e__fused_op_127_0",
                        "bert.encoder.layer.18.attention.self.value.weight",
                        "bert.encoder.layer.18.attention.self.value.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 4,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                },
                "buffer_0_29784_29785": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        7
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "_fused_op_129"
                    ],
                    "t": 16,
                    "mblock": [
                        6,
                        2
                    ],
                    "ublock": [
                        1,
                        6
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        288
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_130": {
                    "type": "fused_op",
                    "grid_loc": [
                        2,
                        0
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "softmax_978.dc.reduce_sum.3.lc1",
                        "dc.input_tensor.softmax_978.4",
                        "buffer_0_29784_29785"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        12
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        96,
                        174
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 4
                    }
                },
                "matmul_989": {
                    "type": "matmul",
                    "grid_loc": [
                        2,
                        5
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "_fused_op_130",
                        "matmul_982"
                    ],
                    "t": 16,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        3,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 32,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "hslice": 16
                        }
                    ],
                    "attributes": {
                        "l1_acc": true,
                        "m_k": 2,
                        "min_buffer_input": 0,
                        "u_kt": 6
                    }
                },
                "matmul_993": {
                    "type": "matmul",
                    "grid_loc": [
                        4,
                        0
                    ],
                    "grid_size": [
                        2,
                        4
                    ],
                    "inputs": [
                        "matmul_989",
                        "bert.encoder.layer.18.attention.output.dense.weight",
                        "bert.encoder.layer.18.attention.output.dense.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 16
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 16,
                        "min_buffer_input": 0,
                        "u_kt": 2
                    }
                },
                "add_997": {
                    "type": "add",
                    "grid_loc": [
                        2,
                        6
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "matmul_993",
                        "e2e__fused_op_127_0"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        48
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "layernorm_998.dc.reduce_sum.0.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        2,
                        7
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "add_997",
                        "lc.input_tensor.layernorm_998.dc.reduce_sum.0.0"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_1_29072_29786": {
                    "type": "nop",
                    "grid_loc": [
                        4,
                        4
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "add_997"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29072_29786": {
                    "type": "nop",
                    "grid_loc": [
                        4,
                        5
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29072_29786"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_131": {
                    "type": "fused_op",
                    "grid_loc": [
                        4,
                        6
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_998.1",
                        "layernorm_998.dc.reduce_sum.0.lc1",
                        "buffer_0_29072_29786"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 32
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 5
                    }
                },
                "layernorm_998.dc.multiply.4": {
                    "type": "multiply",
                    "grid_loc": [
                        4,
                        7
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "_fused_op_131",
                        "_fused_op_131"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "layernorm_998.dc.reduce_sum.5.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        6,
                        0
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "layernorm_998.dc.multiply.4",
                        "lc.input_tensor.layernorm_998.dc.reduce_sum.5.0"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_2_29786_29787": {
                    "type": "nop",
                    "grid_loc": [
                        6,
                        1
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "_fused_op_131"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_1_29786_29787": {
                    "type": "nop",
                    "grid_loc": [
                        6,
                        2
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "buffer_2_29786_29787"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29786_29787": {
                    "type": "nop",
                    "grid_loc": [
                        6,
                        3
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29786_29787"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_132": {
                    "type": "fused_op",
                    "grid_loc": [
                        6,
                        4
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_998.6",
                        "layernorm_998.dc.reduce_sum.5.lc1",
                        "dc.input_tensor.layernorm_998.8",
                        "buffer_0_29786_29787",
                        "bert.encoder.layer.18.attention.output.LayerNorm.weight",
                        "bert.encoder.layer.18.attention.output.LayerNorm.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        32
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        6,
                        0,
                        6,
                        0,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0,
                        0,
                        24,
                        24
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_5_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_4_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 6
                    }
                },
                "matmul_1001": {
                    "type": "matmul",
                    "grid_loc": [
                        8,
                        0
                    ],
                    "grid_size": [
                        2,
                        8
                    ],
                    "inputs": [
                        "_fused_op_132",
                        "bert.encoder.layer.18.intermediate.dense.weight",
                        "bert.encoder.layer.18.intermediate.dense.bias"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "hslice": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "hslice": 2
                        }
                    ],
                    "input_0_tms": [
                        {
                            "broadcast": {
                                "r": 2
                            }
                        },
                        {
                            "vslice": 2
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "gelu_1004": {
                    "type": "gelu",
                    "grid_loc": [
                        6,
                        5
                    ],
                    "grid_size": [
                        2,
                        2
                    ],
                    "inputs": [
                        "matmul_1001"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "approximate_mode": false
                    }
                }
            },
            "fwd_0_47_temporal_epoch_47": {
                "target_device": 0,
                "input_count": 1,
                "matmul_1007": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        0
                    ],
                    "grid_size": [
                        3,
                        8
                    ],
                    "inputs": [
                        "e2e_gelu_1004_0",
                        "bert.encoder.layer.18.output.dense.weight",
                        "bert.encoder.layer.18.output.dense.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        2,
                        4
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 4
                        },
                        "l1_acc": true,
                        "m_k": 16,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                },
                "add_1011": {
                    "type": "add",
                    "grid_loc": [
                        3,
                        0
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "matmul_1007",
                        "e2e__fused_op_132_0"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        48
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "layernorm_1012.dc.reduce_sum.0.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        3,
                        1
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "add_1011",
                        "lc.input_tensor.layernorm_1012.dc.reduce_sum.0.0"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_1_29104_29788": {
                    "type": "nop",
                    "grid_loc": [
                        3,
                        2
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "add_1011"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29104_29788": {
                    "type": "nop",
                    "grid_loc": [
                        3,
                        3
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29104_29788"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_133": {
                    "type": "fused_op",
                    "grid_loc": [
                        3,
                        4
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_1012.1",
                        "layernorm_1012.dc.reduce_sum.0.lc1",
                        "buffer_0_29104_29788"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        128,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 32
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 7
                    }
                },
                "layernorm_1012.dc.multiply.4": {
                    "type": "multiply",
                    "grid_loc": [
                        3,
                        5
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "_fused_op_133",
                        "_fused_op_133"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "layernorm_1012.dc.reduce_sum.5.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        3,
                        6
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "layernorm_1012.dc.multiply.4",
                        "lc.input_tensor.layernorm_1012.dc.reduce_sum.5.0"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_1_29788_29789": {
                    "type": "nop",
                    "grid_loc": [
                        3,
                        7
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "_fused_op_133"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        176
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29788_29789": {
                    "type": "nop",
                    "grid_loc": [
                        6,
                        0
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29788_29789"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        176
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_134": {
                    "type": "fused_op",
                    "grid_loc": [
                        6,
                        1
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_1012.6",
                        "layernorm_1012.dc.reduce_sum.5.lc1",
                        "dc.input_tensor.layernorm_1012.8",
                        "buffer_0_29788_29789",
                        "bert.encoder.layer.18.output.LayerNorm.weight",
                        "bert.encoder.layer.18.output.LayerNorm.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        32
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        4,
                        0,
                        4,
                        0,
                        128,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0,
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_5_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_4_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 8
                    }
                },
                "matmul_1015": {
                    "type": "matmul",
                    "grid_loc": [
                        6,
                        2
                    ],
                    "grid_size": [
                        3,
                        4
                    ],
                    "inputs": [
                        "_fused_op_134",
                        "bert.encoder.layer.19.attention.self.query.weight",
                        "bert.encoder.layer.19.attention.self.query.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 4,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                }
            },
            "fwd_0_48_temporal_epoch_48": {
                "target_device": 0,
                "input_count": 1,
                "matmul_1021": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        0
                    ],
                    "grid_size": [
                        3,
                        4
                    ],
                    "inputs": [
                        "e2e__fused_op_134_0",
                        "bert.encoder.layer.19.attention.self.key.weight",
                        "bert.encoder.layer.19.attention.self.key.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 4,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                },
                "matmul_1027": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        4
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "e2e_matmul_1015_0",
                        "matmul_1021"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        6
                    ],
                    "ublock": [
                        4,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        "transpose",
                        {
                            "vslice": 16
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hslice": 16
                        }
                    ],
                    "attributes": {
                        "l1_acc": true,
                        "m_k": 2,
                        "min_buffer_input": 0,
                        "u_kt": 1
                    }
                },
                "_fused_op_135": {
                    "type": "fused_op",
                    "grid_loc": [
                        0,
                        5
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "matmul_1027",
                        "input_1_multiply_1029",
                        "e2e_multiply_22_attempt_1_input_op_fork_nop2_0"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        6
                    ],
                    "ublock": [
                        4,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        48
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 12
                            }
                        },
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 9,
                        "kernel_broadcast": {
                            "input_1": 1
                        }
                    }
                },
                "softmax_1031.dc.reduce_max.0": {
                    "type": "reduce",
                    "grid_loc": [
                        0,
                        6
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "_fused_op_135"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "dim": "c",
                        "m_k": 1,
                        "type": "max",
                        "u_kt": 12
                    }
                },
                "_fused_op_136": {
                    "type": "fused_op",
                    "grid_loc": [
                        3,
                        0
                    ],
                    "grid_size": [
                        3,
                        6
                    ],
                    "inputs": [
                        "_fused_op_135",
                        "softmax_1031.dc.reduce_max.0"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        400,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 12
                            }
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 10
                    }
                },
                "softmax_1031.dc.reduce_sum.3.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        7
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "_fused_op_136",
                        "lc.input_tensor.softmax_1031.dc.reduce_sum.3.0"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 3,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_1035": {
                    "type": "matmul",
                    "grid_loc": [
                        6,
                        0
                    ],
                    "grid_size": [
                        3,
                        4
                    ],
                    "inputs": [
                        "e2e__fused_op_134_0",
                        "bert.encoder.layer.19.attention.self.value.weight",
                        "bert.encoder.layer.19.attention.self.value.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 4,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                },
                "_fused_op_137": {
                    "type": "fused_op",
                    "grid_loc": [
                        3,
                        6
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "softmax_1031.dc.reduce_sum.3.lc1",
                        "dc.input_tensor.softmax_1031.4",
                        "_fused_op_136"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        12
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        64,
                        260
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 11
                    }
                },
                "matmul_1042": {
                    "type": "matmul",
                    "grid_loc": [
                        3,
                        7
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "_fused_op_137",
                        "matmul_1035"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 32,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "hslice": 16
                        }
                    ],
                    "attributes": {
                        "l1_acc": true,
                        "m_k": 3,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_1046": {
                    "type": "matmul",
                    "grid_loc": [
                        6,
                        4
                    ],
                    "grid_size": [
                        2,
                        4
                    ],
                    "inputs": [
                        "matmul_1042",
                        "bert.encoder.layer.19.attention.output.dense.weight",
                        "bert.encoder.layer.19.attention.output.dense.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 16
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 16,
                        "min_buffer_input": 0,
                        "u_kt": 2
                    }
                }
            },
            "fwd_0_49_temporal_epoch_49": {
                "target_device": 0,
                "input_count": 1,
                "add_1050": {
                    "type": "add",
                    "grid_loc": [
                        0,
                        0
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "e2e_matmul_1046_0",
                        "e2e__fused_op_134_0"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        24,
                        24
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "hslice": 2
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hslice": 2
                        }
                    ]
                },
                "layernorm_1051.dc.reduce_sum.0.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        1
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "add_1050",
                        "lc.input_tensor.layernorm_1051.dc.reduce_sum.0.0"
                    ],
                    "t": 1,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_3_29176_29793": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        2
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "add_1050"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_2_29176_29793": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        3
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_3_29176_29793"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_1_29176_29793": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        4
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_2_29176_29793"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29176_29793": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        5
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29176_29793"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_138": {
                    "type": "fused_op",
                    "grid_loc": [
                        0,
                        6
                    ],
                    "grid_size": [
                        1,
                        2
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_1051.1",
                        "layernorm_1051.dc.reduce_sum.0.lc1",
                        "buffer_0_29176_29793"
                    ],
                    "t": 1,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 32
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 12
                    }
                },
                "layernorm_1051.dc.multiply.4": {
                    "type": "multiply",
                    "grid_loc": [
                        1,
                        0
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "_fused_op_138",
                        "_fused_op_138"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "vslice": 2
                        }
                    ],
                    "input_0_tms": [
                        {
                            "vslice": 2
                        }
                    ]
                },
                "layernorm_1051.dc.reduce_sum.5.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        1,
                        1
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "layernorm_1051.dc.multiply.4",
                        "lc.input_tensor.layernorm_1051.dc.reduce_sum.5.0"
                    ],
                    "t": 2,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 2
                            }
                        },
                        {
                            "broadcast": {
                                "r": 32
                            }
                        },
                        {
                            "hslice": 2
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_4_29793_29794": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        2
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "_fused_op_138"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_0_tms": [
                        {
                            "vslice": 2
                        }
                    ]
                },
                "buffer_3_29793_29794": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        3
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_4_29793_29794"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_2_29793_29794": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        4
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_3_29793_29794"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_1_29793_29794": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        5
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_2_29793_29794"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29793_29794": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        6
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29793_29794"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_139": {
                    "type": "fused_op",
                    "grid_loc": [
                        1,
                        7
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_1051.6",
                        "layernorm_1051.dc.reduce_sum.5.lc1",
                        "dc.input_tensor.layernorm_1051.8",
                        "buffer_0_29793_29794",
                        "bert.encoder.layer.19.attention.output.LayerNorm.weight",
                        "bert.encoder.layer.19.attention.output.LayerNorm.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        32
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        6,
                        0,
                        6,
                        0,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0,
                        0,
                        24,
                        24
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_5_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_4_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_3_tms": [
                        {
                            "vstack": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "vstack": 2
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 6
                    }
                },
                "matmul_1054": {
                    "type": "matmul",
                    "grid_loc": [
                        3,
                        0
                    ],
                    "grid_size": [
                        2,
                        8
                    ],
                    "inputs": [
                        "_fused_op_139",
                        "bert.encoder.layer.19.intermediate.dense.weight",
                        "bert.encoder.layer.19.intermediate.dense.bias"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "hslice": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "hslice": 2
                        }
                    ],
                    "input_0_tms": [
                        {
                            "broadcast": {
                                "r": 2
                            }
                        },
                        {
                            "vslice": 2
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "gelu_1057": {
                    "type": "gelu",
                    "grid_loc": [
                        2,
                        0
                    ],
                    "grid_size": [
                        1,
                        4
                    ],
                    "inputs": [
                        "matmul_1054"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "approximate_mode": false
                    }
                },
                "matmul_1060": {
                    "type": "matmul",
                    "grid_loc": [
                        5,
                        0
                    ],
                    "grid_size": [
                        2,
                        8
                    ],
                    "inputs": [
                        "gelu_1057",
                        "bert.encoder.layer.19.output.dense.weight",
                        "bert.encoder.layer.19.output.dense.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        3,
                        1
                    ],
                    "ublock": [
                        2,
                        4
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 4
                        },
                        "l1_acc": true,
                        "m_k": 16,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                },
                "buffer_7_29794_29208": {
                    "type": "nop",
                    "grid_loc": [
                        2,
                        4
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "_fused_op_139"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_0_tms": [
                        {
                            "hslice": 2
                        }
                    ]
                },
                "buffer_6_29794_29208": {
                    "type": "nop",
                    "grid_loc": [
                        2,
                        5
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_7_29794_29208"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_5_29794_29208": {
                    "type": "nop",
                    "grid_loc": [
                        2,
                        6
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_6_29794_29208"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_4_29794_29208": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        0
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_5_29794_29208"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_3_29794_29208": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        1
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_4_29794_29208"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_2_29794_29208": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        2
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_3_29794_29208"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_1_29794_29208": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        3
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_2_29794_29208"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29794_29208": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        4
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29794_29208"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "add_1064": {
                    "type": "add",
                    "grid_loc": [
                        7,
                        5
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "matmul_1060",
                        "buffer_0_29794_29208"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_0_tms": [
                        {
                            "hslice": 2
                        }
                    ]
                },
                "layernorm_1065.dc.reduce_sum.0.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        7,
                        6
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "add_1064",
                        "lc.input_tensor.layernorm_1065.dc.reduce_sum.0.0"
                    ],
                    "t": 1,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_3_29208_29795": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        7
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "add_1064"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_2_29208_29795": {
                    "type": "nop",
                    "grid_loc": [
                        8,
                        0
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_3_29208_29795"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_1_29208_29795": {
                    "type": "nop",
                    "grid_loc": [
                        8,
                        1
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_2_29208_29795"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29208_29795": {
                    "type": "nop",
                    "grid_loc": [
                        8,
                        2
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29208_29795"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_140": {
                    "type": "fused_op",
                    "grid_loc": [
                        8,
                        3
                    ],
                    "grid_size": [
                        1,
                        2
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_1065.1",
                        "layernorm_1065.dc.reduce_sum.0.lc1",
                        "buffer_0_29208_29795"
                    ],
                    "t": 1,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 32
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 12
                    }
                },
                "layernorm_1065.dc.multiply.4": {
                    "type": "multiply",
                    "grid_loc": [
                        8,
                        5
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "_fused_op_140",
                        "_fused_op_140"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "vslice": 2
                        }
                    ],
                    "input_0_tms": [
                        {
                            "vslice": 2
                        }
                    ]
                },
                "layernorm_1065.dc.reduce_sum.5.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        8,
                        6
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "layernorm_1065.dc.multiply.4",
                        "lc.input_tensor.layernorm_1065.dc.reduce_sum.5.0"
                    ],
                    "t": 2,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 2
                            }
                        },
                        {
                            "broadcast": {
                                "r": 32
                            }
                        },
                        {
                            "hslice": 2
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                }
            },
            "fwd_0_50_temporal_epoch_50": {
                "target_device": 0,
                "input_count": 1,
                "_fused_op_141": {
                    "type": "fused_op",
                    "grid_loc": [
                        0,
                        0
                    ],
                    "grid_size": [
                        6,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_1065.6",
                        "e2e_layernorm_1065.dc.reduce_sum.5.lc1_0",
                        "dc.input_tensor.layernorm_1065.8",
                        "e2e__fused_op_140_0",
                        "bert.encoder.layer.19.output.LayerNorm.weight",
                        "bert.encoder.layer.19.output.LayerNorm.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        32
                    ],
                    "ublock": [
                        2,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        2,
                        0,
                        2,
                        0,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        24,
                        0,
                        24,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_5_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_4_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_1_tms": [
                        {
                            "vstack": 2
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 15,
                        "kernel_broadcast": {
                            "input_5": 64,
                            "input_4": 64
                        }
                    }
                },
                "matmul_1068": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        1
                    ],
                    "grid_size": [
                        6,
                        2
                    ],
                    "inputs": [
                        "_fused_op_141",
                        "bert.encoder.layer.20.attention.self.query.weight",
                        "bert.encoder.layer.20.attention.self.query.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        2,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        96,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 16
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_1074": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        3
                    ],
                    "grid_size": [
                        6,
                        2
                    ],
                    "inputs": [
                        "_fused_op_141",
                        "bert.encoder.layer.20.attention.self.key.weight",
                        "bert.encoder.layer.20.attention.self.key.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        2,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 16
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_1080": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        5
                    ],
                    "grid_size": [
                        6,
                        1
                    ],
                    "inputs": [
                        "matmul_1068",
                        "matmul_1074"
                    ],
                    "t": 16,
                    "mblock": [
                        2,
                        2
                    ],
                    "ublock": [
                        1,
                        6
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        363,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        "transpose",
                        {
                            "vslice": 16
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hslice": 16
                        }
                    ],
                    "attributes": {
                        "l1_acc": true,
                        "m_k": 2,
                        "min_buffer_input": 0,
                        "u_kt": 1
                    }
                },
                "_fused_op_142": {
                    "type": "fused_op",
                    "grid_loc": [
                        0,
                        6
                    ],
                    "grid_size": [
                        6,
                        1
                    ],
                    "inputs": [
                        "matmul_1080",
                        "input_1_multiply_1082",
                        "e2e_multiply_22_attempt_1_input_op_fork_nop2_0"
                    ],
                    "t": 16,
                    "mblock": [
                        2,
                        2
                    ],
                    "ublock": [
                        1,
                        6
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        48
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 12
                            }
                        },
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 16,
                        "kernel_broadcast": {
                            "input_1": 1
                        }
                    }
                },
                "softmax_1084.dc.reduce_max.0": {
                    "type": "reduce",
                    "grid_loc": [
                        0,
                        7
                    ],
                    "grid_size": [
                        6,
                        1
                    ],
                    "inputs": [
                        "_fused_op_142"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        2,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "dim": "c",
                        "m_k": 1,
                        "type": "max",
                        "u_kt": 12
                    }
                }
            },
            "fwd_0_51_temporal_epoch_51": {
                "target_device": 0,
                "input_count": 1,
                "_fused_op_143": {
                    "type": "fused_op",
                    "grid_loc": [
                        0,
                        0
                    ],
                    "grid_size": [
                        2,
                        6
                    ],
                    "inputs": [
                        "e2e__fused_op_142_0",
                        "e2e_softmax_1084.dc.reduce_max.0_0"
                    ],
                    "t": 16,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        3,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 32,
                    "input_dram_io_buf_size_tiles": [
                        24,
                        24
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 12
                            }
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 3
                    }
                },
                "softmax_1084.dc.reduce_sum.3.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        6
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "_fused_op_143",
                        "lc.input_tensor.softmax_1084.dc.reduce_sum.3.0"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 3,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_1088": {
                    "type": "matmul",
                    "grid_loc": [
                        2,
                        1
                    ],
                    "grid_size": [
                        2,
                        4
                    ],
                    "inputs": [
                        "e2e__fused_op_141_0",
                        "bert.encoder.layer.20.attention.self.value.weight",
                        "bert.encoder.layer.20.attention.self.value.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 4,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                },
                "buffer_0_29798_29799": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        7
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "_fused_op_143"
                    ],
                    "t": 16,
                    "mblock": [
                        6,
                        2
                    ],
                    "ublock": [
                        1,
                        6
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        288
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_144": {
                    "type": "fused_op",
                    "grid_loc": [
                        2,
                        0
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "softmax_1084.dc.reduce_sum.3.lc1",
                        "dc.input_tensor.softmax_1084.4",
                        "buffer_0_29798_29799"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        12
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        96,
                        174
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 4
                    }
                },
                "matmul_1095": {
                    "type": "matmul",
                    "grid_loc": [
                        2,
                        5
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "_fused_op_144",
                        "matmul_1088"
                    ],
                    "t": 16,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        3,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 32,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "hslice": 16
                        }
                    ],
                    "attributes": {
                        "l1_acc": true,
                        "m_k": 2,
                        "min_buffer_input": 0,
                        "u_kt": 6
                    }
                },
                "matmul_1099": {
                    "type": "matmul",
                    "grid_loc": [
                        4,
                        0
                    ],
                    "grid_size": [
                        2,
                        4
                    ],
                    "inputs": [
                        "matmul_1095",
                        "bert.encoder.layer.20.attention.output.dense.weight",
                        "bert.encoder.layer.20.attention.output.dense.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 16
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 16,
                        "min_buffer_input": 0,
                        "u_kt": 2
                    }
                },
                "add_1103": {
                    "type": "add",
                    "grid_loc": [
                        2,
                        6
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "matmul_1099",
                        "e2e__fused_op_141_0"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        48
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "layernorm_1104.dc.reduce_sum.0.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        2,
                        7
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "add_1103",
                        "lc.input_tensor.layernorm_1104.dc.reduce_sum.0.0"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_1_29280_29800": {
                    "type": "nop",
                    "grid_loc": [
                        4,
                        4
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "add_1103"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29280_29800": {
                    "type": "nop",
                    "grid_loc": [
                        4,
                        5
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29280_29800"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_145": {
                    "type": "fused_op",
                    "grid_loc": [
                        4,
                        6
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_1104.1",
                        "layernorm_1104.dc.reduce_sum.0.lc1",
                        "buffer_0_29280_29800"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 32
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 5
                    }
                },
                "layernorm_1104.dc.multiply.4": {
                    "type": "multiply",
                    "grid_loc": [
                        4,
                        7
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "_fused_op_145",
                        "_fused_op_145"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "layernorm_1104.dc.reduce_sum.5.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        6,
                        0
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "layernorm_1104.dc.multiply.4",
                        "lc.input_tensor.layernorm_1104.dc.reduce_sum.5.0"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_2_29800_29801": {
                    "type": "nop",
                    "grid_loc": [
                        6,
                        1
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "_fused_op_145"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_1_29800_29801": {
                    "type": "nop",
                    "grid_loc": [
                        6,
                        2
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "buffer_2_29800_29801"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29800_29801": {
                    "type": "nop",
                    "grid_loc": [
                        6,
                        3
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29800_29801"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_146": {
                    "type": "fused_op",
                    "grid_loc": [
                        6,
                        4
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_1104.6",
                        "layernorm_1104.dc.reduce_sum.5.lc1",
                        "dc.input_tensor.layernorm_1104.8",
                        "buffer_0_29800_29801",
                        "bert.encoder.layer.20.attention.output.LayerNorm.weight",
                        "bert.encoder.layer.20.attention.output.LayerNorm.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        32
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        6,
                        0,
                        6,
                        0,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0,
                        0,
                        24,
                        24
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_5_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_4_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 6
                    }
                },
                "matmul_1107": {
                    "type": "matmul",
                    "grid_loc": [
                        8,
                        0
                    ],
                    "grid_size": [
                        2,
                        8
                    ],
                    "inputs": [
                        "_fused_op_146",
                        "bert.encoder.layer.20.intermediate.dense.weight",
                        "bert.encoder.layer.20.intermediate.dense.bias"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "hslice": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "hslice": 2
                        }
                    ],
                    "input_0_tms": [
                        {
                            "broadcast": {
                                "r": 2
                            }
                        },
                        {
                            "vslice": 2
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "gelu_1110": {
                    "type": "gelu",
                    "grid_loc": [
                        6,
                        5
                    ],
                    "grid_size": [
                        2,
                        2
                    ],
                    "inputs": [
                        "matmul_1107"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "approximate_mode": false
                    }
                }
            },
            "fwd_0_52_temporal_epoch_52": {
                "target_device": 0,
                "input_count": 1,
                "matmul_1113": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        0
                    ],
                    "grid_size": [
                        3,
                        8
                    ],
                    "inputs": [
                        "e2e_gelu_1110_0",
                        "bert.encoder.layer.20.output.dense.weight",
                        "bert.encoder.layer.20.output.dense.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        2,
                        4
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 4
                        },
                        "l1_acc": true,
                        "m_k": 16,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                },
                "add_1117": {
                    "type": "add",
                    "grid_loc": [
                        3,
                        0
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "matmul_1113",
                        "e2e__fused_op_146_0"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        48
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "layernorm_1118.dc.reduce_sum.0.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        3,
                        1
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "add_1117",
                        "lc.input_tensor.layernorm_1118.dc.reduce_sum.0.0"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_1_29312_29802": {
                    "type": "nop",
                    "grid_loc": [
                        3,
                        2
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "add_1117"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29312_29802": {
                    "type": "nop",
                    "grid_loc": [
                        3,
                        3
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29312_29802"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_147": {
                    "type": "fused_op",
                    "grid_loc": [
                        3,
                        4
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_1118.1",
                        "layernorm_1118.dc.reduce_sum.0.lc1",
                        "buffer_0_29312_29802"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        128,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 32
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 7
                    }
                },
                "layernorm_1118.dc.multiply.4": {
                    "type": "multiply",
                    "grid_loc": [
                        3,
                        5
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "_fused_op_147",
                        "_fused_op_147"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "layernorm_1118.dc.reduce_sum.5.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        3,
                        6
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "layernorm_1118.dc.multiply.4",
                        "lc.input_tensor.layernorm_1118.dc.reduce_sum.5.0"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_1_29802_29803": {
                    "type": "nop",
                    "grid_loc": [
                        3,
                        7
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "_fused_op_147"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        176
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29802_29803": {
                    "type": "nop",
                    "grid_loc": [
                        6,
                        0
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29802_29803"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        176
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_148": {
                    "type": "fused_op",
                    "grid_loc": [
                        6,
                        1
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_1118.6",
                        "layernorm_1118.dc.reduce_sum.5.lc1",
                        "dc.input_tensor.layernorm_1118.8",
                        "buffer_0_29802_29803",
                        "bert.encoder.layer.20.output.LayerNorm.weight",
                        "bert.encoder.layer.20.output.LayerNorm.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        32
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        4,
                        0,
                        4,
                        0,
                        128,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0,
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_5_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_4_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 8
                    }
                },
                "matmul_1121": {
                    "type": "matmul",
                    "grid_loc": [
                        6,
                        2
                    ],
                    "grid_size": [
                        3,
                        4
                    ],
                    "inputs": [
                        "_fused_op_148",
                        "bert.encoder.layer.21.attention.self.query.weight",
                        "bert.encoder.layer.21.attention.self.query.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 4,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                }
            },
            "fwd_0_53_temporal_epoch_53": {
                "target_device": 0,
                "input_count": 1,
                "matmul_1127": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        0
                    ],
                    "grid_size": [
                        3,
                        4
                    ],
                    "inputs": [
                        "e2e__fused_op_148_0",
                        "bert.encoder.layer.21.attention.self.key.weight",
                        "bert.encoder.layer.21.attention.self.key.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 4,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                },
                "matmul_1133": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        4
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "e2e_matmul_1121_0",
                        "matmul_1127"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        6
                    ],
                    "ublock": [
                        4,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        "transpose",
                        {
                            "vslice": 16
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hslice": 16
                        }
                    ],
                    "attributes": {
                        "l1_acc": true,
                        "m_k": 2,
                        "min_buffer_input": 0,
                        "u_kt": 1
                    }
                },
                "_fused_op_149": {
                    "type": "fused_op",
                    "grid_loc": [
                        0,
                        5
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "matmul_1133",
                        "input_1_multiply_1135",
                        "e2e_multiply_22_attempt_1_input_op_fork_nop2_0"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        6
                    ],
                    "ublock": [
                        4,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        48
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 12
                            }
                        },
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 9,
                        "kernel_broadcast": {
                            "input_1": 1
                        }
                    }
                },
                "softmax_1137.dc.reduce_max.0": {
                    "type": "reduce",
                    "grid_loc": [
                        0,
                        6
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "_fused_op_149"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "dim": "c",
                        "m_k": 1,
                        "type": "max",
                        "u_kt": 12
                    }
                },
                "_fused_op_150": {
                    "type": "fused_op",
                    "grid_loc": [
                        3,
                        0
                    ],
                    "grid_size": [
                        3,
                        6
                    ],
                    "inputs": [
                        "_fused_op_149",
                        "softmax_1137.dc.reduce_max.0"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        400,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 12
                            }
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 10
                    }
                },
                "softmax_1137.dc.reduce_sum.3.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        7
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "_fused_op_150",
                        "lc.input_tensor.softmax_1137.dc.reduce_sum.3.0"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 3,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_1141": {
                    "type": "matmul",
                    "grid_loc": [
                        6,
                        0
                    ],
                    "grid_size": [
                        3,
                        4
                    ],
                    "inputs": [
                        "e2e__fused_op_148_0",
                        "bert.encoder.layer.21.attention.self.value.weight",
                        "bert.encoder.layer.21.attention.self.value.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 4,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                },
                "_fused_op_151": {
                    "type": "fused_op",
                    "grid_loc": [
                        3,
                        6
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "softmax_1137.dc.reduce_sum.3.lc1",
                        "dc.input_tensor.softmax_1137.4",
                        "_fused_op_150"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        12
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        64,
                        260
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 11
                    }
                },
                "matmul_1148": {
                    "type": "matmul",
                    "grid_loc": [
                        3,
                        7
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "_fused_op_151",
                        "matmul_1141"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 32,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "hslice": 16
                        }
                    ],
                    "attributes": {
                        "l1_acc": true,
                        "m_k": 3,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_1152": {
                    "type": "matmul",
                    "grid_loc": [
                        6,
                        4
                    ],
                    "grid_size": [
                        2,
                        4
                    ],
                    "inputs": [
                        "matmul_1148",
                        "bert.encoder.layer.21.attention.output.dense.weight",
                        "bert.encoder.layer.21.attention.output.dense.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 16
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 16,
                        "min_buffer_input": 0,
                        "u_kt": 2
                    }
                }
            },
            "fwd_0_54_temporal_epoch_54": {
                "target_device": 0,
                "input_count": 1,
                "add_1156": {
                    "type": "add",
                    "grid_loc": [
                        0,
                        0
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "e2e_matmul_1152_0",
                        "e2e__fused_op_148_0"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        24,
                        24
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "hslice": 2
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hslice": 2
                        }
                    ]
                },
                "layernorm_1157.dc.reduce_sum.0.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        1
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "add_1156",
                        "lc.input_tensor.layernorm_1157.dc.reduce_sum.0.0"
                    ],
                    "t": 1,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_3_29384_29807": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        2
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "add_1156"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_2_29384_29807": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        3
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_3_29384_29807"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_1_29384_29807": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        4
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_2_29384_29807"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29384_29807": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        5
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29384_29807"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_152": {
                    "type": "fused_op",
                    "grid_loc": [
                        0,
                        6
                    ],
                    "grid_size": [
                        1,
                        2
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_1157.1",
                        "layernorm_1157.dc.reduce_sum.0.lc1",
                        "buffer_0_29384_29807"
                    ],
                    "t": 1,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 32
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 12
                    }
                },
                "layernorm_1157.dc.multiply.4": {
                    "type": "multiply",
                    "grid_loc": [
                        1,
                        0
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "_fused_op_152",
                        "_fused_op_152"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "vslice": 2
                        }
                    ],
                    "input_0_tms": [
                        {
                            "vslice": 2
                        }
                    ]
                },
                "layernorm_1157.dc.reduce_sum.5.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        1,
                        1
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "layernorm_1157.dc.multiply.4",
                        "lc.input_tensor.layernorm_1157.dc.reduce_sum.5.0"
                    ],
                    "t": 2,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 2
                            }
                        },
                        {
                            "broadcast": {
                                "r": 32
                            }
                        },
                        {
                            "hslice": 2
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_4_29807_29808": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        2
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "_fused_op_152"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_0_tms": [
                        {
                            "vslice": 2
                        }
                    ]
                },
                "buffer_3_29807_29808": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        3
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_4_29807_29808"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_2_29807_29808": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        4
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_3_29807_29808"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_1_29807_29808": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        5
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_2_29807_29808"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29807_29808": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        6
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29807_29808"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_153": {
                    "type": "fused_op",
                    "grid_loc": [
                        1,
                        7
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_1157.6",
                        "layernorm_1157.dc.reduce_sum.5.lc1",
                        "dc.input_tensor.layernorm_1157.8",
                        "buffer_0_29807_29808",
                        "bert.encoder.layer.21.attention.output.LayerNorm.weight",
                        "bert.encoder.layer.21.attention.output.LayerNorm.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        32
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        6,
                        0,
                        6,
                        0,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0,
                        0,
                        24,
                        24
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_5_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_4_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_3_tms": [
                        {
                            "vstack": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "vstack": 2
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 6
                    }
                },
                "matmul_1160": {
                    "type": "matmul",
                    "grid_loc": [
                        3,
                        0
                    ],
                    "grid_size": [
                        2,
                        8
                    ],
                    "inputs": [
                        "_fused_op_153",
                        "bert.encoder.layer.21.intermediate.dense.weight",
                        "bert.encoder.layer.21.intermediate.dense.bias"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "hslice": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "hslice": 2
                        }
                    ],
                    "input_0_tms": [
                        {
                            "broadcast": {
                                "r": 2
                            }
                        },
                        {
                            "vslice": 2
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "gelu_1163": {
                    "type": "gelu",
                    "grid_loc": [
                        2,
                        0
                    ],
                    "grid_size": [
                        1,
                        4
                    ],
                    "inputs": [
                        "matmul_1160"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "approximate_mode": false
                    }
                },
                "matmul_1166": {
                    "type": "matmul",
                    "grid_loc": [
                        5,
                        0
                    ],
                    "grid_size": [
                        2,
                        8
                    ],
                    "inputs": [
                        "gelu_1163",
                        "bert.encoder.layer.21.output.dense.weight",
                        "bert.encoder.layer.21.output.dense.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        3,
                        1
                    ],
                    "ublock": [
                        2,
                        4
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 4
                        },
                        "l1_acc": true,
                        "m_k": 16,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                },
                "buffer_7_29808_29416": {
                    "type": "nop",
                    "grid_loc": [
                        2,
                        4
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "_fused_op_153"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_0_tms": [
                        {
                            "hslice": 2
                        }
                    ]
                },
                "buffer_6_29808_29416": {
                    "type": "nop",
                    "grid_loc": [
                        2,
                        5
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_7_29808_29416"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_5_29808_29416": {
                    "type": "nop",
                    "grid_loc": [
                        2,
                        6
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_6_29808_29416"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_4_29808_29416": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        0
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_5_29808_29416"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_3_29808_29416": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        1
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_4_29808_29416"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_2_29808_29416": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        2
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_3_29808_29416"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_1_29808_29416": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        3
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_2_29808_29416"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29808_29416": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        4
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29808_29416"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "add_1170": {
                    "type": "add",
                    "grid_loc": [
                        7,
                        5
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "matmul_1166",
                        "buffer_0_29808_29416"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_0_tms": [
                        {
                            "hslice": 2
                        }
                    ]
                },
                "layernorm_1171.dc.reduce_sum.0.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        7,
                        6
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "add_1170",
                        "lc.input_tensor.layernorm_1171.dc.reduce_sum.0.0"
                    ],
                    "t": 1,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_3_29416_29809": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        7
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "add_1170"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_2_29416_29809": {
                    "type": "nop",
                    "grid_loc": [
                        8,
                        0
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_3_29416_29809"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_1_29416_29809": {
                    "type": "nop",
                    "grid_loc": [
                        8,
                        1
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_2_29416_29809"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29416_29809": {
                    "type": "nop",
                    "grid_loc": [
                        8,
                        2
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29416_29809"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_154": {
                    "type": "fused_op",
                    "grid_loc": [
                        8,
                        3
                    ],
                    "grid_size": [
                        1,
                        2
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_1171.1",
                        "layernorm_1171.dc.reduce_sum.0.lc1",
                        "buffer_0_29416_29809"
                    ],
                    "t": 1,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 32
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 12
                    }
                },
                "layernorm_1171.dc.multiply.4": {
                    "type": "multiply",
                    "grid_loc": [
                        8,
                        5
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "_fused_op_154",
                        "_fused_op_154"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "vslice": 2
                        }
                    ],
                    "input_0_tms": [
                        {
                            "vslice": 2
                        }
                    ]
                },
                "layernorm_1171.dc.reduce_sum.5.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        8,
                        6
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "layernorm_1171.dc.multiply.4",
                        "lc.input_tensor.layernorm_1171.dc.reduce_sum.5.0"
                    ],
                    "t": 2,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 2
                            }
                        },
                        {
                            "broadcast": {
                                "r": 32
                            }
                        },
                        {
                            "hslice": 2
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                }
            },
            "fwd_0_55_temporal_epoch_55": {
                "target_device": 0,
                "input_count": 1,
                "_fused_op_155": {
                    "type": "fused_op",
                    "grid_loc": [
                        0,
                        0
                    ],
                    "grid_size": [
                        6,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_1171.6",
                        "e2e_layernorm_1171.dc.reduce_sum.5.lc1_0",
                        "dc.input_tensor.layernorm_1171.8",
                        "e2e__fused_op_154_0",
                        "bert.encoder.layer.21.output.LayerNorm.weight",
                        "bert.encoder.layer.21.output.LayerNorm.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        32
                    ],
                    "ublock": [
                        2,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        2,
                        0,
                        2,
                        0,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        24,
                        0,
                        24,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_5_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_4_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_1_tms": [
                        {
                            "vstack": 2
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 15,
                        "kernel_broadcast": {
                            "input_5": 64,
                            "input_4": 64
                        }
                    }
                },
                "matmul_1174": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        1
                    ],
                    "grid_size": [
                        6,
                        2
                    ],
                    "inputs": [
                        "_fused_op_155",
                        "bert.encoder.layer.22.attention.self.query.weight",
                        "bert.encoder.layer.22.attention.self.query.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        2,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        96,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 16
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_1180": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        3
                    ],
                    "grid_size": [
                        6,
                        2
                    ],
                    "inputs": [
                        "_fused_op_155",
                        "bert.encoder.layer.22.attention.self.key.weight",
                        "bert.encoder.layer.22.attention.self.key.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        2,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 16
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_1186": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        5
                    ],
                    "grid_size": [
                        6,
                        1
                    ],
                    "inputs": [
                        "matmul_1174",
                        "matmul_1180"
                    ],
                    "t": 16,
                    "mblock": [
                        2,
                        2
                    ],
                    "ublock": [
                        1,
                        6
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        363,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        "transpose",
                        {
                            "vslice": 16
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hslice": 16
                        }
                    ],
                    "attributes": {
                        "l1_acc": true,
                        "m_k": 2,
                        "min_buffer_input": 0,
                        "u_kt": 1
                    }
                },
                "_fused_op_156": {
                    "type": "fused_op",
                    "grid_loc": [
                        0,
                        6
                    ],
                    "grid_size": [
                        6,
                        1
                    ],
                    "inputs": [
                        "matmul_1186",
                        "input_1_multiply_1188",
                        "e2e_multiply_22_attempt_1_input_op_fork_nop2_0"
                    ],
                    "t": 16,
                    "mblock": [
                        2,
                        2
                    ],
                    "ublock": [
                        1,
                        6
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        48
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 12
                            }
                        },
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 16,
                        "kernel_broadcast": {
                            "input_1": 1
                        }
                    }
                },
                "softmax_1190.dc.reduce_max.0": {
                    "type": "reduce",
                    "grid_loc": [
                        0,
                        7
                    ],
                    "grid_size": [
                        6,
                        1
                    ],
                    "inputs": [
                        "_fused_op_156"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        2,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "dim": "c",
                        "m_k": 1,
                        "type": "max",
                        "u_kt": 12
                    }
                }
            },
            "fwd_0_56_temporal_epoch_56": {
                "target_device": 0,
                "input_count": 1,
                "_fused_op_157": {
                    "type": "fused_op",
                    "grid_loc": [
                        0,
                        0
                    ],
                    "grid_size": [
                        2,
                        6
                    ],
                    "inputs": [
                        "e2e__fused_op_156_0",
                        "e2e_softmax_1190.dc.reduce_max.0_0"
                    ],
                    "t": 16,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        3,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 32,
                    "input_dram_io_buf_size_tiles": [
                        24,
                        24
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 12
                            }
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 3
                    }
                },
                "softmax_1190.dc.reduce_sum.3.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        6
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "_fused_op_157",
                        "lc.input_tensor.softmax_1190.dc.reduce_sum.3.0"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 3,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_1194": {
                    "type": "matmul",
                    "grid_loc": [
                        2,
                        1
                    ],
                    "grid_size": [
                        2,
                        4
                    ],
                    "inputs": [
                        "e2e__fused_op_155_0",
                        "bert.encoder.layer.22.attention.self.value.weight",
                        "bert.encoder.layer.22.attention.self.value.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 4,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                },
                "buffer_0_29812_29813": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        7
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "_fused_op_157"
                    ],
                    "t": 16,
                    "mblock": [
                        6,
                        2
                    ],
                    "ublock": [
                        1,
                        6
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        288
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_158": {
                    "type": "fused_op",
                    "grid_loc": [
                        2,
                        0
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "softmax_1190.dc.reduce_sum.3.lc1",
                        "dc.input_tensor.softmax_1190.4",
                        "buffer_0_29812_29813"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        12
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        96,
                        174
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 4
                    }
                },
                "matmul_1201": {
                    "type": "matmul",
                    "grid_loc": [
                        2,
                        5
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "_fused_op_158",
                        "matmul_1194"
                    ],
                    "t": 16,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        3,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 32,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "hslice": 16
                        }
                    ],
                    "attributes": {
                        "l1_acc": true,
                        "m_k": 2,
                        "min_buffer_input": 0,
                        "u_kt": 6
                    }
                },
                "matmul_1205": {
                    "type": "matmul",
                    "grid_loc": [
                        4,
                        0
                    ],
                    "grid_size": [
                        2,
                        4
                    ],
                    "inputs": [
                        "matmul_1201",
                        "bert.encoder.layer.22.attention.output.dense.weight",
                        "bert.encoder.layer.22.attention.output.dense.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 16
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 16,
                        "min_buffer_input": 0,
                        "u_kt": 2
                    }
                },
                "add_1209": {
                    "type": "add",
                    "grid_loc": [
                        2,
                        6
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "matmul_1205",
                        "e2e__fused_op_155_0"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        48
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "layernorm_1210.dc.reduce_sum.0.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        2,
                        7
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "add_1209",
                        "lc.input_tensor.layernorm_1210.dc.reduce_sum.0.0"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_1_29488_29814": {
                    "type": "nop",
                    "grid_loc": [
                        4,
                        4
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "add_1209"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29488_29814": {
                    "type": "nop",
                    "grid_loc": [
                        4,
                        5
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29488_29814"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_159": {
                    "type": "fused_op",
                    "grid_loc": [
                        4,
                        6
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_1210.1",
                        "layernorm_1210.dc.reduce_sum.0.lc1",
                        "buffer_0_29488_29814"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 32
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 5
                    }
                },
                "layernorm_1210.dc.multiply.4": {
                    "type": "multiply",
                    "grid_loc": [
                        4,
                        7
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "_fused_op_159",
                        "_fused_op_159"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "layernorm_1210.dc.reduce_sum.5.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        6,
                        0
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "layernorm_1210.dc.multiply.4",
                        "lc.input_tensor.layernorm_1210.dc.reduce_sum.5.0"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_2_29814_29815": {
                    "type": "nop",
                    "grid_loc": [
                        6,
                        1
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "_fused_op_159"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_1_29814_29815": {
                    "type": "nop",
                    "grid_loc": [
                        6,
                        2
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "buffer_2_29814_29815"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29814_29815": {
                    "type": "nop",
                    "grid_loc": [
                        6,
                        3
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29814_29815"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_160": {
                    "type": "fused_op",
                    "grid_loc": [
                        6,
                        4
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_1210.6",
                        "layernorm_1210.dc.reduce_sum.5.lc1",
                        "dc.input_tensor.layernorm_1210.8",
                        "buffer_0_29814_29815",
                        "bert.encoder.layer.22.attention.output.LayerNorm.weight",
                        "bert.encoder.layer.22.attention.output.LayerNorm.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        32
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        6,
                        0,
                        6,
                        0,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0,
                        0,
                        24,
                        24
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_5_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_4_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 6
                    }
                },
                "matmul_1213": {
                    "type": "matmul",
                    "grid_loc": [
                        8,
                        0
                    ],
                    "grid_size": [
                        2,
                        8
                    ],
                    "inputs": [
                        "_fused_op_160",
                        "bert.encoder.layer.22.intermediate.dense.weight",
                        "bert.encoder.layer.22.intermediate.dense.bias"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "hslice": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "hslice": 2
                        }
                    ],
                    "input_0_tms": [
                        {
                            "broadcast": {
                                "r": 2
                            }
                        },
                        {
                            "vslice": 2
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "gelu_1216": {
                    "type": "gelu",
                    "grid_loc": [
                        6,
                        5
                    ],
                    "grid_size": [
                        2,
                        2
                    ],
                    "inputs": [
                        "matmul_1213"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "approximate_mode": false
                    }
                }
            },
            "fwd_0_57_temporal_epoch_57": {
                "target_device": 0,
                "input_count": 1,
                "matmul_1219": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        0
                    ],
                    "grid_size": [
                        3,
                        8
                    ],
                    "inputs": [
                        "e2e_gelu_1216_0",
                        "bert.encoder.layer.22.output.dense.weight",
                        "bert.encoder.layer.22.output.dense.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        2,
                        4
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 4
                        },
                        "l1_acc": true,
                        "m_k": 16,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                },
                "add_1223": {
                    "type": "add",
                    "grid_loc": [
                        3,
                        0
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "matmul_1219",
                        "e2e__fused_op_160_0"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        48
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "layernorm_1224.dc.reduce_sum.0.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        3,
                        1
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "add_1223",
                        "lc.input_tensor.layernorm_1224.dc.reduce_sum.0.0"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_1_29520_29816": {
                    "type": "nop",
                    "grid_loc": [
                        3,
                        2
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "add_1223"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29520_29816": {
                    "type": "nop",
                    "grid_loc": [
                        3,
                        3
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29520_29816"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_161": {
                    "type": "fused_op",
                    "grid_loc": [
                        3,
                        4
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_1224.1",
                        "layernorm_1224.dc.reduce_sum.0.lc1",
                        "buffer_0_29520_29816"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        128,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 32
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 7
                    }
                },
                "layernorm_1224.dc.multiply.4": {
                    "type": "multiply",
                    "grid_loc": [
                        3,
                        5
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "_fused_op_161",
                        "_fused_op_161"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "layernorm_1224.dc.reduce_sum.5.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        3,
                        6
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "layernorm_1224.dc.multiply.4",
                        "lc.input_tensor.layernorm_1224.dc.reduce_sum.5.0"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_1_29816_29817": {
                    "type": "nop",
                    "grid_loc": [
                        3,
                        7
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "_fused_op_161"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        176
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29816_29817": {
                    "type": "nop",
                    "grid_loc": [
                        6,
                        0
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29816_29817"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        176
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_162": {
                    "type": "fused_op",
                    "grid_loc": [
                        6,
                        1
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_1224.6",
                        "layernorm_1224.dc.reduce_sum.5.lc1",
                        "dc.input_tensor.layernorm_1224.8",
                        "buffer_0_29816_29817",
                        "bert.encoder.layer.22.output.LayerNorm.weight",
                        "bert.encoder.layer.22.output.LayerNorm.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        32
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        4,
                        0,
                        4,
                        0,
                        128,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0,
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_5_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_4_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 8
                    }
                },
                "matmul_1227": {
                    "type": "matmul",
                    "grid_loc": [
                        6,
                        2
                    ],
                    "grid_size": [
                        3,
                        4
                    ],
                    "inputs": [
                        "_fused_op_162",
                        "bert.encoder.layer.23.attention.self.query.weight",
                        "bert.encoder.layer.23.attention.self.query.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 4,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                }
            },
            "fwd_0_58_temporal_epoch_58": {
                "target_device": 0,
                "input_count": 1,
                "matmul_1233": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        0
                    ],
                    "grid_size": [
                        3,
                        4
                    ],
                    "inputs": [
                        "e2e__fused_op_162_0",
                        "bert.encoder.layer.23.attention.self.key.weight",
                        "bert.encoder.layer.23.attention.self.key.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 4,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                },
                "matmul_1239": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        4
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "e2e_matmul_1227_0",
                        "matmul_1233"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        6
                    ],
                    "ublock": [
                        4,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        "transpose",
                        {
                            "vslice": 16
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hslice": 16
                        }
                    ],
                    "attributes": {
                        "l1_acc": true,
                        "m_k": 2,
                        "min_buffer_input": 0,
                        "u_kt": 1
                    }
                },
                "_fused_op_163": {
                    "type": "fused_op",
                    "grid_loc": [
                        0,
                        5
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "matmul_1239",
                        "input_1_multiply_1241",
                        "e2e_multiply_22_attempt_1_input_op_fork_nop2_0"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        6
                    ],
                    "ublock": [
                        4,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        48
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 12
                            }
                        },
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 9,
                        "kernel_broadcast": {
                            "input_1": 1
                        }
                    }
                },
                "softmax_1243.dc.reduce_max.0": {
                    "type": "reduce",
                    "grid_loc": [
                        0,
                        6
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "_fused_op_163"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "dim": "c",
                        "m_k": 1,
                        "type": "max",
                        "u_kt": 12
                    }
                },
                "_fused_op_164": {
                    "type": "fused_op",
                    "grid_loc": [
                        3,
                        0
                    ],
                    "grid_size": [
                        3,
                        6
                    ],
                    "inputs": [
                        "_fused_op_163",
                        "softmax_1243.dc.reduce_max.0"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        400,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 12
                            }
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 10
                    }
                },
                "softmax_1243.dc.reduce_sum.3.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        7
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "_fused_op_164",
                        "lc.input_tensor.softmax_1243.dc.reduce_sum.3.0"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "broadcast": {
                                "z": 16
                            }
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 3,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_1247": {
                    "type": "matmul",
                    "grid_loc": [
                        6,
                        0
                    ],
                    "grid_size": [
                        3,
                        4
                    ],
                    "inputs": [
                        "e2e__fused_op_162_0",
                        "bert.encoder.layer.23.attention.self.value.weight",
                        "bert.encoder.layer.23.attention.self.value.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        4,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 4,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                },
                "_fused_op_165": {
                    "type": "fused_op",
                    "grid_loc": [
                        3,
                        6
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "softmax_1243.dc.reduce_sum.3.lc1",
                        "dc.input_tensor.softmax_1243.4",
                        "_fused_op_164"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        12
                    ],
                    "ublock": [
                        4,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        64,
                        260
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 11
                    }
                },
                "matmul_1254": {
                    "type": "matmul",
                    "grid_loc": [
                        3,
                        7
                    ],
                    "grid_size": [
                        3,
                        1
                    ],
                    "inputs": [
                        "_fused_op_165",
                        "matmul_1247"
                    ],
                    "t": 16,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        4,
                        2
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 32,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "hslice": 16
                        }
                    ],
                    "attributes": {
                        "l1_acc": true,
                        "m_k": 3,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_1258": {
                    "type": "matmul",
                    "grid_loc": [
                        6,
                        4
                    ],
                    "grid_size": [
                        2,
                        4
                    ],
                    "inputs": [
                        "matmul_1254",
                        "bert.encoder.layer.23.attention.output.dense.weight",
                        "bert.encoder.layer.23.attention.output.dense.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        6,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        0,
                        256,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 16
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 8
                        },
                        "l1_acc": true,
                        "m_k": 16,
                        "min_buffer_input": 0,
                        "u_kt": 2
                    }
                }
            },
            "fwd_0_59_temporal_epoch_59": {
                "target_device": 0,
                "input_count": 1,
                "add_1262": {
                    "type": "add",
                    "grid_loc": [
                        0,
                        0
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "e2e_matmul_1258_0",
                        "e2e__fused_op_162_0"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        24,
                        24
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "hslice": 2
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hslice": 2
                        }
                    ]
                },
                "layernorm_1263.dc.reduce_sum.0.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        0,
                        1
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "add_1262",
                        "lc.input_tensor.layernorm_1263.dc.reduce_sum.0.0"
                    ],
                    "t": 1,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_3_29592_29821": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        2
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "add_1262"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_2_29592_29821": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        3
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_3_29592_29821"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_1_29592_29821": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        4
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_2_29592_29821"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29592_29821": {
                    "type": "nop",
                    "grid_loc": [
                        0,
                        5
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29592_29821"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_166": {
                    "type": "fused_op",
                    "grid_loc": [
                        0,
                        6
                    ],
                    "grid_size": [
                        1,
                        2
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_1263.1",
                        "layernorm_1263.dc.reduce_sum.0.lc1",
                        "buffer_0_29592_29821"
                    ],
                    "t": 1,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 32
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 12
                    }
                },
                "layernorm_1263.dc.multiply.4": {
                    "type": "multiply",
                    "grid_loc": [
                        1,
                        0
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "_fused_op_166",
                        "_fused_op_166"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "vslice": 2
                        }
                    ],
                    "input_0_tms": [
                        {
                            "vslice": 2
                        }
                    ]
                },
                "layernorm_1263.dc.reduce_sum.5.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        1,
                        1
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "layernorm_1263.dc.multiply.4",
                        "lc.input_tensor.layernorm_1263.dc.reduce_sum.5.0"
                    ],
                    "t": 2,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 2
                            }
                        },
                        {
                            "broadcast": {
                                "r": 32
                            }
                        },
                        {
                            "hslice": 2
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_4_29821_29822": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        2
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "_fused_op_166"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_0_tms": [
                        {
                            "vslice": 2
                        }
                    ]
                },
                "buffer_3_29821_29822": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        3
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_4_29821_29822"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_2_29821_29822": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        4
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_3_29821_29822"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_1_29821_29822": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        5
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_2_29821_29822"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29821_29822": {
                    "type": "nop",
                    "grid_loc": [
                        1,
                        6
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29821_29822"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_167": {
                    "type": "fused_op",
                    "grid_loc": [
                        1,
                        7
                    ],
                    "grid_size": [
                        2,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_1263.6",
                        "layernorm_1263.dc.reduce_sum.5.lc1",
                        "dc.input_tensor.layernorm_1263.8",
                        "buffer_0_29821_29822",
                        "bert.encoder.layer.23.attention.output.LayerNorm.weight",
                        "bert.encoder.layer.23.attention.output.LayerNorm.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        1,
                        32
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        6,
                        0,
                        6,
                        0,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0,
                        0,
                        24,
                        24
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_5_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_4_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_3_tms": [
                        {
                            "vstack": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "vstack": 2
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 6
                    }
                },
                "matmul_1266": {
                    "type": "matmul",
                    "grid_loc": [
                        3,
                        0
                    ],
                    "grid_size": [
                        2,
                        8
                    ],
                    "inputs": [
                        "_fused_op_167",
                        "bert.encoder.layer.23.intermediate.dense.weight",
                        "bert.encoder.layer.23.intermediate.dense.bias"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        1
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "hslice": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "hslice": 2
                        }
                    ],
                    "input_0_tms": [
                        {
                            "broadcast": {
                                "r": 2
                            }
                        },
                        {
                            "vslice": 2
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "gelu_1269": {
                    "type": "gelu",
                    "grid_loc": [
                        2,
                        0
                    ],
                    "grid_size": [
                        1,
                        4
                    ],
                    "inputs": [
                        "matmul_1266"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "attributes": {
                        "approximate_mode": false
                    }
                },
                "matmul_1272": {
                    "type": "matmul",
                    "grid_loc": [
                        5,
                        0
                    ],
                    "grid_size": [
                        2,
                        8
                    ],
                    "inputs": [
                        "gelu_1269",
                        "bert.encoder.layer.23.output.dense.weight",
                        "bert.encoder.layer.23.output.dense.bias"
                    ],
                    "t": 1,
                    "mblock": [
                        3,
                        1
                    ],
                    "ublock": [
                        2,
                        4
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 4
                        },
                        "l1_acc": true,
                        "m_k": 16,
                        "min_buffer_input": 0,
                        "u_kt": 8
                    }
                },
                "buffer_7_29822_29624": {
                    "type": "nop",
                    "grid_loc": [
                        2,
                        4
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "_fused_op_167"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_0_tms": [
                        {
                            "hslice": 2
                        }
                    ]
                },
                "buffer_6_29822_29624": {
                    "type": "nop",
                    "grid_loc": [
                        2,
                        5
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_7_29822_29624"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_5_29822_29624": {
                    "type": "nop",
                    "grid_loc": [
                        2,
                        6
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_6_29822_29624"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_4_29822_29624": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        0
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_5_29822_29624"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_3_29822_29624": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        1
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_4_29822_29624"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_2_29822_29624": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        2
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_3_29822_29624"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_1_29822_29624": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        3
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_2_29822_29624"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29822_29624": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        4
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29822_29624"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "add_1276": {
                    "type": "add",
                    "grid_loc": [
                        7,
                        5
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "matmul_1272",
                        "buffer_0_29822_29624"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_0_tms": [
                        {
                            "hslice": 2
                        }
                    ]
                },
                "layernorm_1277.dc.reduce_sum.0.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        7,
                        6
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "add_1276",
                        "lc.input_tensor.layernorm_1277.dc.reduce_sum.0.0"
                    ],
                    "t": 1,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "r": 32
                            }
                        }
                    ],
                    "input_0_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_3_29624_29823": {
                    "type": "nop",
                    "grid_loc": [
                        7,
                        7
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "add_1276"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_2_29624_29823": {
                    "type": "nop",
                    "grid_loc": [
                        8,
                        0
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_3_29624_29823"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_1_29624_29823": {
                    "type": "nop",
                    "grid_loc": [
                        8,
                        1
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_2_29624_29823"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29624_29823": {
                    "type": "nop",
                    "grid_loc": [
                        8,
                        2
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29624_29823"
                    ],
                    "t": 2,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_168": {
                    "type": "fused_op",
                    "grid_loc": [
                        8,
                        3
                    ],
                    "grid_size": [
                        1,
                        2
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_1277.1",
                        "layernorm_1277.dc.reduce_sum.0.lc1",
                        "buffer_0_29624_29823"
                    ],
                    "t": 1,
                    "mblock": [
                        12,
                        2
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        48,
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "hstack": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 32
                            }
                        }
                    ],
                    "attributes": {
                        "fused_op_id": 12
                    }
                },
                "layernorm_1277.dc.multiply.4": {
                    "type": "multiply",
                    "grid_loc": [
                        8,
                        5
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "_fused_op_168",
                        "_fused_op_168"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "c",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "vslice": 2
                        }
                    ],
                    "input_0_tms": [
                        {
                            "vslice": 2
                        }
                    ]
                },
                "layernorm_1277.dc.reduce_sum.5.lc1": {
                    "type": "matmul",
                    "grid_loc": [
                        8,
                        6
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "layernorm_1277.dc.multiply.4",
                        "lc.input_tensor.layernorm_1277.dc.reduce_sum.5.0"
                    ],
                    "t": 2,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 2
                            }
                        },
                        {
                            "broadcast": {
                                "r": 32
                            }
                        },
                        {
                            "hslice": 2
                        }
                    ],
                    "attributes": {
                        "kernel_broadcast": {
                            "input_1": 1
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "buffer_2_29823_29824": {
                    "type": "nop",
                    "grid_loc": [
                        8,
                        7
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "_fused_op_168"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_0_tms": [
                        {
                            "vslice": 2
                        }
                    ]
                },
                "buffer_1_29823_29824": {
                    "type": "nop",
                    "grid_loc": [
                        9,
                        0
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_2_29823_29824"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "buffer_0_29823_29824": {
                    "type": "nop",
                    "grid_loc": [
                        9,
                        1
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "buffer_1_29823_29824"
                    ],
                    "t": 2,
                    "mblock": [
                        6,
                        4
                    ],
                    "ublock": [
                        1,
                        8
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3"
                },
                "_fused_op_169": {
                    "type": "fused_op",
                    "grid_loc": [
                        9,
                        2
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "dc.input_tensor.layernorm_1277.6",
                        "layernorm_1277.dc.reduce_sum.5.lc1",
                        "dc.input_tensor.layernorm_1277.8",
                        "buffer_0_29823_29824",
                        "bert.encoder.layer.23.output.LayerNorm.weight",
                        "bert.encoder.layer.23.output.LayerNorm.bias"
                    ],
                    "t": 2,
                    "mblock": [
                        2,
                        32
                    ],
                    "ublock": [
                        3,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_buf_min_size_tiles": [
                        12,
                        0,
                        12,
                        0,
                        0,
                        0
                    ],
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0,
                        0,
                        24,
                        24
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_5_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "vslice": 2
                        }
                    ],
                    "input_4_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "vslice": 2
                        }
                    ],
                    "input_2_tms": [
                        {
                            "vslice": 2
                        }
                    ],
                    "input_0_tms": [
                        {
                            "vslice": 2
                        }
                    ],
                    "attributes": {
                        "approximate_mode": false,
                        "fused_op_id": 169
                    }
                },
                "matmul_1281": {
                    "type": "matmul",
                    "grid_loc": [
                        9,
                        3
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "_fused_op_169",
                        "qa_outputs.weight",
                        "qa_outputs.bias"
                    ],
                    "t": 2,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "vslice": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 2
                            }
                        },
                        {
                            "hslice": 2
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 1,
                            "input_1": 32
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_1281_output_nop_0": {
                    "type": "nop",
                    "grid_loc": [
                        9,
                        5
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "matmul_1281"
                    ],
                    "untilize_output": true,
                    "t": 1,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_0_tms": [
                        {
                            "vstack": 2
                        }
                    ]
                },
                "matmul_1288": {
                    "type": "matmul",
                    "grid_loc": [
                        9,
                        4
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "_fused_op_169",
                        "qa_outputs.weight_fork_clone19",
                        "qa_outputs.bias_fork_clone12"
                    ],
                    "t": 2,
                    "mblock": [
                        1,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0,
                        0,
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b",
                        "Float16_b",
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_2_tms": [
                        {
                            "broadcast": {
                                "r": 12
                            }
                        },
                        {
                            "vslice": 2
                        }
                    ],
                    "input_1_tms": [
                        {
                            "broadcast": {
                                "c": 2
                            }
                        },
                        {
                            "hslice": 2
                        }
                    ],
                    "attributes": {
                        "bias": true,
                        "kernel_broadcast": {
                            "input_2": 1,
                            "input_1": 32
                        },
                        "l1_acc": true,
                        "m_k": 8,
                        "min_buffer_input": 0,
                        "u_kt": 4
                    }
                },
                "matmul_1288_output_nop_0": {
                    "type": "nop",
                    "grid_loc": [
                        9,
                        6
                    ],
                    "grid_size": [
                        1,
                        1
                    ],
                    "inputs": [
                        "matmul_1288"
                    ],
                    "untilize_output": true,
                    "t": 1,
                    "mblock": [
                        2,
                        1
                    ],
                    "ublock": [
                        6,
                        1
                    ],
                    "tile_dim": [
                        32,
                        32
                    ],
                    "buf_size_mb": 2,
                    "input_dram_io_buf_size_tiles": [
                        0
                    ],
                    "ublock_order": "r",
                    "in_df": [
                        "Float16_b"
                    ],
                    "out_df": "Float16_b",
                    "intermed_df": "Float16_b",
                    "acc_df": "Float16_b",
                    "math_fidelity": "HiFi3",
                    "input_0_tms": [
                        {
                            "vstack": 2
                        }
                    ]
                }
            }
        },
        "programs": [
            {
                "run_fwd_0": [
                    {
                        "param": [
                            "$p_loop_count"
                        ]
                    },
                    {
                        "var": {
                            "$c_microbatch_size": 1,
                            "$c_one": 1,
                            "$c_zero": 0
                        }
                    },
                    {
                        "staticvar": {
                            "$gptr_q66_shadow": 0,
                            "$gptr_q59_shadow": 0,
                            "$gptr_q56_shadow": 0,
                            "$gptr_q48_shadow": 0,
                            "$gptr_q45_shadow": 0,
                            "$gptr_q41_shadow": 0,
                            "$gptr_q53_shadow": 0,
                            "$gptr_q10_shadow": 0,
                            "$gptr_q20_shadow": 0,
                            "$gptr_q3_shadow": 0,
                            "$gptr_q28_shadow": 0,
                            "$gptr_q31_shadow": 0,
                            "$gptr_q38_shadow": 0,
                            "$gptr_q80": 0,
                            "$lptr_q81": 0,
                            "$gptr_q17_shadow": 0,
                            "$gptr_q25_shadow": 0,
                            "$gptr_q78": 0,
                            "$lptr_q78": 0,
                            "$gptr_q77": 0,
                            "$gptr_q76_shadow": 0,
                            "$lptr_q75": 0,
                            "$gptr_q73": 0,
                            "$lptr_q73": 0,
                            "$gptr_q74": 0,
                            "$lptr_q74": 0,
                            "$gptr_q72": 0,
                            "$lptr_q72": 0,
                            "$lptr_q71": 0,
                            "$gptr_q71": 0,
                            "$gptr_q69": 0,
                            "$gptr_q62_shadow": 0,
                            "$gptr_q70": 0,
                            "$gptr_q68": 0,
                            "$gptr_q66": 0,
                            "$gptr_q81_shadow": 0,
                            "$lptr_q65": 0,
                            "$lptr_q64": 0,
                            "$lptr_q70": 0,
                            "$lptr_q68": 0,
                            "$gptr_q62": 0,
                            "$lptr_q62": 0,
                            "$gptr_q2": 0,
                            "$lptr_q66": 0,
                            "$lptr_q3": 0,
                            "$lptr_q0": 0,
                            "$lptr_q18": 0,
                            "$gptr_q81": 0,
                            "$lptr_q20": 0,
                            "$gptr_q24": 0,
                            "$gptr_q19": 0,
                            "$lptr_q59": 0,
                            "$lptr_q5": 0,
                            "$lptr_q1": 0,
                            "$gptr_q21": 0,
                            "$lptr_q46": 0,
                            "$lptr_q77": 0,
                            "$gptr_q50": 0,
                            "$gptr_q23": 0,
                            "$lptr_q15": 0,
                            "$gptr_q65": 0,
                            "$gptr_q22": 0,
                            "$lptr_q24": 0,
                            "$gptr_q75": 0,
                            "$gptr_q25": 0,
                            "$gptr_q30": 0,
                            "$lptr_q9": 0,
                            "$lptr_q10": 0,
                            "$gptr_q4": 0,
                            "$lptr_q43": 0,
                            "$gptr_q34_shadow": 0,
                            "$lptr_q67": 0,
                            "$gptr_q17": 0,
                            "$lptr_q35": 0,
                            "$gptr_q6": 0,
                            "$lptr_q4": 0,
                            "$gptr_q69_shadow": 0,
                            "$lptr_q14": 0,
                            "$lptr_q29": 0,
                            "$gptr_q13": 0,
                            "$gptr_q42": 0,
                            "$lptr_q33": 0,
                            "$lptr_q49": 0,
                            "$gptr_q48": 0,
                            "$lptr_q36": 0,
                            "$lptr_q76": 0,
                            "$lptr_q26": 0,
                            "$lptr_q51": 0,
                            "$lptr_q23": 0,
                            "$gptr_q39": 0,
                            "$lptr_q2": 0,
                            "$lptr_q60": 0,
                            "$gptr_q15": 0,
                            "$gptr_q6_shadow": 0,
                            "$lptr_q82": 0,
                            "$lptr_q12": 0,
                            "$gptr_q46": 0,
                            "$gptr_q34": 0,
                            "$gptr_q33": 0,
                            "$lptr_q28": 0,
                            "$lptr_q27": 0,
                            "$gptr_q63": 0,
                            "$lptr_q56": 0,
                            "$gptr_q31": 0,
                            "$lptr_q32": 0,
                            "$lptr_q39": 0,
                            "$gptr_q51": 0,
                            "$lptr_q31": 0,
                            "$gptr_q73_shadow": 0,
                            "$gptr_q76": 0,
                            "$gptr_q28": 0,
                            "$gptr_q35": 0,
                            "$gptr_q32": 0,
                            "$lptr_q41": 0,
                            "$gptr_q38": 0,
                            "$lptr_q80": 0,
                            "$gptr_q7": 0,
                            "$gptr_q79": 0,
                            "$lptr_q42": 0,
                            "$lptr_q44": 0,
                            "$gptr_q27": 0,
                            "$lptr_q30": 0,
                            "$gptr_q5": 0,
                            "$gptr_q37": 0,
                            "$lptr_q7": 0,
                            "$gptr_q3": 0,
                            "$lptr_q61": 0,
                            "$lptr_q69": 0,
                            "$gptr_q20": 0,
                            "$lptr_q17": 0,
                            "$gptr_q82": 0,
                            "$lptr_q6": 0,
                            "$lptr_q8": 0,
                            "$lptr_q45": 0,
                            "$gptr_q8": 0,
                            "$gptr_q0": 0,
                            "$lptr_q40": 0,
                            "$gptr_q55": 0,
                            "$gptr_q9": 0,
                            "$gptr_q11": 0,
                            "$gptr_q64": 0,
                            "$lptr_q34": 0,
                            "$gptr_q10": 0,
                            "$gptr_q12": 0,
                            "$lptr_q19": 0,
                            "$lptr_q63": 0,
                            "$gptr_q14": 0,
                            "$gptr_q13_shadow": 0,
                            "$gptr_q43": 0,
                            "$lptr_q13": 0,
                            "$lptr_q22": 0,
                            "$lptr_q16": 0,
                            "$lptr_q11": 0,
                            "$gptr_q16": 0,
                            "$gptr_q67": 0,
                            "$gptr_q40": 0,
                            "$gptr_q29": 0,
                            "$gptr_q41": 0,
                            "$lptr_q38": 0,
                            "$gptr_q44": 0,
                            "$lptr_q25": 0,
                            "$gptr_q45": 0,
                            "$lptr_q47": 0,
                            "$gptr_q47": 0,
                            "$gptr_q53": 0,
                            "$gptr_q54": 0,
                            "$gptr_q49": 0,
                            "$lptr_q48": 0,
                            "$gptr_q1": 0,
                            "$lptr_q53": 0,
                            "$lptr_q52": 0,
                            "$gptr_q52": 0,
                            "$gptr_q18": 0,
                            "$lptr_q37": 0,
                            "$lptr_q54": 0,
                            "$gptr_q26": 0,
                            "$gptr_q56": 0,
                            "$gptr_q36": 0,
                            "$lptr_q57": 0,
                            "$lptr_q55": 0,
                            "$lptr_q79": 0,
                            "$gptr_q59": 0,
                            "$lptr_q58": 0,
                            "$gptr_q57": 0,
                            "$lptr_q21": 0,
                            "$lptr_q50": 0,
                            "$gptr_q58": 0,
                            "$gptr_q60": 0,
                            "$gptr_q61": 0
                        }
                    },
                    {
                        "loop": "$p_loop_count"
                    },
                    {
                        "varinst": [
                            "$gptr_q38",
                            "set",
                            "$gptr_q38_shadow"
                        ]
                    },
                    {
                        "varinst": [
                            "$gptr_q34",
                            "set",
                            "$gptr_q34_shadow"
                        ]
                    },
                    {
                        "varinst": [
                            "$gptr_q31",
                            "set",
                            "$gptr_q31_shadow"
                        ]
                    },
                    {
                        "varinst": [
                            "$gptr_q28",
                            "set",
                            "$gptr_q28_shadow"
                        ]
                    },
                    {
                        "varinst": [
                            "$gptr_q25",
                            "set",
                            "$gptr_q25_shadow"
                        ]
                    },
                    {
                        "varinst": [
                            "$gptr_q20",
                            "set",
                            "$gptr_q20_shadow"
                        ]
                    },
                    {
                        "varinst": [
                            "$gptr_q17",
                            "set",
                            "$gptr_q17_shadow"
                        ]
                    },
                    {
                        "varinst": [
                            "$gptr_q3",
                            "set",
                            "$gptr_q3_shadow"
                        ]
                    },
                    {
                        "varinst": [
                            "$gptr_q6",
                            "set",
                            "$gptr_q6_shadow"
                        ]
                    },
                    {
                        "varinst": [
                            "$gptr_q10",
                            "set",
                            "$gptr_q10_shadow"
                        ]
                    },
                    {
                        "varinst": [
                            "$gptr_q13",
                            "set",
                            "$gptr_q13_shadow"
                        ]
                    },
                    {
                        "varinst": [
                            "$gptr_q41",
                            "set",
                            "$gptr_q41_shadow"
                        ]
                    },
                    {
                        "varinst": [
                            "$gptr_q45",
                            "set",
                            "$gptr_q45_shadow"
                        ]
                    },
                    {
                        "varinst": [
                            "$gptr_q48",
                            "set",
                            "$gptr_q48_shadow"
                        ]
                    },
                    {
                        "varinst": [
                            "$gptr_q53",
                            "set",
                            "$gptr_q53_shadow"
                        ]
                    },
                    {
                        "varinst": [
                            "$gptr_q56",
                            "set",
                            "$gptr_q56_shadow"
                        ]
                    },
                    {
                        "varinst": [
                            "$gptr_q59",
                            "set",
                            "$gptr_q59_shadow"
                        ]
                    },
                    {
                        "varinst": [
                            "$gptr_q62",
                            "set",
                            "$gptr_q62_shadow"
                        ]
                    },
                    {
                        "varinst": [
                            "$gptr_q66",
                            "set",
                            "$gptr_q66_shadow"
                        ]
                    },
                    {
                        "varinst": [
                            "$gptr_q69",
                            "set",
                            "$gptr_q69_shadow"
                        ]
                    },
                    {
                        "varinst": [
                            "$gptr_q73",
                            "set",
                            "$gptr_q73_shadow"
                        ]
                    },
                    {
                        "varinst": [
                            "$gptr_q76",
                            "set",
                            "$gptr_q76_shadow"
                        ]
                    },
                    {
                        "varinst": [
                            "$gptr_q81",
                            "set",
                            "$gptr_q81_shadow"
                        ]
                    },
                    {
                        "execute": {
                            "graph_name": "fwd_0_0_temporal_epoch_0",
                            "queue_settings": {
                                "pybuda_6_i0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q0",
                                    "rd_ptr_global": "$gptr_q0"
                                },
                                "attention_mask_1": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q0",
                                    "rd_ptr_global": "$gptr_q0"
                                },
                                "lc.input_tensor.layernorm_0.dc.reduce_sum.0.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_0.1": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_0.dc.reduce_sum.5.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_0.6": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_0.8": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.embeddings.LayerNorm.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.embeddings.LayerNorm.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.0.attention.self.query.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.0.attention.self.query.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.0.attention.self.key.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.0.attention.self.key.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "input_1_multiply_18": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "input_0_subtract_21": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "input_1_multiply_22": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                }
                            }
                        }
                    },
                    {
                        "varinst": [
                            "$gptr_q0",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q0",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "execute": {
                            "graph_name": "fwd_0_1_temporal_epoch_1",
                            "queue_settings": {
                                "e2e__fused_op_1_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q1",
                                    "rd_ptr_global": "$gptr_q1"
                                },
                                "e2e__fused_op_2_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q1",
                                    "rd_ptr_global": "$gptr_q1"
                                },
                                "e2e_softmax_24.dc.reduce_max.0_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q1",
                                    "rd_ptr_global": "$gptr_q1"
                                },
                                "lc.input_tensor.softmax_24.dc.reduce_sum.3.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.softmax_24.4": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.0.attention.self.value.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.0.attention.self.value.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.0.attention.output.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.0.attention.output.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_44.dc.reduce_sum.0.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_44.1": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_autoinc": 0,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_44.dc.reduce_sum.5.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_44.6": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_44.8": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.0.attention.output.LayerNorm.weight": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.0.attention.output.LayerNorm.bias": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.0.intermediate.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.0.intermediate.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                }
                            }
                        }
                    },
                    {
                        "varinst": [
                            "$gptr_q1",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q1",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "execute": {
                            "graph_name": "fwd_0_2_temporal_epoch_2",
                            "queue_settings": {
                                "e2e__fused_op_6_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q2",
                                    "rd_ptr_global": "$gptr_q2"
                                },
                                "e2e_gelu_50_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q2",
                                    "rd_ptr_global": "$gptr_q2"
                                },
                                "bert.encoder.layer.0.output.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.0.output.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_58.dc.reduce_sum.0.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_58.1": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_58.dc.reduce_sum.5.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_58.6": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_58.8": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.0.output.LayerNorm.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.0.output.LayerNorm.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.1.attention.self.query.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.1.attention.self.query.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                }
                            }
                        }
                    },
                    {
                        "varinst": [
                            "$gptr_q2",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q2",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "execute": {
                            "graph_name": "fwd_0_3_temporal_epoch_3",
                            "queue_settings": {
                                "e2e_multiply_22_attempt_1_input_op_fork_nop0_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q3",
                                    "rd_ptr_global": "$gptr_q3"
                                },
                                "e2e__fused_op_8_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q3",
                                    "rd_ptr_global": "$gptr_q3"
                                },
                                "e2e_matmul_61_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q4",
                                    "rd_ptr_global": "$gptr_q4"
                                },
                                "bert.encoder.layer.1.attention.self.key.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.1.attention.self.key.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "input_1_multiply_75": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.softmax_77.dc.reduce_sum.3.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.softmax_77.4": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.1.attention.self.value.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.1.attention.self.value.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.1.attention.output.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.1.attention.output.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                }
                            }
                        }
                    },
                    {
                        "varinst": [
                            "$gptr_q3_shadow",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$gptr_q4",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q3",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q4",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "execute": {
                            "graph_name": "fwd_0_4_temporal_epoch_4",
                            "queue_settings": {
                                "e2e__fused_op_8_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q5",
                                    "rd_ptr_global": "$gptr_q5"
                                },
                                "e2e_matmul_92_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q5",
                                    "rd_ptr_global": "$gptr_q5"
                                },
                                "lc.input_tensor.layernorm_97.dc.reduce_sum.0.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_97.1": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_autoinc": 0,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_97.dc.reduce_sum.5.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_97.6": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_97.8": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.1.attention.output.LayerNorm.weight": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.1.attention.output.LayerNorm.bias": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.1.intermediate.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.1.intermediate.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.1.output.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.1.output.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_111.dc.reduce_sum.0.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_111.1": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_autoinc": 0,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_111.dc.reduce_sum.5.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                }
                            }
                        }
                    },
                    {
                        "varinst": [
                            "$gptr_q5",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q5",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "execute": {
                            "graph_name": "fwd_0_5_temporal_epoch_5",
                            "queue_settings": {
                                "e2e_multiply_22_attempt_1_input_op_fork_nop0_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q6",
                                    "rd_ptr_global": "$gptr_q6"
                                },
                                "e2e__fused_op_14_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q7",
                                    "rd_ptr_global": "$gptr_q7"
                                },
                                "e2e_layernorm_111.dc.reduce_sum.5.lc1_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q7",
                                    "rd_ptr_global": "$gptr_q7"
                                },
                                "dc.input_tensor.layernorm_111.6": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_111.8": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.1.output.LayerNorm.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.1.output.LayerNorm.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.2.attention.self.query.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.2.attention.self.query.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.2.attention.self.key.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.2.attention.self.key.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "input_1_multiply_128": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                }
                            }
                        }
                    },
                    {
                        "varinst": [
                            "$gptr_q6_shadow",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$gptr_q7",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q6",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q7",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "execute": {
                            "graph_name": "fwd_0_6_temporal_epoch_6",
                            "queue_settings": {
                                "e2e__fused_op_15_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q8",
                                    "rd_ptr_global": "$gptr_q8"
                                },
                                "e2e__fused_op_16_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q8",
                                    "rd_ptr_global": "$gptr_q8"
                                },
                                "e2e_softmax_130.dc.reduce_max.0_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q8",
                                    "rd_ptr_global": "$gptr_q8"
                                },
                                "lc.input_tensor.softmax_130.dc.reduce_sum.3.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.softmax_130.4": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.2.attention.self.value.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.2.attention.self.value.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.2.attention.output.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.2.attention.output.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_150.dc.reduce_sum.0.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_150.1": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_autoinc": 0,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_150.dc.reduce_sum.5.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_150.6": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_150.8": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.2.attention.output.LayerNorm.weight": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.2.attention.output.LayerNorm.bias": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.2.intermediate.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.2.intermediate.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                }
                            }
                        }
                    },
                    {
                        "varinst": [
                            "$gptr_q8",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q8",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "execute": {
                            "graph_name": "fwd_0_7_temporal_epoch_7",
                            "queue_settings": {
                                "e2e__fused_op_20_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q9",
                                    "rd_ptr_global": "$gptr_q9"
                                },
                                "e2e_gelu_156_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q9",
                                    "rd_ptr_global": "$gptr_q9"
                                },
                                "bert.encoder.layer.2.output.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.2.output.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_164.dc.reduce_sum.0.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_164.1": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_164.dc.reduce_sum.5.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_164.6": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_164.8": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.2.output.LayerNorm.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.2.output.LayerNorm.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.3.attention.self.query.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.3.attention.self.query.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                }
                            }
                        }
                    },
                    {
                        "varinst": [
                            "$gptr_q9",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q9",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "execute": {
                            "graph_name": "fwd_0_8_temporal_epoch_8",
                            "queue_settings": {
                                "e2e_multiply_22_attempt_1_input_op_fork_nop0_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q10",
                                    "rd_ptr_global": "$gptr_q10"
                                },
                                "e2e__fused_op_22_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q10",
                                    "rd_ptr_global": "$gptr_q10"
                                },
                                "e2e_matmul_167_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q11",
                                    "rd_ptr_global": "$gptr_q11"
                                },
                                "bert.encoder.layer.3.attention.self.key.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.3.attention.self.key.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "input_1_multiply_181": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.softmax_183.dc.reduce_sum.3.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.softmax_183.4": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.3.attention.self.value.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.3.attention.self.value.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.3.attention.output.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.3.attention.output.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                }
                            }
                        }
                    },
                    {
                        "varinst": [
                            "$gptr_q10_shadow",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$gptr_q11",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q10",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q11",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "execute": {
                            "graph_name": "fwd_0_9_temporal_epoch_9",
                            "queue_settings": {
                                "e2e__fused_op_22_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q12",
                                    "rd_ptr_global": "$gptr_q12"
                                },
                                "e2e_matmul_198_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q12",
                                    "rd_ptr_global": "$gptr_q12"
                                },
                                "lc.input_tensor.layernorm_203.dc.reduce_sum.0.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_203.1": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_autoinc": 0,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_203.dc.reduce_sum.5.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_203.6": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_203.8": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.3.attention.output.LayerNorm.weight": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.3.attention.output.LayerNorm.bias": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.3.intermediate.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.3.intermediate.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.3.output.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.3.output.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_217.dc.reduce_sum.0.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_217.1": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_autoinc": 0,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_217.dc.reduce_sum.5.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                }
                            }
                        }
                    },
                    {
                        "varinst": [
                            "$gptr_q12",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q12",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "execute": {
                            "graph_name": "fwd_0_10_temporal_epoch_10",
                            "queue_settings": {
                                "e2e_multiply_22_attempt_1_input_op_fork_nop0_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q13",
                                    "rd_ptr_global": "$gptr_q13"
                                },
                                "e2e__fused_op_28_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q14",
                                    "rd_ptr_global": "$gptr_q14"
                                },
                                "e2e_layernorm_217.dc.reduce_sum.5.lc1_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q14",
                                    "rd_ptr_global": "$gptr_q14"
                                },
                                "dc.input_tensor.layernorm_217.6": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_217.8": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.3.output.LayerNorm.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.3.output.LayerNorm.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.4.attention.self.query.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.4.attention.self.query.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.4.attention.self.key.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.4.attention.self.key.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "input_1_multiply_234": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                }
                            }
                        }
                    },
                    {
                        "varinst": [
                            "$gptr_q13_shadow",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$gptr_q14",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q13",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q14",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "execute": {
                            "graph_name": "fwd_0_11_temporal_epoch_11",
                            "queue_settings": {
                                "e2e__fused_op_29_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q15",
                                    "rd_ptr_global": "$gptr_q15"
                                },
                                "e2e__fused_op_30_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q15",
                                    "rd_ptr_global": "$gptr_q15"
                                },
                                "e2e_softmax_236.dc.reduce_max.0_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q15",
                                    "rd_ptr_global": "$gptr_q15"
                                },
                                "lc.input_tensor.softmax_236.dc.reduce_sum.3.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.softmax_236.4": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.4.attention.self.value.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.4.attention.self.value.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.4.attention.output.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.4.attention.output.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_256.dc.reduce_sum.0.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_256.1": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_autoinc": 0,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_256.dc.reduce_sum.5.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_256.6": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_256.8": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.4.attention.output.LayerNorm.weight": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.4.attention.output.LayerNorm.bias": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.4.intermediate.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.4.intermediate.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                }
                            }
                        }
                    },
                    {
                        "varinst": [
                            "$gptr_q15",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q15",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "execute": {
                            "graph_name": "fwd_0_12_temporal_epoch_12",
                            "queue_settings": {
                                "e2e__fused_op_34_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q16",
                                    "rd_ptr_global": "$gptr_q16"
                                },
                                "e2e_gelu_262_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q16",
                                    "rd_ptr_global": "$gptr_q16"
                                },
                                "bert.encoder.layer.4.output.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.4.output.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_270.dc.reduce_sum.0.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_270.1": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_270.dc.reduce_sum.5.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_270.6": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_270.8": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.4.output.LayerNorm.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.4.output.LayerNorm.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.5.attention.self.query.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.5.attention.self.query.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                }
                            }
                        }
                    },
                    {
                        "varinst": [
                            "$gptr_q16",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q16",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "execute": {
                            "graph_name": "fwd_0_13_temporal_epoch_13",
                            "queue_settings": {
                                "e2e_multiply_22_attempt_1_input_op_fork_nop0_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q17",
                                    "rd_ptr_global": "$gptr_q17"
                                },
                                "e2e__fused_op_36_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q17",
                                    "rd_ptr_global": "$gptr_q17"
                                },
                                "e2e_matmul_273_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q18",
                                    "rd_ptr_global": "$gptr_q18"
                                },
                                "bert.encoder.layer.5.attention.self.key.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.5.attention.self.key.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "input_1_multiply_287": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.softmax_289.dc.reduce_sum.3.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.softmax_289.4": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.5.attention.self.value.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.5.attention.self.value.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.5.attention.output.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.5.attention.output.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                }
                            }
                        }
                    },
                    {
                        "varinst": [
                            "$gptr_q17_shadow",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$gptr_q18",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q17",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q18",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "execute": {
                            "graph_name": "fwd_0_14_temporal_epoch_14",
                            "queue_settings": {
                                "e2e__fused_op_36_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q19",
                                    "rd_ptr_global": "$gptr_q19"
                                },
                                "e2e_matmul_304_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q19",
                                    "rd_ptr_global": "$gptr_q19"
                                },
                                "lc.input_tensor.layernorm_309.dc.reduce_sum.0.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_309.1": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_autoinc": 0,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_309.dc.reduce_sum.5.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_309.6": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_309.8": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.5.attention.output.LayerNorm.weight": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.5.attention.output.LayerNorm.bias": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.5.intermediate.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.5.intermediate.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.5.output.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.5.output.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_323.dc.reduce_sum.0.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_323.1": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_autoinc": 0,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_323.dc.reduce_sum.5.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                }
                            }
                        }
                    },
                    {
                        "varinst": [
                            "$gptr_q19",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q19",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "execute": {
                            "graph_name": "fwd_0_15_temporal_epoch_15",
                            "queue_settings": {
                                "e2e_multiply_22_attempt_1_input_op_fork_nop0_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q20",
                                    "rd_ptr_global": "$gptr_q20"
                                },
                                "e2e__fused_op_42_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q21",
                                    "rd_ptr_global": "$gptr_q21"
                                },
                                "e2e_layernorm_323.dc.reduce_sum.5.lc1_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q21",
                                    "rd_ptr_global": "$gptr_q21"
                                },
                                "dc.input_tensor.layernorm_323.6": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_323.8": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.5.output.LayerNorm.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.5.output.LayerNorm.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.6.attention.self.query.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.6.attention.self.query.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.6.attention.self.key.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.6.attention.self.key.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "input_1_multiply_340": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                }
                            }
                        }
                    },
                    {
                        "varinst": [
                            "$gptr_q20_shadow",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$gptr_q21",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q20",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q21",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "execute": {
                            "graph_name": "fwd_0_16_temporal_epoch_16",
                            "queue_settings": {
                                "e2e__fused_op_43_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q22",
                                    "rd_ptr_global": "$gptr_q22"
                                },
                                "e2e__fused_op_44_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q22",
                                    "rd_ptr_global": "$gptr_q22"
                                },
                                "e2e_softmax_342.dc.reduce_max.0_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q22",
                                    "rd_ptr_global": "$gptr_q22"
                                },
                                "lc.input_tensor.softmax_342.dc.reduce_sum.3.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.softmax_342.4": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.6.attention.self.value.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.6.attention.self.value.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.6.attention.output.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.6.attention.output.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_362.dc.reduce_sum.0.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_362.1": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_autoinc": 0,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_362.dc.reduce_sum.5.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_362.6": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_362.8": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.6.attention.output.LayerNorm.weight": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.6.attention.output.LayerNorm.bias": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.6.intermediate.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.6.intermediate.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                }
                            }
                        }
                    },
                    {
                        "varinst": [
                            "$gptr_q22",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q22",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "execute": {
                            "graph_name": "fwd_0_17_temporal_epoch_17",
                            "queue_settings": {
                                "e2e__fused_op_48_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q23",
                                    "rd_ptr_global": "$gptr_q23"
                                },
                                "e2e_gelu_368_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q23",
                                    "rd_ptr_global": "$gptr_q23"
                                },
                                "bert.encoder.layer.6.output.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.6.output.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_376.dc.reduce_sum.0.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_376.1": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_376.dc.reduce_sum.5.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_376.6": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_376.8": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.6.output.LayerNorm.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.6.output.LayerNorm.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.7.attention.self.query.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.7.attention.self.query.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                }
                            }
                        }
                    },
                    {
                        "varinst": [
                            "$gptr_q23",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q23",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "execute": {
                            "graph_name": "fwd_0_18_temporal_epoch_18",
                            "queue_settings": {
                                "e2e_multiply_22_attempt_1_input_op_fork_nop0_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q24",
                                    "rd_ptr_global": "$gptr_q24"
                                },
                                "e2e__fused_op_50_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q25",
                                    "rd_ptr_global": "$gptr_q25"
                                },
                                "e2e_matmul_379_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q24",
                                    "rd_ptr_global": "$gptr_q24"
                                },
                                "bert.encoder.layer.7.attention.self.key.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.7.attention.self.key.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "input_1_multiply_393": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.softmax_395.dc.reduce_sum.3.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.softmax_395.4": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.7.attention.self.value.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.7.attention.self.value.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.7.attention.output.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.7.attention.output.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                }
                            }
                        }
                    },
                    {
                        "varinst": [
                            "$gptr_q24",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$gptr_q25_shadow",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q24",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q25",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "execute": {
                            "graph_name": "fwd_0_19_temporal_epoch_19",
                            "queue_settings": {
                                "e2e__fused_op_50_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q26",
                                    "rd_ptr_global": "$gptr_q26"
                                },
                                "e2e_matmul_410_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q26",
                                    "rd_ptr_global": "$gptr_q26"
                                },
                                "lc.input_tensor.layernorm_415.dc.reduce_sum.0.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_415.1": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_autoinc": 0,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_415.dc.reduce_sum.5.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_415.6": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_415.8": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.7.attention.output.LayerNorm.weight": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.7.attention.output.LayerNorm.bias": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.7.intermediate.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.7.intermediate.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.7.output.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.7.output.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_429.dc.reduce_sum.0.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_429.1": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_autoinc": 0,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_429.dc.reduce_sum.5.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                }
                            }
                        }
                    },
                    {
                        "varinst": [
                            "$gptr_q26",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q26",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "execute": {
                            "graph_name": "fwd_0_20_temporal_epoch_20",
                            "queue_settings": {
                                "e2e__fused_op_56_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q27",
                                    "rd_ptr_global": "$gptr_q27"
                                },
                                "e2e_layernorm_429.dc.reduce_sum.5.lc1_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q27",
                                    "rd_ptr_global": "$gptr_q27"
                                },
                                "e2e_multiply_22_attempt_1_input_op_fork_nop1_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q28",
                                    "rd_ptr_global": "$gptr_q28"
                                },
                                "dc.input_tensor.layernorm_429.6": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_429.8": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.7.output.LayerNorm.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.7.output.LayerNorm.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.8.attention.self.query.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.8.attention.self.query.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.8.attention.self.key.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.8.attention.self.key.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "input_1_multiply_446": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                }
                            }
                        }
                    },
                    {
                        "varinst": [
                            "$gptr_q27",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$gptr_q28_shadow",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q27",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q28",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "execute": {
                            "graph_name": "fwd_0_21_temporal_epoch_21",
                            "queue_settings": {
                                "e2e__fused_op_57_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q29",
                                    "rd_ptr_global": "$gptr_q29"
                                },
                                "e2e__fused_op_58_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q29",
                                    "rd_ptr_global": "$gptr_q29"
                                },
                                "e2e_softmax_448.dc.reduce_max.0_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q29",
                                    "rd_ptr_global": "$gptr_q29"
                                },
                                "lc.input_tensor.softmax_448.dc.reduce_sum.3.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.softmax_448.4": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.8.attention.self.value.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.8.attention.self.value.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.8.attention.output.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.8.attention.output.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_468.dc.reduce_sum.0.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_468.1": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_autoinc": 0,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_468.dc.reduce_sum.5.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_468.6": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_468.8": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.8.attention.output.LayerNorm.weight": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.8.attention.output.LayerNorm.bias": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.8.intermediate.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.8.intermediate.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                }
                            }
                        }
                    },
                    {
                        "varinst": [
                            "$gptr_q29",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q29",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "execute": {
                            "graph_name": "fwd_0_22_temporal_epoch_22",
                            "queue_settings": {
                                "e2e__fused_op_62_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q30",
                                    "rd_ptr_global": "$gptr_q30"
                                },
                                "e2e_gelu_474_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q30",
                                    "rd_ptr_global": "$gptr_q30"
                                },
                                "bert.encoder.layer.8.output.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.8.output.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_482.dc.reduce_sum.0.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_482.1": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_482.dc.reduce_sum.5.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_482.6": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_482.8": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.8.output.LayerNorm.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.8.output.LayerNorm.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.9.attention.self.query.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.9.attention.self.query.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                }
                            }
                        }
                    },
                    {
                        "varinst": [
                            "$gptr_q30",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q30",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "execute": {
                            "graph_name": "fwd_0_23_temporal_epoch_23",
                            "queue_settings": {
                                "e2e_multiply_22_attempt_1_input_op_fork_nop1_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q31",
                                    "rd_ptr_global": "$gptr_q31"
                                },
                                "e2e__fused_op_64_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q31",
                                    "rd_ptr_global": "$gptr_q31"
                                },
                                "e2e_matmul_485_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q32",
                                    "rd_ptr_global": "$gptr_q32"
                                },
                                "bert.encoder.layer.9.attention.self.key.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.9.attention.self.key.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "input_1_multiply_499": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.softmax_501.dc.reduce_sum.3.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.softmax_501.4": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.9.attention.self.value.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.9.attention.self.value.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.9.attention.output.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.9.attention.output.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                }
                            }
                        }
                    },
                    {
                        "varinst": [
                            "$gptr_q31_shadow",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$gptr_q32",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q31",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q32",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "execute": {
                            "graph_name": "fwd_0_24_temporal_epoch_24",
                            "queue_settings": {
                                "e2e__fused_op_64_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q33",
                                    "rd_ptr_global": "$gptr_q33"
                                },
                                "e2e_matmul_516_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q33",
                                    "rd_ptr_global": "$gptr_q33"
                                },
                                "lc.input_tensor.layernorm_521.dc.reduce_sum.0.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_521.1": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_autoinc": 0,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_521.dc.reduce_sum.5.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_521.6": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_521.8": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.9.attention.output.LayerNorm.weight": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.9.attention.output.LayerNorm.bias": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.9.intermediate.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.9.intermediate.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.9.output.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.9.output.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_535.dc.reduce_sum.0.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_535.1": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_autoinc": 0,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_535.dc.reduce_sum.5.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                }
                            }
                        }
                    },
                    {
                        "varinst": [
                            "$gptr_q33",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q33",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "execute": {
                            "graph_name": "fwd_0_25_temporal_epoch_25",
                            "queue_settings": {
                                "e2e_multiply_22_attempt_1_input_op_fork_nop1_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q34",
                                    "rd_ptr_global": "$gptr_q34"
                                },
                                "e2e__fused_op_70_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q35",
                                    "rd_ptr_global": "$gptr_q35"
                                },
                                "e2e_layernorm_535.dc.reduce_sum.5.lc1_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q35",
                                    "rd_ptr_global": "$gptr_q35"
                                },
                                "dc.input_tensor.layernorm_535.6": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_535.8": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.9.output.LayerNorm.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.9.output.LayerNorm.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.10.attention.self.query.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.10.attention.self.query.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.10.attention.self.key.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.10.attention.self.key.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "input_1_multiply_552": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                }
                            }
                        }
                    },
                    {
                        "varinst": [
                            "$gptr_q34_shadow",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$gptr_q35",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q34",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q35",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "execute": {
                            "graph_name": "fwd_0_26_temporal_epoch_26",
                            "queue_settings": {
                                "e2e__fused_op_71_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q36",
                                    "rd_ptr_global": "$gptr_q36"
                                },
                                "e2e__fused_op_72_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q36",
                                    "rd_ptr_global": "$gptr_q36"
                                },
                                "e2e_softmax_554.dc.reduce_max.0_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q36",
                                    "rd_ptr_global": "$gptr_q36"
                                },
                                "lc.input_tensor.softmax_554.dc.reduce_sum.3.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.softmax_554.4": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.10.attention.self.value.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.10.attention.self.value.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.10.attention.output.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.10.attention.output.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_574.dc.reduce_sum.0.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_574.1": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_autoinc": 0,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_574.dc.reduce_sum.5.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_574.6": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_574.8": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.10.attention.output.LayerNorm.weight": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.10.attention.output.LayerNorm.bias": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.10.intermediate.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.10.intermediate.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                }
                            }
                        }
                    },
                    {
                        "varinst": [
                            "$gptr_q36",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q36",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "execute": {
                            "graph_name": "fwd_0_27_temporal_epoch_27",
                            "queue_settings": {
                                "e2e__fused_op_76_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q37",
                                    "rd_ptr_global": "$gptr_q37"
                                },
                                "e2e_gelu_580_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q37",
                                    "rd_ptr_global": "$gptr_q37"
                                },
                                "bert.encoder.layer.10.output.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.10.output.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_588.dc.reduce_sum.0.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_588.1": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_588.dc.reduce_sum.5.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_588.6": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_588.8": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.10.output.LayerNorm.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.10.output.LayerNorm.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.11.attention.self.query.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.11.attention.self.query.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                }
                            }
                        }
                    },
                    {
                        "varinst": [
                            "$gptr_q37",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q37",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "execute": {
                            "graph_name": "fwd_0_28_temporal_epoch_28",
                            "queue_settings": {
                                "e2e_multiply_22_attempt_1_input_op_fork_nop1_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q38",
                                    "rd_ptr_global": "$gptr_q38"
                                },
                                "e2e__fused_op_78_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q38",
                                    "rd_ptr_global": "$gptr_q38"
                                },
                                "e2e_matmul_591_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q39",
                                    "rd_ptr_global": "$gptr_q39"
                                },
                                "bert.encoder.layer.11.attention.self.key.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.11.attention.self.key.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "input_1_multiply_605": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.softmax_607.dc.reduce_sum.3.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.softmax_607.4": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.11.attention.self.value.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.11.attention.self.value.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.11.attention.output.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.11.attention.output.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                }
                            }
                        }
                    },
                    {
                        "varinst": [
                            "$gptr_q38_shadow",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$gptr_q39",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q38",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q39",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "execute": {
                            "graph_name": "fwd_0_29_temporal_epoch_29",
                            "queue_settings": {
                                "e2e__fused_op_78_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q40",
                                    "rd_ptr_global": "$gptr_q40"
                                },
                                "e2e_matmul_622_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q40",
                                    "rd_ptr_global": "$gptr_q40"
                                },
                                "lc.input_tensor.layernorm_627.dc.reduce_sum.0.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_627.1": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_autoinc": 0,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_627.dc.reduce_sum.5.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_627.6": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_627.8": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.11.attention.output.LayerNorm.weight": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.11.attention.output.LayerNorm.bias": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.11.intermediate.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.11.intermediate.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.11.output.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.11.output.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_641.dc.reduce_sum.0.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_641.1": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_autoinc": 0,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_641.dc.reduce_sum.5.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                }
                            }
                        }
                    },
                    {
                        "varinst": [
                            "$gptr_q40",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q40",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "execute": {
                            "graph_name": "fwd_0_30_temporal_epoch_30",
                            "queue_settings": {
                                "e2e_multiply_22_attempt_1_input_op_fork_nop1_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q41",
                                    "rd_ptr_global": "$gptr_q41"
                                },
                                "e2e__fused_op_84_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q42",
                                    "rd_ptr_global": "$gptr_q42"
                                },
                                "e2e_layernorm_641.dc.reduce_sum.5.lc1_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q42",
                                    "rd_ptr_global": "$gptr_q42"
                                },
                                "dc.input_tensor.layernorm_641.6": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_641.8": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.11.output.LayerNorm.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.11.output.LayerNorm.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.12.attention.self.query.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.12.attention.self.query.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.12.attention.self.key.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.12.attention.self.key.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "input_1_multiply_658": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                }
                            }
                        }
                    },
                    {
                        "varinst": [
                            "$gptr_q41_shadow",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$gptr_q42",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q41",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q42",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "execute": {
                            "graph_name": "fwd_0_31_temporal_epoch_31",
                            "queue_settings": {
                                "e2e__fused_op_85_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q43",
                                    "rd_ptr_global": "$gptr_q43"
                                },
                                "e2e__fused_op_86_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q43",
                                    "rd_ptr_global": "$gptr_q43"
                                },
                                "e2e_softmax_660.dc.reduce_max.0_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q43",
                                    "rd_ptr_global": "$gptr_q43"
                                },
                                "lc.input_tensor.softmax_660.dc.reduce_sum.3.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.softmax_660.4": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.12.attention.self.value.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.12.attention.self.value.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.12.attention.output.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.12.attention.output.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_680.dc.reduce_sum.0.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_680.1": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_autoinc": 0,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_680.dc.reduce_sum.5.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_680.6": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_680.8": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.12.attention.output.LayerNorm.weight": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.12.attention.output.LayerNorm.bias": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.12.intermediate.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.12.intermediate.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                }
                            }
                        }
                    },
                    {
                        "varinst": [
                            "$gptr_q43",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q43",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "execute": {
                            "graph_name": "fwd_0_32_temporal_epoch_32",
                            "queue_settings": {
                                "e2e__fused_op_90_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q44",
                                    "rd_ptr_global": "$gptr_q44"
                                },
                                "e2e_gelu_686_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q44",
                                    "rd_ptr_global": "$gptr_q44"
                                },
                                "bert.encoder.layer.12.output.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.12.output.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_694.dc.reduce_sum.0.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_694.1": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_694.dc.reduce_sum.5.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_694.6": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_694.8": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.12.output.LayerNorm.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.12.output.LayerNorm.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.13.attention.self.query.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.13.attention.self.query.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                }
                            }
                        }
                    },
                    {
                        "varinst": [
                            "$gptr_q44",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q44",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "execute": {
                            "graph_name": "fwd_0_33_temporal_epoch_33",
                            "queue_settings": {
                                "e2e_multiply_22_attempt_1_input_op_fork_nop1_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q45",
                                    "rd_ptr_global": "$gptr_q45"
                                },
                                "e2e__fused_op_92_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q45",
                                    "rd_ptr_global": "$gptr_q45"
                                },
                                "e2e_matmul_697_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q46",
                                    "rd_ptr_global": "$gptr_q46"
                                },
                                "bert.encoder.layer.13.attention.self.key.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.13.attention.self.key.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "input_1_multiply_711": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.softmax_713.dc.reduce_sum.3.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.softmax_713.4": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.13.attention.self.value.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.13.attention.self.value.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.13.attention.output.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.13.attention.output.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                }
                            }
                        }
                    },
                    {
                        "varinst": [
                            "$gptr_q45_shadow",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$gptr_q46",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q45",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q46",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "execute": {
                            "graph_name": "fwd_0_34_temporal_epoch_34",
                            "queue_settings": {
                                "e2e__fused_op_92_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q47",
                                    "rd_ptr_global": "$gptr_q47"
                                },
                                "e2e_matmul_728_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q47",
                                    "rd_ptr_global": "$gptr_q47"
                                },
                                "lc.input_tensor.layernorm_733.dc.reduce_sum.0.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_733.1": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_autoinc": 0,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_733.dc.reduce_sum.5.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_733.6": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_733.8": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.13.attention.output.LayerNorm.weight": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.13.attention.output.LayerNorm.bias": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.13.intermediate.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.13.intermediate.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.13.output.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.13.output.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_747.dc.reduce_sum.0.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_747.1": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_autoinc": 0,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_747.dc.reduce_sum.5.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                }
                            }
                        }
                    },
                    {
                        "varinst": [
                            "$gptr_q47",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q47",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "execute": {
                            "graph_name": "fwd_0_35_temporal_epoch_35",
                            "queue_settings": {
                                "e2e_multiply_22_attempt_1_input_op_fork_nop1_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q48",
                                    "rd_ptr_global": "$gptr_q48"
                                },
                                "e2e__fused_op_98_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q49",
                                    "rd_ptr_global": "$gptr_q49"
                                },
                                "e2e_layernorm_747.dc.reduce_sum.5.lc1_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q49",
                                    "rd_ptr_global": "$gptr_q49"
                                },
                                "dc.input_tensor.layernorm_747.6": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_747.8": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.13.output.LayerNorm.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.13.output.LayerNorm.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.14.attention.self.query.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.14.attention.self.query.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.14.attention.self.key.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.14.attention.self.key.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "input_1_multiply_764": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                }
                            }
                        }
                    },
                    {
                        "varinst": [
                            "$gptr_q48_shadow",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$gptr_q49",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q48",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q49",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "execute": {
                            "graph_name": "fwd_0_36_temporal_epoch_36",
                            "queue_settings": {
                                "e2e__fused_op_99_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q50",
                                    "rd_ptr_global": "$gptr_q50"
                                },
                                "e2e__fused_op_100_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q50",
                                    "rd_ptr_global": "$gptr_q50"
                                },
                                "e2e_softmax_766.dc.reduce_max.0_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q50",
                                    "rd_ptr_global": "$gptr_q50"
                                },
                                "lc.input_tensor.softmax_766.dc.reduce_sum.3.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.softmax_766.4": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.14.attention.self.value.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.14.attention.self.value.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.14.attention.output.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.14.attention.output.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_786.dc.reduce_sum.0.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_786.1": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_autoinc": 0,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_786.dc.reduce_sum.5.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_786.6": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_786.8": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.14.attention.output.LayerNorm.weight": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.14.attention.output.LayerNorm.bias": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.14.intermediate.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.14.intermediate.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                }
                            }
                        }
                    },
                    {
                        "varinst": [
                            "$gptr_q50",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q50",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "execute": {
                            "graph_name": "fwd_0_37_temporal_epoch_37",
                            "queue_settings": {
                                "e2e__fused_op_104_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q51",
                                    "rd_ptr_global": "$gptr_q51"
                                },
                                "e2e_gelu_792_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q51",
                                    "rd_ptr_global": "$gptr_q51"
                                },
                                "bert.encoder.layer.14.output.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.14.output.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_800.dc.reduce_sum.0.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_800.1": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_800.dc.reduce_sum.5.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_800.6": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_800.8": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.14.output.LayerNorm.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.14.output.LayerNorm.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.15.attention.self.query.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.15.attention.self.query.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                }
                            }
                        }
                    },
                    {
                        "varinst": [
                            "$gptr_q51",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q51",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "execute": {
                            "graph_name": "fwd_0_38_temporal_epoch_38",
                            "queue_settings": {
                                "e2e_multiply_22_attempt_1_input_op_fork_nop1_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q52",
                                    "rd_ptr_global": "$gptr_q52"
                                },
                                "e2e__fused_op_106_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q53",
                                    "rd_ptr_global": "$gptr_q53"
                                },
                                "e2e_matmul_803_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q52",
                                    "rd_ptr_global": "$gptr_q52"
                                },
                                "bert.encoder.layer.15.attention.self.key.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.15.attention.self.key.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "input_1_multiply_817": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.softmax_819.dc.reduce_sum.3.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.softmax_819.4": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.15.attention.self.value.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.15.attention.self.value.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.15.attention.output.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.15.attention.output.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                }
                            }
                        }
                    },
                    {
                        "varinst": [
                            "$gptr_q52",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$gptr_q53_shadow",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q52",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q53",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "execute": {
                            "graph_name": "fwd_0_39_temporal_epoch_39",
                            "queue_settings": {
                                "e2e__fused_op_106_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q54",
                                    "rd_ptr_global": "$gptr_q54"
                                },
                                "e2e_matmul_834_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q54",
                                    "rd_ptr_global": "$gptr_q54"
                                },
                                "lc.input_tensor.layernorm_839.dc.reduce_sum.0.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_839.1": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_autoinc": 0,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_839.dc.reduce_sum.5.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_839.6": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_839.8": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.15.attention.output.LayerNorm.weight": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.15.attention.output.LayerNorm.bias": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.15.intermediate.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.15.intermediate.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.15.output.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.15.output.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_853.dc.reduce_sum.0.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_853.1": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_autoinc": 0,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_853.dc.reduce_sum.5.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                }
                            }
                        }
                    },
                    {
                        "varinst": [
                            "$gptr_q54",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q54",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "execute": {
                            "graph_name": "fwd_0_40_temporal_epoch_40",
                            "queue_settings": {
                                "e2e__fused_op_112_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q55",
                                    "rd_ptr_global": "$gptr_q55"
                                },
                                "e2e_layernorm_853.dc.reduce_sum.5.lc1_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q55",
                                    "rd_ptr_global": "$gptr_q55"
                                },
                                "e2e_multiply_22_attempt_1_input_op_fork_nop2_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q56",
                                    "rd_ptr_global": "$gptr_q56"
                                },
                                "dc.input_tensor.layernorm_853.6": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_853.8": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.15.output.LayerNorm.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.15.output.LayerNorm.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.16.attention.self.query.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.16.attention.self.query.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.16.attention.self.key.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.16.attention.self.key.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "input_1_multiply_870": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                }
                            }
                        }
                    },
                    {
                        "varinst": [
                            "$gptr_q55",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$gptr_q56_shadow",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q55",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q56",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "execute": {
                            "graph_name": "fwd_0_41_temporal_epoch_41",
                            "queue_settings": {
                                "e2e__fused_op_113_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q57",
                                    "rd_ptr_global": "$gptr_q57"
                                },
                                "e2e__fused_op_114_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q57",
                                    "rd_ptr_global": "$gptr_q57"
                                },
                                "e2e_softmax_872.dc.reduce_max.0_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q57",
                                    "rd_ptr_global": "$gptr_q57"
                                },
                                "lc.input_tensor.softmax_872.dc.reduce_sum.3.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.softmax_872.4": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.16.attention.self.value.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.16.attention.self.value.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.16.attention.output.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.16.attention.output.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_892.dc.reduce_sum.0.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_892.1": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_autoinc": 0,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_892.dc.reduce_sum.5.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_892.6": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_892.8": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.16.attention.output.LayerNorm.weight": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.16.attention.output.LayerNorm.bias": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.16.intermediate.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.16.intermediate.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                }
                            }
                        }
                    },
                    {
                        "varinst": [
                            "$gptr_q57",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q57",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "execute": {
                            "graph_name": "fwd_0_42_temporal_epoch_42",
                            "queue_settings": {
                                "e2e__fused_op_118_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q58",
                                    "rd_ptr_global": "$gptr_q58"
                                },
                                "e2e_gelu_898_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q58",
                                    "rd_ptr_global": "$gptr_q58"
                                },
                                "bert.encoder.layer.16.output.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.16.output.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_906.dc.reduce_sum.0.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_906.1": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_906.dc.reduce_sum.5.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_906.6": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_906.8": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.16.output.LayerNorm.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.16.output.LayerNorm.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.17.attention.self.query.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.17.attention.self.query.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                }
                            }
                        }
                    },
                    {
                        "varinst": [
                            "$gptr_q58",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q58",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "execute": {
                            "graph_name": "fwd_0_43_temporal_epoch_43",
                            "queue_settings": {
                                "e2e_multiply_22_attempt_1_input_op_fork_nop2_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q59",
                                    "rd_ptr_global": "$gptr_q59"
                                },
                                "e2e__fused_op_120_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q59",
                                    "rd_ptr_global": "$gptr_q59"
                                },
                                "e2e_matmul_909_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q60",
                                    "rd_ptr_global": "$gptr_q60"
                                },
                                "bert.encoder.layer.17.attention.self.key.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.17.attention.self.key.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "input_1_multiply_923": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.softmax_925.dc.reduce_sum.3.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.softmax_925.4": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.17.attention.self.value.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.17.attention.self.value.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.17.attention.output.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.17.attention.output.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                }
                            }
                        }
                    },
                    {
                        "varinst": [
                            "$gptr_q59_shadow",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$gptr_q60",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q59",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q60",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "execute": {
                            "graph_name": "fwd_0_44_temporal_epoch_44",
                            "queue_settings": {
                                "e2e__fused_op_120_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q61",
                                    "rd_ptr_global": "$gptr_q61"
                                },
                                "e2e_matmul_940_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q61",
                                    "rd_ptr_global": "$gptr_q61"
                                },
                                "lc.input_tensor.layernorm_945.dc.reduce_sum.0.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_945.1": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_autoinc": 0,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_945.dc.reduce_sum.5.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_945.6": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_945.8": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.17.attention.output.LayerNorm.weight": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.17.attention.output.LayerNorm.bias": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.17.intermediate.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.17.intermediate.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.17.output.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.17.output.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_959.dc.reduce_sum.0.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_959.1": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_autoinc": 0,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_959.dc.reduce_sum.5.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                }
                            }
                        }
                    },
                    {
                        "varinst": [
                            "$gptr_q61",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q61",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "execute": {
                            "graph_name": "fwd_0_45_temporal_epoch_45",
                            "queue_settings": {
                                "e2e_multiply_22_attempt_1_input_op_fork_nop2_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q62",
                                    "rd_ptr_global": "$gptr_q62"
                                },
                                "e2e__fused_op_126_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q63",
                                    "rd_ptr_global": "$gptr_q63"
                                },
                                "e2e_layernorm_959.dc.reduce_sum.5.lc1_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q63",
                                    "rd_ptr_global": "$gptr_q63"
                                },
                                "dc.input_tensor.layernorm_959.6": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_959.8": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.17.output.LayerNorm.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.17.output.LayerNorm.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.18.attention.self.query.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.18.attention.self.query.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.18.attention.self.key.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.18.attention.self.key.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "input_1_multiply_976": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                }
                            }
                        }
                    },
                    {
                        "varinst": [
                            "$gptr_q62_shadow",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$gptr_q63",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q62",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q63",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "execute": {
                            "graph_name": "fwd_0_46_temporal_epoch_46",
                            "queue_settings": {
                                "e2e__fused_op_127_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q64",
                                    "rd_ptr_global": "$gptr_q64"
                                },
                                "e2e__fused_op_128_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q64",
                                    "rd_ptr_global": "$gptr_q64"
                                },
                                "e2e_softmax_978.dc.reduce_max.0_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q64",
                                    "rd_ptr_global": "$gptr_q64"
                                },
                                "lc.input_tensor.softmax_978.dc.reduce_sum.3.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.softmax_978.4": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.18.attention.self.value.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.18.attention.self.value.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.18.attention.output.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.18.attention.output.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_998.dc.reduce_sum.0.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_998.1": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_autoinc": 0,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_998.dc.reduce_sum.5.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_998.6": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_998.8": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.18.attention.output.LayerNorm.weight": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.18.attention.output.LayerNorm.bias": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.18.intermediate.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.18.intermediate.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                }
                            }
                        }
                    },
                    {
                        "varinst": [
                            "$gptr_q64",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q64",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "execute": {
                            "graph_name": "fwd_0_47_temporal_epoch_47",
                            "queue_settings": {
                                "e2e__fused_op_132_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q65",
                                    "rd_ptr_global": "$gptr_q65"
                                },
                                "e2e_gelu_1004_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q65",
                                    "rd_ptr_global": "$gptr_q65"
                                },
                                "bert.encoder.layer.18.output.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.18.output.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_1012.dc.reduce_sum.0.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_1012.1": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_1012.dc.reduce_sum.5.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_1012.6": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_1012.8": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.18.output.LayerNorm.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.18.output.LayerNorm.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.19.attention.self.query.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.19.attention.self.query.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                }
                            }
                        }
                    },
                    {
                        "varinst": [
                            "$gptr_q65",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q65",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "execute": {
                            "graph_name": "fwd_0_48_temporal_epoch_48",
                            "queue_settings": {
                                "e2e_multiply_22_attempt_1_input_op_fork_nop2_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q66",
                                    "rd_ptr_global": "$gptr_q66"
                                },
                                "e2e__fused_op_134_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q66",
                                    "rd_ptr_global": "$gptr_q66"
                                },
                                "e2e_matmul_1015_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q67",
                                    "rd_ptr_global": "$gptr_q67"
                                },
                                "bert.encoder.layer.19.attention.self.key.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.19.attention.self.key.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "input_1_multiply_1029": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.softmax_1031.dc.reduce_sum.3.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.softmax_1031.4": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.19.attention.self.value.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.19.attention.self.value.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.19.attention.output.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.19.attention.output.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                }
                            }
                        }
                    },
                    {
                        "varinst": [
                            "$gptr_q66_shadow",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$gptr_q67",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q66",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q67",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "execute": {
                            "graph_name": "fwd_0_49_temporal_epoch_49",
                            "queue_settings": {
                                "e2e__fused_op_134_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q68",
                                    "rd_ptr_global": "$gptr_q68"
                                },
                                "e2e_matmul_1046_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q68",
                                    "rd_ptr_global": "$gptr_q68"
                                },
                                "lc.input_tensor.layernorm_1051.dc.reduce_sum.0.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_1051.1": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_autoinc": 0,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_1051.dc.reduce_sum.5.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_1051.6": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_1051.8": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.19.attention.output.LayerNorm.weight": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.19.attention.output.LayerNorm.bias": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.19.intermediate.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.19.intermediate.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.19.output.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.19.output.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_1065.dc.reduce_sum.0.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_1065.1": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_autoinc": 0,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_1065.dc.reduce_sum.5.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                }
                            }
                        }
                    },
                    {
                        "varinst": [
                            "$gptr_q68",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q68",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "execute": {
                            "graph_name": "fwd_0_50_temporal_epoch_50",
                            "queue_settings": {
                                "e2e_multiply_22_attempt_1_input_op_fork_nop2_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q69",
                                    "rd_ptr_global": "$gptr_q69"
                                },
                                "e2e__fused_op_140_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q70",
                                    "rd_ptr_global": "$gptr_q70"
                                },
                                "e2e_layernorm_1065.dc.reduce_sum.5.lc1_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q70",
                                    "rd_ptr_global": "$gptr_q70"
                                },
                                "dc.input_tensor.layernorm_1065.6": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_1065.8": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.19.output.LayerNorm.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.19.output.LayerNorm.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.20.attention.self.query.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.20.attention.self.query.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.20.attention.self.key.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.20.attention.self.key.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "input_1_multiply_1082": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                }
                            }
                        }
                    },
                    {
                        "varinst": [
                            "$gptr_q69_shadow",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$gptr_q70",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q69",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q70",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "execute": {
                            "graph_name": "fwd_0_51_temporal_epoch_51",
                            "queue_settings": {
                                "e2e__fused_op_141_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q71",
                                    "rd_ptr_global": "$gptr_q71"
                                },
                                "e2e__fused_op_142_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q71",
                                    "rd_ptr_global": "$gptr_q71"
                                },
                                "e2e_softmax_1084.dc.reduce_max.0_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q71",
                                    "rd_ptr_global": "$gptr_q71"
                                },
                                "lc.input_tensor.softmax_1084.dc.reduce_sum.3.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.softmax_1084.4": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.20.attention.self.value.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.20.attention.self.value.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.20.attention.output.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.20.attention.output.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_1104.dc.reduce_sum.0.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_1104.1": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_autoinc": 0,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_1104.dc.reduce_sum.5.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_1104.6": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_1104.8": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.20.attention.output.LayerNorm.weight": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.20.attention.output.LayerNorm.bias": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.20.intermediate.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.20.intermediate.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                }
                            }
                        }
                    },
                    {
                        "varinst": [
                            "$gptr_q71",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q71",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "execute": {
                            "graph_name": "fwd_0_52_temporal_epoch_52",
                            "queue_settings": {
                                "e2e__fused_op_146_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q72",
                                    "rd_ptr_global": "$gptr_q72"
                                },
                                "e2e_gelu_1110_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q72",
                                    "rd_ptr_global": "$gptr_q72"
                                },
                                "bert.encoder.layer.20.output.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.20.output.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_1118.dc.reduce_sum.0.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_1118.1": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_1118.dc.reduce_sum.5.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_1118.6": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_1118.8": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.20.output.LayerNorm.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.20.output.LayerNorm.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.21.attention.self.query.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.21.attention.self.query.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                }
                            }
                        }
                    },
                    {
                        "varinst": [
                            "$gptr_q72",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q72",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "execute": {
                            "graph_name": "fwd_0_53_temporal_epoch_53",
                            "queue_settings": {
                                "e2e_multiply_22_attempt_1_input_op_fork_nop2_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q73",
                                    "rd_ptr_global": "$gptr_q73"
                                },
                                "e2e__fused_op_148_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q73",
                                    "rd_ptr_global": "$gptr_q73"
                                },
                                "e2e_matmul_1121_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q74",
                                    "rd_ptr_global": "$gptr_q74"
                                },
                                "bert.encoder.layer.21.attention.self.key.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.21.attention.self.key.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "input_1_multiply_1135": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.softmax_1137.dc.reduce_sum.3.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.softmax_1137.4": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.21.attention.self.value.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.21.attention.self.value.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.21.attention.output.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.21.attention.output.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                }
                            }
                        }
                    },
                    {
                        "varinst": [
                            "$gptr_q73_shadow",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$gptr_q74",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q73",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q74",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "execute": {
                            "graph_name": "fwd_0_54_temporal_epoch_54",
                            "queue_settings": {
                                "e2e__fused_op_148_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q75",
                                    "rd_ptr_global": "$gptr_q75"
                                },
                                "e2e_matmul_1152_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q75",
                                    "rd_ptr_global": "$gptr_q75"
                                },
                                "lc.input_tensor.layernorm_1157.dc.reduce_sum.0.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_1157.1": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_autoinc": 0,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_1157.dc.reduce_sum.5.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_1157.6": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_1157.8": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.21.attention.output.LayerNorm.weight": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.21.attention.output.LayerNorm.bias": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.21.intermediate.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.21.intermediate.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.21.output.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.21.output.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_1171.dc.reduce_sum.0.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_1171.1": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_autoinc": 0,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_1171.dc.reduce_sum.5.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                }
                            }
                        }
                    },
                    {
                        "varinst": [
                            "$gptr_q75",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q75",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "execute": {
                            "graph_name": "fwd_0_55_temporal_epoch_55",
                            "queue_settings": {
                                "e2e_multiply_22_attempt_1_input_op_fork_nop2_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q76",
                                    "rd_ptr_global": "$gptr_q76"
                                },
                                "e2e__fused_op_154_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q77",
                                    "rd_ptr_global": "$gptr_q77"
                                },
                                "e2e_layernorm_1171.dc.reduce_sum.5.lc1_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q77",
                                    "rd_ptr_global": "$gptr_q77"
                                },
                                "dc.input_tensor.layernorm_1171.6": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_1171.8": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.21.output.LayerNorm.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.21.output.LayerNorm.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.22.attention.self.query.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.22.attention.self.query.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.22.attention.self.key.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.22.attention.self.key.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "input_1_multiply_1188": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                }
                            }
                        }
                    },
                    {
                        "varinst": [
                            "$gptr_q76_shadow",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$gptr_q77",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q76",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q77",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "execute": {
                            "graph_name": "fwd_0_56_temporal_epoch_56",
                            "queue_settings": {
                                "e2e__fused_op_155_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q78",
                                    "rd_ptr_global": "$gptr_q78"
                                },
                                "e2e__fused_op_156_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q78",
                                    "rd_ptr_global": "$gptr_q78"
                                },
                                "e2e_softmax_1190.dc.reduce_max.0_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q78",
                                    "rd_ptr_global": "$gptr_q78"
                                },
                                "lc.input_tensor.softmax_1190.dc.reduce_sum.3.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.softmax_1190.4": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.22.attention.self.value.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.22.attention.self.value.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.22.attention.output.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.22.attention.output.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_1210.dc.reduce_sum.0.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_1210.1": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_autoinc": 0,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_1210.dc.reduce_sum.5.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_1210.6": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_1210.8": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.22.attention.output.LayerNorm.weight": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.22.attention.output.LayerNorm.bias": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.22.intermediate.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.22.intermediate.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                }
                            }
                        }
                    },
                    {
                        "varinst": [
                            "$gptr_q78",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q78",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "execute": {
                            "graph_name": "fwd_0_57_temporal_epoch_57",
                            "queue_settings": {
                                "e2e__fused_op_160_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q79",
                                    "rd_ptr_global": "$gptr_q79"
                                },
                                "e2e_gelu_1216_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q79",
                                    "rd_ptr_global": "$gptr_q79"
                                },
                                "bert.encoder.layer.22.output.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.22.output.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_1224.dc.reduce_sum.0.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_1224.1": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_1224.dc.reduce_sum.5.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_1224.6": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_1224.8": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.22.output.LayerNorm.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.22.output.LayerNorm.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.23.attention.self.query.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.23.attention.self.query.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                }
                            }
                        }
                    },
                    {
                        "varinst": [
                            "$gptr_q79",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q79",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "execute": {
                            "graph_name": "fwd_0_58_temporal_epoch_58",
                            "queue_settings": {
                                "e2e_multiply_22_attempt_1_input_op_fork_nop2_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q80",
                                    "rd_ptr_global": "$gptr_q80"
                                },
                                "e2e__fused_op_162_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q81",
                                    "rd_ptr_global": "$gptr_q81"
                                },
                                "e2e_matmul_1227_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q80",
                                    "rd_ptr_global": "$gptr_q80"
                                },
                                "bert.encoder.layer.23.attention.self.key.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.23.attention.self.key.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "input_1_multiply_1241": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.softmax_1243.dc.reduce_sum.3.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.softmax_1243.4": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.23.attention.self.value.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.23.attention.self.value.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.23.attention.output.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.23.attention.output.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                }
                            }
                        }
                    },
                    {
                        "varinst": [
                            "$gptr_q80",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$gptr_q81_shadow",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q80",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q81",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "execute": {
                            "graph_name": "fwd_0_59_temporal_epoch_59",
                            "queue_settings": {
                                "e2e__fused_op_162_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q82",
                                    "rd_ptr_global": "$gptr_q82"
                                },
                                "e2e_matmul_1258_0": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$lptr_q82",
                                    "rd_ptr_global": "$gptr_q82"
                                },
                                "lc.input_tensor.layernorm_1263.dc.reduce_sum.0.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_1263.1": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_autoinc": 0,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_1263.dc.reduce_sum.5.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_1263.6": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_1263.8": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.23.attention.output.LayerNorm.weight": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.23.attention.output.LayerNorm.bias": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.23.intermediate.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.23.intermediate.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.23.output.dense.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.23.output.dense.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_1277.dc.reduce_sum.0.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_1277.1": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_autoinc": 0,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "lc.input_tensor.layernorm_1277.dc.reduce_sum.5.0": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_1277.6": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "dc.input_tensor.layernorm_1277.8": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_local": "$c_zero",
                                    "rd_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.23.output.LayerNorm.weight": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "bert.encoder.layer.23.output.LayerNorm.bias": {
                                    "prologue": false,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "qa_outputs.weight": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "qa_outputs.bias": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "qa_outputs.weight_fork_clone19": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                },
                                "qa_outputs.bias_fork_clone12": {
                                    "prologue": true,
                                    "epilogue": false,
                                    "zero": false,
                                    "rd_ptr_global": "$c_zero",
                                    "wr_ptr_global": "$c_zero"
                                }
                            }
                        }
                    },
                    {
                        "varinst": [
                            "$gptr_q82",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    {
                        "varinst": [
                            "$lptr_q82",
                            "incwrap",
                            "$c_microbatch_size",
                            2
                        ]
                    },
                    "endloop"
                ]
            }
        ],
        "fused_ops": {
            "0": {
                "inputs": 3,
                "intermediates": 0,
                "schedules": [
                    [
                        {
                            "layernorm_0.dc.multiply.2.0": {
                                "type": "multiply",
                                "inputs": [
                                    "input0",
                                    "input1"
                                ],
                                "mblock": [
                                    3,
                                    4
                                ],
                                "ublock": [
                                    1,
                                    8
                                ],
                                "output": "dest"
                            }
                        },
                        {
                            "layernorm_0.dc.subtract.3.0": {
                                "type": "subtract",
                                "inputs": [
                                    "input2",
                                    "dest"
                                ],
                                "mblock": [
                                    3,
                                    4
                                ],
                                "ublock": [
                                    1,
                                    8
                                ],
                                "output": "output"
                            }
                        }
                    ]
                ]
            },
            "1": {
                "inputs": 6,
                "intermediates": 1,
                "schedules": [
                    [
                        {
                            "layernorm_0.dc.multiply.7.0": {
                                "type": "multiply",
                                "inputs": [
                                    "input0",
                                    "input1"
                                ],
                                "mblock": [
                                    1,
                                    1
                                ],
                                "ublock": [
                                    3,
                                    1
                                ],
                                "output": "dest"
                            }
                        },
                        {
                            "layernorm_0.dc.add.9.0": {
                                "type": "add",
                                "inputs": [
                                    "dest",
                                    "input2"
                                ],
                                "mblock": [
                                    1,
                                    1
                                ],
                                "ublock": [
                                    3,
                                    1
                                ],
                                "output": "dest"
                            }
                        },
                        {
                            "layernorm_0.dc.sqrt.10.0": {
                                "type": "sqrt",
                                "inputs": [
                                    "dest"
                                ],
                                "mblock": [
                                    1,
                                    1
                                ],
                                "ublock": [
                                    3,
                                    1
                                ],
                                "output": "dest"
                            }
                        },
                        {
                            "layernorm_0.dc.reciprocal.11.0": {
                                "type": "reciprocal",
                                "inputs": [
                                    "dest"
                                ],
                                "mblock": [
                                    1,
                                    1
                                ],
                                "ublock": [
                                    3,
                                    1
                                ],
                                "output": "intermed0"
                            }
                        },
                        {
                            "layernorm_0.dc.multiply.12.0": {
                                "type": "multiply",
                                "inputs": [
                                    "input3",
                                    "intermed0"
                                ],
                                "input_1_tms": [
                                    {
                                        "broadcast": {
                                            "c": 32
                                        }
                                    },
                                    {
                                        "tile_broadcast": "c"
                                    }
                                ],
                                "pop": [
                                    "intermed0"
                                ],
                                "mblock": [
                                    1,
                                    32
                                ],
                                "ublock": [
                                    3,
                                    1
                                ],
                                "output": "dest"
                            }
                        },
                        {
                            "layernorm_0.dc.multiply.13.0": {
                                "type": "multiply",
                                "inputs": [
                                    "dest",
                                    "input4"
                                ],
                                "mblock": [
                                    1,
                                    32
                                ],
                                "ublock": [
                                    3,
                                    1
                                ],
                                "output": "dest"
                            }
                        },
                        {
                            "layernorm_0.dc.add.14.0": {
                                "type": "add",
                                "inputs": [
                                    "dest",
                                    "input5"
                                ],
                                "mblock": [
                                    1,
                                    32
                                ],
                                "ublock": [
                                    3,
                                    1
                                ],
                                "output": "output"
                            }
                        }
                    ]
                ]
            },
            "2": {
                "inputs": 3,
                "intermediates": 0,
                "schedules": [
                    [
                        {
                            "multiply_18.0": {
                                "type": "multiply",
                                "inputs": [
                                    "input0",
                                    "input1"
                                ],
                                "mblock": [
                                    3,
                                    1
                                ],
                                "ublock": [
                                    1,
                                    6
                                ],
                                "output": "dest"
                            }
                        },
                        {
                            "add_23.0": {
                                "type": "add",
                                "inputs": [
                                    "dest",
                                    "input2"
                                ],
                                "input_1_tms": [
                                    {
                                        "tile_broadcast": "r"
                                    }
                                ],
                                "mblock": [
                                    3,
                                    1
                                ],
                                "ublock": [
                                    1,
                                    6
                                ],
                                "output": "output"
                            }
                        }
                    ]
                ]
            },
            "3": {
                "inputs": 2,
                "intermediates": 0,
                "schedules": [
                    [
                        {
                            "softmax_24.dc.subtract.1.0": {
                                "type": "subtract",
                                "inputs": [
                                    "input0",
                                    "input1"
                                ],
                                "input_1_tms": [
                                    {
                                        "tile_broadcast": "c"
                                    }
                                ],
                                "mblock": [
                                    2,
                                    1
                                ],
                                "ublock": [
                                    3,
                                    2
                                ],
                                "output": "dest"
                            }
                        },
                        {
                            "softmax_24.dc.exp.2.0": {
                                "type": "exp",
                                "inputs": [
                                    "dest"
                                ],
                                "mblock": [
                                    2,
                                    1
                                ],
                                "ublock": [
                                    3,
                                    2
                                ],
                                "output": "output"
                            }
                        }
                    ]
                ]
            },
            "4": {
                "inputs": 3,
                "intermediates": 1,
                "schedules": [
                    [
                        {
                            "softmax_24.dc.add.5.0": {
                                "type": "add",
                                "inputs": [
                                    "input0",
                                    "input1"
                                ],
                                "mblock": [
                                    1,
                                    1
                                ],
                                "ublock": [
                                    6,
                                    1
                                ],
                                "output": "dest"
                            }
                        },
                        {
                            "softmax_24.dc.reciprocal.6.0": {
                                "type": "reciprocal",
                                "inputs": [
                                    "dest"
                                ],
                                "mblock": [
                                    1,
                                    1
                                ],
                                "ublock": [
                                    6,
                                    1
                                ],
                                "output": "intermed0"
                            }
                        },
                        {
                            "softmax_24.dc.multiply.7.0": {
                                "type": "multiply",
                                "inputs": [
                                    "input2",
                                    "intermed0"
                                ],
                                "input_1_tms": [
                                    {
                                        "broadcast": {
                                            "c": 12
                                        }
                                    },
                                    {
                                        "tile_broadcast": "c"
                                    }
                                ],
                                "pop": [
                                    "intermed0"
                                ],
                                "mblock": [
                                    1,
                                    12
                                ],
                                "ublock": [
                                    6,
                                    1
                                ],
                                "output": "output"
                            }
                        }
                    ]
                ]
            },
            "5": {
                "inputs": 3,
                "intermediates": 0,
                "schedules": [
                    [
                        {
                            "layernorm_44.dc.multiply.2.0": {
                                "type": "multiply",
                                "inputs": [
                                    "input0",
                                    "input1"
                                ],
                                "mblock": [
                                    6,
                                    4
                                ],
                                "ublock": [
                                    1,
                                    8
                                ],
                                "output": "dest"
                            }
                        },
                        {
                            "layernorm_44.dc.subtract.3.0": {
                                "type": "subtract",
                                "inputs": [
                                    "input2",
                                    "dest"
                                ],
                                "mblock": [
                                    6,
                                    4
                                ],
                                "ublock": [
                                    1,
                                    8
                                ],
                                "output": "output"
                            }
                        }
                    ]
                ]
            },
            "6": {
                "inputs": 6,
                "intermediates": 1,
                "schedules": [
                    [
                        {
                            "layernorm_44.dc.multiply.7.0": {
                                "type": "multiply",
                                "inputs": [
                                    "input0",
                                    "input1"
                                ],
                                "mblock": [
                                    1,
                                    1
                                ],
                                "ublock": [
                                    6,
                                    1
                                ],
                                "output": "dest"
                            }
                        },
                        {
                            "layernorm_44.dc.add.9.0": {
                                "type": "add",
                                "inputs": [
                                    "dest",
                                    "input2"
                                ],
                                "mblock": [
                                    1,
                                    1
                                ],
                                "ublock": [
                                    6,
                                    1
                                ],
                                "output": "dest"
                            }
                        },
                        {
                            "layernorm_44.dc.sqrt.10.0": {
                                "type": "sqrt",
                                "inputs": [
                                    "dest"
                                ],
                                "mblock": [
                                    1,
                                    1
                                ],
                                "ublock": [
                                    6,
                                    1
                                ],
                                "output": "dest"
                            }
                        },
                        {
                            "layernorm_44.dc.reciprocal.11.0": {
                                "type": "reciprocal",
                                "inputs": [
                                    "dest"
                                ],
                                "mblock": [
                                    1,
                                    1
                                ],
                                "ublock": [
                                    6,
                                    1
                                ],
                                "output": "intermed0"
                            }
                        },
                        {
                            "layernorm_44.dc.multiply.12.0": {
                                "type": "multiply",
                                "inputs": [
                                    "input3",
                                    "intermed0"
                                ],
                                "input_1_tms": [
                                    {
                                        "broadcast": {
                                            "c": 32
                                        }
                                    },
                                    {
                                        "tile_broadcast": "c"
                                    }
                                ],
                                "pop": [
                                    "intermed0"
                                ],
                                "mblock": [
                                    1,
                                    32
                                ],
                                "ublock": [
                                    6,
                                    1
                                ],
                                "output": "dest"
                            }
                        },
                        {
                            "layernorm_44.dc.multiply.13.0": {
                                "type": "multiply",
                                "inputs": [
                                    "dest",
                                    "input4"
                                ],
                                "mblock": [
                                    1,
                                    32
                                ],
                                "ublock": [
                                    6,
                                    1
                                ],
                                "output": "dest"
                            }
                        },
                        {
                            "layernorm_44.dc.add.14.0": {
                                "type": "add",
                                "inputs": [
                                    "dest",
                                    "input5"
                                ],
                                "mblock": [
                                    1,
                                    32
                                ],
                                "ublock": [
                                    6,
                                    1
                                ],
                                "output": "output"
                            }
                        }
                    ]
                ]
            },
            "7": {
                "inputs": 3,
                "intermediates": 0,
                "schedules": [
                    [
                        {
                            "layernorm_58.dc.multiply.2.0": {
                                "type": "multiply",
                                "inputs": [
                                    "input0",
                                    "input1"
                                ],
                                "mblock": [
                                    4,
                                    4
                                ],
                                "ublock": [
                                    1,
                                    8
                                ],
                                "output": "dest"
                            }
                        },
                        {
                            "layernorm_58.dc.subtract.3.0": {
                                "type": "subtract",
                                "inputs": [
                                    "input2",
                                    "dest"
                                ],
                                "mblock": [
                                    4,
                                    4
                                ],
                                "ublock": [
                                    1,
                                    8
                                ],
                                "output": "output"
                            }
                        }
                    ]
                ]
            },
            "8": {
                "inputs": 6,
                "intermediates": 1,
                "schedules": [
                    [
                        {
                            "layernorm_58.dc.multiply.7.0": {
                                "type": "multiply",
                                "inputs": [
                                    "input0",
                                    "input1"
                                ],
                                "mblock": [
                                    1,
                                    1
                                ],
                                "ublock": [
                                    4,
                                    1
                                ],
                                "output": "dest"
                            }
                        },
                        {
                            "layernorm_58.dc.add.9.0": {
                                "type": "add",
                                "inputs": [
                                    "dest",
                                    "input2"
                                ],
                                "mblock": [
                                    1,
                                    1
                                ],
                                "ublock": [
                                    4,
                                    1
                                ],
                                "output": "dest"
                            }
                        },
                        {
                            "layernorm_58.dc.sqrt.10.0": {
                                "type": "sqrt",
                                "inputs": [
                                    "dest"
                                ],
                                "mblock": [
                                    1,
                                    1
                                ],
                                "ublock": [
                                    4,
                                    1
                                ],
                                "output": "dest"
                            }
                        },
                        {
                            "layernorm_58.dc.reciprocal.11.0": {
                                "type": "reciprocal",
                                "inputs": [
                                    "dest"
                                ],
                                "mblock": [
                                    1,
                                    1
                                ],
                                "ublock": [
                                    4,
                                    1
                                ],
                                "output": "intermed0"
                            }
                        },
                        {
                            "layernorm_58.dc.multiply.12.0": {
                                "type": "multiply",
                                "inputs": [
                                    "input3",
                                    "intermed0"
                                ],
                                "input_1_tms": [
                                    {
                                        "broadcast": {
                                            "c": 32
                                        }
                                    },
                                    {
                                        "tile_broadcast": "c"
                                    }
                                ],
                                "pop": [
                                    "intermed0"
                                ],
                                "mblock": [
                                    1,
                                    32
                                ],
                                "ublock": [
                                    4,
                                    1
                                ],
                                "output": "dest"
                            }
                        },
                        {
                            "layernorm_58.dc.multiply.13.0": {
                                "type": "multiply",
                                "inputs": [
                                    "dest",
                                    "input4"
                                ],
                                "mblock": [
                                    1,
                                    32
                                ],
                                "ublock": [
                                    4,
                                    1
                                ],
                                "output": "dest"
                            }
                        },
                        {
                            "layernorm_58.dc.add.14.0": {
                                "type": "add",
                                "inputs": [
                                    "dest",
                                    "input5"
                                ],
                                "mblock": [
                                    1,
                                    32
                                ],
                                "ublock": [
                                    4,
                                    1
                                ],
                                "output": "output"
                            }
                        }
                    ]
                ]
            },
            "9": {
                "inputs": 3,
                "intermediates": 0,
                "schedules": [
                    [
                        {
                            "multiply_75.0": {
                                "type": "multiply",
                                "inputs": [
                                    "input0",
                                    "input1"
                                ],
                                "mblock": [
                                    1,
                                    6
                                ],
                                "ublock": [
                                    4,
                                    2
                                ],
                                "output": "dest"
                            }
                        },
                        {
                            "add_76.0": {
                                "type": "add",
                                "inputs": [
                                    "dest",
                                    "input2"
                                ],
                                "input_1_tms": [
                                    {
                                        "tile_broadcast": "r"
                                    }
                                ],
                                "mblock": [
                                    1,
                                    6
                                ],
                                "ublock": [
                                    4,
                                    2
                                ],
                                "output": "output"
                            }
                        }
                    ]
                ]
            },
            "10": {
                "inputs": 2,
                "intermediates": 0,
                "schedules": [
                    [
                        {
                            "softmax_77.dc.subtract.1.0": {
                                "type": "subtract",
                                "inputs": [
                                    "input0",
                                    "input1"
                                ],
                                "input_1_tms": [
                                    {
                                        "tile_broadcast": "c"
                                    }
                                ],
                                "mblock": [
                                    1,
                                    1
                                ],
                                "ublock": [
                                    4,
                                    2
                                ],
                                "output": "dest"
                            }
                        },
                        {
                            "softmax_77.dc.exp.2.0": {
                                "type": "exp",
                                "inputs": [
                                    "dest"
                                ],
                                "mblock": [
                                    1,
                                    1
                                ],
                                "ublock": [
                                    4,
                                    2
                                ],
                                "output": "output"
                            }
                        }
                    ]
                ]
            },
            "11": {
                "inputs": 3,
                "intermediates": 1,
                "schedules": [
                    [
                        {
                            "softmax_77.dc.add.5.0": {
                                "type": "add",
                                "inputs": [
                                    "input0",
                                    "input1"
                                ],
                                "mblock": [
                                    1,
                                    1
                                ],
                                "ublock": [
                                    4,
                                    1
                                ],
                                "output": "dest"
                            }
                        },
                        {
                            "softmax_77.dc.reciprocal.6.0": {
                                "type": "reciprocal",
                                "inputs": [
                                    "dest"
                                ],
                                "mblock": [
                                    1,
                                    1
                                ],
                                "ublock": [
                                    4,
                                    1
                                ],
                                "output": "intermed0"
                            }
                        },
                        {
                            "softmax_77.dc.multiply.7.0": {
                                "type": "multiply",
                                "inputs": [
                                    "input2",
                                    "intermed0"
                                ],
                                "input_1_tms": [
                                    {
                                        "broadcast": {
                                            "c": 12
                                        }
                                    },
                                    {
                                        "tile_broadcast": "c"
                                    }
                                ],
                                "pop": [
                                    "intermed0"
                                ],
                                "mblock": [
                                    1,
                                    12
                                ],
                                "ublock": [
                                    4,
                                    1
                                ],
                                "output": "output"
                            }
                        }
                    ]
                ]
            },
            "12": {
                "inputs": 3,
                "intermediates": 0,
                "schedules": [
                    [
                        {
                            "layernorm_97.dc.multiply.2.0": {
                                "type": "multiply",
                                "inputs": [
                                    "input0",
                                    "input1"
                                ],
                                "mblock": [
                                    12,
                                    2
                                ],
                                "ublock": [
                                    1,
                                    8
                                ],
                                "output": "dest"
                            }
                        },
                        {
                            "layernorm_97.dc.subtract.3.0": {
                                "type": "subtract",
                                "inputs": [
                                    "input2",
                                    "dest"
                                ],
                                "mblock": [
                                    12,
                                    2
                                ],
                                "ublock": [
                                    1,
                                    8
                                ],
                                "output": "output"
                            }
                        }
                    ]
                ]
            },
            "15": {
                "inputs": 6,
                "intermediates": 1,
                "schedules": [
                    [
                        {
                            "layernorm_111.dc.multiply.7.0": {
                                "type": "multiply",
                                "inputs": [
                                    "input0",
                                    "input1"
                                ],
                                "mblock": [
                                    1,
                                    1
                                ],
                                "ublock": [
                                    2,
                                    1
                                ],
                                "output": "dest"
                            }
                        },
                        {
                            "layernorm_111.dc.add.9.0": {
                                "type": "add",
                                "inputs": [
                                    "dest",
                                    "input2"
                                ],
                                "mblock": [
                                    1,
                                    1
                                ],
                                "ublock": [
                                    2,
                                    1
                                ],
                                "output": "dest"
                            }
                        },
                        {
                            "layernorm_111.dc.sqrt.10.0": {
                                "type": "sqrt",
                                "inputs": [
                                    "dest"
                                ],
                                "mblock": [
                                    1,
                                    1
                                ],
                                "ublock": [
                                    2,
                                    1
                                ],
                                "output": "dest"
                            }
                        },
                        {
                            "layernorm_111.dc.reciprocal.11.0": {
                                "type": "reciprocal",
                                "inputs": [
                                    "dest"
                                ],
                                "mblock": [
                                    1,
                                    1
                                ],
                                "ublock": [
                                    2,
                                    1
                                ],
                                "output": "intermed0"
                            }
                        },
                        {
                            "layernorm_111.dc.multiply.12.0": {
                                "type": "multiply",
                                "inputs": [
                                    "input3",
                                    "intermed0"
                                ],
                                "input_1_tms": [
                                    {
                                        "broadcast": {
                                            "c": 32
                                        }
                                    },
                                    {
                                        "tile_broadcast": "c"
                                    }
                                ],
                                "pop": [
                                    "intermed0"
                                ],
                                "mblock": [
                                    1,
                                    32
                                ],
                                "ublock": [
                                    2,
                                    1
                                ],
                                "output": "dest"
                            }
                        },
                        {
                            "layernorm_111.dc.multiply.13.0": {
                                "type": "multiply",
                                "inputs": [
                                    "dest",
                                    "input4"
                                ],
                                "mblock": [
                                    1,
                                    32
                                ],
                                "ublock": [
                                    2,
                                    1
                                ],
                                "output": "dest"
                            }
                        },
                        {
                            "layernorm_111.dc.add.14.0": {
                                "type": "add",
                                "inputs": [
                                    "dest",
                                    "input5"
                                ],
                                "mblock": [
                                    1,
                                    32
                                ],
                                "ublock": [
                                    2,
                                    1
                                ],
                                "output": "output"
                            }
                        }
                    ]
                ]
            },
            "16": {
                "inputs": 3,
                "intermediates": 0,
                "schedules": [
                    [
                        {
                            "multiply_128.0": {
                                "type": "multiply",
                                "inputs": [
                                    "input0",
                                    "input1"
                                ],
                                "mblock": [
                                    2,
                                    2
                                ],
                                "ublock": [
                                    1,
                                    6
                                ],
                                "output": "dest"
                            }
                        },
                        {
                            "add_129.0": {
                                "type": "add",
                                "inputs": [
                                    "dest",
                                    "input2"
                                ],
                                "input_1_tms": [
                                    {
                                        "tile_broadcast": "r"
                                    }
                                ],
                                "mblock": [
                                    2,
                                    2
                                ],
                                "ublock": [
                                    1,
                                    6
                                ],
                                "output": "output"
                            }
                        }
                    ]
                ]
            },
            "169": {
                "inputs": 6,
                "intermediates": 1,
                "schedules": [
                    [
                        {
                            "layernorm_1277.dc.multiply.7.0": {
                                "type": "multiply",
                                "inputs": [
                                    "input0",
                                    "input1"
                                ],
                                "mblock": [
                                    2,
                                    1
                                ],
                                "ublock": [
                                    3,
                                    1
                                ],
                                "output": "dest"
                            }
                        },
                        {
                            "layernorm_1277.dc.add.9.0": {
                                "type": "add",
                                "inputs": [
                                    "dest",
                                    "input2"
                                ],
                                "mblock": [
                                    2,
                                    1
                                ],
                                "ublock": [
                                    3,
                                    1
                                ],
                                "output": "dest"
                            }
                        },
                        {
                            "layernorm_1277.dc.sqrt.10.0": {
                                "type": "sqrt",
                                "inputs": [
                                    "dest"
                                ],
                                "mblock": [
                                    2,
                                    1
                                ],
                                "ublock": [
                                    3,
                                    1
                                ],
                                "output": "dest"
                            }
                        },
                        {
                            "layernorm_1277.dc.reciprocal.11.0": {
                                "type": "reciprocal",
                                "inputs": [
                                    "dest"
                                ],
                                "mblock": [
                                    2,
                                    1
                                ],
                                "ublock": [
                                    3,
                                    1
                                ],
                                "output": "intermed0"
                            }
                        },
                        {
                            "layernorm_1277.dc.multiply.12.0": {
                                "type": "multiply",
                                "inputs": [
                                    "input3",
                                    "intermed0"
                                ],
                                "input_1_tms": [
                                    {
                                        "broadcast": {
                                            "c": 32
                                        }
                                    },
                                    {
                                        "tile_broadcast": "c"
                                    }
                                ],
                                "pop": [
                                    "intermed0"
                                ],
                                "mblock": [
                                    2,
                                    32
                                ],
                                "ublock": [
                                    3,
                                    1
                                ],
                                "output": "dest"
                            }
                        },
                        {
                            "layernorm_1277.dc.multiply.13.0": {
                                "type": "multiply",
                                "inputs": [
                                    "dest",
                                    "input4"
                                ],
                                "mblock": [
                                    2,
                                    32
                                ],
                                "ublock": [
                                    3,
                                    1
                                ],
                                "output": "dest"
                            }
                        },
                        {
                            "layernorm_1277.dc.add.14.0": {
                                "type": "add",
                                "inputs": [
                                    "dest",
                                    "input5"
                                ],
                                "mblock": [
                                    2,
                                    32
                                ],
                                "ublock": [
                                    3,
                                    1
                                ],
                                "output": "output"
                            }
                        }
                    ]
                ]
            }
        }
    },
    "device_info": {
        "grid": {
            "x_size": 10,
            "y_size": 12
        },
        "arc": [
            "0-10"
        ],
        "pcie": [
            "0-3"
        ],
        "dram": [
            [
                "0-0",
                "0-1",
                "0-11"
            ],
            [
                "0-5",
                "0-6",
                "0-7"
            ],
            [
                "5-0",
                "5-1",
                "5-11"
            ],
            [
                "5-2",
                "5-9",
                "5-10"
            ],
            [
                "5-3",
                "5-4",
                "5-8"
            ],
            [
                "5-5",
                "5-6",
                "5-7"
            ]
        ],
        "eth": [
            "9-0",
            "1-0",
            "8-0",
            "2-0",
            "7-0",
            "3-0",
            "6-0",
            "4-0",
            "9-6",
            "1-6",
            "8-6",
            "2-6",
            "7-6",
            "3-6",
            "6-6",
            "4-6"
        ],
        "functional_workers": [
            "1-1",
            "2-1",
            "3-1",
            "4-1",
            "6-1",
            "7-1",
            "8-1",
            "9-1",
            "1-2",
            "2-2",
            "3-2",
            "4-2",
            "6-2",
            "7-2",
            "8-2",
            "9-2",
            "1-3",
            "2-3",
            "3-3",
            "4-3",
            "6-3",
            "7-3",
            "8-3",
            "9-3",
            "1-4",
            "2-4",
            "3-4",
            "4-4",
            "6-4",
            "7-4",
            "8-4",
            "9-4",
            "1-5",
            "2-5",
            "3-5",
            "4-5",
            "6-5",
            "7-5",
            "8-5",
            "9-5",
            "1-7",
            "2-7",
            "3-7",
            "4-7",
            "6-7",
            "7-7",
            "8-7",
            "9-7",
            "1-8",
            "2-8",
            "3-8",
            "4-8",
            "6-8",
            "7-8",
            "8-8",
            "9-8",
            "1-9",
            "2-9",
            "3-9",
            "4-9",
            "6-9",
            "7-9",
            "8-9",
            "9-9",
            "1-10",
            "2-10",
            "3-10",
            "4-10",
            "6-10",
            "7-10",
            "8-10",
            "9-10",
            "1-11",
            "2-11",
            "3-11",
            "4-11",
            "6-11",
            "7-11",
            "8-11",
            "9-11"
        ],
        "harvested_workers": [],
        "router_only": [
            "0-2",
            "0-4",
            "0-8",
            "0-9"
        ],
        "worker_l1_size": 1499136,
        "dram_bank_size": 2147483648,
        "eth_l1_size": 262144,
        "arch_name": "WORMHOLE_B0",
        "features": {
            "unpacker": {
                "version": 2,
                "inline_srca_trans_without_srca_trans_instr": true
            },
            "math": {
                "dst_size_alignment": 32768
            },
            "packer": {
                "version": 2
            },
            "overlay": {
                "version": 2
            }
        }
    }
}